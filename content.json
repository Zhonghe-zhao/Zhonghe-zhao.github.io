{"meta":{"title":"Zhonghe_Zhao","subtitle":"","description":"时间一直在陪伴你","author":"赵忠赫","url":"https://Whuichenggong.github.io","root":"/"},"pages":[{"title":"","date":"2025-05-11T07:38:23.576Z","updated":"2025-05-11T07:38:23.576Z","comments":true,"path":"Gallery/index.html","permalink":"https://whuichenggong.github.io/Gallery/index.html","excerpt":"","text":"北京 中关村"},{"title":"","date":"2025-05-11T07:38:06.666Z","updated":"2025-05-11T07:38:06.666Z","comments":true,"path":"Gallery/beijing.html","permalink":"https://whuichenggong.github.io/Gallery/beijing.html","excerpt":"","text":"[{\"url\":\"/picture/beijing_photo/beijing1.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing2.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing3.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing4.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing5.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing6.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing7.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing8.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing9.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing10.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing11.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing12.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing13.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing14.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing15.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing16.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing17.jpg\",\"alt\":\"\"},{\"url\":\"/picture/beijing_photo/beijing18.jpg\",\"alt\":\"\"}]"},{"title":"音乐","date":"2024-11-08T09:10:13.236Z","updated":"2024-11-08T09:10:13.236Z","comments":true,"path":"Music/index.html","permalink":"https://whuichenggong.github.io/Music/index.html","excerpt":"","text":""},{"title":"字节姑关于框架学习","date":"2024-12-20T13:07:48.519Z","updated":"2024-11-23T11:42:52.387Z","comments":true,"path":"archives/Dance_Frame.html","permalink":"https://whuichenggong.github.io/archives/Dance_Frame.html","excerpt":"","text":"字节内部课程学习一.走进RPC框架1.基本概念本地函数调用 压栈弹出 RPC调用 网上购物 {（付款操作） 远程调用 中间隔着网路 不能用函数指针了 是两个进程 机器id找到函数运行 解决问题 1. 函数映射 数据转换成字节流 （客户端转换成字节流 传送给 服务端） 网络传输（高效稳定传输数据） } 过程：User本地调用 打包参数 -》 RPC -》 对端-》解压-》调用真正业务逻辑 然后在返回 整个流程 IDL文件（接口描述文件） Caller（调用段）和 生成代码 -》 encoder编码 -》字节流 -》打包传送给对端 好处 2.编解码层： 编解码层： 二进制编码 左侧是IDL中写的统一的 -》字节流 有额外的内存开销 多路复用：同一个链接内 可以有多个请求流通过 协议解析： 4.网络通信层： SCOEKT API （ip+端口） 一端关闭套接字 如果另一端如果尝试去读 可能就会返回（End Of File）也就是 EOF 在项目中我好像遇到过这个问题 用postman测试的时候返回了EOF错误和nil 网络库 二.RPC关键指标分析与企业实践稳定性 易用性 扩展性 观测性 高性能 稳定性： 过程：a调用b b调用c c如果响应慢 b就会一直等待 a也就超时了 a就会频繁调用b b堆积大量请求就会宕机 熔断起保护作用 稳定性：请求成功了率 1.均匀调用服务的每个节点 重试几次 备份请求： 左侧正常 1失败 2是重试请求 总时间 t1＋t2 ​ 右侧 t3 tct99（这个值 在这个时间内应该可以返回值）如果在时间内没返回 就发送2请求 总时间就是 t4 1.注册中间件 2.易用性： 自动生成代码工具 ： 减少重复性工作 3.扩展性 用户请求 经过中间件处理-》和远端交互 -》 也通过中间件处理-》服务器 4.观测性： 日志观察 监控面板qbs 链路跟踪（服务通过请求为什么超时了 耗费的时间是多少） linux的top工具类似原理 5.高性能： 高吞吐：在单位时间内尽可能多的处理更多请求 低延迟： 一次请求发出去延迟尽可能地低（重要） ​ 6. 本章总结： 字节实践： 组件 结构 远端交互层 网络库 代码生成工具 （最左侧） 为什么自研网络库？ gonet Netpoll 交互方式pingpang（一发一回） 编解码 应用层协议 优化： 你应该想这些是怎么实现的？ 三.走进HTTP协议1.再谈http协议HTTP 超文本传输协议 http协议将人话以计算机语言传输过去 123456789请求行：分隔 原数据包的字节数大空行我们想说的话下面是回复 上述功能代码： 处理流程: H1的不足 H2也没完全解决 UDP解决对头阻塞 四.HTTP框架实现1.分层设计的好处 高内聚 低耦合 易复用 高扩展性 应用层 中间件层 预处理 路由层 协议层 中间件设计： 洋葱模型 路由设计： map[string]handlers 静态路由有效 动态不太行 前缀匹配树构建路由： 啊啊啊啊：前两天刚看 7_days_golang 构建动态路由的方法 这里就讲解了 啊啊啊 参数路由： 协议层设计 网络层设计 性能修炼之道针对网络库的优化 netpoll （中大包性能高 时延低） go net（流式友好，小包性能高） 存下全部Header 拷贝身体 针对协议的优化 Headers 解析 找到Header Line边界 &#x2F;r&#x2F;n SIMD Sonic 五.微服务架构：单体架构 -》 垂直应用架构 -》 分布式架构 -》 SOA架构 -》 微服务架构 单体架构： 优势： 性能最高 冗余小 劣势： 1.debug困难 2.模块相互影响 3.模块 垂直应用架构： 优点： 业务独立开发维护 缺点 ： 存在冗余 分布式架构： SOA架构： 服务注册中心： 服务注册 劣势： 整个系统设计是中心化的 ​ 需要从上至下设计 ​ 重构困难 微服务架构： 开发效率高 但是运维难度大 安全性 服务： 相同逻辑 的 运行实体 实例 ： 每一个运行实体为一个实例 逻辑划分称一个（集群） 集群包含实例 有状态 无状态服务： 是否存储了可持续化数据 服务间通信： HTTP RPC 目标服务地址： hardcode 服务A调用服务B（指定一个目标服务地址会有什么问题？） ip地址不会固定 只有一个实例可以接受请求 别的接收不到 ip也是会变化的 如果用DNS域名来访问 DNS缓存机制： 导致延时 负载均衡问题：无法指定请求某个ip回应 不支持探活检查 域名无法配置端口 负载均衡算法 若要 下线某个实例： 流量会不会走到第三个实例上面 服务1 和 服务2 压力变大 可以在开启一个实例 统一网关入口 四层负载均衡租用了一台公网ip 现状 找一个物理机 ifconfig将网卡配上这个ip 起server监听即可 应用多 起多个server监听不同的端口 基于ip＋端口 基于某种算法 将报文转发给后端服务器 常见调度算法RR轮询： 加权RR轮询： 最小连接 五元组hash 一致性hash FULLNAT 纯用户态协议栈 无缓存 零拷贝 大页内存 （减少 cache miss） 7层负载均衡 NGINX： 最灵活的高性能Web 7层反向代理 网络接入实践与课程总结 ： 七层负载均衡 配置https访问"},{"title":"青训营直播总结","date":"2024-12-20T13:07:48.521Z","updated":"2024-11-13T12:15:17.824Z","comments":true,"path":"archives/Dance_live.html","permalink":"https://whuichenggong.github.io/archives/Dance_live.html","excerpt":"","text":"听了前端文杰老哥分享 总结：计算机基础很重要必须要持续学习： 例如：计算机原理，操作系统等，在工作中有些人问题你需要定位到它的问题出在了那里，这个问题的对应着是哪个方面的问题学习ai提示词，提高学习效率，练好基本功，多写代码，多用大模型 前期多学习如何编码而不是太多关于工程化的问题 建议：解决问题:事实是，就业环境中大概率没人把你当学生般保护着，别人没有义务要解决你的问题(不合理，不科学)，请务必提升自己解决问题的能力。 学习:工作中，很难找到手把手教你做事的团队，多数时候都是靠自学，没有课本，没有老师，没有标准答案，全凭自己，所以务必提升独立学习能力; 二极化:世界不是非黑即白，代码也是，职业也是，接受、包容多样性吧，多从不同角度思考问题，从不同渠道了解解决问题的方法，学会更体系化地思考; LLM:非常值得花很多时间学习，用好这个工具，提升你个人效率;但它不是魔法，不要幻想着学会了就能怎么这么样; (目前只停留在问题的复制粘贴 效率很低)"},{"title":"学习数据库","date":"2024-12-20T13:07:48.525Z","updated":"2024-12-20T11:33:22.632Z","comments":true,"path":"archives/Database.html","permalink":"https://whuichenggong.github.io/archives/Database.html","excerpt":"","text":"参考书籍： 数据库设计 我先从事务入手： 事务概念 ： 与单个用户或者程序执行，完成读取或者更新数据库内容的一个或一串操作 应用程序的一次执行就是一个事务或者多个事务 示例： 简单事务： 更新x员工的工资（涉及：数据库的读和写，和非数据库操作） 复杂事务：删除x的员工记录，并把x员工的事务交付给其他人去做。 （过程中若并非所有的操作都被执行，那么数据库的引用完整性将遭到破坏）（数据库也处于不一致状态） 尽管一致性暂时遭到破坏，但是数据库总是可以从一种一致状态转换到另一种一致的状态 数据库最终的结果 COMMIT：执行成功，事务最终被提交 （数据库也达到了一种新的状态） ABORTED：事务没有执行成功 （事务被撤销）则数据库必须要还原事务开始之前的一致状态 已经提交的事务不能被撤销，只能通过（补偿事务）进行覆盖 消除事务产生的影响 DBMS将在程序正确结束后自动执行COMMIT操作，若不能成功执行则 ROBACK PARTIALLY COMITTED：若在最后一条语句被执行时产生了 破坏了可串行化或违反了完整约束 因此事务必须被撤销 或者系统出现故障，事务更新的事务没有被安全的写到二级存储设备上（部分提交） 以上两种情况最终都会进入 FAILED（失败状态） 事务无法被提交，或者事务处于ACTIVE状态就被撤销 则 处于FAILED状态 事务性质ACID 原子性： 一致性： 隔离性： 持久性： 事务的隔离级别事务隔离级别控制了事务之间的可见性和并发行为。常见的隔离级别包括： 读未提交（Read Uncommitted）：在这个隔离级别下，一个事务可以读取其他事务尚未提交的数据。这可能导致脏读（读取了未提交的数据）、不可重复读（同一查询在事务执行期间返回不同结果）和幻读（事务在同一查询中看到不同的数据行）等问题。读未提交的隔离级别最不严格，可能会引发数据不一致问题 读已提交（Read Committed）：在这个隔离级别下，一个事务只能读取已经提交的数据，避免了脏读问题。但是，不可重复读和幻读问题仍然可能出现。因为其他事务可能在事务进行期间提交新的数据，导致不同时间点的查询结果不一致。 可重复读（Repeatable Read）：可重复读隔离级别确保在同一事务内，同一个查询的结果保持一致。这意味着一个事务中的查询不会受到其他事务的修改影响。这可以防止脏读和不可重复读问题，但幻读问题仍然可能出现，因为其他事务可能插入新数据，导致新数据行的出现。 串行化（Serializable）：串行化是最严格的隔离级别，它确保每个事务都在独立的时间段内执行，防止了并发问题。事务按照顺序一个接一个地执行，这可以解决脏读、不可重复读和幻读问题。然而，串行化可能会对性能产生较大的影响，因为事务需要依次执行。 事务的隔离级别可以解决脏读、幻读、不可重复读的问题。 脏读： 脏读指的是在一个事务中读取了另一个事务未提交的数据。假设事务 A 修改了某一行数据，但还没有提交。同时，事务 B 尝试读取了事务 A 修改的数据。如果事务 A 最终回滚了，那么事务 B 读取的数据就是不存在的，这就是脏读。脏读会导致不准确的数据展示，因为读取的数据可能是临时的未经验证的。、 不可重复读：不可重复读是指在同一个事务内，多次读取同一数据时，得到不同的结果。这可能是因为在事务执行期间，其他事务修改了数据。例如，事务 A 在读取某一行数据后，事务 B 修改了这行数据，并提交了。现在事务 A 再次读取相同的数据，注重数据：发现数据已经不同了，造成了不一致的现象。 幻读： 幻读是指在同一个事务内，多次查询同一范围的数据时，得到不同的结果。这与不可重复读类似，但幻读关注的是数据的数量变化。例如，事务 A 在查询某个范围内的所有数据时，事务 B 插入了新数据，并提交了。现在事务 A 再次查询同一范围的数据，注重：发现数据行的数量增加了，这就是幻读。 22.2 并发控制 讲解了数据库中的一些问题 幻读等 [点击这里查看PDF文件] (https://github.com/Whuichenggong/Knowledge-network/blob/main/docs/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BD%91%E7%BB%9C.pdf)"},{"title":"11.26日字节直播总结","date":"2024-12-20T13:07:48.522Z","updated":"2024-11-26T12:25:46.917Z","comments":true,"path":"archives/Dance_live2.html","permalink":"https://whuichenggong.github.io/archives/Dance_live2.html","excerpt":"","text":"字节结营直播答疑revue 项目 性能优化 ci&#x2F;cd流程 （ star法则来描述一件事情) 准备找实习 写好简历 zt： 服务端： 计算机基础知识（字节：计算机网络 tcp&#x2F;ip 腾讯：操作系统 阿里： 组成原理） 技术： （数据结构 高阶算法 链表 堆栈 树（面试重点）） leetcode 100 150 200 项目： 烂大街的（入门） 改进一些项目（做优化 项目存在的意义 解决了什么问题？ 带来了什么？ 项目亮点在哪里） 实习经历：（做了什么需求 需求是（谁给的 自己还是别人？）通过实现了什么？ 解决了什么？ 团队收益还是小组收益？） 专业能力： 小厂一门语言 ＋数据库存储 会就ok 大数据 架构数据 微服务层面 八股扎实稳固 算法 中等难度题很快弄出来 项目亮点：能让面试官和你聊下去 如何提升亮点和竞争力 开源社区！ 抄项目 然后手写 尝试自己理解 前端（vue）（react） 数据结构 计算机基础知识 面试官想看你的亮点（你牛逼在哪里？） 做过什么会什么？ 服务端是一些思维 而不是纠结你是用什么语言 从0-1 有没有调研 各行各业的优秀作业 合作项目 责任意识 技术探索：遇到什么问题 怎么解决的？ 业务理解能力 项目受众是谁 项目模块 最重要是哪个模块 怎么优化这个模块 12“开源社区新手入门该参与什么内容，有哪些社区比较活跃”可以看看类似于开源之夏这类的活动往年都是做什么的 多逛github 12“在github中新手怎么找项目”，你用vue就去看VUE文档仓库，看看有没有错别字，有的话修一下 项目的含金量 和自己从0-1实现 组件多 中间件多 新奇的做法等 可以被称为含金量（） 核心能力 技术深度 在广度的前提下 一定要有一个深度 项目一样 面试官能问什么？ 12老哥们 大二第一次找实习的话一般要什么程度我正在跟着别人做一个项目 但是不知道什么时候才够格去投简历”看看面经别人被问了什么你能不能回答 平地起项目 是有条件的： 大厂实习 项目经历&gt;&#x3D;3 等经历 否则不要平地起 对于项目的理解一定是从头到尾的 对项目改造 新增功能 优化 才能体现你的亮点 思考 ： 多人协作是否有沟通 是否涉及复杂逻辑 新颖的想法！ 创造力！ 投简历的方式 如何面对八股 算法 找开源项目：熟悉流程 寻找错别字熟悉流程哈哈哈 看issue bug（解决issue） 知乎 蔚来 比亚迪 从小厂到大厂 循序渐进 字节 99%go 语言是基础无所谓 培养独立解决问题的能力 做出一个合格的项目 （不断回顾自己的项目 查找不足） 后端开发实习生（简历） 数据库的课（掘金的） 《Redis深度历险：核心原理和应用实践》 服务端开源： 不建议新手就去找开源 学习成本很大 2~3段实习之后尝试开源 知名项目源码： 前提一定要熟悉使用这个项目的源码 项目的使用环境 如何启动它 例如：熟练使用docker ， kubernets istio了，再去看源码 i 写出一个对源码理解的文章 对于源码：一步一步慢慢来 该学的东西就学 不要纠结没用的例如学历 没法改变就不去改变 .md .sh 依赖那些中间件 中间件是否具备？ 如何去不使用中间件如何启动这个项目 分析目录结构（单体 还是微服务）包的作用 模块之间的耦合关系 利用isue 项目常见报错解决方式 组队开发的群聊看看能不能找到"},{"title":"分布式系统学习","date":"2024-12-20T13:07:48.527Z","updated":"2024-12-09T13:14:34.908Z","comments":true,"path":"archives/Distributed.html","permalink":"https://whuichenggong.github.io/archives/Distributed.html","excerpt":"","text":"go build -buildmode=plugin ../mrapps/wc.go这个指令是什么意思 : 这个命令的作用是编译 ..&#x2F;mrapps&#x2F;wc.go 文件，并将其生成一个 Go 插件文件。生成的插件文件通常是一个 .so（共享库文件）文件，它可以在运行时被其他 Go 程序通过 plugin 包加载和调用。 例如： 你可以在主程序中使用 plugin 包动态加载 wc.so 插件，并调用插件中的函数。 go run mrsequential.go wc.so pg*.txt： go run：用于编译并运行 Go 程序。它会在内存中临时编译指定的 Go 文件，并立即执行。 mrsequential.go：这是要执行的 Go 源文件，Go 编译器会先编译这个文件并运行它。这个文件应该包含 main 函数，通常是程序的入口点。 wc.so：这是一个 Go 插件文件（共享库）。它通常是通过 go build -buildmode&#x3D;plugin 命令生成的。该文件包含 Go 代码，可能定义了一个插件接口，在运行时可以被主程序（mrsequential.go）动态加载和调用。wc.so 可能提供某些功能，mrsequential.go 将加载并使用这些功能。 pg*.txt：这是一个通配符表达式，表示所有以 pg 开头，后面跟任意字符，且以 .txt 结尾的文件。例如，pg1.txt, pg42.txt, pgfile.txt 都会被匹配并作为参数传递给程序。 more mr-out-0 将会输出很多文本 这是因为： mrsequential.go 将其输出保留在文件 mr-out-0 中。输入来自名为 pg-xxx.txt 的文本文件"},{"title":"Go语言进阶","date":"2024-12-20T13:07:48.534Z","updated":"2024-11-27T12:09:15.291Z","comments":true,"path":"archives/Go_Advanced.html","permalink":"https://whuichenggong.github.io/archives/Go_Advanced.html","excerpt":"","text":"字节青训营学习一.入门篇学习实战篇： 1.猜数字游戏运用 1234567891011121314151617181920212223242526”math/rand“maxNum := 100调用 Intn（maxNum）//注意这并不能使每一次都用都产生不同的值需要加 时间戳 才能每次产生不同的值应该是：maxNum := 100ran.Seed(time.Now().UnixNano())然后调用 ran.Intn（maxNum） 用 &quot;bufio&quot; 这个特别的包以后可以用到 这里读取一行输入用的是 reader := bufo.NewReader(os.Stdin)//调用这个可以更加灵活 input， err := reader.ReadString(&#x27;\\n&#x27;) if err != nil&#123;...&#125; input = strings.TrimSuffix(intput,&quot;\\n&quot;)//去掉换行符 guess,err := strconv.Atoi(input)//转换成数字 菜值逻辑 2.在线词典介绍12345678910go run simpledict/v4/main.go hello//意思是查询hello这个功能//会输出以下内容hello UK:[&#x27;he&#x27;lau]US:[ha&#x27;lo]int.喂；哈罗n.引人注意的呼声V.向人呼（喂调用第三方api 生成请求 https://curlconverter.com/ 写入curl 自动生成代码 示例： 会输出一些列bilibili的东西 json序列化 衍生出以下 1结构体 1234request ：= DicRequest&#123;Trans Type：&quot;en2zh&quot;,Source:&quot;good&quot;&#125;buf, err := json.Marshal(request)//序列化request 变成byte数组if~~~var data = bytes.NewReader(buf) //因为buf返回的是bytes数组所以我们应该 bytes.NewReader 解析response 进行反序列化 json转golang 结构体 https://oktools.net/json2go 反序列化 12345err = json.Unmarshal(bodytext,&amp;dictResponse)//传入结构体fmt.Println(&quot;%#v&quot;,dicResponse) Go进阶1.并发编程并发：多线程在一个核运行 时间碎片 并行： 多核 并行是并发的手段 2.协程 协程：轻量级线程 线程本身重量级 Goroutine：可以实现上万个携程 例子:协程 go关键字开启协程 通过通信来共享内存 channel make创建channel 有缓冲： 无缓冲：进行通信时（两个goroutine同步）也称同步通道 示例： 先make创建通道 把数字放入第一个通道里 然后b把src做平方运算 并发安全 Lock Lock（）临界区 3.依赖管理1.GOPATH bin pkg src（项目源码） 无法实现package 的多版本控制 2.vendor存放依赖副本 也有弊端 3.go module 管理 解决了问题 indirect关键词 b（选择最低兼容版本） 4.依赖分发Github SVN … ​ Developer 无法保证构建稳定性 无法保证依赖可用性 增加第三方压力 Go proxy （）缓存内容版本 从proxy拉取依赖 减少第三方压力 Proxy1 -》 proxy2 -》 Direct 依次进行 5.工具 go getgo mod init tidy download 6.测试事故： 测试的重要性：避免事故的最后一道屏障 单元测试 mock测试 回归测试 集成测试 1.单元测试 保证代码整体覆盖率 提升效率 2. 规则 3例子： go test 【flags】 【packages】 4.assert 5.覆盖率 提升覆盖率 对各个分支测试 使函数代码都经过完备的测试 提升覆盖率 减少事故 6.依赖 7.文件处理 一旦文件被别人篡改 在特定场景下就无法运行！ 8.Mock replacement 打桩函数 通过mock 不对 文件有强依&#x2F;study_photo&#x2F;70.png 优化： fastrand 10.项目实践 话题id -》 获取所有post 初始化话题内存索引 逻辑层： 并行处理 三.高质量编程与实践如何编写更简洁和跟清晰的代码 熟悉GO程序性能分析工具 常用Go语言程序优化手段 了解工程性能优化的原则和流程 :性能调优 性能分析工具 性能调优案例 算法效率 1.高质量编程正确可靠 简洁清晰 各种边界条件是否考虑完备 异常情况处理 稳定性保证 易读易维护 团队合作保证容易读 维护 使其增加和调整更加快速 更加清晰 主要是给人看 让人可以看懂 对已有的功能改善 优化 容易添加功能 2.编码规范代码格式 注释 命名规范 控制流程 错误和异常处理 不需要注释实现接口的方法 这种注释可以删除 1.gofmt推荐使用gofmt 自动格式化代码为官方统一风格 2.注释注释应该解释代码的作用 注释应该解释代码如何做的 注释应该解释代码实现的原因 注释应该解释代码什么情况会错 下面的根本不需要注释没有什么必要 函数名字已经说明了 最后一条语句是很难理解的 如果没有注释 一定要会看英文呵呵 此时的t就减少了很多东西 例如http中调用 Server 是 http.Server 若用 ServerHTTP http.ServerHTTP这样感觉就变得冗余了没有必要 避免if else嵌套 包含同样语句可以去掉 重复语句 这样看起来比较复杂 调整后： 控制流程 ： 线性原理 尽量走直线 避免复杂的嵌套分支 3.错误和异常处理 性能调优原则：1.依靠数据而不是猜测2.定位到最大瓶颈（也就是影响最大的部分），3.不要过早优化4.不要过度优化 性能调优工具：pprofpprof：可视化和性能分析数据的工具 pprof实战项目：下载项目 并且运行： GIthub：https://github.com/wolfogre/go-pprof-practice go run main.go 等待编译 等待一段时间 输入：http://localhost:6060/debug/pprof/ 在浏览器中 此时的cpu 内存状态： 以下输出： 思考： 什么情况下 Flat &#x3D;&#x3D; Cum Flat&#x3D;&#x3D;0 分别为1. 函数中没有调用其他函数 都是本函数使用的时间2. 函数中只有其他函数调用并且时间占用也很少可以忽略不计 在查看到tiger中有一部分占用了很大的时间 把相关的代码注释后 内存方面并没有解决什么 Heap：堆内存分析： 在终端使用这个指令go tool pprof -http=:8080 &quot;http://localhost:6060/debug/pprof/heap&quot;…没有下载工具先放一下 先截屏 锁：go tool pprof -http=:8080 &quot;http://localhost:6060/debug/pprof/mutex&quot; 性能优化GO语言优化内存管理优化 编译器优化 什么是性能优化 ，为什么要做性能优化？ ：提升软件系统处理能力，减少不必要的消耗 ：用户体验，让用户刷抖音不卡顿 ：资源高效利用，成低成本，提高效率 业务代码：处理用户请i去 SDK：go的SDK 基础库： 这两部分提供抽象逻辑（数据结构 网络库 io库） 语言运行时： gc 调度器（go语言） OS 性能分析工具：pprof 依靠数据而非猜测 优化最大瓶颈 Go的SDK 接口 命令 APIs 测试 来 驱动开发 隔离： 通过选择控制是否开启优化 可观测： 静态分析： 自动内存管理基于追踪的垃圾回收 GC 动态内存 malloc 自动内存回收： 避免手动内存管理 专注于实现业务逻辑 保证内存使用的正确性和安全性 为新对象分配空间 偷懒了：实在不知道怎么记了 留着以后学的更深入一些再看吧 四.数据库数据库database&#x2F;sql GORM ： 业务需求驱动开发 基本用法 规定 数据库约束 Select实现级联删除 数据结构与算法1.经典排序算法为什么要用数据结构和算法： 最快的排序算法：Go ： introsort 1.19的默认排序算法：如何设计的 生产环境和课本上的排序算法有什么区别 1.插入排序：（洗牌） 时间复杂度：最好O（n）有序 平均O（n^2） 最坏 （n^2） 缺点：太慢 优点：最好 2。快速排序： 时间复杂度；最好 O（nlogn） 平均O（nlogn）最坏O（n^2） 缺点 最坏太慢 优点 平均的挺好 3.堆排序 网络与部署《负载均衡 高并发网关原理与实践》 协议基础 协议分析（自学） 熟悉tcp&#x2F;ip 熟悉计算机网络 抖音视频 加载出来 会有什么交互（网络是如何交互的）（为什么刷抖音又快又稳）（计算机网络要解决什么问题 发现什么问题） 应用层： 域名解析（DNS） 图片下载 视频下载（HTTP）评论API&#x2F;HTTP 网络接入 网络传输 手机要先访问抖音服务器 终端（pc pad） 通过 4g &#x2F;wifi 通过有线网络 接入 四大运营商网络 -》 接通抖音的机房（服务器） 还用通过光缆（海底） 接通 美国网络 网络接入 （路由）交换机&#x2F;逻辑交换机&#x2F;网络虚拟化 路由一定对称吗？ 路由是工作在哪一层协议？ 路由协议（ip层） 本身不是ip层 动态路由协议（传输层协议bgp）（基于tcp udp）可能 不是很简单 路由改的是ip地址吗？ 不是改ip地址 而是mac地址 路由是为了找到目标ip 怎么找下一跳（网络中间节点）的MAC 通过 ARP协议 跨网段 不能发送ARP 同网段可以发送ARP 否则需要一级一级的发送 免费ARP：（）新加入机器（向其中发送免费ARP ： 防止ip冲突 在同一局域网里有两个同一个ip ） ARP：本质是查找下一跳MAC 而不是目标请求地址 ARP 代理： 中间设备抢先应答 （） IP协议 唯一标识 为什么Mac（2层）（以太网） 地址不能代替ip协议 ： IP协议把MAC地址问题 解决了 ipv4不够用 怎么解决：如果不支持ipv6 ， 用NAT（原理 内部用户 通过NAT） 问题2 ： （NAT ip＋端口）一起改变 解决第二个问题 网络打通视频怎么下载 也就是服务的封装与拆解 如何把域名映射到ip （DNS基于UDP协议（端口＋校验）） 避免分片 丢包丢了UDP也不知道 TCP连接 三次握手TCP连接状态 如果拔了网线，连接会断吗（没有什么关系） keep-alive ：保活机制（不会一定断开在一定场景下） TCP传输 很复杂的协议 Timewait？（） 状态复杂 TCP丢包 滑动窗口 流量控制 网络传输 HTTP&#x2F;HTTP1.1 HTTPS 解密 出来仍然是HTTP 防止中间者偷听一些东西 加密之后中间人听不懂 SSL&#x2F;TLS握手 非对称加密 对称加密 网络架构网络提速 HTTP 2.0 （多路复用） 并行下载 并行访问 一次性加载了多个图片 （并行请求 一次性发送了） 多路复用： TCP （丢包 其他包等待（对头阻塞）） 协议优化： TCP本身协议不可插拔 UDP（基于UDP扩展） kernel （windows mac 安卓 ios ）是否都要去实现呢？ Google实现在了用户态（方便） RTT QUIC（实现了UDP的扩展）(弱网优势) （解决了队头堵塞）（优化了HTTp2.0的多路复用） 路径优化 服务器集合（数据中心） POP接入（核心机房） 边缘机房（靠近用户（上海电信 上海移动……）） 同运营商访问 （访问客户端ip 电信 解析到 电信） 电信 访问 电信 移动 访问 移动 若要使两者跨网访问（丢包率较高） 路径优化（CDN） 网络提速-静态资源 （边缘机房（缓存）直接从缓存中取出资源 如果找不到 -》 核心机房） 动态API （播放 &#x2F; 评论接口）（因为信息不一样） DSA（路径优化算法） 直连最快 机房延迟探测 （做成表（通过算法 找到最优路径）） 网络提速的优化之路几天就挂了怎么办？？ 抖音稳定性如何调高？ 专线： 内部字节机房-》没有走外部internet（如果走internet 如果从北京 访问 上海 可能会造成中间去到江苏再回到上海这样会很慢 并且丢包等）-》自己拉线连接两个机房（通过交换机等）（这样速度更快） b -》 c 外网：机房内部专线以外的网络通过internet连接 （如果专线挂了）需要走外网容灾 微服务可能跨机房 全局容灾系统 ： A机房不可用了 （自动容灾） 探测机房b的容量可以承载 a机房的容量 自动降级&#x2F;容灾 云到端 SDK告诉端，不要访问，崩了的A机房 云控 什么场景云控控制不到（Web服务器 字节搜索&#x2F;百度搜索 ） 故障明确 沟通： 明确是什么业务 什么接口故障 故障体现在哪？ 其他目标是否访问正常（业务A有故障 接口A有问题 其他的是否有问题？） 是否是修改导致的异常？（如果是就回退） 如果你上传导致的错误（找是谁 ） 先止损 再 排查（debug） 如何止损 分段排查 常用指令 最后一个是抓包工具 误判断 摘除了 好的服务器 线上debug（p0级别事故） 抓包： 快速发包（路由对称）实际路由并不是对称的（找下一跳） 故障预防真的很重要 课后作业 企业级输入网页到内容加载出来 中间都经历了什么 （TCP握手 SSL 域名解析） 浏览器抓包 看第一条请求了什么 网络卡 还是服务器满 还是什么？ 企业接入： 域名系统 自建DNS服务器 HTTPS 接入全站加速 四层负载均衡 七层负载均衡 example公司 Host -》 ip映射 问题： 流量和负载 名称冲突 时效性（） 使用域名系统使用域名系统 替换hosts 域名购买 购买二级域名 example.com 域名备案防止从事非法运动 建设外部网站： 自建DNS： 取代云厂商 先访问 本地DNS服务器 -》 根 -》 顶级 -》权威-》本地缓存 DNS查询过程 权威DNS系统架构 接入HTTPS协议HTTP明文传输 被抓去后 信息很容易被暴露出来 加密算法： 对称加密： 一份密钥 非对称加密 ： 公钥和私钥 （公钥加密私钥解密 或者 对调）（锁头和钥匙） SSL 通信过程： 证书链： 公钥是不是可信的 会不会被劫持？ 数字签名 外网访问站点一定是一帆风顺的吗： 1.源站（网站） 容量第 可承载的并发请求数低 容易打跨 2.报文经过的网络设备越多 出问题概率越大 丢包 劫持 3.自主选择网络链路长 时延高 整体看来：就是响应慢 卡顿 优化： 增加后端机器扩容 静态内容 全站加速： 静态加速：CDN cpu访问 （缓存） 动态加速： DCDN原理 ： RTT： 用户到核心 用户到边缘 边缘到汇聚 汇聚到核心 全站加速 消息队列 kafka用户行为： 搜索 点赞 评论 收藏 使用场景： 搜索服务， 直播服务 订单服务 支付服务 如何使用Kafka： 创建集群 新增topic 编写生产者逻辑 编写消费之逻辑 Kafka架构： Zookeeper Producer 批量发送 数据压缩 Broker 数据存储 消息文件结构 磁盘结构 ​ 操作系统： 顺序写： 提高写入效率 Broker 偏移量索引文件 二分查找 Broker 时间戳索引文件 传统数据拷贝： 操作系统层面： 数据的内存拷贝（开销很大） Broker零拷贝 Consumer-消息接收端 通过手动分配 哪一个Consumer消费哪一个Partition 完全由业务决定 缺点 不能自动容灾 优点： 快 自动分配 High-level 存储与数据库数据的持久化 1.校验数据的合法行 （名字是否存在） （修改内存 用高效的数据结构组织数据）（写入存储介质 以寿命 性能友好写入硬件）（） 什么是存储系统？ 一个提供了 读写 控制类接口 能够安全有效的 把 数据持久化的软件 称为 存储系统 user Medium Memory Network(把原有的单机 升级到分布式系统) 还可能与这些有关 特点： 性能敏感 容易受硬件影响 代码既简单又复杂（考虑到多种异常情况） 存储器层级结构： Persistent Memory 数据怎么从应用到存储介质 数据拷贝 消耗cpu 如果cpu全部用来拷贝 软件性能就会降低（减少拷贝的使用） Disk（） RAID技术： 单机存储怎么做到 高性能&#x2F;高性价比&#x2F;高可靠性 背景： 大容量磁盘价格》 多块小容量磁盘 单块磁盘的写入性能 《 多块磁盘的并发写入性能 RAID0 多块磁盘的简单组合 数据条带化存储 调高磁盘带宽 没有额外的容错设计 RAID1 一块磁盘对应一块额外镜像盘 真是空间利用率50% 容错能力强 上面是两个极端 RAID 0 + 1 RAID 0 和 RAID 1 数据库和存储系统不一样吗？关系型数据库（是存储系统） 非关系型数据库 关系是什么： 关系模型（EFCodd）&#x3D; 集合 反映了事务间的关系 关系代数 &#x3D; 运算的抽象查询语句 SQL &#x3D; 一种DSL （方便人类阅读的 关系代数表达式） 关系型数据库：结构化数据友好 支持事务（ACID）支持复杂的查询语言（sql 全集 子集） 非关系型数据库（也是存储系统）： 半结构化数据友好 可能支持事务（ACID） 可能支持复杂查询语言 数据库 vs 经典存储 - 结构化数据管理 事务能力：要么全做 要么全不做 数据状态是一致的 可以隔离多个并发事务 避免影响 事务一旦提交成功 数据保持持久性 复杂查询能力：复杂查询： 请查询出以xiao开头 密码提示问题小于10个字的人 并按照性别分组统计人数 左边灵活简介 右边复杂 支流产品剖析单机存储系统单个计算机节点上的存储软件系统 一般不涉及网络交互 key-value存储 本地文件系统 本地文件系统 一切皆文件： 文件系统管理单元： 文件 文件系统接口： 文件系统繁多 Ext2 遵循VFS统一抽象接口 linux 文件系统的两大数据结构 ：Index Node Directory Entry innode 记录文件元数据 如id 大小 权限 磁盘位置 innode 是一个文件的唯一标识 会被存储到磁盘上 innode总数在格式化文件系统时就固定了 ​ 1：1 1.Directory Entry 记录文件名 innode指针 层级关系 dentry时内存结构 与innode 关系时N：1 key-value存储 put(k,v) get(k) LSM-Tree 某种程度上牺牲读性能 追求写入性能（） 拳头产品： RocksDB 分布式存储： 在单机存储基础上实现了分布式协议，实际大量网络交互 分布式文件系统 分布式对象存储系统 HDFS ： 核心： 支持海量数据存储（使用普通硬件堆叠） 高容错性 弱POSIX语义 使用普通x86服务器-极高性价比高 DataNode Ceph- （分布式存储）开源分布式存储系统里的【万金油】 里面的算法很好 一切皆对象； 数据写入采用主备复制模型 数据分布模型采用CRUSH算法 单机数据库 单个计算机节点上的数据库系统 事务在单机内执行 通过网络交互实现分布式事务 关系数据库 商业产品Oracle 开源产品 MySQL PostgreSQL Page Redo Log 临时文件 内存 与 磁盘之间的交互 非关系型数据库 没有准则 交互方式各不相同 schema相对灵活 SQL查询语言的统治地位很重视 模糊搜索 Query： match 编程语言 好 难度 模糊匹配到小明的帖子 ES天然能够做 模糊搜索 还能自动算出关联程度 传统关系型无法做到这一点 分布式数据库（引入分布式架构）： 容量 弹性 性价比 解决单机时代遇到的问题 解决容量问题： 存储池 动态扩缩容 弹性问题： 随着业务的变化而变化 1t如何搬到200g？ 池化！ 性价比问题 硬件disk不需要怎么准备 什么不够用Storge Pool 分布式存储池来解决这个问题 磁盘池化 内存池化（降低成本） 单写vs多写 从磁盘弹性到内存弹性 分布式事务优化 新技术演进软件架构变更（依赖于操作系统内核） AI增强（智能存储格式转换） 新硬件革命（存储介质变更 计算单元变更 网络硬件变更） cpu中断 使性能降低 与之替换的是用轮询替换 数据存储格式的转换 左边是二维表由 多个行与列 行存 列存 （优势 劣势） ai决策-》行列混存（动态性强） 硬件反推软件变革 课后作业 材料引用 深入理解RDBMS（关系型数据库）存储系统: 块存储 文件存储 对象存储 key-value存储 数据库系统： 大型关系数据库 非关系型数据库 抖音红包雨 从抖音账号扣除1个亿 事务ACID 红包雨与ACID 事务要同时成功与同时失败 账户的钱不能为复数 操作一定要是合法的 隔离性问题 ： 两个操作同时进行 有相互影响的关系 刚开始抢了一个亿（成功） 但是服务器挂了 高并发 10亿人 同时抢红包 一定 数据要有处理高并发的能力 每秒处理事务的请求 高可靠 在关键时间和结点上 保证后台服务可靠 从 纸 到 磁盘文件 第一个数据库 网状数据库（W.Bachman） ​ Collage English computer Maths 多对多 没有交叉 结点 网络结构 父节点可以有多个子节点 层次模型（IBM） 用树形结构描述实体 与 网状结构相似 但是并不交叉树状 每个子节点只有一个父节点 （1对多） 关系模型（IBM）（EFCodd博士） 关键技术一条SQL的一生 ： 解析SQL（语法解析器） 语法树AST 优化器 Plan Executor（执行器） 写入数据 写入日志 分析 为什么还要优化器？（Optimizer） 类比于 （高德地图路线优化） 快 慢 红绿灯 基于规则的优化 条件简化…… Scan优化 基于代价优化： 时间是代价 最少时间到目的地 io cpu NET MEM也是代价 火山模型： 向量化： 每次返回是一批数据 而不是一行数据 优点： 函数调用次数降低为1&#x2F;N CPU cache命中率更高 可以利用CPU提供SIMD机制 一次加法（可以操作多个数据） 编译执行： 存储引擎-InnoDB内存态（做一点内存缓存） 存储引擎-Buffer Pool instance0 instance1 HashMap管理 LRU 算法 保留最近最常使用的保存在内存 其他的 淘汰 内存放不下？ 放磁盘 从磁盘访问数据 存储引擎-Page B+Tree索引 B树的扩展（二分查找树） 事务引擎：原子性 与 Undo Log 同步失败或成功 如何将数据库回退到修改之前的状态？ Undo日志： 逻辑日志 进行事务回滚 保证原子性 isolation 与 锁 如果两个操作同时发生 发生冲突怎么办 锁机制 Share Lock 共享锁 读读 两个人都有共享锁 Exclusice Lock 写锁 读写 一个有写锁另一个不能有 读写 -》 MVCC数据的多版本 一致性： 对数据的修改 永久保存 方案一 事务提交前页面写盘 随机io 写放大 方案二 WAL"},{"title":"Go语法学习","date":"2024-12-20T13:07:48.536Z","updated":"2024-12-16T02:39:31.613Z","comments":true,"path":"archives/Go_Program.html","permalink":"https://whuichenggong.github.io/archives/Go_Program.html","excerpt":"","text":"12345678910111213whatAmI := func(i interface&#123;&#125;) &#123; switch t := i.(type) &#123; case bool: fmt.Println(&quot;I&#x27;m a bool&quot;) case int: fmt.Println(&quot;I&#x27;m an int&quot;) default: fmt.Printf(&quot;Don&#x27;t know type %T\\n&quot;, t) &#125;&#125;whatAmI(true)whatAmI(1)whatAmI(&quot;hey&quot;) 这是一个函数whatAmI，它接受一个interface{}类型的参数。interface{}是 Go 语言中的一种空接口，可以存储任何类型的值。这个switch语句实际上是一个类型switch，它检查接口变量i的具体类型，而不是它的值。根据i的类型，switch将执行不同的case分支。 1234// If you specify the index with `:`, the elements in // between will be zeroed. b = [...]int&#123;100, 3: 400, 500&#125; fmt.Println(&quot;idx:&quot;, b) 3: 400 指定了下标为 3 的位置的值是 400。这意味着索引 1 和 2 的值将被初始化为 0（因为:操作符指定了一个新的下标，并初始化之前未指定的下标对应的元素为 0）。 12var s []string fmt.Println(&quot;uninit:&quot;, s, s == nil, len(s) == 0) uninit: [] true true 12345678910twoD := make([][]int, 3) for i := 0; i &lt; 3; i++ &#123; innerLen := i + 1 twoD[i] = make([]int, innerLen) for j := 0; j &lt; innerLen; j++ &#123; twoD[i][j] = i + j &#125; &#125; fmt.Println(&quot;2d: &quot;, twoD)&#125; 2d: [[0] [1 2] [2 3 4]] 12.3日 map操作： 123456789101112 m[&quot;k1&quot;] = 7m[&quot;k2&quot;] = 13fmt.Println(&quot;map:&quot;, m)fmt.Println(&quot;len:&quot;, len(m))//clear(m)val, prs := m[&quot;k2&quot;] //k2的值， 一个是判断k2是否存在于m中的bool值fmt.Println(&quot;val：&quot;, val, &quot;prs:&quot;, prs)n := map[string]int&#123;&quot;foo&quot;: 1, &quot;bar&quot;: 2&#125;fmt.Println(&quot;&quot;, n)if maps.Equal(n, n2) &#123; fmt.Println(&quot;n == n2&quot;)&#125; 使用变长参数函数（variadic function），即可以接收任意数量参数的函数。这里的 … 标记表示 nums 参数是可变长的，可以接收零个或多个 int 类型的参数 nums 被当作切片使用，可以进行切片相关的操作，例如使用 len(nums) 获取长度，或者用 range 遍历切片元素。 12345678910111213141516171819202122232425262728func sum(nums ...int) &#123; fmt.Print(nums, &quot; &quot;) total := 0 // Within the function, the type of `nums` is // equivalent to `[]int`. We can call `len(nums)`, // iterate over it with `range`, etc. for _, num := range nums &#123; total += num &#125; fmt.Println(total)&#125;func main() &#123; // Variadic functions can be called in the usual way // with individual arguments. sum(1) sum(1, 2) sum(1, 2, 3) // If you already have multiple args in a slice, // apply them to a variadic function using // `func(slice...)` like this. //第二种调用nums的方法使用 nums 切片，通过 sum(nums...) 的方式将切片中的每个元素作为单独的参数传递给 sum 函数。 nums := []int&#123;1, 2, 3, 4&#125; sum(nums...)&#125; 错误示范 123456789101112func allArticles(w http.ResponseWriter, r *http.Request) &#123; articles := Articles&#123; Title: &quot;Test Title&quot;, Desc: &quot;Test Descrption&quot;, Content: &quot;hello world&quot;, &#125;,fmt.Println(&quot;endpoint hit: allArticles&quot;) json.NewEncoder(w).Encode(articles)&#125; 这里的问题是 Articles 类型实际上是一个切片（[]Article），而你试图将一个单独的 Article 结构体实例赋值给 articles 变量。根据 Go 语言的语法，Articles 类型需要的是一个 Article 类型的切片。 要解决这个问题，你需要将 Article 实例放入一个切片中。可以将你的代码修改为： 123456789101112articles := Articles&#123;&#123;Title: &quot;Test Title&quot;,Desc: &quot;Test Descrption&quot;,Content: &quot;hello world&quot;,&#125;,&#125;CopyInsert这里的修改是把 Article 结构体实例用 &#123;&#125; 包围起来，表示这是一个切片中的一个元素。最终的 allArticles 函数应如下所示： 第二种方法： 123456789// 创建Article的实例 newArticle := Article&#123; Title: &quot;Test Title&quot;, Desc: &quot;Test Description&quot;, Content: &quot;hello world&quot;, &#125; // 创建Articles切片并添加上面的实例 articles := Articles&#123;newArticle&#125; go fmt 包的导入者将使用名称来引用其内容，因此包中的导出名称可以使用该事实来避免重复。 （不要使用 import . 表示法，它可以简化必须在正在测试的包外部运行的测试，但应该避免。）例如，bufio 包中的缓冲读取器类型称为 Reader，而不是 BufReader，因为用户将其视为 bufio.Reader，这是一个清晰、简洁的名称。此外，由于导入的实体始终使用其包名称进行寻址，因此 bufio.Reader 不会与 io.Reader 冲突。类似地，创建ring.Ring新实例的函数（Go中构造函数的定义）通常被称为NewRing，但由于Ring是包导出的唯一类型，并且由于包被称为ring，所以它是称为“New”，包的客户端将其视为“ring.New”。使用包结构来帮助您选择好的名称。 另一个简短的例子是once.Do; Once.Do(setup) 读起来很好，并且不会通过编写 Once.DoOrWaitUntilDone(setup) 来改进。长名称不会自动使内容更具可读性。有用的文档注释通常比超长的名称更有价值。 闭包1234567func intSeq() func() int &#123; i := 0 // i 是一个局部变量，用于 intSeq 函数。 return func() int &#123; // 返回一个匿名函数，这个函数可以访问 intSeq 函数的局部变量 i。 i++ // 每次调用这个匿名函数时，i 的值都会增加。 return i // 返回增加后的 i 的值。 &#125;&#125; 返回结果 ：1231 这是因为闭包允许匿名函数捕获并记住 i 变量的状态。这就是闭包的 “魔力” 所在，即使外部函数已经返回，内部函数仍然能够访问和修改外部函数的变量。 stack :&#x3D; []rune{} 与 make :&#x3D; []string{} 的区别：stack :&#x3D; []rune{}：这段代码创建了一个 rune 类型的切片（空切片）。rune 是 Go 中专门用来表示单个字符的类型，适用于你处理字符（尤其是 Unicode 字符）时，能够确保每个元素是一个完整的 Unicode 字符。 make :&#x3D; []string{}：这段代码创建了一个 string 类型的切片。每个元素是一个字符串，字符串通常用于表示一系列字符构成的文本数据。 在 Go 程序中，通过 os.Args 可以访问命令行参数，而 go run main.go file1.txt file2.txt 的执行过程如下： 为什么·go语言 &gt; go run main.go file1.txt file2.txt 在这里执行之后可以读取到文件1 2 1. 命令行参数的解析 命令： go run main.go file1.txt file2.txt go run 会编译并执行 main.go。 命令行中，main.go 后面的 file1.txt 和 file2.txt 被传递给程序作为命令行参数。 在程序中，os.Args 是一个字符串切片（[]string），包含了命令行中的参数： 123os.Args[0] // 包含程序的名字，如 &quot;main.go&quot;os.Args[1] // 第一个参数 &quot;file1.txt&quot;os.Args[2] // 第二个参数 &quot;file2.txt&quot; 例子：假如命令为： 1go run main.go file1.txt file2.txt 则： 1fmt.Println(os.Args) 输出： 1[main file1.txt file2.txt] 2. 打开文件进行读取你的代码解析命令行参数后，会尝试打开这些文件： 1files := os.Args[1:] // 获取命令行参数列表（除程序本身外的部分） files 现在是一个切片：[&quot;file1.txt&quot;, &quot;file2.txt&quot;]。 然后通过循环处理每个文件： 123456789for _, arg := range files &#123; f, err := os.Open(arg) // 打开文件 if err != nil &#123; fmt.Fprintf(os.Stderr, &quot;dup2: %v\\n&quot;, err) // 错误处理 continue &#125; defer f.Close() // 确保文件被正确关闭 countLines(f, counts)&#125; 这段代码中： **os.Open(arg)**： 打开文件（如 file1.txt），返回一个文件指针 *os.File。 如果文件打开失败（文件不存在或权限问题），返回错误并跳过。 **countLines(f, counts)**： 将文件指针传递给 countLines，扫描文件的内容并统计每行的出现次数。 3. 执行结果的输出统计完成后，程序会输出所有出现次数大于 1 的行： 12345for line, n := range counts &#123; if n &gt; 1 &#123; fmt.Printf(&quot;%d\\t%s\\n&quot;, n, line) &#125;&#125; 这会将文件中所有重复的行及其出现次数打印到控制台。 4. 为什么能够读取多个文件这是因为你的代码通过 for _, arg := files 遍历了 os.Args[1:] 中的所有文件，并依次处理它们。程序对每个文件重复以下流程： 打开文件。 按行扫描内容，统计出现次数。 将结果合并到 counts 映射中。 这样，即使你提供多个文件，程序依然可以逐个读取并处理它们。 运行流程示例假设有以下文件内容： file1.txt:123helloworldhello file2.txt:123worldhellogo 执行命令： 1go run main.go file1.txt file2.txt 程序会： 读取 file1.txt： 统计结果：&#123;&quot;hello&quot;: 2, &quot;world&quot;: 1&#125;。 读取 file2.txt，继续更新 counts： 最终统计结果：&#123;&quot;hello&quot;: 3, &quot;world&quot;: 2, &quot;go&quot;: 1&#125;。 打印重复行：123 hello2 world 总结你可以读取多个文件是因为程序通过 os.Args 获取了命令行中的文件名列表，并通过循环逐个打开和读取文件的内容。这种设计使得你的程序能够动态处理任意数量的文件，而无需修改代码。 12.14 日 更考完4级一.Errors “errors” 包 使用给定的错误消息构造一个基本错误值。 errors.New(“can’t work with 42”) nil 表示没有错误 哨兵错误是一个预先声明的变量，用于表示特定的错误情况。 var ErrOutOfTea &#x3D; fmt.Errorf(“no more tea available”)var ErrPower &#x3D; fmt.Errorf(“can’t boil water”) 更高级别的错误来包装错误以添加上下文 最简单的方法是使用 fmt.Errorf 中的 %w 动词。包装错误创建一个逻辑链（A 包装 B，B 包装 C 等），可以使用 error.Is 和 error.As 等函数进行查询。 return fmt.Errorf(“making tea: %w”, ErrPower) if 行中使用内联错误检查 if r, e :&#x3D; f(i); e !&#x3D; nil {fmt.Println(“f failed:”, e)} else {fmt.Println(“f worked:”, r)} error.Is 检查给定错误（或其链中的任何错误）是否与特定错误值匹配。 if errors.Is(err, ErrOutOfTea) {fmt.Println(“We should buy new tea!”)} else if errors.Is(err, ErrPower) {fmt.Println(“Now it is dark.”)} else {fmt.Printf(“unknown error: %s\\n”, err)} 将err和我们自定义的哨兵错误或者特定错误做对比 二.自定义错误 12345678910type argError struct &#123; arg int message string&#125;func (e *argError) Error() string &#123; return fmt.Sprintf(&quot;%d - %s&quot;, e.arg, e.message)&#125; Error 方法并没有直接调用，但 &amp;argError{arg, “can’t work with it”} 被返回为 error 类型时，Error 方法已经在幕后实现了对错误消息的封装。 error.As 是errors.Is 的更高级版本。它检查给定错误（或其链中的任何错误）是否与特定错误类型匹配，并转换为该类型的值，返回 true。如果没有匹配，则返回 false。 Goroutines轻量级的执行线程 go f(s)。这个新的 goroutine 将与调用的 goroutine 同时执行。 12345678func f(from string) &#123; for i := 0; i &lt; 3; i++ &#123; fmt.Println(from, &quot;:&quot;, i) &#125;&#125; go f(&quot;goroutine&quot;) 启动一个 goroutine 来进行匿名函数调用。 123go func(msg string) &#123; fmt.Println(msg) &#125;(&quot;going&quot;) goroutine 是由 Go 运行时同时运行的。 通道通道是连接并发 goroutine 的管道。您可以将值从一个 Goroutine 发送到通道，并将这些值接收到另一个 Goroutine。 messages :&#x3D; make(chan string) 通道 &lt;- 语法将值发送到通道 go func() { messages &lt;- “ping” }() msg :&#x3D; &lt;-messages &lt;-channel 语法从通道接收值。在这里，我们将收到上面发送的“ping”消息并将其打印出来。 发送和接收会阻塞，直到发送者和接收者都准备好为止。此属性允许我们在程序结束时等待“ping”消息，而无需使用任何其他同步。 通道缓冲： messages :&#x3D; make(chan string, 2) 字符串通道，最多缓冲 2 个值 因此我们可以将这些值发送到通道中，而无需相应的并发接收。 12345678 messages := make(chan string, 2)messages &lt;- &quot;buffered&quot;messages &lt;- &quot;channel&quot; fmt.Println(&lt;-messages) fmt.Println(&lt;-messages) 断言和switch用法:1234567891011121314var t interface&#123;&#125;t = functionOfSomeType()switch t := t.(type) &#123;default: fmt.Printf(&quot;unexpected type %T\\n&quot;, t) // %T prints whatever type t hascase bool: fmt.Printf(&quot;boolean %t\\n&quot;, t) // t has type boolcase int: fmt.Printf(&quot;integer %d\\n&quot;, t) // t has type intcase *bool: fmt.Printf(&quot;pointer to boolean %t\\n&quot;, *t) // t has type *boolcase *int: fmt.Printf(&quot;pointer to integer %d\\n&quot;, *t) // t has type *int&#125; 类型断言用于从接口类型值中提取其底层的具体类型。如果断言成功，程序可以安全地将该接口值转换为目标类型并使用。 value, ok :&#x3D; x.(T) x 是一个接口类型的变量。T 是目标类型（可以是具体类型或其他接口类型）。如果 x 的动态类型是 T：value 是 x 转换为 T 后的值。ok 为 true。如果 x 的动态类型不是 T：value 是 T 的零值。ok 为 false，表示断言失败。 12345678var x interface&#123;&#125; = 42 // 空接口存储了一个 int 值value, ok := x.(int) // 断言 x 是 int 类型if ok &#123; fmt.Printf(&quot;x is an int, value: %d\\n&quot;, value)&#125; else &#123; fmt.Println(&quot;x is not an int&quot;)&#125; 空interface空interface(interface{})不包含任何的method，正因为如此，所有的类型都实现了空interface。空interface对于描述起不到任何的作用(因为它不包含任何的method），但是空interface在我们需要存储任意类型的数值的时候相当有用，因为它可以存储任意类型的数值。它有点类似于C语言的void*类型。 1234567// 定义a为空接口var a interface&#123;&#125;var i int = 5s := &quot;Hello world&quot;// a可以存储任意类型的数值a = ia = s 一个函数把interface{}作为参数，那么他可以接受任意类型的值作为参数，如果一个函数返回interface{},那么也就可以返回任意类型的值。是不是很有用啊！ Go并发"},{"title":"7_days_golang学习","date":"2024-12-20T13:07:48.538Z","updated":"2024-11-27T12:47:04.152Z","comments":true,"path":"archives/Goalng_Framework.html","permalink":"https://whuichenggong.github.io/archives/Goalng_Framework.html","excerpt":"","text":"通过学习项目 7_days_golang搭建各种自己的框架了解一些网络工作原理和知识学习geektutu源代码：https://github.com/geektutu/7days-golang 跟着学习的项目代码已经放在: https://github.com/Whuichenggong/Study_Go 1.gee.go关键代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package geeimport ( &quot;fmt&quot; &quot;net/http&quot;)//首先定义了类型HandlerFunc，这是提供给框架用户的，用来定义路由映射的处理方法type HandlerFunc func(http.ResponseWriter, *http.Request)// 在Engine中，添加了一张路由映射表router// key 由请求方法和静态路由地址构成，例如GET-/、GET-/hello、POST-/hello// 如果请求方法不同,可以映射不同的处理方法(Handler)，value 是用户映射的处理方法type Engine struct &#123; router map[string]HandlerFunc&#125;// New is the constructor of gee.Enginefunc New() *Engine &#123; return &amp;Engine&#123;router: make(map[string]HandlerFunc)&#125;&#125;func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123; key := method + pattern engine.router[key] = handler&#125;// 用户调用(*Engine).GET()方法时，会将路由和处理方法注册到映射表 router 中，(*Engine).Run()方法，是 ListenAndServe 的包装。func (engine *Engine) GET(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;GET&quot;, pattern, handler)&#125;func (engine *Engine) POST(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;POST&quot;, pattern, handler)&#125;func (engine *Engine) Run(addr string) (err error) &#123; return http.ListenAndServe(addr, engine)&#125;// Engine实现的 ServeHTTP 方法的作用就是，解析请求的路径，查找路由映射表，如果查到，就执行注册的处理方法。如果查不到，就返回 404 NOT FOUND 。func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; key := req.URL.Path if handler, ok := engine.router[key]; ok &#123; handler(w, req) &#125; else &#123; fmt.Fprintf(w, &quot;404 Not Found: %s\\n&quot;, req.URL) &#125;&#125; 2.go.mod代码12345678module github.com/Whuichenggonggo 1.22.1require gee v0.0.0replace gee =&gt; ./gee replace gee &#x3D;&gt; .&#x2F;gee 这是一个替换指令，它告诉 Go 工具链用本地相对路径 .&#x2F;gee 中的 gee 包替换远程需要的 gee 包。这意味着，尽管 require 指令可能指向一个特定的远程版本或分支，这个 replace 指令实际上将使用当前目录下的 gee 文件夹中的代码。 2.1初始化 Go 模块：如果你的项目还没有被初始化为 Go 模块，你需要先在项目的根目录下运行以下命令来初始化它： go mod init &lt;module-name&gt; 替换 为你的模块名称。例如，如果你的项目名称是 example，你会运行： go mod init example 3.main.go1234567891011121314151617181920212223242526package mainimport ( &quot;fmt&quot; &quot;net/http&quot; &quot;gee&quot;)func main() &#123; r := gee.New() r.GET(&quot;/&quot;, func(w http.ResponseWriter, req *http.Request) &#123; fmt.Fprintf(w, &quot;URL.Path = %q\\n&quot;, req.URL.Path) &#125;) r.GET(&quot;/hello&quot;, func(w http.ResponseWriter, req *http.Request) &#123; for k, v := range req.Header &#123; fmt.Fprintf(w, &quot;Header[%q] = %q\\n&quot;, k, v) &#125; &#125;) r.Run(&quot;:9999&quot;)&#125; 新增：测试 POST 请求启动服务器后，测试 POST 请求可以使用以下工具： 方法 1: 使用 curl执行以下命令发送 POST 请求： curl -X POST http://localhost:8080/submit 12345678910111213141516171819202122232425262728293031323334353637383940package mainimport (&quot;fmt&quot;&quot;io/ioutil&quot;&quot;net/http&quot;)type HandlerFunc func(http.ResponseWriter, *http.Request)type Engine struct &#123;router map[string]HandlerFunc&#125;func New() *Engine &#123;return &amp;Engine&#123;router: make(map[string]HandlerFunc)&#125;&#125;func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123;key := method + patternengine.router[key] = handler&#125;func (engine *Engine) POST(pattern string, handler HandlerFunc) &#123;engine.addRoute(&quot;POST&quot;, pattern, handler)&#125;func (engine *Engine) Run(addr string) error &#123;return http.ListenAndServe(addr, engine)&#125;func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123;key := req.Method + req.URL.Pathif handler, ok := engine.router[key]; ok &#123;handler(w, req)&#125; else &#123;http.NotFound(w, req)&#125;&#125; func main() {engine :&#x3D; New() // 注册一个 POST 路由 engine.POST(&quot;/submit&quot;, func(w http.ResponseWriter, req *http.Request) &#123; // 读取请求体数据 body, err := ioutil.ReadAll(req.Body) if err != nil &#123; http.Error(w, &quot;Failed to read request body&quot;, http.StatusInternalServerError) return &#125; // 响应请求体内容 fmt.Fprintf(w, &quot;Received: %s&quot;, string(body)) &#125;) // 启动服务器 engine.Run(&quot;:8080&quot;) }测试：启动程序后，用 curl 发送 POST 请求并附带数据： bcurl -X POST -d “data&#x3D;HelloWorld” http://localhost:8080/submit服务器返回： kotlin Received: data&#x3D;HelloWorld ServeHTTP好像有点问题main.go附带了对代码的理解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package geeimport ( &quot;fmt&quot; &quot;net/http&quot;)//首先定义了类型HandlerFunc，这是提供给框架用户的，用来定义路由映射的处理方法type HandlerFunc func(http.ResponseWriter, *http.Request)// 在Engine中，添加了一张路由映射表router// key 由请求方法和静态路由地址构成，例如GET-/、GET-/hello、POST-/hello// 如果请求方法不同,可以映射不同的处理方法(Handler)，value 是用户映射的处理方法type Engine struct &#123; router map[string]HandlerFunc&#125;// New is the constructor of gee.Enginefunc New() *Engine &#123; return &amp;Engine&#123;router: make(map[string]HandlerFunc)&#125;&#125;// 这段代码的作用将HTTP请求的路由和对应的处理函数注册到路由表中的核心方法// pattern路由路径func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123; //将HTTp方法和路径拼接成唯一一个键 作为路由表的router的键 key := method + pattern //将处理函数 handler 存入路由表中，关联到对应的路由键。 engine.router[key] = handler&#125;// 用户调用 addRoute(&quot;GET&quot;, &quot;/home&quot;, someHandlerFunc) 在 engine.router 映射表中，会存储一个键值对：// 调用engine.GET(&quot;/home&quot;, someHandlerFunc)： 实际是 等价 engine.addRoute(&quot;GET&quot;, &quot;/home&quot;, someHandlerFunc)func (engine *Engine) GET(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;GET&quot;, pattern, handler)&#125;func (engine *Engine) POST(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;POST&quot;, pattern, handler)&#125;// 这段代码隐藏了调用ServeHTTPfunc (engine *Engine) Run(addr string) (err error) &#123; return http.ListenAndServe(addr, engine)&#125;// Engine实现的 ServeHTTP 方法的作用就是，解析请求的路径，查找路由映射表，如果查到，就执行注册的处理方法。如果查不到，就返回 404 NOT FOUND 。// 不需要显式调用 ServeHTTP// 在 Go 的 HTTP 框架中，ServeHTTP 是 http.Handler 接口的约定方法。当你把 Engine 作为服务器的处理器传递时，它会被 ListenAndServe 自动调用。func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; key := req.URL.Path if handler, ok := engine.router[key]; ok &#123; handler(w, req) &#125; else &#123; fmt.Fprintf(w, &quot;404 Not Found: %s\\n&quot;, req.URL) &#125;&#125; 问题在 ServeHTTP 中，当前只从 req.URL.Path 获取路径，而没有结合 req.Method，会导致不同的 HTTP 方法（如 GET 和 POST）冲突或无法正确匹配。addRoute 方法仅使用了路径（pattern）和方法（method）拼接为路由键，例如：GET&#x2F;home。 1234func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123; key := method + &quot;-&quot; + pattern // 区分 HTTP 方法和路径 engine.router[key] = handler&#125; 修改的这段代码原来只使用了路径（req.URL.Path）作为路由键。例如： 请求路径 &#x2F;hello 的键为 &#x2F;hello。不区分 GET &#x2F;hello 和 POST &#x2F;hello，它们会共用同一个路由键 &#x2F;hello。建议的代码使用 HTTP 方法和路径 拼接成路由键。例如： GET &#x2F;hello 的键为 GET-&#x2F;hello。POST &#x2F;hello 的键为 POST-&#x2F;hello。这样可以区分不同方法对应的路由处理函数。 与gin框架启动很相似 对Web服务来说，无非是根据请求*http.Request，构造响应http.ResponseWriter。但是这两个对象提供的接口粒度太细，比如我们要构造一个完整的响应，需要考虑消息头(Header)和消息体(Body)，而 Header 包含了状态码(StatusCode)，消息类型(ContentType)等几乎每次请求都需要设置的信息。因此，如果不进行有效的封装， 那么框架的用户将需要写大量重复，繁杂的代码且容易出错。针对常用场景，能够高效地构造出 HTTP 响应是一个好的框架必须考虑的点。 代码要学会封装 否则代码整洁度看起来还是会差很多的 对于别人理解一会更方便 为什么要添加context 对于框架来说，还需要支撑额外的功能。例如，将来解析动态路由&#x2F;hello&#x2F;:name，参数:name的值放在哪呢？再比如，框架需要支持中间件，那中间件产生的信息放在哪呢？ contxet保留了你想寻找的一些东西拓展性和复杂性留在内部对外简化了接口。 Context 的作用是为每个 HTTP 请求提供一个上下文对象，方便操作请求和响应，并提供了一些简化开发的工具方法。通过 Context 统一管理 HTTP 请求和响应的逻辑。 可以把 Context 看作是： 一个请求的容器： 它封装了与 HTTP 请求相关的所有信息，并提供了一些方法让你更轻松地操作这些信息。 开发者和 HTTP 请求的桥梁： 开发者通过 Context 与客户端通信，包括读取请求信息和发送响应。 123456789101112func handler(c *Context) &#123;// 获取查询参数name := c.Query(&quot;name&quot;) // 构造 JSON 响应 if name != &quot;&quot; &#123; c.JSON(http.StatusOK, H&#123;&quot;message&quot;: &quot;Hello &quot; + name&#125;) &#125; else &#123; c.String(http.StatusBadRequest, &quot;Name is required&quot;) &#125;&#125; 深入框架原理：阅读 Gin、Echo 等框架的源码，了解它们如何设计和扩展 Context。 尝试扩展功能：在 Context 上添加自定义方法，比如记录日志、追踪请求 ID 等。 http.ResponseWriter 和 *http.Request 的实际意义http.ResponseWriter 作用：代表服务端用来写入 HTTP 响应的接口。开发者通过它向客户端返回数据（如响应头、响应状态码、响应体等）。实际应用：在服务端，http.ResponseWriter 将生成的 HTTP 响应数据写入 TCP 连接的输出流，客户端会接收到这些数据并解析呈现。*http.Request 作用：表示客户端发来的 HTTP 请求，包含了所有请求相关的信息（如 URL、方法、头部、表单数据、Cookie、Body 等）。实际应用：服务端根据 *http.Request 的内容（路径、方法等），判断客户端的需求并生成相应的响应。 12345678910111213141516171819202122package mainimport ( &quot;fmt&quot; &quot;net/http&quot;)func handler(w http.ResponseWriter, req *http.Request) &#123; // 设置响应头 w.Header().Set(&quot;Content-Type&quot;, &quot;text/plain&quot;) // 设置状态码 w.WriteHeader(http.StatusOK) // 写入响应体 fmt.Fprintf(w, &quot;Hello, %s!\\n&quot;, req.URL.Query().Get(&quot;name&quot;))&#125;func main() &#123; http.HandleFunc(&quot;/&quot;, handler) http.ListenAndServe(&quot;:8080&quot;, nil)&#125; 客户端请求示例： 浏览器访问 http://localhost:8080/?name=zhaozhonghe 服务端响应： HTTP&#x2F;1.1 200 OK &#x2F;&#x2F;设置的状态码 200Content-Type: text&#x2F;plain &#x2F;&#x2F;设置的请求头 响应过来了 并且返回到了 客户端页面Content-Length: 12 Hello, zhaozhonghe! &#x2F;&#x2F; 读取 HTTP 请求 将数据写入响应体，通过 w 发送给客户端。 第二天1.添加context1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package geeimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;net/http&quot;)//对Web服务来说，无非是根据请求*http.Request，构造响应http.ResponseWriter// 给map[string]interface&#123;&#125;起了一个别名gee.H，构建JSON数据时，显得更简洁。type H map[string]interface&#123;&#125;// Context目前只包含了http.ResponseWriter和*http.Request，另外提供了对 Method 和 Path 这两个常用属性的直接访问。type Context struct &#123; Writer http.ResponseWriter Req *http.Request Path string Method string StatusCode int&#125;func newContext(w http.ResponseWriter, req *http.Request) *Context &#123; return &amp;Context&#123; Writer: w, Req: req, Path: req.URL.Path, Method: req.Method, &#125;&#125;// 提供了访问Query和PostForm参数的方法。func (c *Context) PostForm(key string) string &#123; return c.Req.FormValue(key)&#125;func (c *Context) Query(key string) string &#123; return c.Req.URL.Query().Get(key)&#125;func (c *Context) Status(code int) &#123; c.StatusCode = code c.Writer.WriteHeader(code)&#125;func (c *Context) SetHeader(key string, value string) &#123; c.Writer.Header().Set(key, value)&#125;// 提供了快速构造String/Data/JSON/HTML响应的方法。func (c *Context) String(code int, format string, values ...interface&#123;&#125;) &#123; c.SetHeader(&quot;Content-Type&quot;, &quot;text/plain&quot;) c.Status(code) c.Writer.Write([]byte(fmt.Sprintf(format, values...)))&#125;func (c *Context) JSON(code int, obj interface&#123;&#125;) &#123; c.SetHeader(&quot;Content-Type&quot;, &quot;application/json&quot;) c.Status(code) encoder := json.NewEncoder(c.Writer) if err := encoder.Encode(obj); err != nil &#123; http.Error(c.Writer, err.Error(), 500) &#125;&#125;func (c *Context) Data(code int, data []byte) &#123; c.Status(code) c.Writer.Write(data)&#125;func (c *Context) HTML(code int, html string) &#123; c.SetHeader(&quot;Content-Type&quot;, &quot;text/html&quot;) c.Status(code) c.Writer.Write([]byte(html))&#125; 2.添加router想 路由需要的参数 路径 方法 处理函数 12345678910111213141516171819202122232425262728293031package geeimport ( &quot;log&quot; &quot;net/http&quot;)type router struct &#123; handlers map[string]HandlerFunc&#125;func newRouter() *router &#123; return &amp;router&#123;handlers: make(map[string]HandlerFunc)&#125;&#125;func (r *router) addRoute(method string, pattern string, handler HandlerFunc) &#123; log.Printf(&quot;Route %4s - %s&quot;, method, pattern) key := method + &quot;-&quot; + pattern r.handlers[key] = handler&#125;func (r *router) handle(c *Context) &#123; key := c.Method + &quot;-&quot; + c.Path if handler, ok := r.handlers[key]; ok &#123; handler(c) &#125; else &#123; c.String(http.StatusNotFound, &quot;404 NOT FOUND: %s\\n&quot;, c.Path) &#125;&#125; r.handlers[key] &#x3D; handler 这段代码将key也就是路径 和 处理函数关连到了一起 post用终端请求1.Invoke-WebRequest -Uri “http://localhost:9999/login“ -Method POST -Body “username&#x3D;zhaozhonghe&amp;password&#x3D;zzh123456” curl.exe -X POST -d “username&#x3D;zhaozhonghe&amp;password&#x3D;zzh123456” http://localhost:9999/login返回结果1&#123;&quot;password&quot;:&quot;zzh123456&quot;,&quot;username&quot;:&quot;zhaozhonghe&quot;&#125; 测试第二天的gee第一种返回结果 123456789101112131415161718StatusCode : 200StatusDescription : OKContent : &#123;&quot;password&quot;:&quot;zzh123456&quot;,&quot;username&quot;:&quot;zhaozhonghe&quot;&#125;RawContent : HTTP/1.1 200 OKContent-Length: 50Content-Type: application/jsonDate: Tue, 26 Nov 2024 13:43:37 GMT &#123;&quot;password&quot;:&quot;zzh123456&quot;,&quot;username&quot;:&quot;zhaozhonghe&quot;&#125;Forms : &#123;&#125;Headers : &#123;[Content-Length, 50], [Content-Type, application/json], [Date, Tue, 26 Nov 2024 13:43:37 GMT]&#125;Images : &#123;&#125;InputFields : &#123;&#125;Links : &#123;&#125;ParsedHtml : mshtml.HTMLDocumentClassRawContentLength : 50 gee.go1234567891011121314151617181920212223242526272829303132333435363738394041package geeimport &quot;net/http&quot;// HandlerFunc defines the request handler used by geetype HandlerFunc func(*Context)// Engine implement the interface of ServeHTTPtype Engine struct &#123; router *router&#125;// New is the constructor of gee.Enginefunc New() *Engine &#123; return &amp;Engine&#123;router: newRouter()&#125;&#125;func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123; engine.router.addRoute(method, pattern, handler)&#125;// GET defines the method to add GET requestfunc (engine *Engine) GET(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;GET&quot;, pattern, handler)&#125;// POST defines the method to add POST requestfunc (engine *Engine) POST(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;POST&quot;, pattern, handler)&#125;// Run defines the method to start a http serverfunc (engine *Engine) Run(addr string) (err error) &#123; return http.ListenAndServe(addr, engine)&#125;func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; c := newContext(w, req) engine.router.handle(c)&#125; 第三天我们用了一个非常简单的map结构存储了路由表，使用map存储键值对，索引非常高效，但是有一个弊端，键值对的存储的方式，只能用来索引静态路由。那如果我们想支持类似于&#x2F;hello&#x2F;:name这样的动态路由怎么办呢？所谓动态路由，即一条路由规则可以匹配某一类型而非某一条固定的路由。例如&#x2F;hello&#x2F;:name，可以匹配&#x2F;hello&#x2F;geektutu、hello&#x2F;jack等。请等待~~~ 11.21日看到了字节的课 是关于动态路由的设计 前缀匹配树 router.go前缀树路由： 重点学习这个数据结构 bilibili: https://www.bilibili.com/video/BV1wT4y1x7xm?t=45.6 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package geeimport ( &quot;net/http&quot; &quot;strings&quot;)type router struct &#123; roots map[string]*node //增加的 handlers map[string]HandlerFunc&#125;func newRouter() *router &#123; return &amp;router&#123; roots: make(map[string]*node), handlers: make(map[string]HandlerFunc), &#125;&#125;// Only one * is allowedfunc parsePattern(pattern string) []string &#123; vs := strings.Split(pattern, &quot;/&quot;) parts := make([]string, 0) for _, item := range vs &#123; if item != &quot;&quot; &#123; parts = append(parts, item) if item[0] == &#x27;*&#x27; &#123; break &#125; &#125; &#125; return parts&#125;func (r *router) addRoute(method string, pattern string, handler HandlerFunc) &#123; parts := parsePattern(pattern) key := method + &quot;-&quot; + pattern _, ok := r.roots[method] if !ok &#123; r.roots[method] = &amp;node&#123;&#125; &#125; r.roots[method].insert(pattern, parts, 0) r.handlers[key] = handler&#125;func (r *router) getRoute(method string, path string) (*node, map[string]string) &#123; searchParts := parsePattern(path) params := make(map[string]string) root, ok := r.roots[method] if !ok &#123; return nil, nil &#125; n := root.search(searchParts, 0) if n != nil &#123; parts := parsePattern(n.pattern) for index, part := range parts &#123; if part[0] == &#x27;:&#x27; &#123; params[part[1:]] = searchParts[index] &#125; if part[0] == &#x27;*&#x27; &amp;&amp; len(part) &gt; 1 &#123; params[part[1:]] = strings.Join(searchParts[index:], &quot;/&quot;) break &#125; &#125; return n, params &#125; return nil, nil&#125;func (r *router) getRoutes(method string) []*node &#123; root, ok := r.roots[method] if !ok &#123; return nil &#125; nodes := make([]*node, 0) root.travel(&amp;nodes) return nodes&#125;func (r *router) handle(c *Context) &#123; n, params := r.getRoute(c.Method, c.Path) if n != nil &#123; c.Params = params key := c.Method + &quot;-&quot; + n.pattern r.handlers[key](c) &#125; else &#123; c.String(http.StatusNotFound, &quot;404 NOT FOUND: %s\\n&quot;, c.Path) &#125;&#125; parsePattern 函数的作用是解析路由路径，将路径按 &#x2F; 分隔成各个部分。比如 &#x2F;user&#x2F;:id 会被分解成 [“user”, “:id”]。如果路径中出现了 *（通常用于匹配任意多的路径部分），解析会在遇到 * 时停止。比如 &#x2F;files&#x2F;*filepath 会解析成 [“files”, “*filepath”]。parts 数组存储了路由路径的各个部分（如静态部分、动态部分、通配符部分） tire.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package geeimport ( &quot;fmt&quot; &quot;strings&quot;)type node struct &#123; pattern string part string children []*node isWild bool&#125;func (n *node) String() string &#123; return fmt.Sprintf(&quot;node&#123;pattern=%s, part=%s, isWild=%t&#125;&quot;, n.pattern, n.part, n.isWild)&#125;func (n *node) insert(pattern string, parts []string, height int) &#123; if len(parts) == height &#123; n.pattern = pattern return &#125; part := parts[height] children := n.matchChildren(part) var child *node if len(children) == 0 &#123; child = &amp;node&#123;part: part, isWild: part[0] == &#x27;:&#x27; || part[0] == &#x27;*&#x27;&#125; n.children = append(n.children, child) &#125; else &#123; child = children[0] // 假设我们总是取第一个匹配的子节点 &#125; child.insert(pattern, parts, height+1)&#125;func (n *node) search(parts []string, height int) *node &#123; if len(parts) == height || strings.HasPrefix(n.part, &quot;*&quot;) &#123; if n.pattern == &quot;&quot; &#123; return nil &#125; return n &#125; part := parts[height] children := n.matchChildren(part) for _, child := range children &#123; result := child.search(parts, height+1) if result != nil &#123; return result &#125; &#125; return nil&#125;func (n *node) travel(list *([]*node)) &#123; if n.pattern != &quot;&quot; &#123; *list = append(*list, n) &#125; for _, child := range n.children &#123; child.travel(list) &#125;&#125;func (n *node) matchChild(part string) *node &#123; for _, child := range n.children &#123; if child.part == part || child.isWild &#123; return child &#125; &#125; return nil&#125;func (n *node) matchChildren(part string) []*node &#123; nodes := make([]*node, 0) for _, child := range n.children &#123; if child.part == part || child.isWild &#123; nodes = append(nodes, child) &#125; &#125; return nodes&#125; 先学习一下前缀树 定义树结点结构体12345type trieNode struct &#123; nexts [26]*trieNode PassCnt int //用来记录中途是否有途径某个节点的个数 end bool //匹配某个单词是否是结尾 比如seat的结尾是t&#125; 树 123type Trie struct &#123; root *trieNode&#125; 12345func Newtrie *Trie&#123; return &amp;Trie&#123; root: &amp;trieNode&#123;&#125;,&#125;&#125; 查询12345 func (t *Trie) Search(word string) bool &#123; //查找目标节点，使根节点开始抵达目标节点沿路跟字符串恰好等于word node := t.search(word) return node != nil &amp;&amp; node.end&#125; Tire.search 方法源码字符➖a如果返回的单词是 前缀树中的别的单词的前缀判断 123456789101112131415161718192021222324func (t *Trie)search(target string)*trieNode&#123;//移动指针从根节点出发move :t.root/依次追历target中的每个字符for_, ch:range target&#123;//倘若nexts中不存在对应于这个字符的节点，说明该单词没插入过，返回ni1if move.nexts[ch-&#x27;a&#x27;]==nil&#123;return nil&#125;//指针向着子节点移动movemove.nexts [ch-&#x27;a&#x27;]&#125;//来到末尾，说明已经完全匹配好单词，直接返回这个节点//需要注意，找到目标节点不一定代表单词存在，因为该节点的end标识未必为true//比如我们之前往trie中插入了apple这个单词，但是查找app这个单词时，预期的返回return move&#125;&#125; 前缀匹配1234//前缀树做前缀匹配很简单 func (t *Trie) StartWith(prefix(string)) bool &#123; return t.search(prefix) != nil&#125; 前缀统计123456789func (t *Trie) PassCnt(prefix string) int&#123; node := t.search(prefix) if node == nil &#123; return 0 &#125; return node.PassCnt&#125; 插入单词例子： 要插入apple 树中app可以复用 则插入 l e 1234567891011121314151617181920 func (t *Trie) Insert(word string) &#123;//如果单词存在直接返回 if t.Search(word)&#123; return&#125; move := t.root for _,ch := range word &#123;//如果不存在创建出来 if move.nexts[ch-&#x27;a&#x27;] == nil &#123; move.nexts[ch-&#x27;a&#x27;] = &amp;trieNode&#123;&#125;&#125; move.nexts[ch-&#x27;a&#x27;].passCnt++ move = move.nexts[ch-&#x27;a&#x27;]move.end =true&#125; 删除流程12345678910111213141516171819func (t *Trie) Erase(word string) bool &#123; if !t.Search(word)&#123;return false&#125; move := t.root for _, ch := range word &#123; move.nexts[ch-&#x27;a&#x27;].passCnt --if move.nexts[ch-&#x27;a&#x27;].passCnt == 0 &#123; move.nexts[ch-&#x27;a&#x27;] = nil return true&#125; move = move.nexts[ch-&#x27;a&#x27;]&#125; move.end = false return true&#125; 整段代码下来还是有点看不懂啊呜呜 11.25日拖了几天感谢tutu 分组控制分组控制是Web框架的基础功能之一，路由的分组，往往某一组路由需要相似的处理 以&#x2F;post开头的路由匿名可访问。以&#x2F;admin开头的路由需要鉴权。以&#x2F;api开头的路由是 RESTful 接口，可以对接第三方平台，需要三方平台鉴权。 &#x2F;post是一个分组&#x2F;post&#x2F;a和&#x2F;post&#x2F;b可以是该分组下的子分组作用在&#x2F;post分组上的中间件(middleware)，也都会作用在子分组，子分组还可以应用自己特有的中间件。 中间件可以给框架提供无限的扩展能力用在分组上的效果也更明显&#x2F;admin的分组，可以应用鉴权中间件；&#x2F;分组应用日志中间件，&#x2F;是默认的最顶层的分组，也就意味着给所有的路由，即整个框架增加了记录日志的能力。 一个 Group 对象需要具备哪些属性呢？首先是前缀(prefix)，比如&#x2F;，或者&#x2F;api；要支持分组嵌套，那么需要知道当前分组的父亲(parent)是谁；中间件是应用在分组上的，那还需要存储应用在该分组上的中间件(middlewares)。 12345r := gee.New()v1 := r.Group(&quot;/v1&quot;)v1.GET(&quot;/&quot;, func(c *gee.Context) &#123; c.HTML(http.StatusOK, &quot;&lt;h1&gt;Hello Gee&lt;/h1&gt;&quot;)&#125;) 好好看看仓库中的代码 梳理思路 感觉好有意思但是看不懂哈哈哈哈 11.26日 回看前三天的代码 增加一些自己的理解和修改 再继续向下学习！"},{"title":"后端项目学习","date":"2024-12-20T13:07:48.557Z","updated":"2024-12-07T05:33:12.530Z","comments":true,"path":"archives/Simple_bank.html","permalink":"https://whuichenggong.github.io/archives/Simple_bank.html","excerpt":"","text":"重新开启simplebank学习！！！一.创建数据库表https://dbdiagram.io 可视化数据库工具 1.创建账户表1234567Table accounts as A &#123; //A作为account的别名 id bigserisal [pk] //pk作为主键 自增的id列 owner varchar balance bigint currency varchar created_at timestamp [default: `now()`] //自动获取时间&#125; 2.创建条目表&#x2F;&#x2F;记录账户余额的变化 123456Table entries &#123; id bigint [pk] // account_id bigint [ref : &gt; A.id] //外键 账户和条目之间是1对多关系 amount bigint [not null note:`可以是负或者正`] //正负取决于取出还是存入 note是添加注释 created_at timestamp [default: `now()`] //记录条目的创建时间&#125; 3.创建 转账表1234567Table transfers &#123; id bigint [pk] from_account_id bigint [ref : &gt; A.id] to_account_id bigint [ref : &gt; A.id] amount bigint [not null note: `一定不能为空`]//note为注释 created_at timestamp [default: `now()`]&#125; 在此之后向列中添加非空约束 例如 ： balance bigint [not null] &#x2F;&#x2F; 非空约束是一种用于限制数据库表中某列不能为空的约束 枚举 1234Enum Currency&#123;USDEUR&#125; 向表中添加索引 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Use DBML to define your database structure// Docs: https://dbml.dbdiagram.io/docsTable accounts as A &#123; id bigserisal [pk] owner varchar [not null] balance bigint [not null] currency varchar [not null] created_at timestamp [default: `now()`] Indexes &#123; owner &#125;&#125;Table entries &#123; id bigint [pk] account_id bigint [ref : &gt; A.id] amount bigint [not null] created_at timestamp [default: `now()`] //列出特定账户的所有条目Indexes &#123; account_id&#125; &#125;Table transfers &#123; id bigint [pk] from_account_id bigint [ref : &gt; A.id] to_account_id bigint [ref : &gt; A.id] amount bigint [not null] created_at timestamp [default: `now()`] Indexes &#123; from_account_id to_account_id (from_account_id,to_account_id)&#125;&#125; 这些做好之后使用导出功能 生成代码 123456789101112131415161718192021222324252627282930313233343536373839404142CREATE TABLE &quot;accounts&quot; ( &quot;id&quot; bigserisal PRIMARY KEY, &quot;owner&quot; varchar NOT NULL, &quot;balance&quot; bigint NOT NULL, &quot;currency&quot; varchar NOT NULL, &quot;created_at&quot; timestamp DEFAULT (now()));CREATE TABLE &quot;entries&quot; ( &quot;id&quot; bigint PRIMARY KEY, &quot;account_id&quot; bigint, &quot;amount&quot; bigint NOT NULL, &quot;created_at&quot; timestamp DEFAULT (now()));CREATE TABLE &quot;transfers&quot; ( &quot;id&quot; bigint PRIMARY KEY, &quot;from_account_id&quot; bigint, &quot;to_account_id&quot; bigint, &quot;amount&quot; bigint NOT NULL, &quot;created_at&quot; timestamp DEFAULT (now()));CREATE INDEX ON &quot;accounts&quot; (&quot;owner&quot;);CREATE INDEX ON &quot;entries&quot; (&quot;account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;from_account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;to_account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;from_account_id&quot;, &quot;to_account_id&quot;);//将外键添加到表中ALTER TABLE &quot;entries&quot; ADD FOREIGN KEY (&quot;account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);ALTER TABLE &quot;transfers&quot; ADD FOREIGN KEY (&quot;from_account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);ALTER TABLE &quot;transfers&quot; ADD FOREIGN KEY (&quot;to_account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;); 二.Docker用指令创建容器的时候 一定要注意-p参数 将容器的端口映射到主机上 一定要保证端口不要被占用 否则将会产生问题 拉取镜像语法 1docker pull &lt;image&gt;:&lt;tag&gt; 开始一个容器指令 1234567891011121314151617181920212223242526272829303132333435361.docker run --name &lt;container_name&gt; -e &lt;environment_variable&gt; -d &lt;image&gt;:tag:2.docker run --name some-postgres -e POSTGRES_PASSWORD=mysecret -d postgres #！！！端口映射 -p 5432:5432 //注意防止端口冲突自行更改示例：docker run --name postgres12 -e POSTGRES_USER=root -e POSTGRES_PASSWORD=secret -d postgres:12-alpine 3. docker exec -it &lt;contain_name_or_id&gt; &lt;comman&gt; [args]示例：#进入psql控制台docker exec -it postgres12 psql -U root4.显示容器日志docker logs &lt;container_name_or_id&gt;示例:docker logs postgres125.连接shell指令：docker exec -it postgres12 /bin/sh#创建新的数据库createdb --username=root --owner=root simple_bank#使用psql连接 psql simple_bank #删除数据库 dropdb [名称] exit退出shell #指令结合 docker exec -it postgres12 createdb --username=root --owner=root simple_bank docker exec -it postgres12 psql -U root simple_bank #查找指令 history | grep &quot;docker run&quot; //linux history | Select-String &quot;docker run&quot;//windows 区分 docker中的 镜像和容器 docker image中包含多个运行 容器的应用实例 类似结构： - docker image ├── container1 ├──container2 ├──container3 三.Tableplus将sql文件导入到tableplus中 在tableplus中删除表 使用sql指令 1DROP TABLE accounts CASCADE; //注意替换表名称 四.DB migration迁移指令： 1migrate create -ext sql -dir db/migration -seq init_schema up&#x2F;down migration：理解迁移 类比栈结构 向上新数据表 向下 旧数据表 使用migrate up指令时 Old DB 在文件中 一次按照 1.up.sql 2.up.sql 3.up.sql 依次运行到New DB 使用migrate down指令时 New DB 在文件中依次按照 3.up.sql 2.up.sql 1.up.sql 依次运行到Old DB old DB schema —–&gt; migrate up —––&gt; x.up.sql —–&gt;New DB schema ​ &lt;—————————- x.down.sql &lt;———migrate down&lt;————- 将最开始的.sql文件放入 .up.sql中 五.Makefile文件创建规则后使用 make指令 快速创建 如果你是萌新开始给到你一个项目 你可以通过makefile文件快速构建 12345678910migrate -help#通过看日志 知道使用什么指令来工作#迁移指令migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank&quot; -verbose up#出现ssl错误添加sslmode=disabled#出现了一系列的迁移错误 解决方案强制更改版本migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; -verbose force 1 六.数据库的CRUDDATAVASE&#x2F;SQL库 GORM sqlx（兼容多） sqlc（最好的 融合了以上两者的优点） 七.使用sqlc1sqlc init 介绍: sqlc 从 SQL 生成类型安全的代码。以下是它的工作原理： 您使用 SQL 编写查询。 运行 sqlc 来生成具有这些查询的类型安全接口的代码。 编写调用生成的代码的应用程序代码。 查看一个交互式示例来了解它的实际应用，以及 sqlc 背后的动机的介绍性博客文章。 八.sqlc.yaml123456789101112131415161718version: &quot;2&quot;sql:- schema: &quot;simplebank/db/migration&quot; //数据库表 queries: &quot;db/query&quot; //数据库查询 首先要编写数据库查询 engine: &quot;postgresql&quot; //使用的数据库 gen: go: package: &quot;db&quot; out: &quot;simplebank/db/sqlc&quot; sql_package: &quot;pgx/v5&quot; emit_json_tags: true emit_interface: false emit_empty_slices: true overrides: - db_type: &quot;timestamptz&quot; go_type: &quot;time.Time&quot; - db_type: &quot;uuid&quot; go_type: &quot;github.com/google/uuid.UUID&quot; account.sql 12345678-- name: CreateAccount :oneINSERT INTO accounts ( owner, balance, currency) VALUES ( $1, $2, $3) RETURNING *; make sqlc 生成代码1.account.sql.go2.db.go3.models.go在生成之后由于没有 初始化项目 使得项目报红 12go mod init project/simplebankgo mod tidy 九.编写单元测试用例1.导入未使用的包在前面添加_可以防止系统自动将它删除 例如： _ “github.com&#x2F;lib&#x2F;pq “ 错误 12345cannot use conn (variable of type *sql.DB) as DBTX value in argument to New: *sql.DB does not implement DBTX (wrong type for method Exec) have Exec(string, ...any) (sql.Result, error) want Exec(context.Context, string, ...interface&#123;&#125;) (pgconn.CommandTag, 你遇到的错误信息表明，你尝试将 *sql.DB 类型的 conn 变量用作 DBTX 类型的参数，但 *sql.DB 并不满足 DBTX 接口的要求。具体来说，DBTX 接口期望的 Exec 方法签名是 (context.Context, string, ...interface&#123;&#125;) (pgconn.CommandTag, error)，而 *sql.DB 提供的 Exec 方法签名是 (string, ...any) (sql.Result, error)。 目前不理解 方法和接口 开始学习 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687//这是接口type DBTX interface &#123; Exec(context.Context, string, ...interface&#123;&#125;) (pgconn.CommandTag, error) Query(context.Context, string, ...interface&#123;&#125;) (pgx.Rows, error) QueryRow(context.Context, string, ...interface&#123;&#125;) pgx.Row&#125;string, ...interface&#123;&#125;//的含义这是可变参数的声明方式。它表示可以接收零个或多个任意类型的参数。在函数内部，这些参数被视为一个 []interface&#123;&#125;（一个接口类型的切片）。例如，如果有一个函数接受一个字符串和任意数量的其他参数：func myFunction(s string, args...interface&#123;&#125;) &#123; // 函数体&#125;可以这样调用这个函数：myFunction(&quot;hello&quot;, 1, &quot;world&quot;, true)/* 在这段代码中有一个这样的错误我不知道怎么修改cannot use conn (variable of type *sql.DB) as DBTX value in argument to New: *sql.DB does not implement DBTX (wrong type for method Exec) have Exec(string, ...any) (sql.Result, error) want Exec(context.Context, string, ...interface&#123;&#125;) (pgconn.CommandTag,要解决这个问题，你需要确保你的 DBTX 接口的方法签名与 *sql.DB 的实现匹配。具体来说，你需要修改 DBTX 接口的 Exec 方法，使其接受 context.Context 参数。以下是一个可能的解决方案：修改 DBTX 接口，使其 Exec 方法的签名为：type DBTX interface &#123; Exec(ctx context.Context, query string, args ...interface&#123;&#125;) (pgconn.CommandTag, error) // 其他方法...&#125;在你的 New 函数中，确保它接受符合 DBTX 接口的类型。例如，使用 sql.DB 时，你可以创建一个适配器来实现 DBTX 接口。这里是一个适配器示例：type DBAdapter struct &#123; *sql.DB&#125;func (db *DBAdapter) Exec(ctx context.Context, query string, args ...interface&#123;&#125;) (pgconn.CommandTag, error) &#123; result, err := db.DB.ExecContext(ctx, query, args...) return result, err&#125;然后在 TestMain 中使用这个适配器：testQueries = New(&amp;DBAdapter&#123;conn&#125;)这样就能确保 *sql.DB 能正确实现 DBTX 接口，从而解决你遇到的错误。*/!!!!!!!!!!!!!!!!!!!!!!gpt给出解决问题的方法在我不知道用pgx的情况下 gpt给出用pgx连接给gpt看完接口定义之后由于你的 DBTX 接口使用了 pgx 库，你可以使用 pgx 的 Conn 类型而不是 *sql.DB。这里是一个简单的解决方案：使用 pgx 连接：确保在代码中使用 pgx 的连接，而不是 *sql.DB。修改你的数据库连接部分：import ( &quot;context&quot; &quot;log&quot; &quot;os&quot; &quot;testing&quot; &quot;github.com/jackc/pgx/v4&quot;)const ( dbDriver = &quot;pgx&quot; dbSource = &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot;)var testQueries *Queriesfunc TestMain(m *testing.M) &#123; conn, err := pgx.Connect(context.Background(), dbSource) if err != nil &#123; log.Fatal(&quot;cannot connect to db:&quot;, err) &#125; testQueries = New(conn) // 确保 New 函数接收 pgx.Conn os.Exit(m.Run())&#125;确保 New 函数接受 pgx.Conn：在你的 New 函数中，确保它接受 pgx.Conn 而不是 *sql.DB。这样，你的 DBTX 接口与 pgx 的连接就能正常工作，避免了类型不匹配的问题。这样也简化了代码，直接使用了 pgx 连接而不需要适配器。 10.8日 解决目前为止遇见的一个问题遇见的第一个大问题 在account_test.go中和main_test.go中出现的一些问题 *和姐聊了一下 解决了 **testQueries &#x3D; New(conn)*中的问题 main_test.go使用 pgx来连接数据库 而不是视频中讲解的sql.open 他们的返回值类型不同造成了错误 测试函数的拼写错误 可能也影响了一大部分 还有最后一处问题 require.NotEmpty(t, err)这一行存在问题。这里应该是检查account是否不为空，而不是检查错误err是否不为空。正确的应该是require.NotEmpty(t, account)。 不熟悉的地方go语言的包 接口 方法 1.最终的account_test.go代码12345678910111213141516171819202122232425262728package dbimport ( &quot;context&quot; &quot;testing&quot; &quot;github.com/stretchr/testify/require&quot;)func TestCreateAccount(t *testing.T) &#123; arg := CreateAccountParams&#123; Owner: &quot;xiaozhao&quot;, Balance: 100, Currency: &quot;USD&quot;, &#125; account, err := testQueries.CreateAccount(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, account) require.Equal(t, arg.Owner, account.Owner) require.Equal(t, arg.Balance, account.Balance) require.Equal(t, arg.Currency, account.Currency) require.NotZero(t, account.ID) require.NotZero(t, account.CreatedAt)&#125; 2.最终的main_test.go代码12345678910111213141516171819202122232425262728293031package dbimport ( &quot;context&quot; &quot;fmt&quot; &quot;os&quot; &quot;testing&quot; &quot;github.com/jackc/pgx/v5&quot;)var testQueries *Queriesconst ( DATABASE_URL = &quot;postgres://root:secret@localhost:5432/simple_bank?sslmode=disable&quot;)func TestMain(m *testing.M) &#123; conn, err := pgx.Connect(context.Background(), DATABASE_URL) if err != nil &#123; fmt.Fprintf(os.Stderr, &quot;Unable to connect to database: %v\\n&quot;, err) os.Exit(1) &#125; defer conn.Close(context.Background()) testQueries = New(conn) os.Exit(m.Run())&#125;//测试通过！！！！！！！ 上面是指定了一个一个账户 我们想让账户的主人 货币 钱是随机的 编写util中的random代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package utilimport ( &quot;math/rand&quot; &quot;strings&quot; &quot;time&quot;)const alphabet = &quot;abcdefghijklmnopqrstuvwxyz&quot;var rng *rand.Randfunc init() &#123; source := rand.NewSource(time.Now().UnixNano()) rng = rand.New(source)&#125;// 返回一个介于 min max 之间的随机的 int64 数字func RandomInt(min, max int64) int64 &#123; return min + rng.Int63n(max-min+1)&#125;// 生成 n 个字符的随机字符串func RandomString(n int) string &#123; var sb strings.Builder k := len(alphabet) for i := 0; i &lt; n; i++ &#123; c := alphabet[rng.Intn(k)] sb.WriteByte(c) &#125; return sb.String()&#125;//随机生成ownerfunc RandomOwner() string&#123; return RandomString(6)&#125;//随机生成钱的数量func RandomMoney() int64&#123; return RandomInt(0,1000 )&#125;//随机产生一种货币func RandowCurrency() string&#123; currencies := []string&#123;&quot;RMB&quot;,&quot;USD&quot;,&quot;CAD&quot;&#125; n := len(currencies) return currencies[rand.Intn(n)]&#125; **学会如何把自己写的包导入到别的文件夹下 这个需要看go mod下的 module project&#x2F;simplebank ** 把moudle中的包作为起始路径 导入到别的文件夹下 就是：”project&#x2F;simplebank&#x2F;util” ok 截止到 10.8日随机生成的数据生成功 问题2 makefile文件中的下面这个指令 test: go test -v -cover .&#x2F;… 这个指令必须在当前目录下找到go的测试文件 就是go.mod文件应该和makefile保持在一起 解决方法在本地的go.mod文件夹下又创建了一个makefile 用来测试 make test 类型断言 interface代表为止类型 使用前需要 转换为具体类型 (从未知类型转为已知类型) 如： 12var i interface&#123;&#125; = 2num1， ok ：= i.(int)//断言 3.account_test.go代码：全部测试通过！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package dbimport ( &quot;context&quot; &quot;project/simplebank/util&quot; &quot;testing&quot; &quot;time&quot; &quot;github.com/stretchr/testify/require&quot;)func createRandomAccount(t *testing.T) Account &#123; arg := CreateAccountParams&#123; Owner: util.RandomOwner(), Balance: util.RandomMoney(), Currency: util.RandomCurrency(), &#125; account, err := testQueries.CreateAccount(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, account) require.Equal(t, arg.Owner, account.Owner) require.Equal(t, arg.Balance, account.Balance) require.Equal(t, arg.Currency, account.Currency) require.NotZero(t, account.ID) require.NotZero(t, account.CreatedAt) return account&#125;func TestCreateAccount(t *testing.T) &#123; createRandomAccount(t)&#125;func TestGetAccount(t *testing.T) &#123; account1 := createRandomAccount(t) account2, err := testQueries.GetAccount(context.Background(), account1.ID) require.NoError(t, err) require.NotEmpty(t, account2) require.Equal(t, account1.ID, account2.ID) require.Equal(t, account1.Owner, account2.Owner) require.Equal(t, account1.Balance, account2.Balance) require.Equal(t, account1.Currency, account2.Currency) require.WithinDuration(t, account1.CreatedAt.Time, account2.CreatedAt.Time, time.Second)&#125;func TestUpdateAccount(t *testing.T) &#123; account1 := createRandomAccount(t) arg := UpdateAccountParams&#123; ID: account1.ID, Balance: util.RandomMoney(), &#125; account2, err := testQueries.UpdateAccount(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, account2) require.Equal(t, account1.ID, account2.ID) require.Equal(t, account1.Owner, account2.Owner) require.Equal(t, arg.Balance, account2.Balance) require.Equal(t, account1.Currency, account2.Currency) require.WithinDuration(t, account1.CreatedAt.Time, account2.CreatedAt.Time, time.Second)&#125;func TestDeleteAccount(t *testing.T) &#123; account1 := createRandomAccount(t) err := testQueries.DeleteAccount(context.Background(), account1.ID) require.NoError(t, err) account2, err := testQueries.GetAccount(context.Background(), account1.ID) require.Error(t, err) // require.EqualError(t, err, sql.ErrNoRows.Error()) require.Empty(t, account2)&#125;func TestListAccount(t *testing.T) &#123; var lastAccount Account for i := 0; i &lt; 10; i++ &#123; lastAccount = createRandomAccount(t) &#125; arg := ListAccountsParams&#123; Owner: lastAccount.Owner, Limit: 5, //返回五条记录 Offset: 0, //设置偏移量 返回后五条记录 这里出现了问题！！！！ &#125; accounts, err := testQueries.ListAccounts(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, accounts) for _, account := range accounts &#123; require.NotEmpty(t, account) require.Equal(t, lastAccount.Owner, account.Owner) &#125;&#125; 4.entry_test.go条目上的account.id要和account表单上的di相对应 问题 id为null 在 PostgreSQL 中，如果一个表的 id 字段没有设置为自增序列（如 bigserial），并且你在插入数据时没有显式地为 id 字段指定值，那么 id 字段的值将会是 NULL，除非该字段设置了默认值。 解决办法 12创建一个序列：首先，你需要创建一个序列，这个序列将用于生成 id 列的值。 CREATE SEQUENCE entries_id_seq; 12设置序列的所有权：将序列与 id 列关联起来。 ALTER SEQUENCE entries_id_seq OWNED BY entries.id; 123设置 id 列的默认值为序列的下一个值：这样，每当你插入新行而没有指定 id 值时，PostgreSQL 会自动使用序列的下一个值。 ALTER TABLE entries ALTER COLUMN id SET DEFAULT nextval(&#x27;entries_id_seq&#x27;); 4确保 id 列是主键：从你提供的信息来看，id 列已经是主键。确保这一点很重要，因为主键约束可以保证 id 列的值是唯一的。 12测试：插入一条新记录，不指定 id 值，检查是否自动生成了 id。 INSERT INTO entries (account_id, amount, created_at) VALUES (1, 100, now()); 1DELETE FROM entries WHERE id=4; 删除特定行的指令 创建账单成功！ 但是只能生成一个数据？？？ 我发现了输出的区别 Running tool: D:\\Go\\bin\\go.exe test -timeout 30s -run ^TestCreateEntry$ project&#x2F;simplebank&#x2F;db&#x2F;sqlc ok project&#x2F;simplebank&#x2F;db&#x2F;sqlc (cached) 这是第二次输出 第一次输出没有cached字样 数据正确的加载到了数据库 但是这个带有cached的数据没有加载到数据库 因为 cached 是因为两次的数据相同 所以才没有被加载到数据库 这个可能是随机数代码的问题 5.transfer_test.go1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package dbimport ( &quot;context&quot; &quot;time&quot; &quot;project/simplebank/util&quot; &quot;testing&quot; &quot;github.com/stretchr/testify/require&quot;)func createRandomTransfer(t *testing.T, account1, account2 Account) Transfer &#123; arg := createTransferParams&#123; FromAccountID: account1.ID, ToAccountID: account2.ID, Amount: util.RandomMoney(), &#125; transfer, err := testQueries.createTransfer(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, transfer) require.Equal(t, arg.FromAccountID, transfer.FromAccountID) require.Equal(t, arg.ToAccountID, transfer.ToAccountID) require.Equal(t, arg.Amount, transfer.Amount) require.NotZero(t, transfer.ID) require.NotZero(t, transfer.CreatedAt) return transfer&#125;func TestCreateTransfer(t *testing.T) &#123; account1 := createRandomAccount(t) account2 := createRandomAccount(t) createRandomTransfer(t, account1, account2)&#125;func TestGetTransfer(t *testing.T) &#123; account1 := createRandomAccount(t) account2 := createRandomAccount(t) transfer1 := createRandomTransfer(t, account1, account2) transfer2, err := testQueries.GetTransfer(context.Background(), transfer1.ID) require.NoError(t, err) require.NotEmpty(t, transfer2) require.Equal(t, transfer1.ID, transfer2.ID) require.Equal(t, transfer1.FromAccountID, transfer2.FromAccountID) require.Equal(t, transfer1.ToAccountID, transfer2.ToAccountID) require.Equal(t, transfer1.Amount, transfer2.Amount) require.WithinDuration(t, transfer1.CreatedAt.Time, transfer2.CreatedAt.Time, time.Second)&#125;func TestListTransfer(t *testing.T) &#123; account1 := createRandomAccount(t) account2 := createRandomAccount(t) for i := 0; i &lt; 5; i++ &#123; createRandomTransfer(t, account1, account2) createRandomTransfer(t, account2, account1) &#125; arg := ListTransfersParams&#123; FromAccountID: account1.ID, ToAccountID: account1.ID, Limit: 5, Offset: 5, &#125; transfers, err := testQueries.ListTransfers(context.Background(), arg) require.NoError(t, err) require.Len(t, transfers, 5) for _, transfer := range transfers &#123; require.NotEmpty(t, transfer) require.True(t, transfer.FromAccountID == account1.ID || transfer.ToAccountID == account1.ID) &#125;&#125; 十.db transactionBEGIN语句启动事务 成功 则更新数据库 失败 则回滚事务（保持原来的状态） ​ 代码对不上了 决定先复制粘贴 学习数据库中的知识点 先从config.go开始 十一.config.go使用viper 创建app.env文件存储配置信息 config.go 12345678910111213141516171819202122232425262728package utilimport ( &quot;github.com/spf13/viper&quot;)// Config stores all configuration of the application.// The values are read by viper from a config file or environment variable.type Config struct &#123; DATABASE_URL string `mapstructure:&quot;DATABASE_URL&quot;`&#125;// LoadConfig reads configuration from file or environment variables.func LoadConfig(path string) (config Config, err error) &#123; viper.AddConfigPath(path) viper.SetConfigName(&quot;app&quot;) viper.SetConfigType(&quot;env&quot;) viper.AutomaticEnv() err = viper.ReadInConfig() if err != nil &#123; return &#125; err = viper.Unmarshal(&amp;config) return&#125; 使用接口来简化一些操作好好学接口 目前为止更正了大部分问题接着往下学。。。。 store.test.go出现了大问题 报错： **Running tool: D:\\Go\\bin\\go.exe test -timeout 30s -run ^TestTransferTx$ project&#x2F;simplebank&#x2F;db&#x2F;sqlc &gt;&gt; before: 1984 3906 — FAIL: TestTransferTx (0.03s) e:\\projects\\simplebank\\db\\sqlc\\store_test.go:83: Error Trace: e:&#x2F;projects&#x2F;simplebank&#x2F;db&#x2F;sqlc&#x2F;store_test.go:83 Error: Should NOT be empty, but was {0 0 {0001-01-01 00:00:00 +0000 UTC finite false}} Test: TestTransferTx FAIL FAIL project&#x2F;simplebank&#x2F;db&#x2F;sqlc **0.571s 因为还没编写代码。。。。。草草草草操操操操哦哦操操操这视频叫我看的 十二.需要仔细处理并发 交易 以避免死锁数据库事务 12345678910111213141516Running tool: D:\\Go\\bin\\go.exe test -timeout 30s -run ^TestTransferTx$ project/simplebank/db/sqlc&gt;&gt; before: 6892 6969&gt;&gt; tx: 6882 6979&gt;&gt; tx: 6882 6989--- FAIL: TestTransferTx (0.04s) e:\\projects\\simplebank\\db\\sqlc\\store_test.go:102: Error Trace: e:/projects/simplebank/db/sqlc/store_test.go:102 Error: Not equal: expected: 10 actual : 20 Test: TestTransferTxFAILFAIL project/simplebank/db/sqlc 0.602sFAIL 这个问题出在 account.sql.go他无法阻止一些东西 123-- name: GetAccount :oneSELECT * FROM accountsWHERE id = $1 LIMIT 1; 在两个终端中并行运行两个事务来观察这个问题 BEGIN；开始事务 ROLLBACK；回滚事务 ：第一个终端 1234567891011121314simple_bank=# BEGIN;BEGINsimple_bank=# BEGIN;WARNING: there is already a transaction in progressBEGINsimple_bank=# ROLLBACK;ROLLBACKsimple_bank=# BEGIN;BEGINsimple_bank=# SELECT * FROM accounts WHERE id=1 FOR UPDATE; id | owner | balance | currency | created_at----+----------+---------+----------+---------------------------- 1 | xiaozhao | 100 | USD | 2024-10-08 09:03:03.272176(1 row) 第二个终端 12345simple_bank=# BEGIN;BEGINsimple_bank=# SELECT * FROM accounts WHERE id=1 FOR UPDATE;这里会被阻止 并且必须等待第一个事务提交或回滚 纠正方法1： 在sql中添加 ： 重新用make sqlc生成 1234-- name: GetAccountForUpdate :oneSELECT * FROM accountsWHERE id = $1 LIMIT 1FOR UPDATE; 但是接下来出现了死锁错误： 添加日志寻找错误 12345678910111213141516171819202122232425262728293031323334353637Running tool: D:\\Go\\bin\\go.exe test -timeout 30s -run ^TestTransferTx$ project/simplebank/db/sqlc&gt;&gt; before: 1826 5993tx 5 Create transfertx 5 Create entry 1tx 5 Create entry 2tx 5 get account 1tx 2 Create transfertx 5 update account 1tx 5 get account 2tx 4 Create transfertx 5 update account 2tx 3 Create transfertx 2 Create entry 1tx 4 Create entry 1tx 3 Create entry 1tx 1 Create transfertx 2 Create entry 2tx 4 Create entry 2tx 3 Create entry 2tx 2 get account 1tx 4 get account 1tx 3 get account 1&gt;&gt; tx: 1816 6003tx 1 Create entry 1tx 1 Create entry 2tx 1 get account 1--- FAIL: TestTransferTx (0.95s) e:\\projects\\simplebank\\db\\sqlc\\store_test.go:52: Error Trace: e:/projects/simplebank/db/sqlc/store_test.go:52 Error: Received unexpected error: ERROR: deadlock detected (SQLSTATE 40P01) Test: TestTransferTxFAILFAIL project/simplebank/db/sqlc 1.470sFAIL 终端事务出现错误： 1INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *; 第一个错误 INSERT INFO transfers 是语法错误，正确的语法是 INSERT INTO transfers。 第二个错误 INSERT INTO transfers (from_account_id to_account_id amount) 也存在语法错误，缺少逗号分隔列名。正确的写法是 INSERT INTO transfers (from_account_id, to_account_id, amount)。 当前事务已中止： 由于之前的 SQL 语句（可能是第一条插入语句）出错，事务被标记为 “aborted”。这意味着在该事务中的所有后续 SQL 命令都将失败，直到事务被回滚。 解决方法 结束当前事务： 在 PostgreSQL 中，你可以通过以下命令结束当前事务并回滚更改： 1ROLLBACK 终端阻塞 事务状态1234561. 确认当前事务状态在 PostgreSQL 中，如果一个事务因为某种原因（例如错误或未处理的异常）而中断，那么所有后续的 SQL 语句将会被忽略，直到你执行 ROLLBACK 或 COMMIT。首先，确保没有事务在进行中。你可以使用以下命令查看当前活动的事务：SELECT * FROM pg_stat_activity WHERE state = &#x27;active&#x27;; 1234567891011121314simple_bank=# INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *;^CCancel request sentERROR: canceling statement due to user requestCONTEXT: SQL statement &quot;SELECT 1 FROM ONLY &quot;public&quot;.&quot;accounts&quot; x WHERE &quot;id&quot; OPERATOR(pg_catalog.=) $1 FOR KEY SHARE OF x&quot;simple_bank=# SELECT * FROM pg_stat_activity WHERE state = &#x27;active&#x27;; datid | datname | pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | xact_start | query_start | state_change | wait_event_type | wait_event | state | backend_xid | backend_xmin | query | backend_type-------+-------------+-----+----------+---------+------------------+-------------+-----------------+-------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------+---------------+--------+-------------+--------------+---------------------------------------------------------------------------------------------+---------------- 16385 | simple_bank | 810 | 10 | root | psql | | | -1 | 2024-10-10 12:58:51.115963+00 | 2024-10-10 13:00:09.094842+00 | 2024-10-10 13:00:09.094842+00 | 2024-10-10 13:00:09.094867+00 | | | active | | 935 | SELECT * FROM pg_stat_activity WHERE state = &#x27;active&#x27;; | client backend 16385 | simple_bank | 802 | 10 | root | psql | | | -1 | 2024-10-10 12:58:07.854964+00 | 2024-10-10 12:58:09.850035+00 | 2024-10-10 12:58:09.850035+00 | 2024-10-10 12:58:09.850039+00 | Lock | tuple | active | 965 | 935 | INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *; | client backend 16385 | simple_bank | 782 | 10 | root | psql | | | -1 | 2024-10-10 12:51:58.685461+00 | 2024-10-10 12:57:47.014409+00 | 2024-10-10 12:57:47.014409+00 | 2024-10-10 12:57:47.014413+00 | Lock | tuple | active | 963 | 935 | INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *; | client backend 16385 | simple_bank | 775 | 10 | root | psql | | | -1 | 2024-10-10 12:51:51.971697+00 | 2024-10-10 12:52:16.478898+00 | 2024-10-10 12:57:54.280622+00 | 2024-10-10 12:57:54.280627+00 | Lock | tuple | active | 964 | 935 | INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *; | client backend 16385 | simple_bank | 556 | 10 | root | psql | | | -1 | 2024-10-10 11:29:44.776508+00 | 2024-10-10 11:56:11.909182+00 | 2024-10-10 11:56:24.551023+00 | 2024-10-10 11:56:24.551027+00 | Lock | transactionid | active | | 935 | SELECT * FROM accounts WHERE id=1 FOR UPDATE; | client backend 16385 | simple_bank | 638 | 10 | root | psql 从你提供的 pg_stat_activity 的查询结果来看，有多个活跃的事务正在等待锁。这可能是导致你无法执行 INSERT 操作的原因。以下是一些步骤，可以帮助你诊断并解决这个问题： 1. 识别并终止阻塞的事务你的查询结果显示了多个 INSERT 操作在等待锁。可以尝试强制终止这些阻塞的事务，以释放锁并允许你的操作继续进行。首先，记录下阻塞的 pid（进程 ID），然后使用以下命令终止它们： 1SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE pid IN (802, 782, 775); 在这个例子中，802、782 和 775 是阻塞的 pid。请根据你的实际情况调整这条命令。 2. 确认事务的状态如果终止了这些连接，确保你没有其他活跃的事务在运行。你可以再次运行以下命令确认： 1SELECT * FROM pg_stat_activity WHERE state = &#x27;active&#x27;; 3. 尝试再次执行插入在确保没有其他事务阻塞后，尝试重新执行你的插入操作： 1234567BEGIN; -- 开始新的事务INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1, 2, 10) RETURNING *; -- 执行插入COMMIT; -- 提交事务指令；SELECT * FROM accounts WHERE id=1 FOR UPDATE;UPDATE accounts SET balance = 600 WHERE id=1; 4. 如果问题依然存在如果问题依然存在，建议检查数据库的锁状态： 1SELECT * FROM pg_locks WHERE granted = false; 又产生错误 123456simple_bank=# SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE pid IN (802, 782, 775,556,638,810);FATAL: terminating connection due to administrator commandserver closed the connection unexpectedly This probably means the server terminated abnormally before or while processing the request.The connection to the server was lost. Attempting reset: Succeeded. 回答： 看起来你在尝试终止阻塞的连接时，PostgreSQL 服务器意外关闭了连接。这可能是由于以下几个原因： 服务器崩溃：可能是因为在终止连接时，某个后台进程遇到了问题，导致服务器崩溃。 资源不足：如果你的 PostgreSQL 服务器资源不足（例如内存或 CPU），在处理请求时可能会出现这种情况。 12345678910111213由于服务器崩溃，重启 Docker 容器可能会帮助你恢复连接：docker restart postgres12在重启后检查连接：重启后，尝试重新连接到数据库，并检查活动连接：SELECT * FROM pg_stat_activity;再次终止阻塞的连接：如果连接正常，尝试再次运行终止命令：SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE pid IN (802, 782, 775, git上传一个项目没有共同历史 12检查是否有共同历史git log --oneline --graph --all 12强制合并冲突git pull origin main --allow-unrelated-histories 终端1：在没有阻塞的情况下 1234567891011121314simple_bank=# BEGIN;BEGINsimple_bank=# SELECT * FROM accounts WHERE id=1 FOR UPDATE; id | owner | balance | currency | created_at----+----------+---------+----------+---------------------------- 1 | xiaozhao | 100 | USD | 2024-10-08 09:03:03.272176(1 row)simple_bank=# UPDATE accounts SET balance = 600 WHERE id=1;UPDATE 1simple_bank=# COMMIT;COMMITsimple_bank=# 在终端一提交事务时 终端二会显示出结果 1234567891011simple_bank=# BEGIN;BEGINsimple_bank=# SELECT * FROM accounts WHERE id=1 FOR UPDATE; id | owner | balance | currency | created_at----+----------+---------+----------+---------------------------- 1 | xiaozhao | 600 | USD | 2024-10-08 09:03:03.272176(1 row)simple_bank=# sql QUERIER 1234567891011121314BEGIN;INSERT INTO transfers (from_account_id,to_account_id,amount) VALUE (1,2,10) RETURNING *;INSERT INTO entries (account_id,amount) VALUES (1,-10) RETURNING *;INSERT INTO entries (account_id,amount) VALUES (2,10) RETURNING *;SELECT * FROM accounts WHERE id=1 FOR UPDATE;UPDATE accounts SET balance = 90 WHERE id = 1 RETURNING *;SELECT * FROM accounts WHERE id =2 FOR UPDATE;UPDATE accounts SET balance = 110 WHERE id = 2 RETURNING *;ROLLBACK; 5.postgres lock：帮助查询哪里有锁The following query may be helpful to see what processes are blocking SQL statements (these only find row-level locks, not object-level locks). 1234567891011121314151617181920212223SELECT blocked_locks.pid AS blocked_pid, blocked_activity.usename AS blocked_user, blocking_locks.pid AS blocking_pid, blocking_activity.usename AS blocking_user, blocked_activity.query AS blocked_statement, blocking_activity.query AS current_statement_in_blocking_process FROM pg_catalog.pg_locks blocked_locks JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid AND blocking_locks.pid != blocked_locks.pid JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid WHERE NOT blocked_locks.granted; 1SELECT * FROM accounts WHERE id=1 FOR UPDATE; 这条语句阻塞了 12345678910111213141516Here&#x27;s an alternate view of that same data that includes an idea how old the state is# 列出所有锁SELECT a.datname, l.relation::regclass, l.transactionid, //事务id l.mode, 锁的mod l.GRANTED, a.usename, who a.query, a.query_start, age(now(), a.query_start) AS &quot;age&quot;, a.pidFROM pg_stat_activity aJOIN pg_locks l ON l.pid = a.pidORDER BY a.query_start; 死锁是由外键约束引起的 1.删除约束 修改sql 1234-- name: GetAccountForUpdate :oneSELECT * FROM accountsWHERE id = $1 LIMIT 1FOR NO KEY UPDATE;//这步时解决死锁的关键 避免死锁是关键：微调事务中的查询 十三.隔离级别数据库事务必须满足 ACID 原子性 一致性 隔离性 持久性 Read Phenomenaa1.脏读当一个事务读取了 其他并发事务写入的尚未提交的数据（导致 如果尚未提交的数据 最终回滚 可能导致用到错误的数据 ） 2.不可重复读当一个事务两次读取到同一记录并看到不同的值 因为第一次读取后提交的其他事务修改 3.幻读影响多行 4.四种隔离级别READ UNCOMMITMED： 可以看到其他未提交事务写入的数据 READ COMMITED：只能看到其他事务已经提交的数据 REPEATABLE READ: SERIALIZABLE: 5.mysql选择隔离级别123set sexxion transaction isolation level read commited;select @@一种隔离级别 6.postgresql选择隔离级别 只有三个12345在postgresql中 未提交和已提交是一个级别show transaction isolation levelset transaction isolation level read uncommited 十四.持续集成或CI自动化构建和测试流程进行验证 1.Github Action首先上传项目到github时如果出现了连接问题 就切换成ssh连接 1234git remote set-url origin git@github.com:Whuichenggong/projects.gitPS E:\\projects&gt; git pull origin main --tagsFrom github.com:Whuichenggong/projects * branch main -&gt; FETCH_HEAD 创建文件 1echo. &gt; .github\\workflows\\ci.yml 安装工具 1golang migrate 但是目前我看不到页面我的action 十五.RESTful HEEP API1.创建api文件夹account.go 12345678910111213141516171819202122232425262728293031323334package apiimport ( &quot;net/http&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;github.com/gin-gonic/gin&quot;)type CreateAccountRequest struct &#123; Owner string `json:&quot;owner&quot; binding:&quot;required&quot;` Currency string `json:&quot;currency&quot; binding:&quot;required,oneof= USD EUR&quot;`&#125;func (server *Server) createAccount(ctx *gin.Context) &#123; var req CreateAccountRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; arg := db.CreateAccountParams&#123; Owner: req.Owner, Currency: req.Currency, Balance: 0, &#125; account, err := server.store.CreateAccount(ctx, arg) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; ctx.JSON(http.StatusOK, account)&#125; server.go 123456789101112131415161718192021222324252627282930313233343536package apiimport ( db &quot;project/simplebank/db/sqlc&quot; &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot;)type Server struct &#123; config util.Config store db.Store router *gin.Engine&#125;func NewServer(config util.Config, store db.Store) (*Server, error) &#123; server := &amp;Server&#123; config: config, store: store, &#125; router := gin.Default() router.POST(&quot;/accounts&quot;, server.createAccount) server.router = router return server, nil&#125;func errorResponse(err error) gin.H &#123; return gin.H&#123;&quot;error&quot;: err.Error()&#125;&#125;func (server *Server) Start(address string) error &#123; return server.router.Run(address)&#125; main.go 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( &quot;context&quot; &quot;log&quot; &quot;project/simplebank/api&quot; &quot;project/simplebank/util&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;github.com/jackc/pgx/v5/pgxpool&quot;)func main() &#123; config, err := util.LoadConfig(&quot;.&quot;) if err != nil &#123; log.Fatal(&quot;cannot load config:&quot;, err) &#125; connPool, err := pgxpool.New(context.Background(), config.DATABASE_URL) if err != nil &#123; log.Fatal(&quot;cannot connect to db:&quot;, err) &#125; //初始化数据库服务 store := db.NewStore(connPool) //运行gin框架 runGinServer(config, store) if err != nil &#123; log.Fatal(&quot;cannot start server:&quot;, err) &#125;&#125;func runGinServer(config util.Config, store db.Store) &#123; server, err := api.NewServer(config, store) if err != nil &#123; log.Fatalf(&quot;cannot create server: %v&quot;, err) &#125; err = server.Start(config.HTTPServerAddress) if err != nil &#123; log.Fatalf(&quot;cannot start server: %v&quot;, err) &#125;&#125; 数据库重置 1234567891011MySQL 数据库：使用 TRUNCATE TABLE 语句： TRUNCATE TABLE table_name; PostgreSQL 数据库：使用 TRUNCATE TABLE 语句： TRUNCATE TABLE table_name RESTART IDENTITY; TRUNCATE TABLE accounts, entries RESTART IDENTITY; 同时截断两个表 listaccount.go 用postman请求时：&#x2F;&#x2F;查询参数 page_id 1 page_size 5 在使用多组查找的时候没有找到用户？？？ 目前为止还是无法解决 找了喜春学哥帮我找到了问题的所在在ListAccounts中 传进去的arg.Owner是个空值导致了出现了问题 把arg.Owner改成一个数据库中具体的值 就能找到问题的所在 12func (q *Queries) ListAccounts(ctx context.Context, arg ListAccountsParams) ([]Account, error) &#123; rows, err := q.db.Query(ctx, listAccounts, arg.Owner/*问题所在*/, arg.Limit, arg.Offset) 2.模拟数据库测试1234使用mock go get github.com/golang/mock/mockgen@v1.6.0 PS E:\\projects\\simplebank\\db\\mock&gt; mockgen -destination db/mock/store.go project/simplebank/db/sqlc Store 3.account_test.go出现的问题 你提到的问题是由于 mock_sqlc.MockStore 未完全实现 db.Store 接口，特别是缺少 createTransfer 方法。为了解决这个问题，您可以采取以下步骤： 解决步骤： 确认 db.Store 接口的定义： 首先，确保 db.Store 接口定义了所有需要的方法。特别是，确认接口中是否包含 createTransfer 方法。 也就是： 1234567891011121314在你当前的测试代码中，store := mockdb.NewMockStore(ctrl) 返回的确实是 *mockdb.MockStore 类型，而 NewServer 需要的参数是 db.Store 接口类型。那么为什么没有类型错误呢？这是因为在 Go 中，接口是基于方法集实现的，而 *mockdb.MockStore 实现了 db.Store 接口中的所有方法。具体原因分析：接口实现方式：在 Go 语言中，接口并不关心你传递的具体类型（如 *mockdb.MockStore），它只关心该类型是否实现了接口中定义的所有方法。如果 *mockdb.MockStore 实现了 db.Store 接口的所有方法，那么它就可以被赋值给 db.Store 类型的变量。gomock 的自动生成：你使用 gomock 生成了 *mockdb.MockStore，这个 mock 类型会模拟 db.Store 接口的所有方法。因为它是通过 gomock 自动生成的，并且已经包含了 db.Store 中的所有方法，所以它实际上是符合 db.Store 接口的实现。类型匹配：在 Go 中，赋值 *mockdb.MockStore 给 db.Store 类型是可以的，因为 *mockdb.MockStore 实现了 db.Store 接口。即便 *mockdb.MockStore 是一个具体类型，只要它的方法集与 db.Store 接口的方法集匹配，Go 会认为它是一个合法的接口实现。为什么没有错误？由于 *mockdb.MockStore 实现了 db.Store 接口的所有方法，Go 编译器允许将 *mockdb.MockStore 传递给 NewServer 这个需要 db.Store 类型的函数参数。具体的原因是：NewMockStore 生成的 mock 类型实现了 db.Store 的所有方法，因此符合 db.Store 接口。在 Go 语言中，接口实现是隐式的，不需要显式声明实现接口，只要结构体的方法集与接口匹配即可。 方法 1：使用类型断言验证 在 Go 中，你可以通过静态类型检查来验证一个类型是否实现了某个接口。具体方法是使用以下代码： 1var _ db.Store = (*mockdb.MockStore)(nil) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package apiimport ( &quot;bytes&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;io&quot; &quot;net/http&quot; &quot;net/http/httptest&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;project/simplebank/util&quot; &quot;testing&quot; mockdb &quot;project/simplebank/db/mock&quot; &quot;github.com/golang/mock/gomock&quot; &quot;github.com/stretchr/testify/require&quot;)func TestGetAccountAPI(t *testing.T) &#123; config, err := util.LoadConfig(&quot;.&quot;) if err != nil &#123; fmt.Println(&quot;配置文件出错&quot;) &#125; //user, _ := randomUser(t) account := randomAccount() testCases := []struct &#123; name string accountID int64 //setupAuth func(t *testing.T, request *http.Request, tokenMaker token.Maker) buildStubs func(store *mockdb.MockStore) checkResponse func(t *testing.T, recoder *httptest.ResponseRecorder) &#125;&#123; &#123; name: &quot;OK&quot;, accountID: account.ID, // setupAuth: func(t *testing.T, request *http.Request, tokenMaker token.Maker) &#123; // addAuthorization(t, request, tokenMaker, authorizationTypeBearer, user.Username, user.Role, time.Minute) // &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT(). GetAccount(gomock.Any(), gomock.Eq(account.ID)). Times(1). Return(account, nil) &#125;, checkResponse: func(t *testing.T, recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusOK, recorder.Code) requireBodyMatchAccount(t, recorder.Body, account) &#125;, &#125;, &#125; for i := range testCases &#123; tc := testCases[i] t.Run(tc.name, func(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() store := mockdb.NewMockStore(ctrl) tc.buildStubs(store) server, _ := NewServer(config, store) recorder := httptest.NewRecorder() url := fmt.Sprintf(&quot;/accounts/%d&quot;, tc.accountID) request, err := http.NewRequest(http.MethodGet, url, nil) require.NoError(t, err) //tc.setupAuth(t, request, server.tokenMaker) server.router.ServeHTTP(recorder, request) tc.checkResponse(t, recorder) &#125;) &#125;&#125;func randomAccount() db.Account &#123; return db.Account&#123; ID: util.RandomInt(1, 1000), //Owner: owner, Balance: util.RandomMoney(), Currency: util.RandomCurrency(), &#125;&#125;func requireBodyMatchAccount(t *testing.T, body *bytes.Buffer, account db.Account) &#123; data, err := io.ReadAll(body) require.NoError(t, err) var gotAccount db.Account err = json.Unmarshal(data, &amp;gotAccount) require.NoError(t, err) require.Equal(t, account, gotAccount)&#125; 在这段代码中有不懂的地方 123456789store := mockdb.NewMockStore(ctrl) tc.buildStubs(store) server, _ := NewServer(config, store)store是 *mockdb.MockStore类型而func NewServer(config util.Config, store db.Store) (*Server, error) 需要的是db.store类型server, _ := NewServer(config, store)//我觉得这是自相矛盾 切片 123456789101112131415161718192021222324252627282930313233343536373839testCases := []struct &#123; name string accountID int64 //setupAuth func(t *testing.T, request *http.Request, tokenMaker token.Maker) buildStubs func(store *mockdb.MockStore) checkResponse func(t *testing.T, recoder *httptest.ResponseRecorder) &#125;&#123; &#123; name: &quot;OK&quot;, accountID: account.ID, // setupAuth: func(t *testing.T, request *http.Request, tokenMaker token.Maker) &#123; // addAuthorization(t, request, tokenMaker, authorizationTypeBearer, user.Username, user.Role, time.Minute) // &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT(). GetAccount(gomock.Any(), gomock.Eq(account.ID)). Times(1). Return(account, nil) &#125;, checkResponse: func(t *testing.T, recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusOK, recorder.Code) requireBodyMatchAccount(t, recorder.Body, account) &#125;, &#125;, &#123; name: &quot;NotFound&quot;, accountID: account.ID, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT(). GetAccount(gomock.Any(), gomock.Eq(account.ID)). Times(1). Return(db.Account&#123;&#125;, sql.ErrNoRows) &#125;, checkResponse: func(t *testing.T, recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusNotFound, recorder.Code) &#125;, &#125;, &#125; 目前的问题是notfound处理不符合预期 1234567891011121314151617&#123; name: &quot;NotFound&quot;, accountID: account.ID, setupAuth: func(t *testing.T, request *http.Request, tokenMaker token.Maker) &#123; addAuthorization(t, request, tokenMaker, authorizationTypeBearer, user.Username, user.Role, time.Minute) &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT(). GetAccount(gomock.Any(), gomock.Eq(account.ID)). Times(1). Return(db.Account&#123;&#125;, db.ErrRecordNotFound) &#125;, checkResponse: func(t *testing.T, recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusNotFound, recorder.Code)//我手动把 recorder.Code换成404jiu&#x27;cheng&#x27;gogn &#125;, &#125;, 4.transfer.goCurrency string json:&quot;currency&quot; binding:&quot;required,currency&quot; 添加了currency验证器 因为正常json不能识别USD等货币 实现思路 在go run mian.go后使用gin框架请求路由前 使用自己添加的数字验证器 在server.go中添加如下内容 12345678910111213141516171819202122232425262728293031323334353637383940// 自定义验证函数，检查 currency 是否为 &quot;USD&quot;func validCurrency(fl validator.FieldLevel) bool &#123; currency := fl.Field().String() return currency == &quot;USD&quot;&#125;// 注册自定义验证器func (server *Server) setupValidator() &#123; if v, ok := binding.Validator.Engine().(*validator.Validate); ok &#123; v.RegisterValidation(&quot;currency&quot;, validCurrency) &#125;&#125;func NewServer(config util.Config, store db.Store) (*Server, error) &#123; server := &amp;Server&#123; config: config, store: store, &#125; // 注册自定义验证器 server.setupValidator() router := gin.Default() router.POST(&quot;/accounts&quot;, server.createAccount) router.GET(&quot;/accounts/:id&quot;, server.getAccount) router.GET(&quot;/accounts&quot;, server.listAccount) router.POST(&quot;transfers&quot;, server.createTransfer) server.router = router return server, nil&#125;func errorResponse(err error) gin.H &#123; return gin.H&#123;&quot;error&quot;: err.Error()&#125;&#125;func (server *Server) Start(address string) error &#123; return server.router.Run(address)&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package apiimport ( &quot;errors&quot; &quot;fmt&quot; &quot;net/http&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;github.com/gin-gonic/gin&quot;)type transferRequest struct &#123; FromAccountID int64 `json:&quot;from_account&quot; binding:&quot;required,min=1&quot;` ToAccountID int64 `json:&quot;to_account&quot; binding:&quot;required,min=1&quot;` Amount int64 `json:&quot;amount&quot; binding:&quot;required,gt=0&quot;` Currency string `json:&quot;currency&quot; binding:&quot;required,currency&quot;`&#125;func (server *Server) createTransfer(ctx *gin.Context) &#123; var req transferRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; // 获取并处理 FromAccount fromAccount, valid := server.validAccount(ctx, req.FromAccountID, req.Currency) if !valid &#123; return &#125; // 获取并处理 ToAccount toAccount, valid := server.validAccount(ctx, req.ToAccountID, req.Currency) if !valid &#123; return &#125; arg := db.TransferTxParams&#123; FromAccountID: fromAccount.ID, ToAccountID: toAccount.ID, Amount: req.Amount, &#125; result, err := server.store.TransferTx(ctx, arg) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; ctx.JSON(http.StatusOK, result)&#125;// 检查id和货币func (server *Server) validAccount(ctx *gin.Context, accountID int64, currency string) (db.Account, bool) &#123; account, err := server.store.GetAccount(ctx, accountID) if err != nil &#123; if errors.Is(err, db.ErrRecordNotFound) &#123; ctx.JSON(http.StatusNotFound, errorResponse(err)) return account, false &#125; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return account, false &#125; if account.Currency != currency &#123; err := fmt.Errorf(&quot;account [%d] currency mismatch: %s vs %s&quot;, account.ID, account.Currency, currency) ctx.JSON(http.StatusBadRequest, errorResponse(err)) return account, false &#125; return account, true&#125; 用postman测试得到的内容 1234567891011121314151617181920212223242526272829303132333435&#123; &quot;transfer&quot;: &#123; &quot;id&quot;: 35, &quot;from_account_id&quot;: 3, &quot;to_account_id&quot;: 5, &quot;amount&quot;: 12, &quot;created_at&quot;: &quot;2024-10-20T04:53:01.433988Z&quot; &#125;, &quot;from_account&quot;: &#123; &quot;id&quot;: 3, &quot;owner&quot;: &quot;afmxtl&quot;, &quot;balance&quot;: 103, &quot;currency&quot;: &quot;USD&quot;, &quot;created_at&quot;: &quot;2024-10-13T13:33:43.423875Z&quot; &#125;, &quot;to_account&quot;: &#123; &quot;id&quot;: 5, &quot;owner&quot;: &quot;bdupue&quot;, &quot;balance&quot;: 119, &quot;currency&quot;: &quot;USD&quot;, &quot;created_at&quot;: &quot;2024-10-13T13:37:04.113466Z&quot; &#125;, &quot;from_entry&quot;: &#123; &quot;id&quot;: 45, &quot;account_id&quot;: 3, &quot;amount&quot;: -12, &quot;created_at&quot;: &quot;2024-10-20T04:53:01.433988Z&quot; &#125;, &quot;to_entry&quot;: &#123; &quot;id&quot;: 46, &quot;account_id&quot;: 5, &quot;amount&quot;: 12, &quot;created_at&quot;: &quot;2024-10-20T04:53:01.433988Z&quot; &#125;&#125; 十六.用户身份验证和授权1.建user数据库表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// Use DBML to define your database structure// Docs: https://dbml.dbdiagram.io/docsTable user as U&#123; username carchar [pk] hashed_paassword varchar [not null] full_name varchar [not null] email varchar [unique, not null] password_changed_at timestamp [not null, default: `0001-01-01 00:00:00Z`] create_at timestamptz [not null,default: `now()`]&#125;Table accounts as A &#123; id bigser [pk] owner varchar [ref:&gt; U.username,not null] balance bigint [not null] currency varchar [not null] created_at timestamp [not null,default: `now()`] Indexes &#123; (owner, currency) [unique] &#125;&#125;Table entries &#123; id bigint [pk] account_id bigint [ref : &gt; A.id,not null] amount bigint [not null] created_at timestamp [not null,default: `now()`] Indexes &#123; account_id&#125;&#125;Table transfers &#123; id bigint [pk] from_account_id bigint [ref : &gt; A.id,not null] to_account_id bigint [ref : &gt; A.id,not null] amount bigint [not null] created_at timestamp [not null,default: `now()`] Indexes &#123; from_account_id to_account_id (from_account_id,to_account_id)&#125;&#125; 新建数据库迁移： 1migrate create -ext sql -dir db/migration -seq add_users 出现了错误 12345678910111213141516171819make migrateupmigrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; -verbose up2024/10/20 15:11:16 Start buffering 2/u add_users2024/10/20 15:11:16 Read and execute 2/u add_users2024/10/20 15:11:16 error: migration failed: syntax error at or near &quot;00&quot; (column 69) in line 6: CREATE TABLE &quot;user&quot; ( &quot;username&quot; carchar PRIMARY KEY, &quot;hashed_paassword&quot; varchar NOT NULL, &quot;full_name&quot; varchar NOT NULL, &quot;email&quot; varchar UNIQUE NOT NULL, &quot;password_changed_at&quot; timestamp NOT NULL DEFAULT (0001-01-01 00:00:00Z), &quot;create_at&quot; timestamptz NOT NULL DEFAULT (now()));ALTER TABLE &quot;accounts&quot; ADD FOREIGN KEY (&quot;owner&quot;) REFERENCES &quot;user&quot; (&quot;username&quot;);--CREATE UNIQUE INDEX ON &quot;accounts&quot; (&quot;owner&quot;, &quot;currency&quot;);ALTER TABLE &quot;acounts&quot; ADD CONSTRAINT &quot;owner_currency-unique&quot; UNIQUE (&quot;owner&quot;, &quot;currency&quot;) (details: pq: syntax error at or near &quot;00&quot;)make: *** [migrateup] 错误 1 原因：违反了外键约束 十七.迁移失败原因sql语句写错了 IF写成ID **理解去除外键等 ** 2.问题：在执行数据库迁移时，出现的错误是因为在 accounts 表上有外键依赖 (transfers 表中的 transfers_from_account_id_fkey 和 transfers_to_account_id_fkey 约束依赖于 accounts 表)。当你尝试删除 accounts 表时，PostgreSQL 不允许删除这个表，因为还有其他表（如 transfers）依赖它。 但是执行了migrateup指令就会出现脏读现象 使得数据库版本变为2 所以我们要先回退到1版本 1234567make migratedownmigrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; -verbose down2024/10/20 15:15:34 Are you sure you want to apply all down migrations? [y/N]y2024/10/20 15:15:36 Applying all down migrations2024/10/20 15:15:36 error: Dirty database version 2. Fix and force version.make: *** [migratedown] 错误 1 修改迁移表的值为 FALSE：没管用 1234567891011执行migratedown操作时失败，并出现错误信息 “cannot drop table accounts because other objects depend on it”，这表明accounts表有其他数据库对象依赖于它。原因包括：transfers表中的外键约束引用了accounts表。直接删除含外键的表会引发错误。建议：修改迁移脚本，先删除依赖的对象，如约束、触发器、视图等。使用CASCADE选项强制删除所有依赖的对象。在 makefile 中为migrate命令添加条件检查。可能的迁移修正示例：DROP TABLE IF EXISTS transfers CASCADE;DROP TABLE IF EXISTS accounts; 3.解除外键约束1234567891011解决方案：你可以按以下步骤修改你的迁移文件，确保先删除外键约束，再删除相关的表。删除外键约束： 在迁移文件中，先删除 transfers 表中的外键约束：ALTER TABLE transfers DROP CONSTRAINT IF EXISTS transfers_from_account_id_fkey;ALTER TABLE transfers DROP CONSTRAINT IF EXISTS transfers_to_account_id_fkey;删除表： 然后，按顺序删除表：DROP TABLE IF EXISTS transfers;DROP TABLE IF EXISTS entries;DROP TABLE IF EXISTS accounts; migrate 出现的错误可能就是 把外键依赖删除然后在执行数据库迁移语句 有没有可能你在写数据库迁移的时候就没有在migratedown中加入 删除外键约束的语句呢从而导致这么麻烦？？？ 编写migratedown时操作是和migrateup相反的 1 4.问题：1234make migratedown1migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; -verbose down 12024/10/20 17:22:21 error: Dirty database version 1. Fix and force version.make: *** [migratedown1] 错误 1 这个错误信息表明数据库处于 “dirty” 状态，通常意味着上一次的迁移未成功完成，导致数据库的迁移版本与实际执行情况不一致。要解决这个问题，你可以尝试以下步骤： 5.解决：检查数据库的迁移状态 使用 migrate 查看当前的迁移状态，以确认哪个版本是 dirty： 1migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; version 这将显示当前数据库的版本号以及 dirty 状态。 强制迁移版本 使用 migrate force 命令将数据库状态恢复为干净的版本。你可以将其设置为版本 1，这样可以清除 “dirty” 标志，同时保留当前的版本号。 执行以下命令： 1migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; force 1 这个命令不会运行任何迁移，它只是将数据库的迁移版本重置为 1，同时将脏状态清除。 6.检查当前数据库中的约束名如果不确定数据库中的约束名，可以通过以下 SQL 查询当前表中的约束名称： 1SELECT conname FROM pg_constraint WHERE conrelid = &#x27;accounts&#x27;::regclass; 每条语句后面要写分号啊啊啊啊！！！！！ 十八. user_test.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package dbimport ( &quot;context&quot; util &quot;project/simplebank/util&quot; &quot;testing&quot; &quot;time&quot; &quot;github.com/stretchr/testify/require&quot;)func createRandomUser(t *testing.T) User &#123; arg := CreateUserParams&#123; Username: util.RandomOwner(), HashedPassword: &quot;secret&quot;, FullName: util.RandomOwner(), Email: util.RandomEmail(), &#125; user, err := testStore.CreateUser(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, user) require.Equal(t, arg.Username, user.Username) require.Equal(t, arg.HashedPassword, user.HashedPassword) require.Equal(t, arg.FullName, user.FullName) require.Equal(t, arg.Email, user.Email) require.NotZero(t, user.CreateAt) return user&#125;func TestCreateUser(t *testing.T) &#123; createRandomUser(t)&#125;func TestGetUser(t *testing.T) &#123; user1 := createRandomUser(t) user2, err := testStore.GetUser(context.Background(), user1.Username) require.NoError(t, err) require.NotEmpty(t, user2) require.Equal(t, user1.Username, user2.Username) require.Equal(t, user1.HashedPassword, user2.HashedPassword) require.Equal(t, user1.FullName, user2.FullName) require.Equal(t, user1.Email, user2.Email) require.WithinDuration(t, user1.PasswordChangedAt.Time, user2.PasswordChangedAt.Time, time.Second) require.WithinDuration(t, user1.CreateAt.Time, user2.CreateAt.Time, time.Second)&#125; 在第29行代码有一个断言语句判断 ： 1require.True(t, user.PasswordChangedAt.Time.IsZero()) 这个语句目前不能通过测试 往后看吧看看是么时候找到问题 1. 10.23外键约束问题运行真个包测试出现的问题 1这个外键错误提示 &quot;ERROR: insert or update on table&quot;accounts&quot;violates foreign key constraint&quot;accounts_owner_fkey&quot;(SQLSTATE 23503)&quot; 意味着在尝试往 &quot;accounts&quot; 表中插入或更新数据时违反了名为 &quot;accounts_owner_fkey&quot; 的外键约束。 应该是 一个用户链接到账户 这就是主表与副表的关系 设置外键 将两个表链接到一起 2.数据库表出现错误数据库语句就写错了 正常每个表的 id序列都应该是自增的 如果不是这样将会出现以下错误 1ERROR: null value in column &quot;id&quot; violates not-null constraint (SQLSTATE 23502) 我们要重新修改数据库迁移语句 12345678910111213141516171819202122232425262728293031323334353637383940414243CREATE TABLE &quot;accounts&quot; ( &quot;id&quot; bigserial PRIMARY KEY, &quot;owner&quot; varchar NOT NULL, &quot;balance&quot; bigint NOT NULL, &quot;currency&quot; varchar NOT NULL, &quot;created_at&quot; timestamptz NOT NULL DEFAULT (now()));CREATE TABLE &quot;entries&quot; ( &quot;id&quot; bigserial PRIMARY KEY, &quot;account_id&quot; bigint NOT NULL, &quot;amount&quot; bigint NOT NULL, &quot;created_at&quot; timestamptz NOT NULL DEFAULT (now()));CREATE TABLE &quot;transfers&quot; ( &quot;id&quot; bigserial PRIMARY KEY, &quot;from_account_id&quot; bigint NOT NULL, &quot;to_account_id&quot; bigint NOT NULL, &quot;amount&quot; bigint NOT NULL, &quot;created_at&quot; timestamptz NOT NULL DEFAULT (now()));ALTER TABLE &quot;entries&quot; ADD FOREIGN KEY (&quot;account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);ALTER TABLE &quot;transfers&quot; ADD FOREIGN KEY (&quot;from_account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);ALTER TABLE &quot;transfers&quot; ADD FOREIGN KEY (&quot;to_account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);CREATE INDEX ON &quot;accounts&quot; (&quot;owner&quot;);CREATE INDEX ON &quot;entries&quot; (&quot;account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;from_account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;to_account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;from_account_id&quot;, &quot;to_account_id&quot;);COMMENT ON COLUMN &quot;entries&quot;.&quot;amount&quot; IS &#x27;can be negative or positive&#x27;;COMMENT ON COLUMN &quot;transfers&quot;.&quot;amount&quot; IS &#x27;must be positive&#x27;; 修改过后 正常运行account_test.go 3.修改状态码12345678910111213141516account, err := server.store.CreateAccount(ctx, arg)if err != nil &#123; if pqErr, ok := err.(*pq.Error); ok &#123; switch pqErr.Code.Name() &#123; case &quot;foreign_key_violation&quot;, &quot;unique_violation&quot;: ctx.JSON(http.StatusForbidden, errorResponse(err)) return default: log.Println(pqErr.Code.Name()) &#125; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; ctx.JSON(http.StatusOK, account)&#125; 出现错误了 等待明天修改 10.24 将上述代码语句修改为 123456if err != nil &#123; errCode := db.ErrorCode(err) if errCode == db.ForeignKeyViolation || errCode == db.UniqueViolation &#123; ctx.JSON(http.StatusForbidden, errorResponse(err)) return &#125; 成功解决了问题 。 这是为什么呢？？ 应该是: 1if errCode == db.ForeignKeyViolation || errCode == db.UniqueViolation 这段代码起到了主要i作用 在error.go中 1234const ( ForeignKeyViolation = &quot;23503&quot; UniqueViolation = &quot;23505&quot;) 这代表了： 123ForeignKeyViolation 常量的值是 &quot;23503&quot;，它代表 PostgreSQL 中的一个错误代码。当执行的数据库操作违反外键约束时，会触发这个错误。外键约束保证了不同表之间的关系，如果尝试插入、更新或删除的数据并不能被其他表中的相关记录引用，就会抛出这个错误。UniqueViolation 常量的值是 &quot;23505&quot;，这也是一个 PostgreSQL 错误代码。当向需要唯一值的字段插入了重复的值时，会引发这个错误。违反唯一性约束意味着这样的操作将导致两个记录含有相同的值，这在数据库规则中通常是不允许的，因为唯一约束保护了记录唯一识别数据的能力。 十九.在数据库中安全的存储密码1.password.go1234567891011121314151617181920212223package utilimport ( &quot;fmt&quot; &quot;golang.org/x/crypto/bcrypt&quot;)func HashPassword(password string) (string, error) &#123; hashedPassword, err := bcrypt.GenerateFromPassword([]byte(password), bcrypt.DefaultCost) if err != nil &#123; return &quot;&quot;, fmt.Errorf(&quot;哈希加密失败:%w&quot;, err) &#125; return string(hashedPassword), nil&#125;// checkPasswordfunc CheckPassword(password string, hashedPassword string) error &#123; return bcrypt.CompareHashAndPassword([]byte(hashedPassword), []byte(password))&#125; 2.password_test.go1234567891011121314151617181920212223package utilimport ( &quot;testing&quot; &quot;github.com/stretchr/testify/require&quot; &quot;golang.org/x/crypto/bcrypt&quot;)func TestPassword(t *testing.T) &#123; password := RandomString(6) hashPassword, err := HashPassword(password) require.NoError(t, err) err = CheckPassword(password, hashPassword) require.NoError(t, err) wrongPassword := RandomString(6) err = CheckPassword(wrongPassword, hashPassword) require.EqualError(t, err, bcrypt.ErrMismatchedHashAndPassword.Error())&#125; 3.user.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package apiimport ( &quot;net/http&quot; db &quot;project/simplebank/db/sqlc&quot; util &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot;)type CreateUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,alphanum&quot;` FullName string `json:&quot;fullname&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot; binding:&quot;required,email&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6&quot;`&#125;func (server *Server) createUser(ctx *gin.Context) &#123; var req CreateUserRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; hashedPassword, err := util.HashedPassword(req.Password) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; arg := db.CreateUserParams&#123; Username: req.Username, FullName: req.FullName, Email: req.Email, HashedPassword: hashedPassword, &#125; account, err := server.store.CreateUser(ctx, arg) if err != nil &#123; errCode := db.ErrorCode(err) //此处只保留一个外键约束 if errCode == db.UniqueViolation &#123; ctx.JSON(http.StatusForbidden, errorResponse(err)) return &#125; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; ctx.JSON(http.StatusOK, account)&#125; 返回结果 12345678&#123; &quot;username&quot;: &quot;ZhongHe&quot;, &quot;hashed_password&quot;: &quot;$2a$10$RRGhHuYmPf9tRVPDckNI5.q6VJ1TzG9aFJ12edZglg7kp97vGwtKO&quot;, &quot;full_name&quot;: &quot;ZhongHe Zhao&quot;, &quot;email&quot;: &quot;zhaozhonghe40@gmail.com&quot;, &quot;password_changed_at&quot;: &quot;2024-10-24T07:14:46.169687Z&quot;, &quot;create_at&quot;: &quot;2024-10-24T07:14:46.169687Z&quot;&#125; 想让返回结果没有 这个字段 1&quot;hashed_password&quot;: &quot;$2a$10$RRGhHuYmPf9tRVPDckNI5.q6VJ1TzG9aFJ12edZglg7kp97vGwtKO&quot;, 添加 12345678type CreateUserResponse struct &#123; Username string `json:&quot;username&quot;` FullName string `json:&quot;full_name&quot;` Email string `json:&quot;email&quot;` PasswordChangedAt time.Time `json:&quot;password_changed_at&quot;` CreateAt time.Time `json:&quot;create_at&quot;`&#125; 123456789rsp := CreateUserResponse&#123; Username: user.Username, FullName: user.FullName, Email: user.Email, PasswordChangedAt: user.PasswordChangedAt.Time, CreateAt: user.CreateAt.Time, &#125; ctx.JSON(http.StatusOK, rsp) 二十.user_test.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package apiimport ( &quot;bytes&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;io&quot; &quot;net/http&quot; &quot;net/http/httptest&quot; &quot;reflect&quot; &quot;testing&quot; mockdb &quot;project/simplebank/db/mock&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot; &quot;github.com/golang/mock/gomock&quot; &quot;github.com/stretchr/testify/require&quot;)type eqCreateUserParamsMatcher struct &#123; arg db.CreateUserParams password string&#125;func (e eqCreateUserParamsMatcher) Matches(x interface&#123;&#125;) bool &#123; arg, ok := x.(db.CreateUserParams) if !ok &#123; return false &#125; err := util.CheckPassword(e.password, arg.HashedPassword) if err != nil &#123; return false &#125; e.arg.HashedPassword = arg.HashedPassword return reflect.DeepEqual(e.arg, arg)&#125;func (e eqCreateUserParamsMatcher) String() string &#123; return fmt.Sprintf(&quot;matches arg %v and password %v&quot;, e.arg, e.password)&#125;func EqCreateUserParams(arg db.CreateUserParams, password string) gomock.Matcher &#123; return eqCreateUserParamsMatcher&#123;arg, password&#125;&#125;func TestCreateUserAPI(t *testing.T) &#123; user, password := randomUser(t) testCases := []struct &#123; name string body gin.H buildStubs func(store *mockdb.MockStore) checkResponse func(recoder *httptest.ResponseRecorder) &#125;&#123; &#123; name: &quot;OK&quot;, body: gin.H&#123; &quot;username&quot;: user.Username, &quot;password&quot;: password, &quot;full_name&quot;: user.FullName, &quot;email&quot;: user.Email, &#125;, buildStubs: func(store *mockdb.MockStore) &#123; arg := db.CreateUserParams&#123; Username: user.Username, FullName: user.FullName, Email: user.Email, HashedPassword: user.HashedPassword, &#125; store.EXPECT(). CreateUser(gomock.Any(), EqCreateUserParams(arg, password)). Times(1). Return(user, nil) &#125;, checkResponse: func(recorder *httptest.ResponseRecorder) &#123; fmt.Printf(&quot;Response code: %d\\n&quot;, recorder.Code) require.Equal(t, http.StatusOK, recorder.Code) requireBodyMatchUser(t, recorder.Body, user) &#125;, &#125;, &#125; for i := range testCases &#123; tc := testCases[i] t.Run(tc.name, func(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() store := mockdb.NewMockStore(ctrl) tc.buildStubs(store) server := newTestServer(t, store) recorder := httptest.NewRecorder() // Marshal body data to JSON data, err := json.Marshal(tc.body) require.NoError(t, err) fmt.Printf(&quot;Request body: %s\\n&quot;, string(data)) // 打印请求体 url := &quot;/users&quot; request, err := http.NewRequest(http.MethodPost, url, bytes.NewReader(data)) require.NoError(t, err) server.router.ServeHTTP(recorder, request) tc.checkResponse(recorder) fmt.Printf(&quot;Request body: %v\\n&quot;, tc.body) &#125;) &#125;&#125;func randomUser(t *testing.T) (user db.User, password string) &#123; password = util.RandomString(6) hashedPassword, err := util.HashedPassword(password) require.NoError(t, err) user = db.User&#123; Username: util.RandomOwner(), HashedPassword: hashedPassword, FullName: util.RandomOwner(), Email: util.RandomEmail(), &#125; return&#125;func requireBodyMatchUser(t *testing.T, body *bytes.Buffer, user db.User) &#123; data, err := io.ReadAll(body) require.NoError(t, err) var gotUser db.User err = json.Unmarshal(data, &amp;gotUser) require.NoError(t, err) require.Equal(t, user.Username, gotUser.Username) require.Equal(t, user.FullName, gotUser.FullName) require.Equal(t, user.Email, gotUser.Email) require.Empty(t, gotUser.HashedPassword)&#125; gomock.Any()这个验证的 准确度太低 任何测试基本都能通过 解决方法 使用 新的自定义匹配器 1234567891011121314151617181920212223242526272829 type eqCreateUserParamsMatcher struct &#123; arg db.CreateUserParams password string&#125;func (e eqCreateUserParamsMatcher) Matches(x interface&#123;&#125;) bool &#123; arg, ok := x.(db.CreateUserParams) if !ok &#123; return false &#125; err := util.CheckPassword(e.password, arg.HashedPassword) if err != nil &#123; return false &#125; e.arg.HashedPassword = arg.HashedPassword return reflect.DeepEqual(e.arg, arg)&#125;func (e eqCreateUserParamsMatcher) String() string &#123; return fmt.Sprintf(&quot;matches arg %v and password %v&quot;, e.arg, e.password)&#125;func EqCreateUserParams(arg db.CreateUserParams, password string) gomock.Matcher &#123; return eqCreateUserParamsMatcher&#123;arg, password&#125;&#125; 1.问题长记性 json的字段名错误 我测试了一下午 123456type CreateUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,alphanum&quot;` FullName string `json:&quot;full_name&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot; binding:&quot;required,email&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6&quot;`&#125; FullName string json:&quot;full_name&quot; binding:&quot;required&quot;这里的json标签我把full_name 写成了fullname 二十一.JWT1.JSON Web令牌密钥算法 服务器一般使用RSA 和 RS256来验证令牌 对称算法 非对称算法 必须在服务器代码中 检查令牌的算法标头 JWT令牌的很多问题： RASETO作为替代JWT的安全方案 2.基于令牌的身份验证的工作原理是什么？基于令牌的身份验证从用户登录至系统、设备或应用程序开始，通常使用密码或安全问题。授权服务器验证初始身份验证，然后发放访问令牌，访问令牌是一小段数据，允许客户端应用程序向 API 服务器发出安全调用或信号。 基于令牌的身份验证的工作原理是为服务器提供第二种高度可靠的方式来验证用户的身份和请求的真实性。 完成该基于令牌的初始身份验证协议后，令牌就像盖了章的票据一样：用户可以在令牌生命周期内连续无缝访问相关资源，而无需重新进行身份验证。 该生命周期在用户注销或退出应用程序时结束，也可由设定的超时协议触发。 3.基于令牌的身份验证有何益处？基于令牌的身份验证能为多个利益相关者提供许多便利： 即时的用户体验：用户无需在每次返回系统、应用程序或网页时重新输入凭据并重新进行身份验证，只要令牌仍然有效（通常会持续到会话因注销或退出而结束），用户就可以保持即时访问。 增加了数字安全性：基于令牌的身份验证在传统的基于密码或基于服务器的身份验证之上又增加了一道安全保护。通常，令牌比密码更难被窃取、被黑客入侵或以其他方式泄露。 管理员控制：基于令牌的身份验证为管理员提供了对每个用户操作和事项的更精细的控制和可见性。 减轻技术负担：由于令牌生成可以与令牌验证完全分离，因此验证可以由辅助服务（如 Entrust 身份和访问管理解决方案提供的服务）来处理。这将显著减少内部服务器和设备上的负载。 二十二.编写令牌make.go123456789101112131415package tokenimport ( &quot;time&quot;)// Maker is an interface for managing tokenstype Maker interface &#123; // CreateToken creates a new token for a specific username and duration CreateToken(username string, role string, duration time.Duration) (string, *Payload, error) // VerifyToken checks if the token is valid or not VerifyToken(token string) (*Payload, error)&#125; payload.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package tokenimport ( &quot;errors&quot; &quot;time&quot; &quot;github.com/google/uuid&quot;)// Different types of error returned by the VerifyToken functionvar ( ErrInvalidToken = errors.New(&quot;token is invalid&quot;) ErrExpiredToken = errors.New(&quot;token has expired&quot;))// Payload contains the payload data of the tokentype Payload struct &#123; ID uuid.UUID `json:&quot;id&quot;` Username string `json:&quot;username&quot;` Role string `json:&quot;role&quot;` IssuedAt time.Time `json:&quot;issued_at&quot;` ExpiredAt time.Time `json:&quot;expired_at&quot;`&#125;// NewPayload creates a new token payload with a specific username and durationfunc NewPayload(username string, role string, duration time.Duration) (*Payload, error) &#123; tokenID, err := uuid.NewRandom() if err != nil &#123; return nil, err &#125; payload := &amp;Payload&#123; ID: tokenID, Username: username, Role: role, IssuedAt: time.Now(), ExpiredAt: time.Now().Add(duration), &#125; return payload, nil&#125;// Valid checks if the token payload is valid or notfunc (payload *Payload) Valid() error &#123; if time.Now().After(payload.ExpiredAt) &#123; return ErrExpiredToken &#125; return nil&#125; jwt_maker.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package tokenimport ( &quot;errors&quot; &quot;fmt&quot; &quot;time&quot; &quot;github.com/dgrijalva/jwt-go&quot;)const minSecretKeySize = 32// JWTMaker is a JSON Web Token makertype JWTMaker struct &#123; secretKey string&#125;// NewJWTMaker creates a new JWTMakerfunc NewJWTMaker(secretKey string) (Maker, error) &#123; if len(secretKey) &lt; minSecretKeySize &#123; return nil, fmt.Errorf(&quot;invalid key size: must be at least %d characters&quot;, minSecretKeySize) &#125; return &amp;JWTMaker&#123;secretKey&#125;, nil&#125;// CreateToken creates a new token for a specific username and durationfunc (maker *JWTMaker) CreateToken(username string, role string, duration time.Duration) (string, *Payload, error) &#123; payload, err := NewPayload(username, role, duration) if err != nil &#123; return &quot;&quot;, payload, err &#125; jwtToken := jwt.NewWithClaims(jwt.SigningMethodHS256, payload) token, err := jwtToken.SignedString([]byte(maker.secretKey)) return token, payload, err&#125;// VerifyToken checks if the token is valid or notfunc (maker *JWTMaker) VerifyToken(token string) (*Payload, error) &#123; keyFunc := func(token *jwt.Token) (interface&#123;&#125;, error) &#123; _, ok := token.Method.(*jwt.SigningMethodHMAC) if !ok &#123; return nil, ErrInvalidToken &#125; return []byte(maker.secretKey), nil &#125; jwtToken, err := jwt.ParseWithClaims(token, &amp;Payload&#123;&#125;, keyFunc) if err != nil &#123; verr, ok := err.(*jwt.ValidationError) if ok &amp;&amp; errors.Is(verr.Inner, ErrExpiredToken) &#123; return nil, ErrExpiredToken &#125; return nil, ErrInvalidToken &#125; payload, ok := jwtToken.Claims.(*Payload) if !ok &#123; return nil, ErrInvalidToken &#125; return payload, nil&#125; jwt_test.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package tokenimport ( &quot;testing&quot; &quot;time&quot; &quot;project/simplebank/util&quot; &quot;github.com/dgrijalva/jwt-go&quot; &quot;github.com/stretchr/testify/require&quot;)func TestJWTMaker(t *testing.T) &#123; maker, err := NewJWTMaker(util.RandomString(32)) require.NoError(t, err) username := util.RandomOwner() role := util.DepositorRole duration := time.Minute issuedAt := time.Now() expiredAt := issuedAt.Add(duration) token, err := maker.CreateToken(username, duration) require.NoError(t, err) require.NotEmpty(t, token) payload, err := maker.VerifyToken(token) require.NoError(t, err) require.NotEmpty(t, payload) require.NotZero(t, payload.ID) require.Equal(t, username, payload.Username) require.Equal(t, role, payload.Role) require.WithinDuration(t, issuedAt, payload.IssuedAt, time.Second) require.WithinDuration(t, expiredAt, payload.ExpiredAt, time.Second)&#125;func TestExpiredJWTToken(t *testing.T) &#123; maker, err := NewJWTMaker(util.RandomString(32)) require.NoError(t, err) token, err := maker.CreateToken(util.RandomOwner(), -time.Minute) require.NoError(t, err) require.NotEmpty(t, token) payload, err := maker.VerifyToken(token) require.Error(t, err) require.EqualError(t, err, ErrExpiredToken.Error()) require.Nil(t, payload)&#125;func TestInvalidJWTTokenAlgNone(t *testing.T) &#123; payload, err := NewPayload(util.RandomOwner(), time.Minute) require.NoError(t, err) jwtToken := jwt.NewWithClaims(jwt.SigningMethodNone, payload) token, err := jwtToken.SignedString(jwt.UnsafeAllowNoneSignatureType) require.NoError(t, err) maker, err := NewJWTMaker(util.RandomString(32)) require.NoError(t, err) payload, err = maker.VerifyToken(token) require.Error(t, err) require.EqualError(t, err, ErrInvalidToken.Error()) require.Nil(t, payload)&#125; 作者说 passeto是比JWT更简洁更好用 passeto_maker.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package tokenimport ( &quot;fmt&quot; &quot;time&quot; &quot;github.com/aead/chacha20poly1305&quot; &quot;github.com/o1egl/paseto&quot;)// PasetoMaker is a PASETO token makertype PasetoMaker struct &#123; paseto *paseto.V2 symmetricKey []byte&#125;// NewPasetoMaker creates a new PasetoMakerfunc NewPasetoMaker(symmetricKey string) (Maker, error) &#123; if len(symmetricKey) != chacha20poly1305.KeySize &#123; return nil, fmt.Errorf(&quot;invalid key size: must be exactly %d characters&quot;, chacha20poly1305.KeySize) &#125; maker := &amp;PasetoMaker&#123; paseto: paseto.NewV2(), symmetricKey: []byte(symmetricKey), &#125; return maker, nil&#125;// CreateToken creates a new token for a specific username and durationfunc (maker *PasetoMaker) CreateToken(username string, duration time.Duration) (string, error) &#123; payload, err := NewPayload(username, duration) if err != nil &#123; return &quot;&quot;, err &#125; return maker.paseto.Encrypt(maker.symmetricKey, payload, nil)&#125;// VerifyToken checks if the token is valid or notfunc (maker *PasetoMaker) VerifyToken(token string) (*Payload, error) &#123; payload := &amp;Payload&#123;&#125; err := maker.paseto.Decrypt(token, maker.symmetricKey, payload, nil) if err != nil &#123; return nil, ErrInvalidToken &#125; err = payload.Valid() if err != nil &#123; return nil, err &#125; return payload, nil&#125; paseto_make_test.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package tokenimport ( &quot;testing&quot; &quot;time&quot; &quot;project/simplebank/util&quot; &quot;github.com/stretchr/testify/require&quot;)func TestPasetoMaker(t *testing.T) &#123; maker, err := NewJWTMaker(util.RandomString(32)) require.NoError(t, err) username := util.RandomOwner() duration := time.Minute issuedAt := time.Now() expiredAt := issuedAt.Add(duration) token, err := maker.CreateToken(username, duration) require.NoError(t, err) require.NotEmpty(t, token) payload, err := maker.VerifyToken(token) require.NoError(t, err) require.NotEmpty(t, payload) require.NotZero(t, payload.ID) require.Equal(t, username, payload.Username) require.WithinDuration(t, issuedAt, payload.IssuedAt, time.Second) require.WithinDuration(t, expiredAt, payload.ExpiredAt, time.Second)&#125;func TestExpiredPasetoToken(t *testing.T) &#123; maker, err := NewPasetoMaker(util.RandomString(32)) require.NoError(t, err) token, err := maker.CreateToken(util.RandomOwner(), -time.Minute) require.NoError(t, err) require.NotEmpty(t, token) payload, err := maker.VerifyToken(token) require.Error(t, err) require.EqualError(t, err, ErrExpiredToken.Error()) require.Nil(t, payload)&#125;//None算法 10.28学习如何用令牌登录api1.server.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package apiimport ( &quot;fmt&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;project/simplebank/token&quot; &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot; &quot;github.com/gin-gonic/gin/binding&quot; &quot;github.com/go-playground/validator/v10&quot;)type Server struct &#123; config util.Config store db.Store router *gin.Engine tokenMaker token.Maker&#125;// 自定义验证函数，检查 currency 是否为 &quot;USD&quot;func validCurrency(fl validator.FieldLevel) bool &#123; currency := fl.Field().String() return currency == &quot;RMB&quot;&#125;// 注册自定义验证器func (server *Server) setupValidator() &#123; if v, ok := binding.Validator.Engine().(*validator.Validate); ok &#123; v.RegisterValidation(&quot;currency&quot;, validCurrency) &#125;&#125;func NewServer(config util.Config, store db.Store) (*Server, error) &#123; tokenMaker, err := token.NewPasetoMaker(config.TokenSymmetricKey) if err != nil &#123; fmt.Printf(&quot;Key length in bytes: %d\\n&quot;, len([]byte(config.TokenSymmetricKey))) return nil, fmt.Errorf(&quot;cannot create token maker: %w&quot;, err) &#125; server := &amp;Server&#123; config: config, store: store, tokenMaker: tokenMaker, &#125; // 注册自定义验证器 server.setupValidator() server.setupRouter() return server, nil&#125;func (server *Server) setupRouter() &#123; router := gin.Default() router.POST(&quot;/users/login&quot;, server.loginUser) router.POST(&quot;transfers&quot;, server.createTransfer) router.POST(&quot;/accounts&quot;, server.createAccount) router.GET(&quot;/accounts/:id&quot;, server.getAccount) router.POST(&quot;/users&quot;, server.createUser) router.GET(&quot;/accounts&quot;, server.listAccounts) server.router = router&#125;func errorResponse(err error) gin.H &#123; return gin.H&#123;&quot;error&quot;: err.Error()&#125;&#125;func (server *Server) Start(address string) error &#123; return server.router.Run(address)&#125; 2.user.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package apiimport ( &quot;errors&quot; &quot;fmt&quot; &quot;net/http&quot; &quot;time&quot; db &quot;project/simplebank/db/sqlc&quot; util &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot; //&quot;github.com/jackc/pgtype&quot;)type CreateUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,alphanum&quot;` FullName string `json:&quot;full_name&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot; binding:&quot;required,email&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6&quot;`&#125;type UserResponse struct &#123; Username string `json:&quot;username&quot;` FullName string `json:&quot;full_name&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot;` PasswordChangedAt time.Time `json:&quot;password_changed_at&quot;` CreateAt time.Time `json:&quot;create_at&quot;`&#125;func newUserResponse(user db.User) UserResponse &#123; return UserResponse&#123; Username: user.Username, FullName: user.FullName, Email: user.Email, PasswordChangedAt: user.PasswordChangedAt.Time, CreateAt: user.CreateAt.Time, &#125;&#125;func (server *Server) createUser(ctx *gin.Context) &#123; var req CreateUserRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; fmt.Printf(&quot;Received request: %+v\\n&quot;, req) // 打印请求体 hashedPassword, err := util.HashedPassword(req.Password) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(fmt.Errorf(&quot;failed to hash password: %v&quot;, err))) return &#125; arg := db.CreateUserParams&#123; Username: req.Username, FullName: req.FullName, Email: req.Email, HashedPassword: hashedPassword, &#125; user, err := server.store.CreateUser(ctx, arg) if err != nil &#123; fmt.Printf(&quot;Error creating user: %v\\n&quot;, err) // 打印错误 errCode := db.ErrorCode(err) //此处只保留一个外键约束 if errCode == db.UniqueViolation &#123; return &#125; ctx.JSON(http.StatusForbidden, errorResponse(err)) return &#125; rsp := newUserResponse(user) ctx.JSON(http.StatusOK, rsp)&#125;type loginUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,alphanum&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6&quot;`&#125;type loginUserResponse struct &#123; AccessToken string `json:&quot;access_token&quot;` User UserResponse `json:&quot;user&quot;`&#125;func (server *Server) loginUser(ctx *gin.Context) &#123; var req loginUserRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; user, err := server.store.GetUser(ctx, req.Username) if err != nil &#123; if errors.Is(err, db.ErrRecordNotFound) &#123; ctx.JSON(http.StatusNotFound, errorResponse(err)) return &#125; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; err = util.CheckPassword(req.Password, user.HashedPassword) if err != nil &#123; ctx.JSON(http.StatusUnauthorized, errorResponse(err)) return &#125; accessToken, err := server.tokenMaker.CreateToken( user.Username, server.config.AccessTokenDuration, ) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; rsp := loginUserResponse&#123; AccessToken: accessToken, User: newUserResponse(user), &#125; ctx.JSON(http.StatusOK, rsp)&#125; 3.问题1为什么运行transfer_text.go出现了很多错误： 4.解决1在学习的时候图方便把作者的代码全部拉了下来 在transfer_test.go中 有很多情况 在transfer中并没有实现 导致无法对应这些情况 正常时作者留给你的任务 让你去课后实现这些功能 重新回顾第13集： 模拟数据库进行测试： 确保模拟数据库实现与真是数据库相同的接口 出问题的两段代码： 123456789101112131415161718192021222324252627282930313233343536&#123; name: &quot;UnauthorizedUser&quot;, body: gin.H&#123; &quot;from_account_id&quot;: account1.ID, &quot;to_account_id&quot;: account2.ID, &quot;amount&quot;: amount, &quot;currency&quot;: util.RandomCurrency(), &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT().GetAccount(gomock.Any(), gomock.Eq(account1.ID)).Times(1).Return(account1, nil) store.EXPECT().GetAccount(gomock.Any(), gomock.Eq(account2.ID)).Times(0) store.EXPECT().TransferTx(gomock.Any(), gomock.Any()).Times(0) &#125;,checkResponse: func(recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusUnauthorized, recorder.Code) &#125;,&#125;,&#123; name: &quot;NoAuthorization&quot;, body: gin.H&#123; &quot;from_account_id&quot;: account1.ID, &quot;to_account_id&quot;: account2.ID, &quot;amount&quot;: amount, &quot;currency&quot;: util.USD, &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT().GetAccount(gomock.Any(), gomock.Any()).Times(0) store.EXPECT().TransferTx(gomock.Any(), gomock.Any()).Times(0)&#125;, checkResponse: func(recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusUnauthorized, recorder.Code) &#125;,&#125;, 5.问题2为什么得到分组用户出错 6.解决21234567891011121314151617181920212223242526//为什么得到分页的时候用户为空 错误出现在这里func (q *Queries) ListAccounts(ctx context.Context, arg ListAccountsParams) ([]Account, error) &#123; rows, err := q.db.Query(ctx, listAccounts, arg.Owner, arg.Limit, arg.Offset) if err != nil &#123; return nil, err &#125; defer rows.Close() items := []Account&#123;&#125; for rows.Next() &#123; var i Account if err := rows.Scan( &amp;i.ID, &amp;i.Owner, &amp;i.Balance, &amp;i.Currency, &amp;i.CreatedAt, ); err != nil &#123; return nil, err &#125; items = append(items, i) &#125; if err := rows.Err(); err != nil &#123; return nil, err &#125; return items, nil&#125; rows, err :&#x3D; q.db.Query(ctx, listAccounts, arg.Owner, arg.Limit, arg.Offset) 这里查询的条件有arg.owner 但是我们在测试的时候并没有设置owner 可以显示尝试把owner去掉 11.6日 二十二.身份验证中间件 授权API请求使用make sqlc 和 make mock 重新为listAccount增加 Owner字段 搞了半天 app.env配置错了 应该是 ACCESS_TOKEN_DURATION&#x3D;15m 我写成别的了 二十三.部署目前的程序1.对程序进行docker化运用git部署 注意：永远不要将更改直接推送到主分支 1.创建新分支-》推送分支-》产生以下结果-》复制url-》创建标题-》创建拉取请求-》从而可以看到 Files changed 文件的更改 1234567remote: Resolving deltas: 100% (2/2), completed with 2 local objects.remote: remote: Create a pull request for &#x27;ft/docker&#x27; on GitHub by visiting:remote: https://github.com/Whuichenggong/projects/pull/new/ft/dockerremote:To github.com:Whuichenggong/projects.git * [new branch] ft/docker -&gt; ft/docker 重新回看第10集 配置工作流 最近这两天了解到了工作流有了更深的理解 1234567891011121314151617181920212223242526272829# This workflow will build a golang project# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-goname: Goon: push: branches: [ &quot;main&quot; ] pull_request: branches: [ &quot;main&quot; ]jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Set up Go uses: actions/setup-go@v4 with: go-version: &#x27;1.20&#x27; - name: Build run: go build -v ./... - name: Test run: go test -v ./... go语言的工作流模板 giuthub action 相当于将一些列配置放到了github上的一个服务器上 也就是相当于将东西放进了github的服务器 11.10日还是github action问题 终于把 Install golang-migrate解决了 因为： 在最开始推送项目到github的时候 就是因为把项目结构推送错了 ，导致推送到github上的项目根目录没有go.mod文件这造成了很大的错误 导致一直失败 今天又解决了 install golang-migrate问题 因为sudo mv migrate &#x2F;usr&#x2F;bin&#x2F;migrate 把之前的 名称换成 migrate就好用了 问题2： make migratedown migrate -path &#x2F;db&#x2F;migration -database “postgresql:&#x2F;&#x2F;root:secret@localhost:5432&#x2F;simple_bank?sslmode&#x3D;disable” -verbose down 2024&#x2F;11&#x2F;10 13:30:17 error: open &#x2F;db&#x2F;migration.: The system cannot find the path specified. make: *** [migratedown] 错误 1 在Makefile中的指令的 路径又弄错了 必须让指令能找到位置所在 卧槽：成功了 绿了 妈的 牛逼 Dockerfile官方镜像 Dockerfile 123456789# Build stageFROM golang:1.16-alpine3.13 WORKDIR /appCOPY . .RUN go build -o main main.goEXPOSE 8080 CMD [ &quot;/app/main&quot; ] docker build -t simplebank:latest 使用这个指令构建镜像 images的大小很大 123docker images REPOSITORY TAG IMAGE ID CREATED SIZEsimplebank latest 48621dad3f4d 5 minutes ago 656MB 分阶段构建可以减少体积 也就是 123456789101112131415# Build stage 构建二进制文件FROM golang:1.23-alpine3.20 AS buildWORKDIR /appCOPY . .RUN go build -o main main.go# Production stage 生产环境FROM alpine:3.20WORKDIR /appCOPY --from=build /app/main .EXPOSE 8080 CMD [ &quot;/app/main&quot; ] 最终体积 123docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEsimplebank latest f64691fae70e 7 seconds ago 27.1MB 123456789101112131415161718192021222324252627282930313233docker ps -a列出容器状态docker rmi f64691fae70eUntagged: simplebank:latestDeleted: sha256:f64691fae70e516b799ed846bbeef10045388dae1932ecafc8b93fb208b403f0//运行这条指令便启动了容器 监听8080端口 docker run --name simplebank -p 8080:8080 simplebank:latest[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production. - using env: export GIN_MODE=release - using code: gin.SetMode(gin.ReleaseMode)[GIN-debug] POST /users --&gt; project/simplebank/api.(*Server).createUser-fm (3 handlers)[GIN-debug] POST /users/login --&gt; project/simplebank/api.(*Server).loginUser-fm (3 handlers)[GIN-debug] GET /accounts/:id --&gt; project/simplebank/api.(*Server).getAccount-fm (4 handlers)[GIN-debug] POST /accounts --&gt; project/simplebank/api.(*Server).createAccount-fm (4 handlers)[GIN-debug] GET /accounts --&gt; project/simplebank/api.(*Server).listAccounts-fm (4 handlers)[GIN-debug] POST /transfers --&gt; project/simplebank/api.(*Server).createTransfer-fm (4 handlers)[GIN-debug] [WARNING] You trusted all proxies, this is NOT safe. We recommend you to set a value.Please check https://pkg.go.dev/github.com/gin-gonic/gin#readme-don-t-trust-all-proxies for details.[GIN-debug] Listening and serving HTTP on 127.0.0.1:1124//重新启动镜像PS E:\\projects\\simplebank&gt; docker rm simplebanksimplebankPS E:\\projects\\simplebank&gt; docker run --name simplebank -p 8080:8080 -e GIN_MODE=release simplebank:latest这样启动就不会有上面的输出了 docker container inspect postgres12 检查网络设置 11.13日问题：解决用docker启动后 无法用postman测试接口的问题 1docker run --name simplebank -p 8083:8083 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simplebank?sslmode=disable&quot; simplebank:latest 每次修改完dockerfiles或者什么 要记住重新构建镜像 1docker build --no-cache -t simplebank:latest . 关键：先使用调试功能 查看是否正确监听端口 12345678910111213141516docker run --name simplebank -p 8080:8080 simplebank:latest[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production. - using env: export GIN_MODE=release - using code: gin.SetMode(gin.ReleaseMode)[GIN-debug] POST /users --&gt; project/simplebank/api.(*Server).createUser-fm (3 handlers)[GIN-debug] POST /users/login --&gt; project/simplebank/api.(*Server).loginUser-fm (3 handlers)[GIN-debug] GET /accounts/:id --&gt; project/simplebank/api.(*Server).getAccount-fm (4 handlers)[GIN-debug] POST /accounts --&gt; project/simplebank/api.(*Server).createAccount-fm (4 handlers)[GIN-debug] GET /accounts --&gt; project/simplebank/api.(*Server).listAccounts-fm (4 handlers)[GIN-debug] POST /transfers --&gt; project/simplebank/api.(*Server).createTransfer-fm (4 handlers)[GIN-debug] [WARNING] You trusted all proxies, this is NOT safe. We recommend you to set a value.Please check https://pkg.go.dev/github.com/gin-gonic/gin#readme-don-t-trust-all-proxies for details.[GIN-debug] Listening and serving HTTP on 0.0.0.0:8080 这次在测试的时候 有了反应 12PS E:\\projects\\simplebank&gt; docker run --name simplebank -p 8080:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simplebank?sslmode=disable&quot; simplebank:latest[GIN] 2024/11/13 - 01:17:23 | 401 | 39.567µs | 172.17.0.1 | GET &quot;/accounts/1&quot; 此更改导致了postgres连接出错 #####不使用ip地址使用用户定义的网络 连接到postrges docker network ls 1234567NETWORK ID NAME DRIVER SCOPEca0046b2c82c bank-network bridge localcf35f34026f7 bridge bridge local1500c05159ef host host local074a556122c6 none null localfafb76e1721e start_gvb-network bridge local 桥接网络 查看更详细的网络信息docker network inspect bridge 删除网络: docker network rm 0fd871187ef1 创建自己的网络&#96;&#96;docker network create bank_network&#96; 1`0fd871187ef1e3b3bee37ac898e895cf54615e267bd6af9d7b2c045fc5178a14 连接创建的网络docker network connect bank-network 将postrges12 连接到我们创建的网络 docker network connect bank-network postgres12 docker network inspect bank-network 得先启动 postrges12验证 postgres12 容器是否正在运行： 检查 named 的容器是否正在运行：postgres12 1docker ps -a 查找具有名称的容器并检查其状态。如果容器未运行，请启动容器：postgres12 1docker start postgres12 再次将 postgres12 连接到网络： 现在，尝试将容器连接到 ：postgres12``bank-network 1docker network connect bank-network postgres12 现在已经成功添加了postrges12 12345678&quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;7ba14f6dd2f7a81db9264c0814e9686e921b0d86c01b2df325dad4a1cca35c40&quot;: &#123; &quot;Name&quot;: &quot;postgres12&quot;, &quot;EndpointID&quot;: &quot;b3dc1614431f2f11f2b0d6c8bb7f33b529baacefa39521bf522c84a7f526a882&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; 此时查看 docker container inspect postgres12 这个容器将会有两段网络 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&quot;NetworkSettings&quot;: &#123; &quot;Bridge&quot;: &quot;&quot;, &quot;SandboxID&quot;: &quot;2ea1e674576863a5e20fe6dda2a3ea265dd11b0223dc4a94bbfa23c57adc66d9&quot;, &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/2ea1e6745768&quot;, &quot;Ports&quot;: &#123; &quot;5432/tcp&quot;: [ &#123; &quot;HostIp&quot;: &quot;0.0.0.0&quot;, &quot;HostPort&quot;: &quot;5432&quot; &#125; ] &#125;, &quot;HairpinMode&quot;: false, &quot;LinkLocalIPv6Address&quot;: &quot;&quot;, &quot;LinkLocalIPv6PrefixLen&quot;: 0, &quot;SecondaryIPAddresses&quot;: null, &quot;SecondaryIPv6Addresses&quot;: null, &quot;EndpointID&quot;: &quot;d85289ea4f7ca088375523781a14955e1b1fc58e5af731fe7f4c48fecba470e6&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;Networks&quot;: &#123; &quot;bank-network&quot;: &#123; &quot;IPAMConfig&quot;: &#123;&#125;, &quot;Links&quot;: null, &quot;Aliases&quot;: [ &quot;7ba14f6dd2f7&quot; ], &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;NetworkID&quot;: &quot;ca0046b2c82ccb1fe4c996950a815d9c374c58514921c9b919899d8169cb9881&quot;, &quot;EndpointID&quot;: &quot;b3dc1614431f2f11f2b0d6c8bb7f33b529baacefa39521bf522c84a7f526a882&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot;, &quot;IPAddress&quot;: &quot;172.18.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;DriverOpts&quot;: &#123;&#125;, &quot;DNSNames&quot;: [ &quot;postgres12&quot;, &quot;7ba14f6dd2f7&quot; ] &#125;, &quot;bridge&quot;: &#123; &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;NetworkID&quot;: &quot;cf35f34026f787fe91864d7e7a2ab23d482b6a6b956a10d596ae0d9818aa7e16&quot;, &quot;EndpointID&quot;: &quot;d85289ea4f7ca088375523781a14955e1b1fc58e5af731fe7f4c48fecba470e6&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;DriverOpts&quot;: null, &quot;DNSNames&quot;: null &#125; &#125; &#125; 重新使用指令 docker run --name simplebank --network bank-network -p 8080:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simplebank?sslmode=disable&quot; simplebank:latest 此时 simplebank容器将与postgres12运行在同一个网络上 将172.17.0.2替换成postgres12 因为可以通过名称访问网络 启动容器指令： 12docker run --name simplebank --network bank-network -p 8080:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@postgres12:5432/simplebank?sslmode=disable&quot; simplebank:latest[GIN] 2024/11/13 - 02:06:27 | 400 | 105.754µs | 172.18.0.1 | POST &quot;/users/login&quot; docker network inspect bank-network 1234567891011121314151617181920212223242526272829303132333435363738394041424344[ &#123; &quot;Name&quot;: &quot;bank-network&quot;, &quot;Id&quot;: &quot;ca0046b2c82ccb1fe4c996950a815d9c374c58514921c9b919899d8169cb9881&quot;, &quot;Created&quot;: &quot;2024-05-10T13:32:42.557489581Z&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;7ba14f6dd2f7a81db9264c0814e9686e921b0d86c01b2df325dad4a1cca35c40&quot;: &#123; &quot;Name&quot;: &quot;postgres12&quot;, &quot;EndpointID&quot;: &quot;b3dc1614431f2f11f2b0d6c8bb7f33b529baacefa39521bf522c84a7f526a882&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;a76e19ef1c210d1cc4f458ed9b2238db810872417e0a1072e8467dda82663a2a&quot;: &#123; &quot;Name&quot;: &quot;simplebank&quot;, &quot;EndpointID&quot;: &quot;487f3ec81ada3bf84e44af700d0ae930075ce8c683755d789c27cadc7f95ed06&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125; 目前有两个容器在自定义的网络中运行 之后的postrges就可以正常使用了 更改Makefile文件 12postgres: docker run --name postgres12 --network bank-network -p 5432:5432 -e POSTGRES_USER=root -e POSTGRES_PASSWORD=secret -d postgres:12-alpine 在github中 pullrequest中可以查看更改 并且 merge 分支到主分支-》然后确认合并—》Delete branch 二十四.docker-composehttps://docs.docker.com 创建docker-compose.yaml文件 123456789101112131415161718192021 version: &quot;3.9&quot;services: postgres: image: postgres:12-alpine environment: - POSTGRES_USER=root - POSTGRES_PASSWORD=secret - POSTGRES_DB=simple_bank ports: - &quot;5432:5432&quot; api: build: context: . dockerfile: Dockerfile ports: - &quot;8080:8080&quot; environment: - DB_SOURCE=postgresql://root:secret@postgres:5432/simple_bank?sslmode=disable docker compose up 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 docker compose up[+] Running 1/0 ✔ Container simplebank-api-1 Created 0.0s Attaching to api-1, postgres-1api-1 | [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.api-1 |api-1 | [GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production.api-1 | - using env: export GIN_MODE=releaseapi-1 | - using code: gin.SetMode(gin.ReleaseMode)api-1 |api-1 | [GIN-debug] POST /users --&gt; project/simplebank/api.(*Server).createUser-fm (3 handlers)api-1 | [GIN-debug] POST /users/login --&gt; project/simplebank/api.(*Server).loginUser-fm (3 handlers)api-1 | [GIN-debug] GET /accounts/:id --&gt; project/simplebank/api.(*Server).getAccount-fm (4 handlers)api-1 | [GIN-debug] POST /accounts --&gt; project/simplebank/api.(*Server).createAccount-fm (4 handlers)api-1 | [GIN-debug] GET /accounts --&gt; project/simplebank/api.(*Server).listAccounts-fm (4 handlers)api-1 | [GIN-debug] POST /transfers --&gt; project/simplebank/api.(*Server).createTransfer-fm (4 handlers)api-1 | [GIN-debug] [WARNING] You trusted all proxies, this is NOT safe. We recommend you to set a value.api-1 | Please check https://pkg.go.dev/github.com/gin-gonic/gin#readme-don-t-trust-all-proxies for details.api-1 | [GIN-debug] Listening and serving HTTP on 0.0.0.0:8080postgres-1 | The files belonging to this database system will be owned by user &quot;postgres&quot;.postgres-1 | This user must also own the server process.postgres-1 |postgres-1 | The database cluster will be initialized with locale &quot;en_US.utf8&quot;.postgres-1 | The default database encoding has accordingly been set to &quot;UTF8&quot;.postgres-1 | The default text search configuration will be set to &quot;english&quot;.postgres-1 |postgres-1 | Data page checksums are disabled.postgres-1 |postgres-1 | fixing permissions on existing directory /var/lib/postgresql/data ... okpostgres-1 | creating subdirectories ... okpostgres-1 | selecting dynamic shared memory implementation ... posixpostgres-1 | selecting default max_connections ... 100postgres-1 | selecting default shared_buffers ... 128MBpostgres-1 | selecting default time zone ... UTCpostgres-1 | creating configuration files ... okpostgres-1 | running bootstrap script ... okpostgres-1 | sh: locale: not foundpostgres-1 | 2024-11-13 06:50:42.795 UTC [30] WARNING: no usable system locales were foundpostgres-1 | performing post-bootstrap initialization ... okpostgres-1 | syncing data to disk ... okpostgres-1 |postgres-1 |postgres-1 | Success. You can now start the database server using:postgres-1 |postgres-1 | pg_ctl -D /var/lib/postgresql/data -l logfile startpostgres-1 |postgres-1 | initdb: warning: enabling &quot;trust&quot; authentication for local connectionspostgres-1 | You can change this by editing pg_hba.conf or using the option -A, orpostgres-1 | --auth-local and --auth-host, the next time you run initdb.postgres-1 | waiting for server to start....2024-11-13 06:50:43.144 UTC [36] LOG: starting PostgreSQL 12.18 on x86_64-pc-linux-musl, compiled by gcc (Alpine 13.2.1_git20231014) 13.2.1 20231014, 64-bitpostgres-1 | 2024-11-13 06:50:43.146 UTC [36] LOG: listening on Unix socket &quot;/var/run/postgresql/.s.PGSQL.5432&quot;postgres-1 | 2024-11-13 06:50:43.160 UTC [37] LOG: database system was shut down at 2024-11-13 06:50:43 UTCpostgres-1 | 2024-11-13 06:50:43.164 UTC [36] LOG: database system is ready to accept connectionspostgres-1 | donepostgres-1 | server startedpostgres-1 | CREATE DATABASEpostgres-1 |postgres-1 |postgres-1 | /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*postgres-1 |postgres-1 | waiting for server to shut down....2024-11-13 06:50:43.315 UTC [36] LOG: received fast shutdown requestpostgres-1 | 2024-11-13 06:50:43.316 UTC [36] LOG: aborting any active transactionspostgres-1 | 2024-11-13 06:50:43.318 UTC [36] LOG: background worker &quot;logical replication launcher&quot; (PID 43) exited with exit code 1postgres-1 | 2024-11-13 06:50:43.318 UTC [38] LOG: shutting downpostgres-1 | 2024-11-13 06:50:43.330 UTC [36] LOG: database system is shut downpostgres-1 | donepostgres-1 | server stoppedpostgres-1 |postgres-1 | PostgreSQL init process complete; ready for start up.postgres-1 |postgres-1 | 2024-11-13 06:50:43.447 UTC [1] LOG: starting PostgreSQL 12.18 on x86_64-pc-linux-musl, compiled by gcc (Alpine 13.2.1_git20231014) 13.2.1 20231014, 64-bitpostgres-1 | 2024-11-13 06:50:43.447 UTC [1] LOG: listening on IPv4 address &quot;0.0.0.0&quot;, port 5432postgres-1 | 2024-11-13 06:50:43.447 UTC [1] LOG: listening on IPv6 address &quot;::&quot;, port 5432postgres-1 | 2024-11-13 06:50:43.450 UTC [1] LOG: listening on Unix socket &quot;/var/run/postgresql/.s.PGSQL.5432&quot;postgres-1 | 2024-11-13 06:50:43.461 UTC [51] LOG: database system was shut down at 2024-11-13 06:50:43 UTCpostgres-1 | 2024-11-13 06:50:43.465 UTC [1] LOG: database system is ready to accept connections 构建镜像完成后 1234docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEsimplebank-api latest eb772c9e932f 6 hours ago 27.1MBsimplebank latest 9f145f0ce89f 6 hours ago 27.1MB 查看占用端口的进程 1234567891011121314`netstat -ano | findstr :5432` TCP 0.0.0.0:5432 0.0.0.0:0 LISTENING 30352 TCP [::]:5432 [::]:0 LISTENING 30352 TCP [::1]:5432 [::]:0 LISTENING 35464PS E:\\projects\\simplebank&gt; `tasklist /FI &quot;PID eq 30352&quot;``映像名称 PID 会话名 会话# 内存使用========================= ======== ================ =========== ============com.docker.backend.exe 30352 Console 2 117,104 KPS E:\\projects\\simplebank&gt; `tasklist /FI &quot;PID eq 35464&quot;``映像名称 PID 会话名 会话# 内存使用========================= ======== ================ =========== ============wslrelay.exe 35464 Console 2 8,328 K 在 Windows 上（终止进程）： 12taskkill /PID 30352 /Ftaskkill /PID 35464 /F docker ps 123CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESdab18d564f9c postgres:12-alpine &quot;docker-entrypoint.s…&quot; About an hour ago Up 7 minutes 0.0.0.0:5432-&gt;5432/tcp simplebank-postgres-1c4c37a8a870a simplebank-api &quot;/app/main&quot; About an hour ago Up 7 minutes 0.0.0.0:8080-&gt;8080/tcp simplebank-api-1 docker network inspect simplebank_default 两个服务容器实际在同一个网络上运行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 docker network inspect simplebank_default[ &#123; &quot;Name&quot;: &quot;simplebank_default&quot;, &quot;Id&quot;: &quot;fab69439b1a55525d81fa70d9e789c3b6d51ba8d7899924deb8413fb724ca951&quot;, &quot;Created&quot;: &quot;2024-11-13T05:28:49.358856507Z&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.20.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.20.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;c4c37a8a870a75e9fa626c7034dd935c8f3afdb86c5e2c37b012503bff9c7ab7&quot;: &#123; &quot;Name&quot;: &quot;simplebank-api-1&quot;, &quot;EndpointID&quot;: &quot;8a247db55db70983d6b2d619caef09bf2593964daa02be5773448fbd74f9d791&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:14:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.20.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;dab18d564f9c4554ef255e50205be2f4dd9c1fada3391dde698d7717d0e642ff&quot;: &#123; &quot;Name&quot;: &quot;simplebank-postgres-1&quot;, &quot;EndpointID&quot;: &quot;2b9220ab1bcc031b29631a2ecb462a48a475a722b10592c478124c03d95e29df&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:14:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.20.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123; &quot;com.docker.compose.network&quot;: &quot;default&quot;, &quot;com.docker.compose.project&quot;: &quot;simplebank&quot;, &quot;com.docker.compose.version&quot;: &quot;2.24.6&quot; &#125; &#125;] docker compose down 删除现在所有网络 Dockerfile 1234567891011121314151617# Build stage 构建二进制文件FROM golang:1.23-alpine3.20 AS buildWORKDIR /appCOPY . .RUN go build -o main main.go# Run stage FROM alpine:3.20WORKDIR /appCOPY --from=build /app/main .COPY app.env .# 这一步可以解决2024/11/13 08:08:06 cannot load config:Config File &quot;app&quot; Not Found in &quot;[/app]&quot;EXPOSE 8080 CMD [ &quot;/app/main&quot; ] 操 最后一刻验证成功了 用终端输入指令 带入参数 172.17.0.2 这样 viper可以自动读取配置 1234docker run --name simplebank -p 8080:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simple_bank?sslmode=disable&quot; simplebank:latestReceived request: &#123;Username:Zhonghe FullName:zhaohzonghe Email:3041322213@qq.com Password:zzh123456&#125;[GIN] 2024/11/13 - 12:54:07 | 200 | 57.106456ms | 172.17.0.1 | POST &quot;/users&quot; app.env中的配置 12345DATABASE_URL=postgres://root:secret@localhost:5432/simple_bank?sslmode=disableMIGRATION_URL=project/simplebank/db/migrationHTTPServerAddress=0.0.0.0:8080TOKEN_SYMMETRIC_KEY=12345678901234567890123456789012ACCESS_TOKEN_DURATION=15m 11.18日docker ps docker network inspect simplebank_default 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES81aa7c463a58 postgres:12-alpine &quot;docker-entrypoint.s…&quot; About a minute ago Up About a minute 0.0.0.0:5432-&gt;5432/tcp simplebank-postgres-1047f0bb9fbc8 simplebank-api &quot;/app/main&quot; About a minute ago Up About a minute 0.0.0.0:8080-&gt;8080/tcp simplebank-api-1PS E:\\projects\\simplebank&gt; [ &#123; &quot;Name&quot;: &quot;simplebank_default&quot;, &quot;Id&quot;: &quot;9afc6c5d5e9252f2161f204008596b067fceecd49ac5a9171910c58f4717e205&quot;, &quot;Created&quot;: &quot;2024-11-18T11:05:59.526768414Z&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;047f0bb9fbc8fdbe07cc311b134c00ff27cb0a2cbcb4322746a6b30cbbb404bf&quot;: &#123; &quot;Name&quot;: &quot;simplebank-api-1&quot;, &quot;EndpointID&quot;: &quot;b607176500386abe6ac7ad27f31d9c453a3f2087dacade426d50a72b1e30b585&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;81aa7c463a58ad777dd3d99f9ba3c442c024c02d0f91be924903ffa423f99426&quot;: &#123; &quot;Name&quot;: &quot;simplebank-postgres-1&quot;, &quot;EndpointID&quot;: &quot;ce4ec4fda5631c27ba1e8c96503ef86f1bfea3bc8f563ecf7528c75ca91f1bb6&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123; &quot;com.docker.compose.network&quot;: &quot;default&quot;, &quot;com.docker.compose.project&quot;: &quot;simplebank&quot;, &quot;com.docker.compose.version&quot;: &quot;2.24.6&quot; &#125; &#125;] 两个服务器运行在同一个网络 通过名字彼此发现自己 123456789101112131415&quot;Containers&quot;: &#123; &quot;047f0bb9fbc8fdbe07cc311b134c00ff27cb0a2cbcb4322746a6b30cbbb404bf&quot;: &#123; &quot;Name&quot;: &quot;simplebank-api-1&quot;, &quot;EndpointID&quot;: &quot;b607176500386abe6ac7ad27f31d9c453a3f2087dacade426d50a72b1e30b585&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;81aa7c463a58ad777dd3d99f9ba3c442c024c02d0f91be924903ffa423f99426&quot;: &#123; &quot;Name&quot;: &quot;simplebank-postgres-1&quot;, &quot;EndpointID&quot;: &quot;ce4ec4fda5631c27ba1e8c96503ef86f1bfea3bc8f563ecf7528c75ca91f1bb6&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; 目前是链接不上数据库的因为没有执行数据库迁移 重新构建docker-compose docker files文件 docker compose down[+] Running 3&#x2F;3✔ Container simplebank-postgres-1 Removed 0.7s✔ Container simplebank-api-1 Removed 0.6s✔ Network simplebank_default Removed 删除目前所有容器和网络 使用docker rmi …. 删除simplebank_api镜像 出错ERROR [api internal] load metadata for docker.io&#x2F;library&#x2F;builder:latest 错误的核心在于 tar 解压的文件名与你 mv 命令中期望的文件名不匹配。具体表现为 tar 解压生成的文件名并不是 migrate.linux-amd64，而是 migrate。 解决方法1. 修改 RUN 命令中的文件名引用 根据错误日志，tar 解压后生成的文件名是 migrate，而非 migrate.linux-amd64。因此，mv 命令应改为直接操作 migrate： 12dockerfile复制代码RUN curl -L https://github.com/golang-migrate/migrate/releases/download/v4.17.0/migrate.linux-amd64.tar.gz \\ | tar -xz &amp;&amp; mv migrate /app/migrate 这将确保正确地将解压出的 migrate 文件移动到 /app/migrate。 2. 验证文件解压和路径 为了确保过程正确，可以在 RUN 指令中加入调试信息以打印文件列表： 12dockerfile复制代码RUN curl -L https://github.com/golang-migrate/migrate/releases/download/v4.17.0/migrate.linux-amd64.tar.gz \\ | tar -xz &amp;&amp; ls -l &amp;&amp; mv migrate /app/migrate 原因：要保持 builer同意 我写成了一个build 另一个builder 因该换成build 12COPY --from=build /app/main .COPY --from=build /app/migrate /usr/bin/migrate 欧克解决了 完整的 dockerfile 1234567891011121314151617181920212223# Build stageFROM golang:1.23-alpine3.20 AS buildWORKDIR /appCOPY . .RUN go build -o main main.goRUN apk add curlRUN curl -L https://github.com/golang-migrate/migrate/releases/download/v4.17.0/migrate.linux-amd64.tar.gz | tar xvz &amp;&amp; mv migrate /app/migrate # Run stageFROM alpine:3.20WORKDIR /appCOPY --from=build /app/main .COPY --from=build /app/migrate /usr/bin/migrateCOPY app.env .COPY start.sh . COPY db/migration ./migrationEXPOSE 8080 CMD [ &quot;/app/main&quot; ]ENTRYPOINT [ &quot;/app/start.sh&quot; ] 完整的 docker-compose.yaml 12345678910111213141516171819202122version: &quot;3.9&quot;services: postgres: image: postgres:12-alpine environment: - POSTGRES_USER=root - POSTGRES_PASSWORD=secret - POSTGRES_DB=simple_bank ports: - &quot;5432:5432&quot; api: build: context: . dockerfile: Dockerfile ports: - &quot;8080:8080&quot; environment: - DB_SOURCE=postgresql://root:secret@postgres:5432/simple_bank?sslmode=disable depends_on: - postgres 下载wait-for工具 mv &quot;C:\\Users\\30413\\Downloads\\wait-for&quot; ./wait-for.sh 目前测试api问题： 123&#123; &quot;error&quot;: &quot;failed to connect to `user=root database=simple_bank`:\\n\\t127.0.0.1:5432 (localhost): dial error: dial tcp 127.0.0.1:5432: connect: connection refused\\n\\t[::1]:5432 (localhost): dial error: dial tcp [::1]:5432: connect: cannot assign requested address&quot;&#125; 二.11.22日解决上次的问题无论怎么样构建无法用postman接口调试 这是因为 你在 star.sh中 12345678910#!/bin/shset -eecho &quot;run db migrations&quot;/app/migrate -path /app/migration -database &quot;$DB_SOURCE&quot; -verbose upecho &quot;start the app&quot;exec &quot;$@&quot; 解决 使用的连接数据库的 参数是 $DB_SOURCE” 但是你在app.env中配置的名字不是DB_SOURCE 是DATABASE_URL 这种错误造成的原因可能是目前你并不了解一些列的工具是如何真正使用的没有真正了解 之前的配置 都是用DATABASE_URL来配置的 12345DATABASE_URL=postgres://root:secret@localhost:5432/simple_bank?sslmode=disableMIGRATION_URL=project/simplebank/db/migrationHTTPServerAddress=0.0.0.0:8080TOKEN_SYMMETRIC_KEY=12345678901234567890123456789012ACCESS_TOKEN_DURATION=15m 更改为 DB_SOURCE后api测试成功 三.11.23日部署应用程序 创建AWS(最大的云提供商)账户部署应用程序地址 https://aws.amazon.com/free/ emmm不知道银行卡的cvv 自动构建docker镜像并推送到AWS ECR1.创建一个存储库存储docker镜像 将docker 镜像推送到CLI每当新代码合并到主分支时 我们将使用 Github Actions自动构建标记和推送镜像 deploy.yml 关键 目前没有招商卡无法使用AWS 先使用快过期的aliyun试一试 添加go到linux环境 12345678echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin[root@iZt4nbaeq7uzlvq978l1xqZ simplebank]# ^C[root@iZt4nbaeq7uzlvq978l1xqZ simplebank]# export PATH=$PATH:/usr/local/go/bin[root@iZt4nbaeq7uzlvq978l1xqZ simplebank]# go run main.gogo: downloading github.com/jackc/pgx/v5 v5.7.1go: downloading github.com/gin-gonic/gin v1.10.0 四.11.29日 尝试在仅剩5个月的服务器中 把这个简单的项目部署到服务器上 配置服务器的docker的yum源 否则下载东西很费劲 设置国内镜像【不设置可能会导致拉取镜像失败】进入&#x2F;etc&#x2F;docker文件夹下，修改daemon.json。如果文件不存在则，创建该文件。 daemon.json文件内容如下 123456789101112131415&#123;&quot;registry-mirrors&quot; : [ &quot;https://jkfdsf2u.mirror.aliyuncs.com&quot;, &quot;https://registry.docker-cn.com&quot; ], &quot;insecure-registries&quot; : [ &quot;docker-registry.zjq.com&quot; ], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;10m&quot;, &quot;max-file&quot;: &quot;10&quot; &#125;, &quot;data-root&quot;: &quot;/data/docker&quot;&#125; 拉取docker pull镜像 123docker pull postgres:12-alpine 。。。。 配置不够cpu直接干到100% 看看有没有 简化的方法 11.30日 还是执着一点 弄了一台2核2gb的服务器 用docker部署 首先是源的配置 安装docker 安装docker-compose 然后是构建项目中出现的问题 反复构建 赋予权限等 权限问题在ubuntu中也是一个很重要的问题 哪个用户使用ubuntu也会导致不同的结果 123456789从 ls -ld 命令的输出可以看到，/home/ubuntu/projects/simplebank 目录的所有者和所属组都是 ubuntu，权限也允许当前用户进行访问。这意味着该目录的所有权和权限没有问题。但根据 Git 提示的错误信息，Git 依然检测到目录的所有权问题，因此需要添加该目录到 安全目录 列表中。解决方案：运行以下命令，将该目录添加到 Git 的安全目录列表中：git config --global --add safe.directory /home/ubuntu/projects/simplebank 看到希望了 12345root@VM-12-4-ubuntu:/home/ubuntu/projects/simplebank# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESroot@VM-12-4-ubuntu:/home/ubuntu/projects/simplebank# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES758e9432d178 e054039bb12c &quot;/app/start.sh /app/…&quot; 27 minutes ago Created 0.0.0.0:8080-&gt;8080/tcp, :::8080-&gt;8080/tcp simplebank 还需要配置数据库吗？？我有点蒙了 docker run与docker start的区别 五.2024年 11.30日 21：27分 成了把项目成功部署到了云服务器上太不容易了 12345678root@VM-12-4-ubuntu:/home/ubuntu/projects/simplebank# docker run --name simplebank -p 80:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simple_bank?sslmode=disable&quot; simplebank:latestrun db migrations2024/11/30 13:25:56 no change2024/11/30 13:25:56 Finished after 977.24µs2024/11/30 13:25:56 Closing source and databasestart the appReceived request: &#123;Username:Zhonghe FullName:zhaohzonghe Email:3041322213@qq.com Password:zzh123456&#125;[GIN] 2024/11/30 - 13:26:07 | 200 | 75.179039ms | 202.97.179.126 | POST &quot;/users&quot; 为什么把端口8080:8080改成 80:8080就好用了 啊啊啊啊好兴奋 感谢老哥们 从把项目移动到 ubuntu 配置dockers环境 使用docker build构建项目 然后就是用postman测试 这期间 多次使用的 Docker 指令docker run docker images docker ps -a docekr pull docker build -t simplebank:latest . docker network create bank_network docker network rm 0fd871187ef1 docker rm simplebank docker rmi docker network connect bank-network postgres12 docker network ls docker container inspect postgres12 目前服务器中的 postgres12大体网络模式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485root@VM-12-4-ubuntu:/home/ubuntu/projects/simplebank# docker container inspect postgres12[ &#123; &quot;Id&quot;: &quot;100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47&quot;, &quot;Created&quot;: &quot;2024-11-30T09:24:02.785101065Z&quot;, &quot;Path&quot;: &quot;docker-entrypoint.sh&quot;, &quot;Args&quot;: [ &quot;postgres&quot; ], &quot;State&quot;: &#123; &quot;Status&quot;: &quot;running&quot;, &quot;Running&quot;: true, &quot;Paused&quot;: false, &quot;Restarting&quot;: false, &quot;OOMKilled&quot;: false, &quot;Dead&quot;: false, &quot;Pid&quot;: 315509, &quot;ExitCode&quot;: 0, &quot;Error&quot;: &quot;&quot;, &quot;StartedAt&quot;: &quot;2024-11-30T11:54:14.985494404Z&quot;, &quot;FinishedAt&quot;: &quot;2024-11-30T11:35:40.792853655Z&quot; &#125;, &quot;Image&quot;: &quot;sha256:486566ce0ca8f59e321b2b5999de4b50237b2c60bcc3414d8a602fb96cb12c6f&quot;, &quot;ResolvConfPath&quot;: &quot;/data/docker/containers/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47/resolv.conf&quot;, &quot;HostnamePath&quot;: &quot;/data/docker/containers/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47/hostname&quot;, &quot;HostsPath&quot;: &quot;/data/docker/containers/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47/hosts&quot;, &quot;LogPath&quot;: &quot;/data/docker/containers/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47-json.log&quot;, &quot;Name&quot;: &quot;/postgres12&quot;, &quot;RestartCount&quot;: 0, &quot;Driver&quot;: &quot;overlay2&quot;, &quot;Platform&quot;: &quot;linux&quot;, &quot;MountLabel&quot;: &quot;&quot;, &quot;ProcessLabel&quot;: &quot;&quot;, &quot;AppArmorProfile&quot;: &quot;docker-default&quot;, &quot;ExecIDs&quot;: null, &quot;HostConfig&quot;: &#123; &quot;Binds&quot;: null, &quot;ContainerIDFile&quot;: &quot;&quot;, &quot;LogConfig&quot;: &#123; &quot;Type&quot;: &quot;json-file&quot;, &quot;Config&quot;: &#123; &quot;max-file&quot;: &quot;10&quot;, &quot;max-size&quot;: &quot;10m&quot; &quot;Networks&quot;: &#123; &quot;bank_network&quot;: &#123; &quot;IPAMConfig&quot;: &#123;&#125;, &quot;Links&quot;: null, &quot;Aliases&quot;: [], &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;DriverOpts&quot;: &#123;&#125;, &quot;NetworkID&quot;: &quot;c2a3ada685148d5607a5a6fc39e1690e5fbd161f0607df5a3a189f74ced100fa&quot;, &quot;EndpointID&quot;: &quot;07a57c58250657bf968d33d1f93cea6e9225d0cae314648d1b1c639c3811c9c1&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot;, &quot;IPAddress&quot;: &quot;172.18.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;DNSNames&quot;: [ &quot;postgres12&quot;, &quot;100ff1a5f0bf&quot; ] &#125;, &quot;bridge&quot;: &#123; &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;DriverOpts&quot;: null, &quot;NetworkID&quot;: &quot;83e7fddfe207131e6199fb11fb5daa38bf044b67817fba2de02bd7f1639d4bb8&quot;, &quot;EndpointID&quot;: &quot;d9449d910f4e7be735031acb301f0e418999b091bb8c75450fecf983eca2aa24&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;DNSNames&quot;: null &#125; &#125; &#125; &#125;] 还是看跟着课程走一走吧 AWS的EKS 将工作节点 添加到EKS集群 使用 kubectl 连接到集群 如何创建新的EKS集群并向其中添加工作节点大多都是用AWS目前没有卡还是先不要弄了 学习一下其他的知识 进阶后端master haha 管理用户会话 用PASETO JWT作为基于令牌的身份验证 因为这些是无状态设计 这些令牌不会存储到数据库中 寿命应该很短 他们的过期时间通常为10~15分钟 如果token每次都在这么短时间过期重新输入用户名和密码一定不是一个好的体验 刷新令牌 在服务器上维护有状态的会话 它将存储在数据库中 生命周期长 创建一个新的字段添加到app.env中 REFRESH_TOKEN_DURATION&#x3D;24h 同时config中添加新字段 RefreshTokenDuration time.Duration mapstructure:&quot;REFRESH_TOKEN_DURATION&quot; 使用指令 migrate create -ext sql -dir db&#x2F;migration -seq 1，用于创建一个新的迁移文件。该指令参数的意义如下：&lt;migration_name&gt;表示迁移文件的名称；-ext sql指定迁移文件的扩展名；-dir db/migration定义了迁移文件的存储路径；-seq代表创建顺序迁移文件，并在文件名前加上序号。这个命令会在指定目录下生成两个文件，一个用于执行迁移（.up.sql），另一个用于回滚迁移（.down.sql），以实现数据库的版本控制和变更管理。 add_sessions.up.sql12345678910111213CREATE TABLE &quot;sessions&quot; ( &quot;id&quot; uuid PRIMARY KEY, &quot;username&quot; varchar NOT NULL, &quot;refresh_token&quot; varchar NOT NULL, &quot;user_agent&quot; varchar NOT NULL, &quot;client_ip&quot; varchar NOT NULL, &quot;is_blocked&quot; boolean NOT NULL DEFAULT false, &quot;expires_at&quot; timestamptz NOT NULL, &quot;created_at&quot; timestamptz NOT NULL DEFAULT (now()));ALTER TABLE &quot;sessions&quot; ADD FOREIGN KEY (&quot;username&quot;) REFERENCES &quot;users&quot; (&quot;username&quot;); “is_blocked” boolean NOT NULL DEFAULT false, 添加bool列来阻止会话 以防止刷新令牌被泄露 “expires_at” timestamptz NOT NULL, 刷新令牌的过期时间 ALTER TABLE “sessions” ADD FOREIGN KEY (“username”) REFERENCES “users” (“username”); 外键约束 11.30日理清楚sqlc generate 到底是什么意思 依赖于sqlc.yml文件 123456789101112131415161718version: &quot;2&quot;sql:- schema: &quot;./db/migration&quot; queries: &quot;./db/query&quot; engine: &quot;postgresql&quot; gen: go: package: &quot;db&quot; out: &quot;./db/sqlc&quot; sql_package: &quot;pgx/v5&quot; emit_json_tags: true emit_interface: true emit_empty_slices: true overrides: - db_type: &quot;timestamptz&quot; go_type: &quot;time.Time&quot; - db_type: &quot;uuid&quot; go_type: &quot;github.com/google/uuid.UUID&quot; 指定一些列路径 自动生成代码到哪个位置 依赖的是.sql文件自动生成 相关的代码 12.2日加入更多的响应"},{"title":"存算一体架构","date":"2024-12-22T11:01:03.138Z","updated":"2024-12-22T11:01:03.138Z","comments":true,"path":"archives/ai.html","permalink":"https://whuichenggong.github.io/archives/ai.html","excerpt":"","text":"冯诺依曼体系 是我们现在计算机的处理架构 把数据放入存储中 再从存储中把数据取出来并去计算 大脑的功耗为什么低？ CPU GPU等训练大模型的功耗为什么高？ 大脑是怎么工作的？ 而现在的体系呢？ 非常好的观点！： https://www.youtube.com/watch?v=d1dGmqovyaU 抛开表面事实 回归基础原理 找到问题关键 顶着风险！第一性：找到正确的方向 共成长 长期主义 持续学习"},{"title":"理解鉴权，权限等名词的区别","date":"2024-12-20T13:07:48.510Z","updated":"2024-12-07T09:15:05.767Z","comments":true,"path":"archives/authority.html","permalink":"https://whuichenggong.github.io/archives/authority.html","excerpt":"","text":"GPT很好的给出了答案问： 用户通过了身份验证，但是不具有访问资源所需的权限。 这句话我应该怎么理解，我还有的疑惑是Cookie，Token，鉴权，权限等这几个名词都是什么意思，我现在对他们的理解有点模糊 答： 这些概念是 Web 安全和权限管理的核心部分。让我们分两步：先理解句子的含义，再深入解析相关概念（Cookie、Token、鉴权、权限等）。 1. 句子的含义 “用户通过了身份验证，但是不具有访问资源所需的权限。” 这句话分为两个阶段： 身份验证（Authentication）：系统确认了用户的身份（比如你用正确的用户名和密码登录）。 说明：你确实是你声称的那个人。 类比：这就像进入公司时，你刷卡证明你是公司的员工。 权限检查（Authorization）：系统检查用户是否有权访问某些特定资源。 说明：通过身份验证并不代表你可以访问所有东西。例如： 普通用户可能无法访问管理员界面。 销售部门员工可能无法查看财务报表。 类比：在公司内部，即使你刷卡进门，也可能需要额外权限才能进入某些区域（比如机房）。 总结：身份验证是“你是谁”，权限检查是“你是否被允许做某件事”。通过身份验证 ≠ 获得所有权限。 2. 概念解析(1) Cookie 定义：一种小型数据，存储在用户浏览器中，由服务器生成，用来记录用户的会话状态或其他信息。 用途： 会话管理：比如记录你是否已登录。 个性化：比如保存语言设置。 追踪：用于广告和分析。 类比：Cookie 就像一个身份证明牌，浏览器每次请求时带上它，服务器根据这个证明牌识别你的身份。 (2) Token 定义：类似于数字化的通行证，通常由服务器生成并发放给用户，用户每次请求时带上 Token，证明自己已通过身份验证。 常见类型： **JWT (JSON Web Token)**：一种格式化的 Token，常用于现代 Web 应用。 区别于 Cookie： Cookie 是浏览器特有的存储机制，而 Token 是一个通用的凭证。 Cookie 通常自动附加在请求中，Token 需要开发者手动附加（如放在请求头中）。 类比：Token 就像一个“通行证”，你需要用它向服务器证明你有访问权限。 (3) 鉴权 定义：确定用户是否具有访问资源或执行操作的权限。 过程： 用户发起请求时，系统会验证用户提供的凭证（比如 Token 或 Cookie）。 系统根据用户的角色、组或策略，判断是否允许操作。 类比：鉴权就像安保检查，你拿着门卡，安保会检查你的权限，决定你是否可以进入某些区域。 (4) 权限 定义：指用户被允许执行的操作范围或访问的资源类型。 示例： 读权限：允许查看文件内容。 写权限：允许修改文件内容。 管理权限：允许管理其他用户。 类比：权限就像不同的钥匙，钥匙决定了你能打开哪些门。 3. 总结关系和区别 Cookie：存储用户会话信息，让服务器识别用户是谁。 Token：携带用户身份信息，用于证明用户已通过身份验证。 鉴权：判断用户是否有权访问特定资源。 权限：用户可以做的事情或访问的资源范围。 4. 一个完整的例子 用户访问网站，输入用户名和密码（身份验证）。 服务器验证用户名和密码正确，生成一个 Token 返回给用户。 Token 或者对应的 Session ID 会存储在用户的 Cookie 中。 用户请求资源时，浏览器自动带上 Cookie（或你自己带上 Token）。 服务器接收到请求后，验证 Token 或 Cookie 的合法性。 服务器检查权限（鉴权）。 如果你有权限，资源返回给你。 如果你没有权限，服务器返回 “403 Forbidden”。 你可以将这些过程看成一道流水线：身份验证 -&gt; 带凭证发请求 -&gt; 权限检查 -&gt; 返回结果。 就是我是 赵忠鹤 检查 赵忠鹤是不是有权限访问这个内容，大体就是这个意思"},{"title":"UDP socket的ack机制和丢包重传","date":"2024-12-20T13:07:48.560Z","updated":"2024-12-15T12:37:16.302Z","comments":true,"path":"archives/UDP_socket.html","permalink":"https://whuichenggong.github.io/archives/UDP_socket.html","excerpt":"","text":"参考连接： https://juejin.cn/post/7263378772040122429 Go语言实现UDP socket的ack机制和丢包重传UDP 在通讯之前不需要建立连接 可以直接发送数据包 是一种无连接协议（常用于音视频传输） 但是在有些场景 即需要UDP传输也需要向TCP一样（TCP的可靠传输） 解决丢包问题： 1.添加 seq&#x2F;ack机制 确保数据发送到对端 什么是 seq&#x2F;ack机制 123456789101112131415在TCP（传输控制协议）中，序号（Sequence Number，简称seq）和确认应答号（Acknowledgment Number，简称ack）是协议头部非常关键的字段，它们共同确保了TCP的可靠性和数据按顺序传输的特性。** Sequence Number **含义：序号是指一个TCP报文段中第一个字节的数据序列标识。它表示在一个TCP连接中，该报文段所携带的数据的开始位置。序号是用来保证数据传输的顺序性和完整性的。作用：在TCP连接建立时，双方各自随机选择一个初始序列号（ISN）。随后传输的每个报文段的序号将基于这个初始值递增，其增量为该报文段所携带的数据量（字节数）。通过这种方式，接收方可以根据序号重组乱序到达的数据片段，确保数据的正确顺序和完整性。如果接收到的报文段不连续，接收方可以通过TCP的重传机制请求发送方重新发送缺失的数据。**Acknowledgment Number**含义：确认应答号是接收方期望从发送方接收到的下一个报文段的序号。它实质上是接收方告诉发送方：“我已经成功接收到了哪个序号之前的所有数据，请从这个序号开始发送后续的数据。”作用：确认应答号用于实现可靠性传输。当一个报文段被接收方正确接收时，接收方会发送一个ACK报文，其中包含的确认应答号是接收到的数据加上1（即接收方期望接收的下一个数据的序号）。通过检查这个确认应答号，发送方能够知道其发送的数据是否已被接收方正确接收，并据此决定是否需要重传某些数据段。 ack和seq 保证了： 确保数据的顺序性：即使数据片段在网络中的传输过程中顺序被打乱，接收方也能根据序号正确地重组这些数据。 检测丢包：如果发送方发送的数据长时间未被确认（即没有收到对应的ACK报文），它会判断这些数据可能已丢失，并将其重新发送。 实现流量控制和拥塞控制：通过调整发送未被确认数据的量（即控制窗口大小），TCP可以根据网络条件动态调整数据发送的速率，避免网络拥塞。 Golang的socket编程：Go语言通过标准库中的net包来实现UDP和TCP的socket编程。net包提供了用于创建和管理网络连接的函数，以及用于进行数据传输的相关类型和方法，不同于C++需要手动设置和管理socket API，不论实现UDP还是TCP都可以直接使用封装好的方法进行操作，大大简化了socket编程： 使用net包实现UDP通信1.client.go1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;net&quot; &quot;os&quot;)func main() &#123; // 创建UDP连接到服务器的地址和端口号 c, err := net.DialUDP(&quot;udp&quot;, nil, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Println(&quot;dial err: %v\\n&quot;, err) return &#125; defer c.Close() // 将 defer 放在 if 语句外面 // 从标准输入读取用户输入的数据 input := bufio.NewReader(os.Stdin) for &#123; // 读取用户输入知道遇见换行符 s, err := input.ReadString(&#x27;\\n&#x27;) if err != nil &#123; fmt.Printf(&quot;read from stdin failed, err: %v\\n&quot;, err) return &#125; // 将用户输入的数据转换为字节数组并通过UDP连接发送给服务器 _, err = c.Write([]byte(s)) if err != nil &#123; fmt.Printf(&quot;send to server failed, err: %v\\n&quot;, err) return &#125; // 接收来自服务器的数据 var buf [1024]byte n, addr, err := c.ReadFromUDP(buf[:]) if err != nil &#123; fmt.Printf(&quot;recv from udp failed, err: %v\\n&quot;, err) return &#125; // 打印来自服务器的数据 fmt.Printf(&quot;服务器 %v, 响应数据: %v\\n&quot;, addr, string(buf[:n])) &#125;&#125; 2.server.go首先创建UDP监听器监听指定IP和端口，等待连接客户端，连接后会读取客户端发来的数据并打印收到的数据，并将接收的响应信息返回发送给客户端，使用死循环使其能够持续获取客户端数据，同样实现了UDP的数据接收和发送，实现了简单的UDP服务器； 1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( &quot;fmt&quot; &quot;net&quot;)// udp serverfunc main() &#123; // 创建一个UDP监听器，监听本地IP地址的端口 listen, err := net.ListenUDP(&quot;udp&quot;, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;listen failed,err:%v\\n&quot;, err) return &#125; defer listen.Close() for &#123; var buf [1024]byte // 从UDP连接中读取数据到buf中，n为读取到的字节数，addr为数据发送者的地址 n, addr, err := listen.ReadFromUDP(buf[:]) if err != nil &#123; fmt.Printf(&quot;read from udp failed,err:%v\\n&quot;, err) return &#125; // 打印接收到的数据 fmt.Println(&quot;接收到的数据：&quot;, string(buf[:n])) // 将接收到的数据原样发送回给数据发送者 _, err = listen.WriteToUDP(buf[:n], addr) if err != nil &#123; fmt.Printf(&quot;write to %v failed,err:%v\\n&quot;, addr, err) return &#125; &#125;&#125; 效果：（好有趣） 12345678&gt; go run client.gohello服务器 127.0.0.1:8282, 响应数据: helloworld服务器 127.0.0.1:8282, 响应数据: world 123456 go run server.go接收到的数据： hello接收到的数据： world 基于seq&#x2F;apkclient 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package mainimport ( &quot;fmt&quot; &quot;net&quot; &quot;strconv&quot; &quot;strings&quot; &quot;time&quot;)type Message struct &#123; Seq int Msg string&#125;func main() &#123; c, err := net.DialUDP(&quot;udp&quot;, nil, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;dail err:%v\\n&quot;, err) &#125; defer c.Close() input := []string&#123;&quot;Message1&quot;, &quot;Message2&quot;, &quot;Message3&quot;, &quot;Message4&quot;, &quot;Message5&quot;&#125; seq := 0 for _, msg := range input &#123; seq++ message := Message&#123;Seq: seq, Msg: msg&#125; fmt.Printf(&quot;Sending seq=%d: %s\\n&quot;, message.Seq, message.Msg) // 发送带有序列号的数据包 _, err = c.Write(encodeMessage(message)) if err != nil &#123; fmt.Printf(&quot;send to server failed,err:%v\\n&quot;, err) return &#125; &#125; // 等待ACK，设置超时时间 buf := make([]byte, 1024) c.SetReadDeadline(time.Now().Add(5 * time.Second)) n, _, err := c.ReadFromUDP(buf) if err != nil &#123; fmt.Println(&quot;ACK not received. Timeout or Error.&quot;) return &#125; else &#123; ack := decodeMessage(buf[:n]) if ack.Seq == seq+1 &#123; fmt.Printf(&quot;ACK = %d\\n&quot;, ack.Seq) &#125; else &#123; fmt.Println(&quot;Invalid ACK received. Retry.&quot;) return &#125; &#125;&#125;func encodeMessage(msg Message) []byte &#123; // 将序列号和消息文本编码成字节数据 return []byte(fmt.Sprintf(&quot;%d;%s&quot;, msg.Seq, msg.Msg))&#125;func decodeMessage(data []byte) Message &#123; // 解码收到的数据，提取序列号和消息文本 parts := strings.Split(string(data), &quot;;&quot;) seq, _ := strconv.Atoi(parts[0]) msg := parts[1] return Message&#123;Seq: seq, Msg: msg&#125;&#125; server 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package mainimport ( &quot;fmt&quot; &quot;net&quot; &quot;strconv&quot; &quot;strings&quot;)type Message2 struct &#123; Seq int Msg string&#125;func main() &#123; listen, err := net.ListenUDP(&quot;udp&quot;, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;listen failed,err:%v\\n&quot;, err) return &#125; defer listen.Close() for &#123; var buf [1024]byte n, addr, err := listen.ReadFromUDP(buf[:]) if err != nil &#123; fmt.Printf(&quot;read from udp failed,err:%v\\n&quot;, err) return &#125; // 处理接收到的数据，提取序列号和消息文本 message := decodeMessage1(buf[:n]) fmt.Printf(&quot;Received seq=%d from %v: %s\\n&quot;, message.Seq, addr, message.Msg) // 发送ACK回复给客户端，ACK=Seq+1 ack := Message2&#123;Seq: message.Seq + 1, Msg: &quot;ACK&quot;&#125; _, err = listen.WriteToUDP(encodeMessage1(ack), addr) if err != nil &#123; fmt.Printf(&quot;write to %v failed,err:%v\\n&quot;, addr, err) return &#125; &#125;&#125;func encodeMessage1(msg Message2) []byte &#123; // 将序列号和消息文本编码成字节数据 return []byte(fmt.Sprintf(&quot;%d;%s&quot;, msg.Seq, msg.Msg))&#125;func decodeMessage1(data []byte) Message2 &#123; // 解码收到的数据，提取序列号和消息文本 parts := strings.Split(string(data), &quot;;&quot;) seq, _ := strconv.Atoi(parts[0]) msg := parts[1] return Message2&#123;Seq: seq, Msg: msg&#125;&#125;&#125; 问题核心：在同一文件夹内，Go 默认将所有文件视为同一包的一部分，可能导致重复定义或未定义的错误。推荐解决方法：分文件夹运行。提取共享逻辑到单独的文件。运行时显式指定所有 .go 文件。额外改进：通过参数区分服务端和客户端运行模式，进一步优化程序结构。 ，服务器监听的端口可能是某个固定端口（例如 12345），而客户端的UDP数据包来自 127.0.0.1:59653。这意味着：UDP允许客户端选择任意可用的端口号作为源端口，并将数据包发送到服务器的监听端口。这也是为什么你看到不同的端口号。 4.实现超时重传最简单的方法就是当超时没有收到ack回复或者ack回复错误乱序时，阻塞后续发包，先进行重传，把丢失的包重传后再继续发包，因此主要是在客户端更改一些发包的逻辑，服务端则没有变化； client.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package mainimport ( &quot;fmt&quot; &quot;net&quot; &quot;strconv&quot; &quot;strings&quot; &quot;time&quot;)type Message struct &#123; Seq int Msg string&#125;func main() &#123; c, err := net.DialUDP(&quot;udp&quot;, nil, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;dial,err:%v\\n&quot;, err) return &#125; defer c.Close() // 示例数据 input := []string&#123;&quot;Message 1&quot;, &quot;Message 2&quot;, &quot;Message 3&quot;, &quot;Message 4&quot;, &quot;Message 5&quot;&#125; for seq, msg := range input &#123; for &#123; message := Message&#123;Seq: seq + 1, Msg: msg&#125; fmt.Printf(&quot;Sending seq=%d: %s\\n&quot;, message.Seq, message.Msg) // 发送带有序列号的数据包 _, err := c.Write(encodeMessage(message)) if err != nil &#123; fmt.Printf(&quot;send to server failed,err:%v\\n&quot;, err) return &#125; // 开始等待ACK，设置超时时间 buf := make([]byte, 1024) c.SetReadDeadline(time.Now().Add(5 * time.Second)) // 循环等待ACK，直到收到正确的ACK或超时 n, _, err := c.ReadFromUDP(buf) if err != nil &#123; // 超时或发生错误，需要重传 fmt.Println(&quot;ACK not received. Timeout or Error. Retrying...&quot;) continue &#125; else &#123; //解码从服务器传来的ack ack := decodeMessage(buf[:n]) if ack.Seq == seq+2 &#123; fmt.Printf(&quot;ACK = %d\\n&quot;, ack.Seq) // 收到正确的ACK，跳出内部循环，继续发送下一个消息 break &#125; else &#123; // 收到错误的ACK，继续等待，内部循环会重发相同的消息 fmt.Println(&quot;Invalid ACK received. Waiting for correct ACK...&quot;) continue &#125; &#125; &#125; &#125;&#125;func encodeMessage(msg Message) []byte &#123; // 将序列号和消息文本编码成字节数据 return []byte(fmt.Sprintf(&quot;%d;%s&quot;, msg.Seq, msg.Msg))&#125;func decodeMessage(data []byte) Message &#123; // 解码收到的数据，提取序列号和消息文本 parts := strings.Split(string(data), &quot;;&quot;) seq, _ := strconv.Atoi(parts[0]) msg := parts[1] return Message&#123;Seq: seq, Msg: msg&#125;&#125; server.go 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;net&quot; &quot;strconv&quot; &quot;strings&quot;)type Message struct &#123; Seq int Msg string&#125;func main() &#123; listen, err := net.ListenUDP(&quot;udp&quot;, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;listen failed,err:%v\\n&quot;, err) return &#125; defer listen.Close() for &#123; var buf [1024]byte n, addr, err := listen.ReadFromUDP(buf[:]) if err != nil &#123; fmt.Printf(&quot;read from udp failed,err:%v\\n&quot;, err) return &#125; // 以20%的概率模拟丢包 if rand.Float32() &lt; 0.2 &#123; fmt.Printf(&quot;From %v lost package\\n&quot;, addr) continue &#125; // 处理接收到的数据，解码字节流 提取序列号和消息文本 message := decodeMessage(buf[:n]) fmt.Printf(&quot;Received seq=%d from %v: %s\\n&quot;, message.Seq, addr, message.Msg) // 发送ACK回复给客户端，ACK=Seq+1 ack := Message&#123;Seq: message.Seq + 1, Msg: &quot;ACK&quot;&#125; //写入ack向UDP连接中 _, err = listen.WriteToUDP(encodeMessage(ack), addr) if err != nil &#123; fmt.Printf(&quot;write to %v failed,err:%v\\n&quot;, addr, err) return &#125; &#125;&#125;func encodeMessage(msg Message) []byte &#123; // 将序列号和消息文本编码成字节数据 return []byte(fmt.Sprintf(&quot;%d;%s&quot;, msg.Seq, msg.Msg))&#125;func decodeMessage(data []byte) Message &#123; // 解码收到的数据，提取序列号和消息文本 parts := strings.Split(string(data), &quot;;&quot;) seq, _ := strconv.Atoi(parts[0]) msg := parts[1] return Message&#123;Seq: seq, Msg: msg&#125;&#125; 上述方法实现的丢包重传虽然能够正常工作，但是发送端使用双层循环嵌套，并且每次丢包都阻塞了后续发包，这样会导致重传的效率很低，只适用于小宽带低延时的情况，而且超时重传容易产生误判，主要有以下两种情况： 对方收到了数据包，但是ack发送途中丢失，其实就是我服务器模拟丢包的情况，服务器可能收到了数据，但是因为某种原因ack没能正确发送；ack在回传的途中，但是时间已经超过了发送端的ack等待时间即超过了一次RTO，这样也会导致接收端收到数据却仍然重传的问题。 学习 滑动窗口 拥塞控制 优化一些东西 深入理解seq&#x2F;ack的原理和超时重传的逻辑 Go语言进行socket编程的方法 UDP和TCP的一些知识 借鉴文章：https://blog.csdn.net/weixin_41500064/article/details/135119715 流量控制：作用：为了解决发送方和接收方速度不同而导致的数据丢失问题,当发送方发送的太快,接收方来不及接受就会导致数据丢失； 方式：由接收端采用滑动窗口的形式，告知发送方允许&#x2F;停止发包解决TCP丢包问题。 拥塞控制：作用：为了解决过多的数据注入到网络导致网络崩溃和超负荷问题； 方式：由发送方采用拥塞窗口的形式去判断网络状态，从而采取不同算法执行TCP动态发包解决网络整体质量问题。 典型的场景如以太网场景中10G设备向1G设备发TCP包：10G网卡 10Gbps 持续发送TCP包 交换机 以 1Gbps每秒接收TCP包TCP 提供一种机制可以让发送端根据接收端的实际接收能力控制发送的数据量。这就是所谓的流控制。接收端主机向发送端主机通知自已可以接收数据的大小；是发送端会发送不超过这个限度的数据，该大小限度就被称作窗口大小。窗口大小的值由接收端主机决定，而在TCP 首部中，专门有一个字段用来通知窗口大小：接收主机将自己可以接收的缓冲区大小放入这个字段中通知给发送端，这个字段的值越大，说明网络的吞吐量越高。发送端主机会根据接收端主机的指示，对发送数据的量进行控制。这也就形成了一个完整的TCP流控制(流量控制)。当Window&#x3D;0时，即告知发送方停止发送数据。 慢开始发送方先探测网络拥塞程度，并不是一开始就发送大量的数据，发送方会根据拥塞程度增大拥塞窗口cwnd。拥塞窗口cwnd值是几就能发送几个数据段 拥塞避免继上图达到cwnd≥ssthresh后采用该算法用来控制拥塞窗口的增长速率。 计算方法：每经过一个传输轮次cwnd值加1，让cwnd值呈线性缓慢增大 拥塞发生当网络发生拥塞丢包时（如图假定cwnd&#x3D;24），会有两种情况： 超时重传（1988年TCP Tahoe版本，已废弃不用） 更新后的 ssthresh 值变为 12(即为出现超时时的窗口数值 24 的一半)，拥窗口再重新设置为1并执行慢开始算法。当cwnd &#x3D; ssthresh &#x3D; 12 时改为执行拥塞避免算法拥塞窗口按线性规律增长，每经过一个往返时间增加一个MSS的大小。在TCP拥塞控制的文献中经常可看见“乘法减小”(Multiplicative Decrease)和“加法增大”(Additive Increase)这样的提法。“乘法减小”是指不论在开始阶段还是拥塞避免阶段，只要出现超时(即很可能出现了网络拥塞)，就把慢开始门限值 ssthresh 减半，即设置为当前的拥塞窗口的一半(与此同时，执行慢开始算法)。而“加法增大”是指执行拥塞避免算法后，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。上面两种算法合起来常称为 AIMD算法(加法增大乘法减小)。 快重传与快恢复超时重传算法直接把cwnd减小到1太过强烈，若还能收到连续3个ACK说明网络质量没那么差。同时采用快重传和快恢复算法，过程如下： （1）当发送方连续收到3个重复确认时即执行“乘法减小”算法，把慢开始门限ssthresh 减半； （2）由于发送方现在认为网络不那么差，于是把cwnd值设置为开始门限ssthresh 减半后的数值； （3）开始执行拥塞避免算法 (“加法增大”)使拥塞窗口缓慢地线性增大。 12.25 日根据计算机网络这本书，深入了解UDP套接字编程： 整体的一个过程： 进程间彼此通过向套接字发送报文来进行通信 一个主机-》多个进程 1个进程-》多个套接字 帮助记忆： 进程是一间房子 而 套接字是房子门 还需要一个 端口 来识别我具体要将信息发送到哪间房子，也就是具体的房间号（端口） 客户从键盘键入数据，并向服务器发送数据（将数据编码成字节流）， 服务器接收数据（接收字节流）-》并将其解码为原始客户端输入的数据 （并把小写转换为大写） 服务器将修改的数据（编码为字节流）发送回客户端 客户端接收数据后解码 并显示在屏幕上 接收源地址（ip+端口号）和分组"},{"title":"计算机网络持续学习中~","date":"2024-12-20T13:07:48.512Z","updated":"2024-12-18T09:06:52.759Z","comments":true,"path":"archives/computer_network.html","permalink":"https://whuichenggong.github.io/archives/computer_network.html","excerpt":"","text":"记录一下自己在黑皮书中的学习记录下有用的部分 非常好的学习HTTP RESTFUL API 链接链接1： https://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html 链接2： https://www.ruanyifeng.com/blog/2016/08/http.html 链接3： https://florimond.dev/en/posts/2018/08/restful-api-design-13-best-practices-to-make-your-users-happy应用层2.1应用层协议原理：Web应用程序中两个互相通讯的不同程序： 运行在用户主机上浏览器程序 运行在Web服务器主机上 网络上的核心设备并不在应用层起作用， 这将应用软件限制在了端系统，这促进了大量网络应用程序的迅速研发与部署 2.1.1网络应用程序体系结构应用层的体系结构 明显 不同于网络的体系结构（网络的体系结构是固定的，提供了特定的服务集合） 应用层体系结构（大体两个）： 客户-服务器体系结构 p2p体系结构 1.客户-服务器体系结构：有一个总打开的主机被称为：服务器（它服务于许多其他称为客户的主机请求） 例子： Web应用服务器：（Web服务器服务于浏览器（运行在客户机）的请求） 在这个体系结构中 客户之间并不直接通信 而是 客户通过向该服务器的ip地址发送分组 用来取得联系 著名的Web应用： Web FTP Telent 电子邮箱 在这个体系中 如果只有一台服务器 在某些情况（大量的所有请i去）会导致服务器变得不堪重负，因此-配备大量主机的 数据中心 流行的因特网服务： 搜索引擎（Google，bing，百度）等 应用了一个或多个数据中心（1个数据中心 可以有数十万台服务器） 2. p2p体系结构主机对之间使用直接通信（对等方），引人入胜的特性（自扩展性）， 面临挑战： 高度非集中式，面临安全性，性能和可靠性等挑战 应用： 文件共享，对等方协助下载器（迅雷）因特网电话和视频会议 有的应用具有两种的混合体系： 服务器被用来跟踪用户的ip地址 但 用户到用户的报文在用户到主机之间 直接发送 2.1.2进程通信运行在多个端系统上的程序如何互相通信，进行通信实际上是进程而不是程序进程可以被认为是运行在端系统的一个程序。 多个进程运行在相同的端系统时使用进程间通信机制互相通信（通信规则由 _端系统上的操作系统制定_） 关注的是 运行在不同端系统上的进程间的通信在不同的端系统上的进程 通过 跨越进程通过网络互相发送报文 发送进程 生成并 向网络中 发送报文 -》接收进程接收报文并通过回送报文响应 1.客户和服务器进程网络应用程序由 成对的进程组成 进程之间 通过网路互相发送报文 例子： 客户浏览器进程 与 Web服务器进程交换报文 在p2p中： 文件从一个对等方中的进程 传输到 另一个对等放进程 其中一个进程被表示为客户 另一个进程被标记为服务器 2.进程与计算机网络之间的接口（api）进程 通过一个称为套接字（socket） 的软件接口 向网络发送报文和从网络接收报文 套接字： 是同一台主机被应用层与传输层之间的接口 套接字被称为 应用进程 和 网络之间的（api） 我们可以控制套接字在应用端的一切 但是 对运输层几乎没有控制权 仅限于：选择运输层协议 也能设定几个运输层协议（最大缓存，最大报文长度） 3.进程寻址主机由ip地址标识， ip地址： 是32比特的量它能够标识该主机 端口号： 众所周知的端口号列表： http://www.iana.org 2.1.3 可供应用程序使用的运输服务运输层协议负责从接收进程的套接字得到该报文 开发应用时还要选择根基情况 选择合适的协议 选择服务 服务： 可靠数据传输 吞吐量 定时 安全性 1.可靠数据传输因为 分组可能在计算机网络中丢失， 例子： 分组能够使路由器中的缓存溢出， 分组中的某些比特损坏后可能被丢弃 在某些特定情况下： 电子邮件，文件传输，远程主机访问如果数据丢失可能会造成灾难性的损失， 因此 当运输层协议提供一种可靠传输， 发送进程只需要将数据传递到套接字中 就可以完全相信数据无差别的到达接收进程但是也有一些东西可以容忍数据的丢失（不适用可靠数据传输时） 音频&#x2F;视频 2.吞吐量吞吐量就是发送进程能够向接收进程交付比特的速率 会话 将共享沿着网络路径的带宽 运输层协议能够确保可用吞吐量为至少r&#x2F;bit&#x2F;s当（应用程序请求r&#x2F;bit&#x2F;s） 示例：电话需要固定的bit进行编码 如果不能提供这中吞吐量或者较小 造成放弃发送（因为接收一半可能是没用的）弹性应用：可以根据 可用的宽带或多或少来利用可供使用的吞吐量当然 吞吐量越高越好哈哈哈 3.定时运输层协议也能提供定时保证 因为在特定情况下 电话，虚拟环境 多方游戏（对时间有严格的限制） 否则会造成停顿， 较长的时延但 端到端的时延没有严格的约束 4，安全性运输协议为应用提供 一种或多种安全性服务 能加密发送进程传输的所有数据 防止数据以某种方式 在两个进程之间被观察 2.1.4 因特网提供的运输服务因特网（TCp&#x2F;IP网络）为应用程序提供两个运输层协议（TCP&#x2F;UDP） 1.TCP服务特点： 面向连接服务和可靠数据传输服务 面向连接： 在应用层数据报文开始流动之前， TCP使 客户 和 服务器 之前相互交换 运输层控制信息（握手过程） 让它们提前做好准备握手之后 TCP连接就建立了 连接时双工的： 双方可以连接上 同时进行报文的收发 当收发结束后 必须拆除连接 可靠的数据传送服务： 通信进程依靠TCP 无差错的按照顺序交付所有的发送数据 当一方将字节流传入套接字时 依靠TCP将相同的字节流交付给接收方的套接字 没有字节的丢失和冗余 TCP具有拥塞控制机制 当发送方和接收方之间网络出现问题堵塞 TCP的机制可以抑制发送进程 也试图限制每个TCP连接 达到公平共享网络宽带目的 原文链接： https://github.com/wolverinn/Waking-Up/blob/master/Computertree-way-handshake 简单理解： 三次握手（三报文握手）第一次握手：Client将SYN置1，随机产生一个初始序列号seq发送给Server，进入SYN_SENT状态；第二次握手：Server收到Client的SYN&#x3D;1之后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number&#x3D;sequence number+1，并随机产生一个自己的初始序列号，发送给客户端；进入SYN_RCVD状态；第三次握手：客户端检查acknowledge number是否为序列号+1，ACK是否为1，检查正确之后将自己的ACK置为1，产生一个acknowledge number&#x3D;服务器发的序列号+1，发送给服务器；进入ESTABLISHED状态；服务器检查ACK为1和acknowledge number为序列号+1之后，也进入ESTABLISHED状态；完成三次握手，连接建立。 目的： 建立 TCP连接 两次握手呢？只发送前两次报文 不会有 最后一次的客户端同步状态报文这就会导致超时重传把问题想象成发送报文就好理解了：一段时间后，之前滞留在网络中的那个失效的TCP连接请求报文段到达了TCP服务器进程，TCP 服务器进程会误认为这是TCP客户进程又发起了一个新的TCP连接请求，于是给TCP客户进程发送TCP连接请求确认报文段并进入连接已建立状态。该报文段到达TCP客户进程，由于TCP客户进程并没有发起新的TCP连接请求，并且处于关闭状态，因此不会理会该报文段。 不可以！ 如果不是用三次握手 那么只要client发出确认报文段， server发出确认新的连接就建立了因为第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了延误到连接释放以后的某个时间才到达但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。 四次握手？可以。但是会降低传输的效率。 四次握手是指：第二次握手：Server只发送ACK和acknowledge number；而Server的SYN和初始序列号在第三次握手时发送；原来协议中的第三次握手变为第四次握手。出于优化目的，四次握手中的二、三可以合并。 了解名词ACK acknowledge number SYN 初始序列号 参考链接： https://juejin.cn/post/7028003193502040072 确认标志位ACK： 取值为1时确认号字段才有效；取值为0时确认号字段无效。TCP规定，在连接建立后所有传送的TCP报文段都必须把ACK置1。 源端口：16bit 目的端口： 16bit序号：32bit 同步标志位SYN： 在TCP连接建立时用来同步序号。终止标志位FIN： 用来释放TCP连接。复位标志位RST： 用来复位TCP连接。 推送标志位PSH： 接收方的TCP收到该标志位为1的报文段会尽快上交应用进程，而不必等到接收缓存都填满后再向上交付。 TCP建立需要解决的问题： 1、使TCP双方能够确知对方的存在 。 2、使TCP双方能够协商一些参数（ 最大窗口值是否使用窗口扩大选项和时间戳选项，以及服务质量等）。 3、使TCP双方能够对运输实体资源（例如缓存大小连接表中的项目等）进行分配。 TCP规定SYN被设置为1的报文段不能携带数据但要消耗掉一个序号。 TCP服务器进程收到TCP连接请求报文段后，如果同意建立连接，则向TCP客户进程发送TCP连接请求确认报文段，并进入同步已接收状态 总结：如果没有第三次握手告诉服务器客户端能否收到服务器传输的数据的话，服务器端的端口就会一直开着，等到客户端因超时重新发出请求时，服务器就会重新开启一个端口连接。长此以往， 这样的端口越来越多，就会造成服务器开销的浪费。 探测报文检测 确认客户端是否出现故障 然后关闭连接 四次挥手第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入FIN_WAIT_1状态；第二次挥手：Server收到FIN之后，发送一个ACK&#x3D;1，acknowledge number&#x3D;收到的序列号+1；进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。第三次挥手：Server将FIN置1，发送一个序列号给Client；进入LAST_ACK状态；第四次挥手：Client收到服务器的FIN后，进入TIME_WAIT状态；接着将ACK置1，发送一个acknowledge number&#x3D;序列号+1给服务器；服务器收到后，确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。 还有些不太理解学习一下这些名字之后再来理解 2.UDP服务UDP是 轻量级运输协议仅提供最小服务 状态：无连接的，两个进程通信没有握手过程， 提供：不可靠传输协议：不保证报文到达接收进程报文也可能是乱序到达 也没有拥塞控制机制 因特网运输协议所不提供的服务TCP在应用层 用SSL加强提供安全服务 漏掉了 吞吐量，和定时保证 2.1.5 应用层协议定义了： 交换的报文类型 如：请求报文，响应报文 报文类型语法 如：报文字段是如何描述的 字段的语义 就是信息含义 确定进程何时发送报文 Web的应用层协议是HTTP： 因特网电子邮件应用：包括 电子邮件报文结构的标准 以及 定义报文如何在服务器之间以及如何在服务器与邮件客户程序之间传递的应用层协议 2.2Web和HTTP2.2.1HTTP概况Web层应用层协议是超文本传输协议 HTTP由两个程序实现（客户程序）（服务器程序） 通过交换HTTP报文进行会话 Web界面它是由文档组成的也就是（对象）： 一个对象是一个文件 例如： HTML文件 JPEG图形 例如： 如果一个HTML文件＋五个图片 也就是 Web页面有6个对象 URL地址两部分组成：服务器主机名 和 对象 URL：http://www/someSchool.edu/someDepartment/picture.gif 到edu是主机名后面是路径名 Web服务器 实现了HTTP服务器端 用于存储Web对象 流行的Web服务器：Apache等 2.2.2非持续连接和持续链接两个问题： 每个请求&#x2F;响应是 经 一个单独的TCP连接： 这称为（非持续连接）还是 经相同的TCP连接发送： 这称为（持续链接） 1.采用非持续连接的HTTP过程： 每个TCP只传输一个请求报文和一个响应报文 串行TCP： 并行TCP： 浏览器可以设置并行数 如果设为1 那么就会变化串行连接 并行连接可以减少响应时间 往返时间（RTT） RTT包括： 分组传播时延 分组在（中间路由器）（交换机）的排队时延 分组时延 三次握手过程 客户向服务器发送小TCP报文 服务器用小TCP报文做出确认和响应 客户向服务器返回确认 这三次握手中 前两部分花费 一个RTT握手后向该TCP连接发送HTTP请求报文 一旦请求报文到达服务器 服务器就在TCP连接上发送HTML文件该HTTP的请求和响应用了一个HTTP 服务器传输HTML花费了时间一共为 2RTT+传输时间 2.采用持续连接的HTTP 非持续链接的缺点： 每次连接都需要： 分配TCP缓存区和保持TCP变量 这给Web服务器造成了很大的负担 每一个对象都会造成上面的时延时间 HTTP1.1 在服务器响应后 保持TCP打开 用单个TCP进行传送 在一定的时间间隔没有被使用HTTP服务器再关闭连接HTTP2 它允许再相同连接中多个请求和回答错误 增加了连接中优化HTTP报文请i去和回答机制 2.2.3 HTTP请求报文格式1.HTTP 请求报文12345GET /somedir/page.html HTTP/1.1HOST: www.someschool.eduConnection: closeUser-agent: Mozilla/5.0Accept-language: fr 第一行：请求行后继行：首部行 2.HTTP 响应报文真实的HTTP响应报文：用Telnet 登录到喜欢的Web服务器上 请求报文请求放在该服务器上的某些对象 123456789101112131415161718telnet gaia.cs.umass.edu 80Trying 128.119.245.12...Connected to gaia.cs.umass.edu.Escape character is &#x27;^]&#x27;.GET /kurose_ross/interactive/index.php HTTP/1.1Host: gaia.cs.umass.eduHTTP/1.1 200 OKDate: Wed, 27 Nov 2024 13:06:02 GMTServer: Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips PHP/7.4.33 mod_perl/2.0.11 Perl/v5.16.3X-Powered-By: PHP/7.4.33Set-Cookie: DevMode=0Transfer-Encoding: chunkedContent-Type: text/html; charset=UTF-8&lt;!DOCTYPE HTML&gt;&lt;html&gt; 这里的GET &#x2F;kurose_ross&#x2F;interactive&#x2F;index.php HTTP&#x2F;1.1Host: gaia.cs.umass.edu格式很重要 回车必不可少 只想看HTTP协议的报文行 用HEAD代替GET上述简短的两行代码 打开了主机 .edu的80端口的TCP连接 发送了一个HTTP请求报文 1234567891011121314telnet gaia.cs.umass.edu 80Trying 128.119.245.12...Connected to gaia.cs.umass.edu.Escape character is &#x27;^]&#x27;.HEAD /kurose_ross/interactive/index.php HTTP/1.1Host: gaia.cs.umass.eduHTTP/1.1 200 OKDate: Wed, 27 Nov 2024 13:11:35 GMTServer: Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips PHP/7.4.33 mod_perl/2.0.11 Perl/v5.16.3X-Powered-By: PHP/7.4.33Set-Cookie: DevMode=0Content-Type: text/html; charset=UTF-8 插入GT方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，可以对GET请求的数据做缓存，这个缓存可以做到浏览器本身上(彻底避免浏览器发请求)，也可以做到代理上（如gix)，而且在浏览器中GET请求可以保存为书签。 POST因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。所以，浏览器一般不会缓存POST请求，也不能把POST请求保存为书签。 减少HTTP请求次数1.减少重定向请求次数 重定向请求越多，那么客户端就要多次发起 HTTP 请求 每一次的 HTTP 请求都得经过网络，这无疑会越降低网络性能 重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了代理服务器知晓了重定向规则后，可以进一步减少消息传递次数 2.2.4用户与服务器的交互 cookieHTTP服务器是无状态的 不需要验证。但是站点是希望能够标识用户， 因为服务器可能需要限制用户的访问，这就需要把内容和用户关联到一起HTTP使用了 cookie cookie的四个组件 HTTP响应报文的一个cookie首部行 HTTP请求报文的一个cookie首部行 用户端系统保留一个cookie文件浏览器进行管理 位于WEB站点的后端数据库 这样当Susan再次访问一个站点的时候 浏览器放入首部行 就不用再输入一些信息了实行了”点击购物“ 2.2.5 Web缓存 还需要 深入理解缓存器带来的好处 HTTP中的 强制缓存和协商缓存 强制缓存定义：强制缓存是指客户端直接使用本地缓存的数据，而不会向服务器发送请求验证数据的有效性。 工作方式： HTTP 头部中：使用 Cache-Control 指定缓存策略（例如 max-age）。或使用 Expires（HTTP&#x2F;1.0，已逐步被 Cache-Control 替代）指定缓存失效时间。如果缓存未过期，浏览器会直接从本地缓存读取数据，而不会与服务器通信。特点： 节约资源：不需要请求服务器。时效性：受 max-age 或 Expires 的约束，可能存在缓存失效时间的误差。 协商缓存 (Conditional Cache)定义： 协商缓存是指客户端向服务器发送请求，验证本地缓存是否有效。如果有效，服务器返回一个状态码（如 304 Not Modified），客户端可以继续使用本地缓存的数据；否则，服务器返回最新的数据。 工作方式： HTTP 头部中：请求头：使用 If-Modified-Since 或 If-None-Match。响应头：服务器返回 Last-Modified（表示资源最后修改时间）或 ETag（资源的唯一标识符）。客户端会将缓存中记录的 ETag 或 Last-Modified 发送到服务器进行验证：如果验证通过（服务器认为缓存未修改），返回 304。如果验证失败（资源已更新），返回新的资源数据（200 OK）。特点： 相对准确：确保缓存数据的有效性。需要通信：每次都需要向服务器发送请求进行验证。 缓存命中率内容分发网络（CDN）：多个共享CDN 专用CDN 条件GET方法问题： 存放在混村其中的对象副本是旧的，或者再保存到服务器中的对象再缓存到客户上之后 就被修改了HTTP协议机制： 允许缓存器证实它的对象是最新的 也就是（条件GET） If-modified-since: Wed, 9 Sep 2015 09:23:24 ”If-Modified-Since“首部行 这个请求报文就是条件GET请求报文 缓存器在存储对象的同时也存储了最后的修改日期 缓存器通过一个条件GET执行最新查询这条语句告诉服务器 仅当指定日期后该对象被修改过 才发送对象 如果没有修改过 则相应的时候没有body 因为再次返回一样的body会浪费宽带 插入 数据流在实践中，客户端指定数据流的优先级通常是在使用 HTTP&#x2F;2 时实现的。HTTP&#x2F;2 引入了流优先级（Stream Priority）机制，允许客户端为每个流指定一个优先级值，这个值会影响服务器在资源争用时对请求的处理顺序。 流优先级机制优先级参数：每个 HTTP&#x2F;2 流都可以有一个权重值（weight），范围是 1 到 256，数字越大，优先级越高。依赖关系：每个流还可以声明依赖于另一个流（dependency）。如果一个流依赖于另一个流，服务器会优先完成被依赖的流。服务器根据这些参数决定如何分配带宽和计算资源。 实现流优先级的例子客户端的实现（使用 cURL）我们可以用支持 HTTP&#x2F;2 的工具，如 curl，来演示流优先级的使用。 发送两个并发请求（模拟流） curl –http2 -o output1.html https://example.com/slow-response &amp;curl –http2 -o output2.html https://example.com/fast-response &amp;wait默认情况下，这两个流的优先级相同，服务器会尽力均匀分配资源来处理它们。 设置优先级 使用 –http2-prioritize 选项来设置优先级。例如： curl –http2 –http2-prioritize-weight 256 -o fast.html https://example.com/fast-response &amp;curl –http2 –http2-prioritize-weight 1 -o slow.html https://example.com/slow-response &amp;wait这里： fast-response 的优先级为 256（最高）。slow-response 的优先级为 1（最低）。服务器会优先响应 fast-response 流。 2.3 因特网中的电子邮件3个主体组成部分 用户代理 邮件服务器 简单邮件传输协议 SMTP： 应用层协议 使用TCP可靠数据传输 每台邮件服务器上：既运行SMTP的客户端也运行SMTP的服务器端因为： SMTP发送邮件的时候 表现为： 客户端 SMTP接收邮件的时候 表现为： 服务器端 使用7bit ASCII标识 2.3.1 SMTP 12.18 日 套接字编程： UDP套接字： TCP套接字"},{"title":"操作系统学习","date":"2024-12-20T13:07:48.514Z","updated":"2024-12-16T02:53:54.307Z","comments":true,"path":"archives/computer_operate.html","permalink":"https://whuichenggong.github.io/archives/computer_operate.html","excerpt":"","text":"6.cs081os学习 感谢： 参考资料： https://www.geeksforgeeks.org/pipe-system-call/ 很好的文章： https://swtch.com/~rsc/thread/ 同步机制：https://zybtree.github.io/2020/08/12/%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/ 参考答案： https://github.com/relaxcn/xv6-labs-2022-solutions/blob/main/doc/utils.md 学习链接： https://pdos.csail.mit.edu/6.828/2021/schedule.html 直接从进程与线程入手 进程与线程单独的CPU变换成多个虚拟的CPU 进程当网页请求进入的时候 先查看 网页是否在缓存中 如果不是启动一个磁盘请求用来获取网页 磁盘请求会花费很多时间 等待的过程中会有更多的请求进入每个进程有它自己的虚拟的CPU 真正的CPU在进程之间来回切换需要一些方法例如多个磁盘 模拟控制并发 进程就能发挥作用来回切换称： 多道程序设计 支持多进程的多道程序系统一个核一次也只能运行一个进程 12.1日一.进程的并发执行 并发 进程的执行是间断的 每个进程的生命周期期间CPU执行 由于某种原因暂停 每个进程执行是间断性的 进程的执行速度是不可预测的 进程调度，有其他事件的发生，每个进程上cpu执行坑你一点时间听着再接着运行 共享 进程线程之间的制约性在一个并发环境下多个进程或者线程之间会共享某些资源，在这些资源的使用过程中会产生进程之间的一种制约性。比如当一个进程享用打印机这个资源，另外一个进程在第一个进程没有释放这个资源的前提之下就得不到这个资源，那就得等待。 不确定性 进程执行的结果与其执行的相对速度有关 进程执行的结果和它的相对执行速度是有关系的，因此在不同的执行顺序的情况下，进程的执行结果也是不确定的。 二.进程互斥由于各进程要求使用共享资源(变量、文件等)， 而这些资源需要排他性使用，各进程之间竞争使用这些资源，这一关系称为进程互斥。 临界资源系统中某些资源一次只允许一个进程使用，称这样的资源为临界资源或互斥资源或共享变量。这些程序片段，分散在不同的进程里，它们的共同的特点是对同一个共享变量进行一些操作这一段代码，和另外一个进程的这一段代码互为临界区，互为互斥区 冯诺依曼模型计算机基本结构：运算器 控制器 存储器 输入设备 输出设备 内存程序和数据都是存储在内存，存储区域是线性的 存储数据的基本单位是 字节 每一个字节对应一个内存地址 最后一个地址为内存总字节数 -1 结构就像数序中的数据 中央处理器也就是cpu：32位cpu一次可以计算4个字节64位cpu一次可以计算8个字节 位数也就是cpu的位宽 代表cpu一次可以计算的数据量 8 位的 CPU，那么一次只能计算 1 个字节也就是0~255 范围内的数值 那么 32位也就是一次可以计算出 2的32次方这么大的数值cpu内部组件：寄存器，控制单元和逻辑运算单元 为什么有了内存还需要寄存器？ 寄存器种类（通用寄存器）（程序计数器）（指令寄存器） 因为： 内存离 CPU 太远了，而寄存器就在 CPU 里，紧挨着控制单元和逻辑运算单元，自然计算时速度会很快。 总线总线用于cpu和内存以及其他设备之前的通信 （地址总线）：指定CPU将要操作的内存地址 （数据总线）：用于读写内存的数据 （控制总线）： 发送和接收信号，比如中断，设备复位等信号 CPU 要读写内存数据的时候： 首先要通过「地址总线」来指定内存的地址； 然后通过「控制总线」控制是读或写命令； 最后通过「数据总线」来传输数据； 输入输出设备输入设备向计算机输入数据，计算机经过计算后，把数据输出给输出设备。如果输入设备是键盘，按下按键时是需要和 CPU 进行交互的，这时就需要用到控制总线了。 线路位宽与CPU位宽数据是如何通过线路传输的呢操作电压，低电压表示 0，高压电压则表示 1 101 二进制数据，十进制则表示 5，如果只有一条线路，就意味着每次只能传递 1 bit 的数据， 那么传输 101 这个数据，就需要 3 次才能传输完成，这样的效率非常低。 增加线路，数据并行传输 CPU 想要操作「内存地址」就需要「地址总线」： 地址总线只有 1 条，那每次只能表示 「0 或 1」这两种地址 最大数量为 2（2^1）个 如果地址总线有 2 条，那么能表示 00、01、10、11 这四种地址 最大数量为 4（2^2）个 CPU 操作 4G 大的内存，那么就需要 32 条地址总线，因为 2 ^ 32 &#x3D; 4G CPU位宽最好不要小于线路位宽 a little operater systerm链接 ： https://lwn.net/Articles/250967/ 所有 CPU（前面的示例中为两个，但可以有更多）都通过公共总线（前端总线，FSB）连接到北桥。除其他外，北桥还包含内存控制器，其实现决定了计算机使用的 RAM 芯片的类型。不同类型的 RAM，例如 DRAM、Rambus 和 SDRAM，需要不同的内存控制器。 要访问所有其他系统设备，北桥必须与南桥进行通信。南桥通常称为 I&#x2F;O 桥，通过各种不同的总线处理与设备的通信。如今，PCI、PCI Express、SATA 和 USB 总线最为重要，但南桥也支持 PATA、IEEE 1394、串行和并行端口。较旧的系统具有连接到北桥的 AGP 插槽。这样做是出于与北桥和南桥之间的连接速度不够快相关的性能原因。然而，如今 PCI-E 插槽全部连接到南桥。 让终端显示出自己说的话1234567cd ~root@xiaoxinxiaohao:~# vim .bashrcroot@xiaoxinxiaohao:~# source ~/.bashrc赵忠鹤闪亮登场Today is: Fri Dec 6 05:12:09 PM CST 2024今天也要充满活力哇咔咔听从了一些学习的建议，带着问题去读书，想学什么，去书中学，带着问题去读书 12.16日 看到了b站的一个关于Go并发设计了解协程： 协程是一种用户级的轻量级线程。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈 主流语言基本上都选择了多线程作为并发设施 线程相关的概念就是抢占式多任务（Preemptive multitasking），而与协程相关的是协作式多任务 多线程编程是比较困难的， 因为调度程序任何时候都能中断线程， 必须记住保留锁， 去保护程序中重要部分， 防止多线程在执行的过程中断 协程默认会做好全方位保护， 以防止中断 协程相比于多线程的优点无需系统内核的上下文切换，减小开销； 因为：协程它不像线程和进程那样，需要进行系统内核上的上下文切换，协程的上下文切换是由开发人员决定的 无需原子操作锁定及同步的开销，不用担心资源共享的问题 单线程即可实现高并发，单核 CPU 即便支持上万的协程都不是问题，所以很适合用于高并发处理，尤其是在应用在网络爬虫中 缺点 无法使用 CPU 的多核 因为： 协程的本质是个单线程 写协程就意味着你要一值写一些非阻塞的代码，使用各种异步版本的库，比如后面的异步爬虫教程中用的 aiohttp 协程的概念最核心的点其实就是函数或者一段程序能够被挂起（说暂停其实也没啥问题），待会儿再恢复"},{"title":"为什么别人写项目知道用什么？","date":"2024-12-20T13:07:48.515Z","updated":"2024-12-07T09:20:17.605Z","comments":true,"path":"archives/confusion.html","permalink":"https://whuichenggong.github.io/archives/confusion.html","excerpt":"","text":"同样来自GPT的回答： 你的疑惑非常好！许多人在学习编程时都会有类似的感受，尤其是在学习阶段，看到博主轻松选择某些包或者工具来解决问题时，会觉得他们似乎“无所不知”。事实上，这背后是经验和积累的结果。以下几点可以帮助你理解和逐步建立这种能力： 1. 经验的积累 博主的背景：他们可能已经解决过类似问题，因此知道哪些包是高效的选择。这是经验的体现。 类比：就像一位厨师在做菜时，很容易知道用什么调料，而新手可能需要查配方。 你可以这样做： 多看、多学：通过模仿优秀项目和学习文档，积累对常用库和框架的了解。 练习总结：每次解决问题后，记录用到的包和方法，慢慢形成自己的“工具箱”。 2. 文档与生态 语言和框架的生态：每种语言或框架都有一些社区公认的、常用的库。 比如，Go 语言处理配置时，大家常用 viper 或 yaml。 HTTP 请求：net/http（原生）或社区的 gin（框架）。 社区推荐：很多库被推荐使用，是因为它们： 功能齐全。 易于使用。 社区活跃，有长期维护。 你可以这样做： 了解生态：多逛 GitHub、Go 的标准库文档以及社区资源（比如 Go 的官方博客）。 参考优秀代码：通过学习开源项目，你可以快速了解哪些包解决了哪些问题。 3. 搜索能力 很多开发者的知识并不是“记住的”，而是“查到的”。他们遇到问题时，会： 搜索问题：查找类似场景的解决方案。 评估方案：根据实际需求选择合适的库或框架。 搜索时的技巧： 用精准关键词，比如“Go JWT authentication package”。 看社区推荐，比如 Stack Overflow、Reddit、GitHub 等。 你可以这样做： 当不知道用哪个包时，搜索类似场景的关键词，看看其他开发者用了什么库。 慢慢熟悉常用的社区推荐来源，比如： Awesome Go：列出了 Go 的优秀库。 Go Packages：Go 的官方包文档和搜索平台。 4. 理解需求，选择工具 博主并不是“盲选”包，而是基于需求选工具。 例如：需要读取配置文件，就会选择支持多种格式的 viper。 需要快速搭建 Web 服务框架，就会用 gin 或 echo。 你可以这样做： 学会分析问题：问自己——“这个问题需要解决什么？”“有没有原生支持？” 学会看库文档： 比如，在 GitHub 项目中，看 ReadMe 和示例代码，理解库的功能。 5. 你的问题如何转换为实践 明确目标：先理解你要解决的问题，比如“实现一个 JWT 登录功能”。 学习思路：看看博主怎么解决的，模仿过程并分析他们选择的工具是否合理。 尝试自己实现：不要依赖博主的方案，尝试用其他库或者原生代码实现。 总结：知识的形成是一个积累过程博主看似“知道一切”，实际上是基于： 经验积累：长期的项目经验让他们知道常用包。 良好工具链：对语言生态了解，知道优秀的社区推荐。 高效搜索：遇到新问题时，他们可以快速找到解决方案。 行动建议： 多积累项目经验，模仿优秀代码，逐渐形成自己的“工具箱”。 学会分解问题和尝试不同工具，在实践中找到更适合的解决方案。坚持下去，你也会越来越“有经验”！ 😊"},{"title":"聊聊最近","date":"2024-12-20T13:07:48.517Z","updated":"2024-12-13T07:20:24.060Z","comments":true,"path":"archives/current.html","permalink":"https://whuichenggong.github.io/archives/current.html","excerpt":"","text":"最近的日子在想着达到就业的水平，不断地提升额，嗯然后今天手机掉水里了，烘干24小时，看看能不能复活吧，突然觉得之前手机不是那么重要，回想起它占用我的时间，好像都不是什么重要的事情，近期来，感觉是为了让自己舒服一点，白天学完，晚上回去就刷手机而且就是 12点 1点，恶性循环，本想着晚上回去看会书，自己却暗示自己，学一天了，玩吧哈哈哈。好像都没做，但是确实没有那么重要，吃饭可以让同学帮我付，哈哈，还是得学习呢，反省一下，是不是你想要的太多了而导致你很累，那种精神上的压迫自己，反思~ 今天12.12日试着实现将单片机的数据传输到数据库中交互先简单的使用按钮的高低电平0 1 实现交互试试看 后端服务代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;log&quot; &quot;net/http&quot; &quot;context&quot; &quot;github.com/jackc/pgx/v4&quot;)type ButtonPress struct &#123; DeviceID string `json:&quot;device_id&quot;` Button int `json:&quot;button&quot;` Timestamp string `json:&quot;timestamp&quot;`&#125;const ( dbHost = &quot;localhost&quot; dbPort = 5432 dbUser = &quot;root&quot; dbPassword = &quot;secret&quot; dbName = &quot;data&quot;)func main() &#123; // Set up the database connection connStr := fmt.Sprintf(&quot;postgresql://%s:%s@%s:%d/%s&quot;, dbUser, dbPassword, dbHost, dbPort, dbName) conn, err := pgx.Connect(context.Background(), connStr) if err != nil &#123; log.Fatalf(&quot;Unable to connect to the database: %v&quot;, err) &#125; defer conn.Close(context.Background()) // Set up the HTTP server http.HandleFunc(&quot;/receive&quot;, func(w http.ResponseWriter, r *http.Request) &#123; if r.Method != http.MethodPost &#123; http.Error(w, &quot;Only POST requests are supported&quot;, http.StatusMethodNotAllowed) return &#125; var data ButtonPress if err := json.NewDecoder(r.Body).Decode(&amp;data); err != nil &#123; http.Error(w, &quot;Invalid JSON format&quot;, http.StatusBadRequest) return &#125; log.Printf(&quot;Received data: %+v&quot;, data) if data.Button == 1 &#123; // Store the data in the database query := &quot;INSERT INTO button_presses (device_id, button, timestamp) VALUES ($1, $2, $3)&quot; _, err := conn.Exec(context.Background(), query, data.DeviceID, data.Button, data.Timestamp) if err != nil &#123; http.Error(w, &quot;Failed to store data in the database&quot;, http.StatusInternalServerError) return &#125; log.Println(&quot;Data successfully stored in the database&quot;) &#125; w.WriteHeader(http.StatusOK) w.Write([]byte(&quot;Data received and processed&quot;)) &#125;) log.Println(&quot;Starting server on 192.168.111.1:8080&quot;) if err := http.ListenAndServe(&quot;192.168.111.1:8080&quot;, nil); err != nil &#123; log.Fatalf(&quot;Server failed: %v&quot;, err) &#125;&#125; 这是简单的实现 单片机端代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;ESP8266WiFi.h&gt;#include &lt;ESP8266HTTPClient.h&gt;const char* ssid = &quot;Your_SSID&quot;; // Wi-Fi 名称const char* password = &quot;Your_PASSWORD&quot;; // Wi-Fi 密码const char* serverUrl = &quot;http://8.222.186.212:8080/send&quot;; // 后端服务器地址void setup() &#123; Serial.begin(115200); // 初始化串口 WiFi.begin(ssid, password); // 连接到 Wi-Fi Serial.print(&quot;Connecting to Wi-Fi&quot;); while (WiFi.status() != WL_CONNECTED) &#123; delay(1000); Serial.print(&quot;.&quot;); &#125; Serial.println(&quot;\\nConnected to Wi-Fi&quot;);&#125;void loop() &#123; if (WiFi.status() == WL_CONNECTED) &#123; HTTPClient http; http.begin(serverUrl); // 设置服务器 URL http.addHeader(&quot;Content-Type&quot;, &quot;application/json&quot;); // 设置请求头 // 示例 JSON 数据 String jsonData = &quot;&#123;\\&quot;sensor\\&quot;: \\&quot;temperature\\&quot;, \\&quot;value\\&quot;: 25.5&#125;&quot;; // POST 请求 int httpResponseCode = http.POST(jsonData); // 检查响应状态 if (httpResponseCode &gt; 0) &#123; String response = http.getString(); Serial.println(&quot;Response: &quot; + response); &#125; else &#123; Serial.println(&quot;Error on sending POST: &quot; + String(httpResponseCode)); &#125; http.end(); // 关闭连接 &#125; else &#123; Serial.println(&quot;Wi-Fi not connected&quot;); &#125; delay(5000); // 每 5 秒发送一次数据&#125; HTTP就是那么的神奇"},{"title":"数据结构的实现","date":"2024-12-20T13:07:48.524Z","updated":"2024-11-24T13:06:56.677Z","comments":true,"path":"archives/data_structure.html","permalink":"https://whuichenggong.github.io/archives/data_structure.html","excerpt":"","text":"双链表的实现基于go语言实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package mainimport &quot;fmt&quot;// Node 定义双链表节点type Node struct &#123; data interface&#123;&#125; prev *Node next *Node&#125;// DoublyLinkedList 定义双链表type DoublyLinkedList struct &#123; head *Node tail *Node size int&#125;// InsertTail 向链表尾部插入节点func (dll *DoublyLinkedList) InsertTail(data interface&#123;&#125;) &#123; newNode := &amp;Node&#123;data: data&#125; if dll.size == 0 &#123; dll.head = newNode dll.tail = newNode &#125; else &#123; dll.tail.next = newNode newNode.prev = dll.tail dll.tail = newNode &#125; dll.size++&#125;// InsertHead 向链表头部插入节点func (dll *DoublyLinkedList) InsertHead(data interface&#123;&#125;) &#123; newNode := &amp;Node&#123;data: data&#125; if dll.size == 0 &#123; dll.head = newNode dll.tail = newNode &#125; else &#123; newNode.next = dll.head dll.head.prev = newNode dll.head = newNode &#125; dll.size++&#125;// Remove 删除节点func (dll *DoublyLinkedList) Remove(node *Node) &#123; if node.prev != nil &#123; node.prev.next = node.next &#125; else &#123; dll.head = node.next &#125; if node.next != nil &#123; node.next.prev = node.prev &#125; else &#123; dll.tail = node.prev &#125; node.prev = nil node.next = nil dll.size--&#125;// Display 打印双链表func (dll *DoublyLinkedList) Display() &#123; curr := dll.head for curr != nil &#123; fmt.Print(curr.data, &quot; &quot;) curr = curr.next &#125; fmt.Println()&#125;func main() &#123; dll := DoublyLinkedList&#123;&#125; dll.InsertTail(1) dll.InsertTail(2) dll.InsertHead(0) dll.Display() // 应该输出：0 1 2 // 删除节点 headNode := dll.head dll.Remove(headNode) dll.Display() // 应该输出：1 2&#125; 基于c语言实现双链表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;// 定义双链表节点结构typedef struct Node &#123; int data; struct Node* prev; struct Node* next;&#125; Node;// 创建一个新节点Node* createNode(int data) &#123; Node* newNode = (Node*)malloc(sizeof(Node)); if (newNode == NULL) &#123; printf(&quot;内存分配失败&quot;); exit(1); &#125; newNode-&gt;data = data; newNode-&gt;prev = NULL; newNode-&gt;next = NULL; return newNode;&#125;// 在双链表前插入节点void insertFront(Node** head, int data) &#123; Node* newNode = createNode(data); newNode-&gt;next = *head; if (*head != NULL) &#123; (*head)-&gt;prev = newNode; &#125; *head = newNode;&#125;// 在双链表后插入节点void insertRear(Node** head, int data) &#123; Node* newNode = createNode(data); if (*head == NULL) &#123; *head = newNode; return; &#125; Node* last = *head; while (last-&gt;next != NULL) &#123; last = last-&gt;next; &#125; last-&gt;next = newNode; newNode-&gt;prev = last;&#125;// 删除双链表前的节点void deleteFront(Node** head) &#123; if (*head == NULL) &#123; printf(&quot;链表为空，无法删除&quot;); return; &#125; Node* temp = *head; *head = (*head)-&gt;next; if (*head != NULL) &#123; (*head)-&gt;prev = NULL; &#125; free(temp);&#125;// 删除双链表后的节点void deleteRear(Node** head) &#123; if (*head == NULL) &#123; printf(&quot;链表为空，无法删除&quot;); return; &#125; Node* secondLast = *head; while (secondLast-&gt;next-&gt;next != NULL) &#123; secondLast = secondLast-&gt;next; &#125; Node* temp = secondLast-&gt;next; secondLast-&gt;next = NULL; free(temp);&#125;// 打印双链表void printList(Node* node) &#123; while (node != NULL) &#123; printf(&quot;%d &quot;, node-&gt;data); node = node-&gt;next; &#125; printf(&quot;\\n&quot;);&#125;int main() &#123; Node* head = NULL; insertFront(&amp;head, 10); insertFront(&amp;head, 20); insertRear(&amp;head, 30); insertRear(&amp;head, 40); printList(head); // 输出：20 10 30 40 deleteFront(&amp;head); deleteRear(&amp;head); printList(head); // 输出：10 30 return 0;&#125; 区别： c语言的双链表 我们要清楚 改变了头节点 所以要传入二级指针 才能正确的记录到头指针的变化 而Go语言，因为 Go 中的切片、映射和通道等是引用类型，它们在函数参数传递时本身就是按引用传递的，不需要通过指针的指针（二级指针）来实现修改。这实际上是 Go 语言的一个特性：切片、映射和通道在函数间传递时，共享底层数据结构，因此不需要额外的二级指针。 栈的c语言实现1.数组12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include&lt;stdio.h&gt;#include&lt;stdbool.h&gt;typedef struct Stack &#123; int data[10]; int top;&#125; Stack;void InitStack(Stack* stack) &#123; stack-&gt;top = -1;&#125;bool IsFull(Stack* stack) &#123; return stack-&gt;top == 9;&#125;bool IsEmpty(Stack* stack) &#123; return stack-&gt;top == -1;&#125;bool push(Stack* stack, int data) &#123; if (IsFull(stack)) &#123; printf(&quot;栈已经满了不能执行入栈操作\\n&quot;); return false; &#125; stack-&gt;data[++stack-&gt;top] = data; return true;&#125;int pop(Stack* stack) &#123; if (IsEmpty(stack)) &#123; printf(&quot;栈已经空了不能出栈\\n&quot;); return -1; &#125; return stack-&gt;data[stack-&gt;top--];&#125;void Println(Stack* stack) &#123; printf(&quot;栈中元素：&quot;); for (int i = stack-&gt;top; i &gt;= 0 ; i--) &#123; printf(&quot;%d &quot;, stack-&gt;data[i]); &#125; printf(&quot;\\n&quot;);&#125;int main() &#123; Stack stack; InitStack(&amp;stack); push(&amp;stack, 1); push(&amp;stack, 2); push(&amp;stack, 3); push(&amp;stack, 4); Println(&amp;stack); //pop(&amp;stack); pop(&amp;stack); pop(&amp;stack); // pop(&amp;stack); Println(&amp;stack); return 0;&#125; 2.链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdbool.h&gt;typedef struct stack &#123; int data; struct stack* next;&#125; Stack;void InitStack(Stack** top) &#123; *top = NULL; // 初始化为空链表，头指针为NULL&#125;bool IsEmpty(Stack* top) &#123; return top == NULL;&#125;Stack* CreateNode(int data) &#123; Stack* node = (Stack*)malloc(sizeof(Stack)); if (node == NULL) &#123; printf(&quot;分配空间出现错误&quot;); return NULL; &#125; node-&gt;data = data; node-&gt;next = NULL; return node;&#125;void Push(Stack** top, int data) &#123; Stack* newnode = CreateNode(data); if (newnode == NULL) return; newnode-&gt;next = *top; *top = newnode; // 更新头指针指向新节点&#125;int Pop(Stack** top) &#123; if (IsEmpty(*top)) &#123; printf(&quot;栈已经空了不能出栈\\n&quot;); return -1; &#125; Stack* temp = *top; int data = temp-&gt;data; *top = temp-&gt;next; // 更新头指针指向下一个节点 free(temp); return data;&#125;void Println(Stack* top) &#123; Stack* temp = top; while (temp != NULL) &#123; printf(&quot;%d &quot;, temp-&gt;data); temp = temp-&gt;next; &#125; printf(&quot;\\n&quot;);&#125;int main() &#123; Stack* stack; InitStack(&amp;stack); Push(&amp;stack, 1); Push(&amp;stack, 2); Push(&amp;stack, 3); Push(&amp;stack, 4); Println(stack); printf(&quot;出栈: %d\\n&quot;, Pop(&amp;stack)); printf(&quot;出栈: %d\\n&quot;, Pop(&amp;stack)); Println(stack); return 0;&#125; 队列c语言实现数组实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdbool.h&gt;typedef struct stack &#123; int data; struct stack* next;&#125; Stack;void InitStack(Stack** top) &#123; *top = NULL; // 初始化为空链表，头指针为NULL&#125;bool IsEmpty(Stack* top) &#123; return top == NULL;&#125;Stack* CreateNode(int data) &#123; Stack* node = (Stack*)malloc(sizeof(Stack)); if (node == NULL) &#123; printf(&quot;分配空间出现错误&quot;); return NULL; &#125; node-&gt;data = data; node-&gt;next = NULL; return node;&#125;void Push(Stack** top, int data) &#123; Stack* newnode = CreateNode(data); if (newnode == NULL) return; newnode-&gt;next = *top; *top = newnode; // 更新头指针指向新节点&#125;int Pop(Stack** top) &#123; if (IsEmpty(*top)) &#123; printf(&quot;栈已经空了不能出栈\\n&quot;); return -1; &#125; Stack* temp = *top; int data = temp-&gt;data; *top = temp-&gt;next; // 更新头指针指向下一个节点 free(temp); return data;&#125;void Println(Stack* top) &#123; Stack* temp = top; while (temp != NULL) &#123; printf(&quot;%d &quot;, temp-&gt;data); temp = temp-&gt;next; &#125; printf(&quot;\\n&quot;);&#125;int main() &#123; Stack* stack; InitStack(&amp;stack); Push(&amp;stack, 1); Push(&amp;stack, 2); Push(&amp;stack, 3); Push(&amp;stack, 4); Println(stack); printf(&quot;出栈: %d\\n&quot;, Pop(&amp;stack)); printf(&quot;出栈: %d\\n&quot;, Pop(&amp;stack)); Println(stack); return 0;&#125; 哈希表c简单实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#define NUM 5typedef struct HashList &#123; int num; char data[NUM]; // 修改为字符数组&#125; HashList;HashList* initList() &#123; HashList* list = (HashList*)malloc(sizeof(HashList)); list-&gt;num = 0; for (int i = 0; i &lt; NUM; i++) &#123; list-&gt;data[i] = 0; // 初始化所有元素为0 &#125; return list;&#125;// ASCII码计算自动计算int hash(int data) &#123; return data % NUM;&#125;void put(HashList* list, char data) &#123; int index = hash(data); printf(&quot;index = %d\\n&quot;, index); // 发生冲突 while (list-&gt;data[index] != 0) &#123; // 确保这个位置已经被占用 int count = 1; index = hash(index + 1); // 线性查找 count++; printf(&quot;index = %d\\n&quot;, index); &#125; list-&gt;data[index] = data;&#125;int main() &#123; HashList* list = initList(); put(list, &#x27;A&#x27;); put(list, &#x27;F&#x27;); for (int i = 0; i &lt; NUM; i++) &#123; if (list-&gt;data[i] != 0) &#123; // 只打印已经使用的槽位 printf(&quot;%c\\n&quot;, list-&gt;data[i]); &#125; &#125; return 0;&#125; 借鉴： https://github.com/hunterhug/goa.c/blob/master/algorithm/dict.md go实现可变数组123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package mainimport ( &quot;fmt&quot; &quot;sync&quot;)// Array 可变长数组type Array struct &#123; array []int // 固定大小的数组，用满容量和满大小的切片来代替 len int // 真正长度 cap int // 容量 lock sync.Mutex // 为了并发安全使用的锁&#125;// Make 新建一个可变长数组func Make(len, cap int) *Array &#123; s := new(Array) if len &gt; cap &#123; panic(&quot;len large than cap&quot;) &#125; // 把切片当数组用 array := make([]int, cap, cap) // 元数据 s.array = array s.cap = cap s.len = 0 return s&#125;// Append 增加一个元素func (a *Array) Append(element int) &#123; // 并发锁 a.lock.Lock() defer a.lock.Unlock() // 大小等于容量，表示没多余位置了 if a.len == a.cap &#123; // 没容量，数组要扩容，扩容到两倍 newCap := 2 * a.len // 如果之前的容量为0，那么新容量为1 if a.cap == 0 &#123; newCap = 1 &#125; newArray := make([]int, newCap, newCap) // 把老数组的数据移动到新数组 for k, v := range a.array &#123; newArray[k] = v &#125; // 替换数组 a.array = newArray a.cap = newCap &#125; // 把元素放在数组里 a.array[a.len] = element // 真实长度+1 a.len = a.len + 1&#125;// AppendMany 增加多个元素func (a *Array) AppendMany(element ...int) &#123; for _, v := range element &#123; a.Append(v) &#125;&#125;// Get 获取某个下标的元素func (a *Array) Get(index int) int &#123; // 越界了 if a.len == 0 || index &gt;= a.len &#123; panic(&quot;index over len&quot;) &#125; return a.array[index]&#125;// Len 返回真实长度func (a *Array) Len() int &#123; return a.len&#125;// Cap 返回容量func (a *Array) Cap() int &#123; return a.cap&#125;// Print 辅助打印func Print(array *Array) (result string) &#123; result = &quot;[&quot; for i := 0; i &lt; array.Len(); i++ &#123; // 第一个元素 if i == 0 &#123; result = fmt.Sprintf(&quot;%s%d&quot;, result, array.Get(i)) continue &#125; result = fmt.Sprintf(&quot;%s %d&quot;, result, array.Get(i)) &#125; result = result + &quot;]&quot; return&#125;func main() &#123; // 创建一个容量为3的动态数组 a := Make(0, 3) fmt.Println(&quot;cap&quot;, a.Cap(), &quot;len&quot;, a.Len(), &quot;array:&quot;, Print(a)) // 增加一个元素 a.Append(10) fmt.Println(&quot;cap&quot;, a.Cap(), &quot;len&quot;, a.Len(), &quot;array:&quot;, Print(a)) // 增加一个元素 a.Append(9) fmt.Println(&quot;cap&quot;, a.Cap(), &quot;len&quot;, a.Len(), &quot;array:&quot;, Print(a)) // 增加多个元素 a.AppendMany(8, 7) fmt.Println(&quot;cap&quot;, a.Cap(), &quot;len&quot;, a.Len(), &quot;array:&quot;, Print(a))&#125; 字典123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;unsafe&quot;)// 集合结构体type Set struct &#123; m map[int]struct&#123;&#125; // 用字典来实现，因为字段键不能重复 len int // 集合的大小 sync.RWMutex // 锁，实现并发安全&#125;// 新建一个空集合func NewSet(cap int64) *Set &#123; temp := make(map[int]struct&#123;&#125;, cap) return &amp;Set&#123; m: temp, &#125;&#125;// 增加一个元素func (s *Set) Add(item int) &#123; s.Lock() defer s.Unlock() s.m[item] = struct&#123;&#125;&#123;&#125; // 实际往字典添加这个键 s.len = len(s.m) // 重新计算元素数量&#125;// 移除一个元素func (s *Set) Remove(item int) &#123; s.Lock() defer s.Unlock() // 集合没元素直接返回 if s.len == 0 &#123; return &#125; delete(s.m, item) // 实际从字典删除这个键 s.len = len(s.m) // 重新计算元素数量&#125;// 查看是否存在元素func (s *Set) Has(item int) bool &#123; s.RLock() defer s.RUnlock() _, ok := s.m[item] return ok&#125;// 查看集合大小func (s *Set) Len() int &#123; return s.len&#125;// 清除集合所有元素func (s *Set) Clear() &#123; s.Lock() defer s.Unlock() s.m = map[int]struct&#123;&#125;&#123;&#125; // 字典重新赋值 s.len = 0 // 大小归零&#125;// 集合是够为空func (s *Set) IsEmpty() bool &#123; if s.Len() == 0 &#123; return true &#125; return false&#125;// 将集合转化为列表func (s *Set) List() []int &#123; s.RLock() defer s.RUnlock() list := make([]int, 0, s.len) for item := range s.m &#123; list = append(list, item) &#125; return list&#125;// 为什么使用空结构体func other() &#123; a := struct&#123;&#125;&#123;&#125; b := struct&#123;&#125;&#123;&#125; if a == b &#123; fmt.Printf(&quot;right:%p\\n&quot;, &amp;a) &#125; fmt.Println(unsafe.Sizeof(a))&#125;func main() &#123; //other() // 初始化一个容量为5的不可重复集合 s := NewSet(5) s.Add(1) s.Add(1) s.Add(2) fmt.Println(&quot;list of all items&quot;, s.List()) s.Clear() if s.IsEmpty() &#123; fmt.Println(&quot;empty&quot;) &#125; s.Add(1) s.Add(2) s.Add(3) if s.Has(2) &#123; fmt.Println(&quot;2 does exist&quot;) &#125; s.Remove(2) s.Remove(3) fmt.Println(&quot;list of all items&quot;, s.List())&#125; 加并发锁，实现线程安全，然后往结构体s *Set 里面的内置 map 添加该元素：item，元素作为字典的键，会自动去重。同时，集合大小重新生成。 s.m[item] &#x3D; struct{}{} 这行代码向 m 这个映射中添加一个 item 作为键，并将其值设置为 struct{}{}。由于 m 是 map[int]struct{} 类型的，它的键是 int 类型，而值是空结构体 struct{} 类型，它们不占用任何空间。这一步实际上是往字典添加一个键，而不需要关心值。 最大堆的建立堆排序中的（递归）是制造最大堆的关键 其实也可以不用最大堆 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include&lt;stdio.h&gt;void heapsort(int a[],int length,int i);void buildheap(int a[], int length);void swap(int* a, int* b);void prinarry(int a[], int length);void prinarry(int a[], int length)&#123; for (int i = 0; i &lt; length; i++) &#123; printf(&quot;%d&quot;, a[i]); &#125; printf(&quot;\\n&quot;);&#125;void swap(int* a, int* b)&#123; int temp = 0; temp=*a; * a = *b; * b = temp;&#125;//重点在这里如何交换使得成为最大堆void heapsort(int a[], int length, int i)&#123; int largest = i; int left = 2 * i + 1; int right = 2 * i + 2; if (left&lt;length &amp;&amp; a[left]&gt;a[largest]) &#123; largest = left; &#125; if (right&lt;length &amp;&amp; a[right]&gt;a[largest]) &#123; largest = right; &#125; if (largest != i) &#123; swap(&amp;a[i], &amp;a[largest]);//必须加&amp; heapsort(a, length, largest);//这步递归是关键能确保整体保证是堆的性质 &#125;&#125;void buildheap(int a[], int length)//建立堆&#123; int i = (length - 1) / 2; for(i=(length-1)/2;i&gt;=0;i--) &#123; heapsort(a, length, i); &#125; &#125;int main()&#123; int arry[6] = &#123; 2,4,7,9,5,8&#125;; int length = sizeof(arry) / sizeof(arry[0]); buildheap(arry, length); prinarry(arry, length); return 0;&#125; 好像不对劲 如果你期望的是排序后的数组（比如 120 100 90 50），你的代码缺少以下步骤： 交换堆顶和末尾元素：将最大堆的根节点（最大值）移动到数组末尾。重新堆化剩余部分：对剩余的数组部分（即去掉最后一个元素的堆）重新堆化。重复步骤：直到数组完全排序。 你的代码本身并没有严重的问题，但它仅仅完成了“构建最大堆”的功能，没有实现堆排序，因此输出的数组只是一个堆的结构（满足最大堆性质，但并非有序数组）。如果你预期的结果是排序后的数组，那么确实还需要补充代码来完成堆排序的逻辑。 啊我靠 go实现最大堆123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101// 一个最大堆，一棵完全二叉树// 最大堆要求节点元素都不小于其左右孩子type Heap struct &#123; // 堆的大小 Size int // 使用内部的数组来模拟树 // 一个节点下标为 i，那么父亲节点的下标为 (i-1)/2 // 一个节点下标为 i，那么左儿子的下标为 2i+1，右儿子下标为 2i+2 Array []int&#125;// 初始化一个堆func NewHeap(array []int) *Heap &#123; h := new(Heap) h.Array = array return h&#125;// 最大堆插入元素func (h *Heap) Push(x int) &#123; // 堆没有元素时，使元素成为顶点后退出 if h.Size == 0 &#123; h.Array[0] = x h.Size++ return &#125; // i 是要插入节点的下标 i := h.Size // 如果下标存在 // 将小的值 x 一直上浮 for i &gt; 0 &#123; // parent为该元素父亲节点的下标 parent := (i - 1) / 2 // 如果插入的值小于等于父亲节点，那么可以直接退出循环，因为父亲仍然是最大的 if x &lt;= h.Array[parent] &#123; break &#125; // 否则将父亲节点与该节点互换，然后向上翻转，将最大的元素一直往上推 h.Array[i] = h.Array[parent] i = parent &#125; // 将该值 x 放在不会再翻转的位置 h.Array[i] = x // 堆数量加一 h.Size++&#125;// 最大堆移除根节点元素，也就是最大的元素func (h *Heap) Pop() int &#123; // 没有元素，返回-1 if h.Size == 0 &#123; return -1 &#125; // 取出根节点 ret := h.Array[0] // 因为根节点要被删除了，将最后一个节点放到根节点的位置上 h.Size-- x := h.Array[h.Size] // 将最后一个元素的值先拿出来 h.Array[h.Size] = ret // 将移除的元素放在最后一个元素的位置上 // 对根节点进行向下翻转，小的值 x 一直下沉，维持最大堆的特征 i := 0 for &#123; // a，b为下标 i 左右两个子节点的下标 a := 2*i + 1 b := 2*i + 2 // 左儿子下标超出了，表示没有左子树，那么右子树也没有，直接返回 if a &gt;= h.Size &#123; break &#125; // 有右子树，拿到两个子节点中较大节点的下标 if b &lt; h.Size &amp;&amp; h.Array[b] &gt; h.Array[a] &#123; a = b &#125; // 父亲节点的值都大于或等于两个儿子较大的那个，不需要向下继续翻转了，返回 if x &gt;= h.Array[a] &#123; break &#125; // 将较大的儿子与父亲交换，维持这个最大堆的特征 h.Array[i] = h.Array[a] // 继续往下操作 i = a &#125; // 将最后一个元素的值 x 放在不会再翻转的位置 h.Array[i] = x return ret&#125; 这段代码太帅了 没有使用递归 用循环 构造了最大堆！ 学习思想"},{"title":"git使用总结","date":"2024-12-20T13:07:48.529Z","updated":"2024-11-09T10:45:53.823Z","comments":true,"path":"archives/git.html","permalink":"https://whuichenggong.github.io/archives/git.html","excerpt":"","text":"git1.git clone &#x2F;&#x2F; 到本地2.git checkout -b xxx 切换至新分支xxx（相当于复制了remote的仓库到本地的xxx分支上3.修改或者添加本地代码（部署在硬盘的源文件上）4.git diff 查看自己对代码做出的改变5.git add 上传更新后的代码至暂存区6.git commit 可以将暂存区里更新后的代码更新到本地git7.git push origin xxx 将本地的xxxgit分支上传至github上的git （如果在写自己的代码过程中发现远端GitHub上代码出现改变）1.git checkout main 切换回main分支2.git pull origin master(main) 将远端修改过的代码再更新到本地3.git checkout xxx 回到xxx分支4.git rebase main 我在xxx分支上，先把main移过来，然后根据我的commit来修改成新的内容（中途可能会出现，rebase conflict —–》手动选择保留哪段代码）5.git push -f origin xxx 把rebase后并且更新过的代码再push到远端github上（-f —》强行）6.原项目主人采用pull request 中的 squash and merge 合并所有不同的commit 远端完成更新后1.git branch -d xxx 删除本地的git分支2.git pull origin master 再把远端的最新代码拉至本地"},{"title":"github参与开源应该做什么","date":"2024-12-20T13:07:48.530Z","updated":"2024-11-09T10:51:43.826Z","comments":true,"path":"archives/github.html","permalink":"https://whuichenggong.github.io/archives/github.html","excerpt":"","text":"第一次参与开源项目应该做些什么借鉴Moment老哥文档 https://juejin.cn/post/7354233858063925267 第一步forkfork到自己的仓库下 且选择fork所有分支 这样就可以有修改项目的权限通过Pull Request方式 commits合到上游项目 第二步克隆项目git clone … 第三步更新本地分支代码1234git remote add upstream &lt;原始仓库的URL&gt;git fetch upstreamgit checkout maingit rebase upstream/main 等等指令在此省略 详细的等到具体运用中再做增加 创建新的分支并在新的分支上作出修改 回到fork的仓库中找到pullRequestNewRequest并把自己更改的分支上传到作者的仓库也就完成了一次Request 写入你想更改的地方提交你的更改 开一个PR在完成 push 操作后，我们打开 GitHub，可以看到一个黄色的提示框，告诉我们可以开一个 Pull Request 了 参考： https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fxun082%2Fcreate-neat%2Fpull%2F83一定要参与一次实践，才懂得如何去做。只有错过了，才能保证下一次的完美运行。 最后希望自己早入加入开源大家庭中，加油！ 2024 11.5日"},{"title":"发布博客出现的问题","date":"2024-12-20T13:07:48.532Z","updated":"2024-11-09T10:43:49.613Z","comments":true,"path":"archives/github_actions.html","permalink":"https://whuichenggong.github.io/archives/github_actions.html","excerpt":"","text":"每一次用push推送到githubpage都会出现构建部署错误 我问了一下ai原因 这才有点明白到底是为什么 原因为什么会有这种差异？GitHub Pages 和 本地环境的差异： 在本地执行 hexo d 时，你的本地环境会根据 package.json 中的依赖来安装所有的主题和插件，确保所有必要的资源都存在。但是 GitHub Pages 仅仅依赖仓库中已经推送的文件（通常是 public&#x2F; 文件夹和 ._config.yml），它不会自动运行 npm、yarn 或 pnpm 来安装依赖。换句话说，GitHub Pages 并不会在部署过程中安装缺少的主题或插件。依赖没有正确推送： 你在本地运行 hexo d 时，可能已经正确地安装了 butterfly 主题，并且该主题存在于本地的 _config.yml 中和 node_modules 文件夹中。然而，在推送到 GitHub 上时，你没有将 node_modules 中的 butterfly 主题或相关配置文件推送到 GitHub 仓库。GitHub Pages 需要能够访问这些主题文件，而它不会在部署过程中下载和安装这些依赖。GitHub Pages 配置问题： 如果你直接使用 GitHub Pages 作为部署平台，GitHub 并不会自动安装你的 Hexo 依赖，因此它不能像本地环境一样找到 butterfly 主题。GitHub Pages 需要使用一个可以通过静态文件夹来部署的版本，而 Hexo 本地运行时通常会将主题内容放在 node_modules 中，这些内容并不会自动推送到 GitHub，除非你特别将它们包含在仓库中。 解决方法使用github-actions并且在google查找到的方法添加 .nojekyll文件 让github站点不适用jekyll 1234567891011121314151617181920212223242526272829name: Hexo Deployon: push: branches: - main # 监听主分支的推送jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Setup Node.js uses: actions/setup-node@v2 with: node-version: &#x27;16&#x27; - name: Install dependencies run: | npm install - name: Generate and Deploy run: | hexo generate hexo deploy env: HEXO_DEPLOY_PATH: $&#123;&#123; secrets.HEXO_DEPLOY_PATH &#125;&#125; # 设置部署路径 多看源码 基础真的很重要 多看官方文档能解决很多问题"},{"title":"北京之旅","date":"2024-12-20T13:07:48.539Z","updated":"2024-11-04T08:44:58.056Z","comments":true,"path":"archives/hello-world.html","permalink":"https://whuichenggong.github.io/archives/hello-world.html","excerpt":"","text":"开源社在偶然一次发现中 开源社举办了第九届中国开源年会，我很是激动，心中迅速萌发了去北京参加的冲动并和小伙伴赵冰决定这周五来一次说走就走的旅行~~~ 到达北京在周六的早上到达会场 扫了入场的码 领到了活动给的一些礼品 7点多我俩就到达了会场，刚开始觉得平平无奇，后来直到大会开始，陆陆续续的大家都来到了会场，开源社的老哥，老姐们开始了自己的演讲，我发现这真的不是一个普通大会，很多人报着开源的理念 一直维持着开源社，让开源社越来越大虽然是第一次参加，但是我对于这种氛围是非常的喜欢，各位有着自己想法的人都在开源社散发光辉，有为抗癌人士专门发布app的小胰宝等其他的产品，这令我深受触动，把科技真真正正的融合到了生活当中，使人们都能享受科技带来的便捷！大会中的每一个人的演讲都令我感到激动！但是对我印象的最深刻的就是yihong0618这个id，伊洪老师的演讲令我眼前一亮心里一跳哈哈哈哈简直太爽啦！！！ yihong0618请大家自己去看伊洪老师的github，你真的能从中学到很多，在火车上我一直再看伊洪老师的github每一件事是写的那么的真诚，有很多我也感同身受，生活的迷茫原来真的不是自己才有，面临各种压力，各种抉择！做好自己。老师的仓库里也有非常多的实用的产品大家可以自己去看！！ [github] https://github.com/yihong0618 在伊洪老师的演讲中，令我觉得钦佩的是，每一天的记录自己，我太喜欢这种感觉了，发布到github上，我也便想向这么做在4日赶回来我便从网上学习搭建博客，坚持记录每一天 结语这次旅程，说走就走，哈哈哈，这才是大学生嘛，遇见了开源社的大家，我希望从今的每一天，慢慢的融入到开源社这个大家庭 -感谢冰哥陪我这次旅行 2024年11.4日"},{"title":"archives","date":"2024-12-20T12:33:01.000Z","updated":"2024-12-20T12:33:01.439Z","comments":true,"path":"archives/index.html","permalink":"https://whuichenggong.github.io/archives/index.html","excerpt":"","text":""},{"title":"一些找工作或实习的渠道","date":"2024-12-20T13:07:48.545Z","updated":"2024-11-13T12:18:18.023Z","comments":true,"path":"archives/job.html","permalink":"https://whuichenggong.github.io/archives/job.html","excerpt":"","text":"Boss直聘 offershow github上查找 linkedin"},{"title":"20岁生日","date":"2024-12-20T13:07:48.550Z","updated":"2024-11-16T12:24:16.923Z","comments":true,"path":"archives/live.html","permalink":"https://whuichenggong.github.io/archives/live.html","excerpt":"","text":"生活的意义就是在于享受每一天，有开心，有难过，有惊喜！ 享受它，生活就是这样！有了博客可以让时间更具象化，留住每一刻，想看的时候翻一翻 感受真的不一样！ 本来不想过生日的，但还是被寝室的兄弟们发现了哈哈哈哈好开心呢上大学的两年都收到了寝室5个兄弟给我送的蛋糕感谢你们啦，尽管离开了家还是有人陪你过生日，非常开心，还是你们陪我走完大学四年上高中的时候也没怎么正经过过生日，到了大学是你们让我的今天变得过呢更有意义，尽管在生活中有磕碰，但那是难以避免的！希望你们每个人以后路越来越好 也是收到家里人的好多红包啊哈哈啊哈好开心！ 感谢家人时刻牵挂着我！ 2023年的今天 2024年的今天 每年的生日许愿都是很广泛的 我姐说那是没有意义的哈哈哈一定要为自己许个愿望在新的一年实现它！ 小彩蛋 11.16日"},{"title":"一位老哥的分享给了我一些启发","date":"2024-12-20T13:07:48.551Z","updated":"2024-12-18T12:57:34.101Z","comments":true,"path":"archives/live3.html","permalink":"https://whuichenggong.github.io/archives/live3.html","excerpt":"","text":"学习方法：老哥的思维方式也给了我一些启发 以下是老哥的分享： 当知识点量大起来时, 我觉得”写作”的意义应该在于辅助思考 因为短时间内可能我们能记得很好, 但是对于长时间的庞大知识体系的学习, 就容易忘记一些分支内容 所以第一步我做的是把长长的博客尽量拆解为小的讨论主题 作为”词条”存在 比如我写了个k8s主题的词条 写道”容器”这个词会自动链接到我之前写过的容器相关的内容 里面的内容是否符合当下我需要的定义 如果是, 那么可以知识复用 如果不是, 那么我需不需要创建新的词条来讨论这个主题然后关联知识形成网络 比如一个使用mysql + reids搭建的系统, 即用到了mysql, 又用到了redis, 同时它本身还是个系统设计就会难以归类 但是 一个文章可以同时带有mysql, redis, 系统设计三种tag 让知识形成网络！ 先把书的标题提取出来 建立一个词条 然后去网上查, 这个东西包含哪些东西 然后去网上查, 这个东西包含哪些东西 等熟悉了基于零散信息的网络后 再去快速浏览权威书籍 迭代网络 听了老哥的分享！ 我觉得自己再生活中真的缺乏太多的思考了！什么事知道他困难，不想办法，应该去思考一些东西才能让东西变得更活！"},{"title":"leet-code之旅","date":"2024-12-20T13:07:48.548Z","updated":"2024-12-17T12:24:07.547Z","comments":true,"path":"archives/leet-code.html","permalink":"https://whuichenggong.github.io/archives/leet-code.html","excerpt":"","text":"正式开启刷leet-code第225.用两个队列实现栈问题： 请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通栈的全部四种操作（push、top、pop 和 empty）。 实现 MyStack 类： void push(int x) 将元素 x 压入栈顶。int pop() 移除并返回栈顶元素。int top() 返回栈顶元素。boolean empty() 如果栈是空的，返回 true ；否则，返回 false 。 我的代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849type MyStack struct &#123; list1 := list.New() list2 := list.New()&#125;func Constructor() MyStack &#123; MyStack.Push(x) MyStack.Push(x) MyStack.Push(x) MyStack.Pop() MyStack.Top() MyStack.empty()&#125;func (this *MyStack) Push(x int) &#123; this.list1.PushBack(x) temp := x this.list2.PushFront(temp)&#125;func (this *MyStack) Pop() int &#123; temp = this.list2.Value e = e.Next&#125;func (this *MyStack) Top() int &#123; temp = this.list2.Value return temp&#125;func (this *MyStack) Empty() bool &#123; if this.list2.Value == nil return false&#125;/** * Your MyStack object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Top(); * param_4 := obj.Empty(); */ 虚伪的正确的代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package mainimport (&quot;container/list&quot;)type MyStack struct &#123;list1 *list.Listlist2 *list.List&#125;func Constructor() MyStack &#123;return MyStack &#123;list1: list.New(),list2: list.New(),&#125;&#125;func (this *MyStack) Push(x int) &#123;this.list1.PushBack(x)temp := xthis.list2.PushFront(temp)&#125;func (this *MyStack) Pop() int &#123;if this.list2.Len() == 0 &#123;return -1 // 如果stack为空返回-1或者其他适当的值&#125;temp := this.list2.Front()this.list2.Remove(temp)return temp.Value.(int)&#125;func (this *MyStack) Top() int &#123;if this.list2.Len() == 0 &#123;return -1 // 如果栈为空则返回-1或者其他适当的值&#125;temp := this.list2.Front().Value(int)return temp&#125;func (this *MyStack) Empty() bool &#123;return this.list2.Len() == 0&#125;/*** Your MyStack object will be instantiated and called as such:* obj := Constructor();* obj.Push(x);* param_2 := obj.Pop();* param_3 := obj.Top();* param_4 := obj.Empty(); */ 使用go语言内置的list包 也就是双向链表的操作运用到了go语言的断言 this.list2.Front().Value.(int) 但是 虽然通过了 但是思路应该是错了哈哈哈哈 ！ 这段代码并没有用到队列的性质而是双链表。。。。并没有遵守题目的规则代码问题： 而只是使用了两个链表，其中 list2 实际上扮演了“栈”的角色。这样的话，list2 单独一个链表就能实现后进先出，不需要 list1 的辅助。 真正的正确代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package mainimport &quot;container/list&quot;type MyStack struct &#123; queue1 *list.List queue2 *list.List&#125;func Constructor() MyStack &#123; return MyStack&#123; queue1: list.New(), queue2: list.New(), &#125;&#125;func (this *MyStack) Push(x int) &#123; this.queue1.PushBack(x)&#125;func (this *MyStack) Pop() int &#123; if this.queue1.Len() == 0 &#123; return -1 &#125; for this.queue1.Len() &gt; 1 &#123; front := this.queue1.Front() this.queue1.Remove(front) this.queue2.PushBack(front.Value) &#125; top := this.queue1.Front() this.queue1.Remove(top) this.queue1, this.queue2 = this.queue2, this.queue1 return top.Value.(int)&#125;func (this *MyStack) Top() int &#123; if this.queue1.Len() == 0 &#123; return -1 &#125; for this.queue1.Len() &gt; 1 &#123; front := this.queue1.Front() this.queue1.Remove(front) this.queue2.PushBack(front.Value) &#125; top := this.queue1.Front() this.queue2.PushBack(top.Value) this.queue1, this.queue2 = this.queue2, this.queue1 return top.Value.(int)&#125;func (this *MyStack) Empty() bool &#123; return this.queue1.Len() == 0&#125; 第20题有效括号问题： 给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串 s ，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。左括号必须以正确的顺序闭合。每个右括号都有一个对应的相同类型的左括号。 解答过程123456789101112131415161718192021222324252627282930func isValid(s string) bool &#123; // 创建一个栈来存储左括号 stack := make([]rune, 0) // 括号的对应关系 pairs := map[rune]rune&#123; &#x27;)&#x27;: &#x27;(&#x27;, &#x27;&#125;&#x27;: &#x27;&#123;&#x27;, &#x27;]&#x27;: &#x27;[&#x27;, &#125; // 遍历字符串s for _, char := range s &#123; // 如果是右括号 if _, exists := pairs[char]; exists &#123; // 取出栈顶元素，如果栈为空或者不匹配则返回false if len(stack) == 0 || stack[len(stack)-1] != pairs[char] &#123; return false &#125; // 否则弹出栈顶元素 stack = stack[:len(stack)-1] &#125; else &#123; // 如果是左括号，压入栈中 stack = append(stack, char) &#125; &#125; // 如果栈为空，则所有括号正确匹配 return len(stack) == 0&#125; 栈的问题 字节刷题（队列）相关：问题： 小R的随机播放顺序问题描述小有一个特殊的随机播放规则。他首先播放歌单中的第一首歌，播放后将其从歌单中移除。如果歌单中还有歌曲，则会将当前第一首歌移到最后一首。这个过程会一直重复，直到歌单中没有任何歌曲。例如，给定歌单[5,3,2,1,4]，真实的播放顺序是[5,2,4,1,3]。保证歌曲中的id两两不同。测试样例样例1：输入：n&#x3D;5,a&#x3D;[5,3,2,1,4]输出：[5,2,4,1,3]样2：输入：n&#x3D;4,a&#x3D;[4,1,3,2]输出：[4,3,1,2]样3：输入：n&#x3D;6,a&#x3D;[1,2,3,4,5,6]输出：[1,3,5,2,6,4] 看完题之后的思路 ： 就是队列问题 如何操作栈 在文中也就是实现： 先出栈-》再执行出栈入栈-》再出栈 这是目前简单的思路然后搜索Go语言队列的相关操作 用slice实现队列：或者 list实现队列 题解：12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;func solution(n int, a []int) []int &#123; result := []int&#123;&#125; // 用于存储播放顺序 for len(a) &gt; 0 &#123; // 播放第一首歌并加入到结果中 result = append(result, a[0]) // 移除播放的歌曲 a = a[1:] // 如果歌单还有剩余，将当前第一首歌移到最后 if len(a) &gt; 0 &#123; a = append(a[1:], a[0]) &#125; &#125; return result&#125;func main() &#123; fmt.Println(fmt.Sprintf(&quot;%v&quot;, solution(5, []int&#123;5, 3, 2, 1, 4&#125;)) == fmt.Sprintf(&quot;%v&quot;, []int&#123;5, 2, 4, 1, 3&#125;)) fmt.Println(fmt.Sprintf(&quot;%v&quot;, solution(4, []int&#123;4, 1, 3, 2&#125;)) == fmt.Sprintf(&quot;%v&quot;, []int&#123;4, 3, 1, 2&#125;)) fmt.Println(fmt.Sprintf(&quot;%v&quot;, solution(6, []int&#123;1, 2, 3, 4, 5, 6&#125;)) == fmt.Sprintf(&quot;%v&quot;, []int&#123;1, 3, 5, 2, 6, 4&#125;))&#125; 看到题解我蒙了：我在思考的时候确实想如何实现这个队列并且如何实现添加元素并且删除元素 但是 在这道题中，Go 切片的特性其实已经很好地帮你实现了这些操作。切片的 append 和切片操作符 a[1:] 直接完成了队列的“入队”和“出队”需求。只是在简化的问题上，利用 Go 自带的切片操作让解决方案更简洁、易懂。 12.2 日重刷两数之和我的代码1234567891011func twoSum(nums []int, target int) []int &#123; k := make(map[int]int) for i, v := range nums &#123; other := target - v if _ , ok := map[other]; ok &#123; return &#123;i, map[nums[i]]&#125; &#125; m[nums[i]] = i &#125; return nil&#125; 更正后：1234567891011func twoSum(nums []int, target int) []int &#123; k := make(map[int]int) for i, v := range nums &#123; other := target - v if idx , ok := k[other]; ok &#123; return []int&#123;i, idx&#125; &#125; k[v] = i &#125; return nil&#125; 删除有序数组中的重复项错误的代码1234567891011121314151617func removeDuplicates(nums []int) int &#123; k := make([]int,10) for i:=0;i&lt;len(nums);i++ &#123; for j:=i; j&lt;len(nums); j++&#123; if nums[i] == nums[j] &#123; nums[i] = nums[j] continue &#125; k[i] = nums[i] break &#125; &#125; return len(k)&#125; 题目要求：题目需要在原地删除重复项，使用 O(1) 额外空间，返回去重后数组的长度。去重后的元素必须保留在数组的前部，后续位置可以随意。代码中存在的问题： 额外空间不符合要求：你使用了 k 数组存储去重后的结果，违背了 O(1) 额外空间的限制。逻辑问题：双重循环实际上是在尝试复制和比较元素，但逻辑上没有保证正确的去重。continue 和 break 的混乱：循环控制没有明确目的，导致部分逻辑跳过了关键步骤。返回值错误：你返回的是辅助数组 k 的长度，而不是修改后数组 nums 的有效长度。 正确解法：123456789101112131415func removeDuplicates(nums []int) int &#123; if len(nums) == 0&#123; return 0 &#125; var k = 0 for i :=1; i&lt;len(nums); i++ &#123; if nums[k] != nums [i] &#123; k++ nums[k] = nums[i] &#125; &#125; return k+1 &#125; 27 移除元素错误代码12345678910111213func removeElement(nums []int, val int) int &#123; var length = 0 for i := length; i&lt;len(nums); i++ &#123; if val == nums[length] &#123; var k = 0 k = nums[length] length ++ &#125; &#125; return length&#125; 不出意外又是错误的代码k 被赋值：k &#x3D; nums[length]然而，k 在后续的代码中并没有被用于任何地方，它没有被打印、返回、存储或进一步处理。只是简单地在 if 语句内被赋值。 k 的作用无效： k 是在 if 语句中声明并赋值的，但它没有发挥任何作用。Go 编译器会在编译时检查到这一点，并给出警告，因为声明了一个变量却没有用到。 正确代码：123456789101112func removeElement(nums []int, val int) int &#123; var length = 0 for i := 0; i &lt; len(nums); i++ &#123; if nums[i] != val &#123; nums[length] = nums[i] length++ &#125; &#125; return length&#125; 思路是 把不相等的元素按照顺序放到开头 而我是想覆盖相同的元素 处理不了这个撮箕 28 找出字符串中的第一个匹配项下标 题目： 输入：haystack &#x3D; “sadbutsad”, needle &#x3D; “sad”输出：0解释：”sad” 在下标 0 和 6 处匹配。第一个匹配项的下标是 0 ，所以返回 0 。示例 2： 输入：haystack &#x3D; “leetcode”, needle &#x3D; “leeto”输出：-1解释：”leeto” 没有在 “leetcode” 中出现，所以返回 -1 。 12345678910111213141516 var num intfunc strStr(haystack string, needle string) int &#123; for i:=0; i&lt;len(haystack); i++ &#123; for j := 0; j&lt;len(needle); j++ &#123; if needle[j] == haystack[i]&#123; num++ i++ if num == len(needle)&#123; return i-len(needle) &#125; &#125; &#125; &#125; return -1 &#125; 只通过了一个用例， 你要反思了 只通过一个用例，说明了你的想法是错的 暴力解法： 123456789101112131415func strStr(haystack string, needle string) int &#123; if len(needle) == 0 &#123; // 空字符串直接返回 0 return 0 &#125; for i := 0; i &lt;= len(haystack)-len(needle); i++ &#123; j := 0 for j &lt; len(needle) &amp;&amp; haystack[i+j] == needle[j] &#123; j++ &#125; if j == len(needle) &#123; return i // 完全匹配，返回起始索引 &#125; &#125; return -1 // 未找到匹配&#125; 多多练习， haystack[i+j] &#x3D;&#x3D; needle[j] 这里是很巧妙的地方，同时比对了两个字符串， i的位置就是起始位置， 如果整个字符串都在内部匹配完成了，说明i就是起始位置记录需要对比的字符串长度 58题： 最后一个单词的长度示例 1： 输入：s &#x3D; “Hello World”输出：5解释：最后一个单词是“World”，长度为 5。示例 2： 输入：s &#x3D; “ fly me to the moon “输出：4解释：最后一个单词是“moon”，长度为 4。示例 3： 输入：s &#x3D; “luffy is still joyboy”输出：6解释：最后一个单词是长度为 6 的“joyboy”。 我的代码： 12345678910111213var length intfunc lengthOfLastWord(s string) int &#123; for i := len(s)-1; i&gt;0; i-- &#123; if s[i] != &#x27; &#x27; &#123; for s[i] != &#x27; &#x27;&#123; length++ i-- &#125; return length &#125;&#125;return 0&#125; 还是错了 但是错的不太离谱，简单的呗GPT加了一点就过了 12345678910111213func lengthOfLastWord(s string) int &#123; length := 0 for i := len(s) - 1; i &gt;= 0; i-- &#123; // 修正条件为 i &gt;= 0 if s[i] != &#x27; &#x27; &#123; for i &gt;= 0 &amp;&amp; s[i] != &#x27; &#x27; &#123; // 避免索引越界 length++ i-- &#125; return length &#125; &#125; return 0 // 如果没有找到任何单词，返回 0&#125; 但是在其中话是有一个有意思的事情 1234567891011121314func lengthOfLastWord(s string) int &#123; length := 0 for i := len(s)-1; i&gt;=0; i-- &#123; if s[i] != &#x27; &#x27; &#123; for s[i] != &#x27; &#x27; &amp;&amp; i &gt;= 0&#123; length++ i-- &#125; return length &#125;&#125;return 0&#125; 代码我是这么写的 跟上面的没什么区别，但是没有通过 我又询问到底是为什么 关键在于顺序 以防止越界 for s[i] !&#x3D; ‘ ‘ &amp;&amp; i &gt;&#x3D; 0 内层循环条件： for s[i] !&#x3D; ‘ ‘ &amp;&amp; i &gt;&#x3D; 0 {当 i 等于 0 时，s[i] 可能会访问索引 0 的内容，然后才进行 i &gt;&#x3D; 0 的检查。由于条件的顺序，s[i] 的访问可能在 i &lt; 0 时执行，导致索引越界。也就是说： 问题在于： 在执行 s[i] !&#x3D; ‘ ‘ 这个条件时，i 可能会变成负数（比如 i &#x3D;&#x3D; 0 时，接下来你做 i–，i 会变成 -1）。但是，i &gt;&#x3D; 0 的条件是后面的检查，也就是说，在 i– 之后，s[i] !&#x3D; ‘ ‘ 已经执行了，导致 i &#x3D;&#x3D; -1 时，程序尝试访问 s[-1]，而 Go 语言数组下标不能为负数，这样会导致 索引越界 错误。 21 合并两个有序链表：l1 &#x3D; [1,2,4], l2 &#x3D; [1,3,4]输出：[1,1,2,3,4,4]示例 2： 输入：l1 &#x3D; [], l2 &#x3D; []输出：[]示例 3： 输入：l1 &#x3D; [], l2 &#x3D; [0]输出：[0] 我写的又臭又长的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode &#123; list3 := &amp;ListNode&#123; Val: 0, Next: nil,&#125; if list1 == nil &#123; return list2 &#125; if list2 == nil &#123; return list1 &#125; for list1.Val &lt;= list2.Val &#123; if list1.Next == nil &#123; for list2.Next != nil&#123; list3.Val = list2.Val list2 = list2.Next &#125; &#125;else &#123; list3.Val = list1.Val list3 = list3.Next list1 = list1.Next &#125; if list1.Next == nil &#123; for list1.Next != nil &#123; list3.Val = list1.Val list1 = list1.Next &#125; &#125;else &#123; list3.Val = list2.Val list3 = list3.Next list2 = list2.Next &#125; &#125; for list1.Val &gt;= list2.Val &#123; &#125;return list3&#125; 疑惑： 你说得对，list3 :&#x3D; &amp;ListNode{} 确实只初始化了一个节点，但这个节点的作用是 哨兵节点 (dummy node)，用来简化链表操作和边界条件处理。 哨兵节点的主要特点是： 它本身并不存储有效数据（值通常是默认值，比如 0）。它的作用是作为链表的起点，使链表构造和返回操作更加简单和一致。以下是对你的疑问的详细解释： 为什么哨兵节点只初始化一个节点却能构造完整链表？哨兵节点的作用只是提供链表的起点，后续节点是通过动态创建并连接到它的 Next 指针上构造的。例如： list3 :&#x3D; &amp;ListNode{} &#x2F;&#x2F; 初始化哨兵节点current :&#x3D; list3 &#x2F;&#x2F; current 指向哨兵节点 current.Next &#x3D; &amp;ListNode{Val: 1} &#x2F;&#x2F; 创建第一个有效节点current &#x3D; current.Next &#x2F;&#x2F; 移动指针到新节点 current.Next &#x3D; &amp;ListNode{Val: 2} &#x2F;&#x2F; 创建第二个有效节点current &#x3D; current.Next &#x2F;&#x2F; 移动指针到新节点这段代码最终形成的链表结构是： scss复制代码哨兵节点 (值: 0) -&gt; 节点1 (值: 1) -&gt; 节点2 (值: 2)返回值时，通过 list3.Next 跳过哨兵节点，直接指向第一个有效节点。 正确思维： 期望行为：应该创建一个新节点并将其连接到 current.Next。 我没有理解怎么初始化一个链表，并为后续创建新的结点添加值 emm 正解 正确代码：123456789101112131415161718192021func mergeTwoLists(list1, list2 *ListNode) *ListNode &#123; dummy := ListNode&#123;&#125; // 用哨兵节点简化代码逻辑 cur := &amp;dummy // cur 指向新链表的末尾 for list1 != nil &amp;&amp; list2 != nil &#123; if list1.Val &lt; list2.Val &#123; cur.Next = list1 // 把 list1 加到新链表中 list1 = list1.Next &#125; else &#123; // 注：相等的情况加哪个节点都是可以的 cur.Next = list2 // 把 list2 加到新链表中 list2 = list2.Next &#125; cur = cur.Next &#125; // 拼接剩余链表 if list1 != nil &#123; cur.Next = list1 &#125; else &#123; cur.Next = list2 &#125; return dummy.Next&#125; 这段代码中直接使用 list1 或 list2 而不是 list1.Val 是因为它要把整个节点连接到新链表中，而不仅仅是节点的值。 区别list1.Val 仅获取当前节点的值。 如果只使用 Val，你只能获得一个值，无法直接将这个值插入链表中，还需要手动创建一个新节点。list1 是指针，代表当前节点。 直接使用 list1 表示把当前节点（包括其 Val 和 Next 指针）插入到新链表中，效率更高且代码更简单。 今天又重新做了一下20题 有效括号 刚开始我在想，电脑应该怎么区分左括号和右括号这两个是怎么合并的？ 绞尽脑汁。 最终思想就是遍历字符串， 将左括号放入栈中 将栈顶元素和当前元素作比较 如果相同弹出括号，成功的标志是栈中元素为空 232 用两个栈实现队列 [“MyQueue”, “push”, “push”, “peek”, “pop”, “empty”][[], [1], [2], [], [], []]输出：[null, null, null, 1, 1, false] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647type MyQueue struct &#123; Rear *MyQueue Head *MyQueue size int&#125;func Constructor() MyQueue &#123; Stack1 := []int Stack2 := []int &#125;func (this *MyQueue) Push(x int) &#123; Stack1 := []int Stack2 := []int Stack1 = append(Stack1,x) legth := len(Stack1) v := Stack1[l-1]&#125;func (this *MyQueue) Pop() int &#123; Stack1 = Stack1(:len(Stack1)-1) Stack2 = append(Stack2,)&#125;func (this *MyQueue) Peek() int &#123; &#125;func (this *MyQueue) Empty() bool &#123; &#125;/** * Your MyQueue object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Peek(); * param_4 := obj.Empty(); */ 看到代码有点不知所措了，在每个地方应该放入什么 两个栈实现队列：思路我是有的 把数字放入其中一个栈中，然后在弹出来，放入第二个栈中，然后在第二个栈中弹出来就是队列 思路是对的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576type MyQueue struct &#123; Stack1 []int Stack2 []int&#125;func Constructor() MyQueue &#123; return MyQueue&#123;&#125;&#125;func (this *MyQueue) Push(x int) &#123; this.Stack1 = append (this.Stack1,x)&#125;func (this *MyQueue) Pop() int &#123; if len(this.Stack2) == 0 &amp;&amp; len(this.Stack1) == 0 &#123; return -1 &#125; if len(this.Stack1) != 0 &#123; for len(this.Stack1) &gt; 0 &#123; length1 := len(this.Stack1)-1 val := this.Stack1[length1] this.Stack1 = this.Stack1[:length1] this.Stack2 = append(this.Stack2,val) &#125; &#125; length2 := len(this.Stack2)-1 result := this.Stack2[length2] this.Stack2 = this.Stack2[:length2] return result&#125;func (this *MyQueue) Peek() int &#123; if len(this.Stack1) == 0 &amp;&amp; len(this.Stack2) == 0 &#123; return -1 &#125; if len(this.Stack1) != 0 &#123; for len(this.Stack1) &gt;0 &#123; length1 := len(this.Stack1)-1 val := this.Stack1[length1] this.Stack1 = this.Stack1[:length1] this.Stack2 = append(this.Stack2,val) &#125; &#125; length2 := len(this.Stack2) -1 return this.Stack2[length2]&#125;func (this *MyQueue) Empty() bool &#123; return len(this.Stack1) == 0 &amp;&amp; len(this.Stack2) == 0&#125;/** * Your MyQueue object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Peek(); * param_4 := obj.Empty(); */ 重新写了一遍 用例没有完全通过 [null,null,null,null,null,1,null,5,2,3,4] 预期结果[null,null,null,null,null,1,null,2,3,4,5] 有两个地方出错导致没有通过 if len(this.Stack1) !&#x3D; 0 条件判断句 改成 &#x3D;&#x3D;0 就通过了 思考为什么 383.赎金信参考两数之和的哈希表用法 我写出了以下代码 12345678910111213141516171819func canConstruct(ransomNote string, magazine string) bool &#123; m := make(map[byte]int) for i:=1 ; i&lt;len(ransomNote); i++ &#123; if _,ok := m[ransomNote[i]]; ok&#123; continue &#125; m[ransomNote[i]] = i &#125; for k:=1; k&lt;len(magazine); k++ &#123; if _, ok := m[magazine[k]]; ok &#123; continue &#125; if k == len(magazine) &#123; return true &#125; &#125; return false&#125; 但是没有通过，应该是情况考虑错了 123456789101112131415161718func canConstruct(ransomNote string, magazine string) bool &#123; m := make(map[byte]int) for i:=0; i&lt;len(magazine); i++ &#123; if _,ok := m[magazine[i]]; ok&#123; continue &#125; m[magazine[i]] = i &#125; for k:=0; k&lt;len(ransomNote); k++ &#123; if _, ok := m[ransomNote[k]]; ok &#123; continue &#125; else &#123; return false &#125; &#125; return true&#125; 最终修改成这样 题目中话有一个条件 字母无法重复使用！！！这点给忘记给忘记了问了这一点！ 关键就是对于字符的统计！ 正确代码： 12345678910111213141516171819func canConstruct(ransomNote string, magazine string) bool &#123; // 用一个 map 记录 magazine 中每个字符出现的次数 m := make(map[byte]int) for i := 0; i &lt; len(magazine); i++ &#123; m[magazine[i]]++ &#125; // 检查 ransomNote 中的每个字符是否在 magazine 中有足够的次数 for i := 0; i &lt; len(ransomNote); i++ &#123; if m[ransomNote[i]] &gt; 0 &#123; m[ransomNote[i]]-- // 使用一个字符 &#125; else &#123; return false // 如果次数不足，无法构造 &#125; &#125; return true // 所有字符都能满足&#125; 我的疑惑：我理解前两个a会增到2 但是第三个字符是b的时候为什么会从0开始计算起而不是2 这是因为在 Go 的 map 中，每个键（key）是独立的，互相之间没有关联。 在你的例子中，当处理第三个字符 b 时： 之前已经对 a 进行了计数，所以 m[‘a’] &#x3D; 2。但是 b 是一个新的键，之前并没有在 map 中出现过。当访问 m[‘b’] 时，由于 map 默认返回未初始化键的值为类型的 零值（对于 int 类型来说，零值是 0），所以 m[‘b’] &#x3D; 0。然后执行 m[‘b’]++，将其从 0 增加到 1。 141.环形链表 123456789101112131415161718192021/** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func hasCycle(head *ListNode) bool &#123; if head == nil &#123; return false &#125; m := make(map[*ListNode]int) for head != nil &#123; m[head]++ if _,ok := m[head]; ok &#123; return true &#125; head = head.Next &#125; return false&#125; 又没有一次性通过 条件感太差了！ 啊居然自己改对了！！！ 调整了一下顺序， 12345678910111213141516171819202122/** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func hasCycle(head *ListNode) bool &#123; if head == nil &#123; return false &#125; m := make(map[*ListNode]int) for head != nil &#123; m[head]++ head = head.Next if _,ok := m[head]; ok &#123; return true &#125; &#125; return false&#125; 在其中出现的错误： map中的地址应该是结构体指针 而不是 *int 如何在go中使用中序遍历 94题： 12345678910111213141516171819func inorderTraversal(root *TreeNode) []int &#123; result := []int&#123;&#125; // 用于存储中序遍历的结果 // 定义递归函数 var inorder func(node *TreeNode) inorder = func(node *TreeNode) &#123; if node == nil &#123; // 递归终止条件：当前节点为空 return &#125; inorder(node.Left) // 遍历左子树 result = append(result, node.Val) // 访问当前节点 inorder(node.Right) // 遍历右子树 &#125; inorder(root) // 从根节点开始中序遍历 return result // 返回结果&#125; inorder &#x3D; func(node *TreeNode) {if node &#x3D;&#x3D; nil { &#x2F;&#x2F; 递归终止条件：当前节点为空return} 这块使用我不太清楚 我还以为是对原函数递归 933.最近的请求次数 写一个 RecentCounter 类来计算特定时间范围内最近的请求。 请你实现 RecentCounter 类： RecentCounter() 初始化计数器，请求数为 0 。int ping(int t) 在时间 t 添加一个新请求，其中 t 表示以毫秒为单位的某个时间，并返回过去 3000 毫秒内发生的所有请求数（包括新请求）。确切地说，返回在 [t-3000, t] 内发生的请求数。保证 每次对 ping 的调用都使用比之前更大的 t 值。 输入：[“RecentCounter”, “ping”, “ping”, “ping”, “ping”][[], [1], [100], [3001], [3002]]输出：[null, 1, 2, 3, 3] 解释：RecentCounter recentCounter &#x3D; new RecentCounter();recentCounter.ping(1); &#x2F;&#x2F; requests &#x3D; [1]，范围是 [-2999,1]，返回 1recentCounter.ping(100); &#x2F;&#x2F; requests &#x3D; [1, 100]，范围是 [-2900,100]，返回 2recentCounter.ping(3001); &#x2F;&#x2F; requests &#x3D; [1, 100, 3001]，范围是 [1,3001]，返回 3recentCounter.ping(3002); &#x2F;&#x2F; requests &#x3D; [1, 100, 3001, 3002]，范围是 [2,3002]，返回 3 读题读了一会才读懂，最后反应过来应该就是返回 在范围内的ping次数 需要用一个切片（其实应该是队列思想 入队 出队不符合条件的 返回符合条件的数量）（这在go语言中就可以用切片来简化操作 返回 符合条件的ping次数 也就是 队列中剩下的长度 len（）） 正确解答 1234567891011121314151617181920212223242526272829type RecentCounter struct &#123; count []int&#125;func Constructor() RecentCounter &#123; return RecentCounter &#123; count: []int&#123;&#125;, &#125;&#125;func (this *RecentCounter) Ping(t int) int &#123; this.count = append(this.count,t) //重点怎么移除不符合条件的 一个个对比 for len(this.count)&gt;0 &amp;&amp; this.count[0]&lt;t-3000 &#123; this.count = this.count[1:] &#125; return len(this.count)&#125;/** * Your RecentCounter object will be instantiated and called as such: * obj := Constructor(); * param_1 := obj.Ping(t); */ 1.学会初始化结构体2.学会使用切片思想实现 队列 栈等 加强对切片的操作 12.17日 开始执行树和递归 104 二叉树的最大深度110 平衡二叉树 104代码 123456789101112func maxDepth(root *TreeNode) int &#123; if root == nil &#123; return 0 &#125; var l, r = maxDepth(root.Left), maxDepth(root.Right) if l &gt; r &#123; return l + 1 &#125; else &#123; return r + 1 &#125;&#125; 这段代码我是抄的 我对递归的思想还是不太理解 递归的 隐式深度记录 是通过调用栈实现的： 每次递归调用时，程序会进入一个新的函数调用，并等待其返回值。当递归调用到底（即遇到叶子节点或 nil 节点）时，递归开始返回。每一层递归通过返回值，将子树的深度信息逐层传递回上一层。可以理解为： 每个函数调用相当于“记住”当前节点的状态，等待左右子树的深度计算完成后，才计算当前节点的深度并返回。 递归的返回值 自然累加 深度的方式，不需要额外的变量来显式记录深度。"},{"title":"美化博客","date":"2024-12-20T13:07:48.547Z","updated":"2024-11-08T12:35:19.490Z","comments":true,"path":"archives/lasting_beauty.html","permalink":"https://whuichenggong.github.io/archives/lasting_beauty.html","excerpt":"","text":"使博客看起来更加美观，持续更新中！"},{"title":"数据库学习","date":"2024-12-20T13:07:48.552Z","updated":"2024-12-08T10:52:44.696Z","comments":true,"path":"archives/postgres.html","permalink":"https://whuichenggong.github.io/archives/postgres.html","excerpt":"","text":"学习文档： https://www.rockdata.net/zh-cn/tutorial/toc/ WHERE 语句如何使用 https://www.rockdata.net/zh-cn/tutorial/dml-where/、 总结来说： 放入condition，返回结果只会返回符合condition条件的， 搭配 AND OR IN LIKE等使用"},{"title":"文章分类","date":"2025-05-11T07:07:44.340Z","updated":"2025-05-11T07:07:44.340Z","comments":false,"path":"categories/index.html","permalink":"https://whuichenggong.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于我学习的一些资源和方法","date":"2024-12-20T13:07:48.554Z","updated":"2024-12-15T07:45:24.392Z","comments":true,"path":"archives/resource.html","permalink":"https://whuichenggong.github.io/archives/resource.html","excerpt":"","text":"兄弟，我理解你的心态，觉得实践的收获更直观，看书反而有点慢。但实际上，看书和实践结合，效果会倍增。下面我不仅推荐优质资源，还会分享高效阅读的方法，帮你更好地平衡学习时间。 学习资料推荐1. 数据库相关 书籍：《高性能 MySQL》 重点阅读：索引优化、事务机制、查询优化。 免费在线教程： SQL 教程（w3schools） MySQL 官方文档 2. 计算机网络 书籍：《计算机网络：自顶向下方法》或《图解HTTP》 重点章节：HTTP、TCP&#x2F;IP、DNS、HTTPS。 免费资源： HTTP 协议详解 Wireshark 网络分析教程 3. 操作系统 书籍：《现代操作系统》 重点章节：进程、线程、同步、内存管理。 免费资源： Operating Systems: Three Easy Pieces Linux 操作系统入门 4. 系统设计 书籍：《系统设计入门》（Grokking the System Design Interview） 重点学习：缓存、负载均衡、限流。 博客： 系统设计基础 5. Redis 书籍：《Redis 实战》 重点章节：缓存机制、分布式锁。 免费资源： Redis 官方文档 6. 算法与数据结构 书籍：《算法（第4版）》或《编程珠玑》 重点章节：常用数据结构（栈、队列、二叉树）、动态规划。 网站： LeetCode 官方 VisuAlgo（算法可视化） 高效看书方法1. 目的导向阅读 明确目标：每次看书前，明确你要解决的问题。比如： “我需要理解事务是怎么实现的” → 阅读事务相关章节，跳过其他部分。 “我需要掌握 TCP 的连接过程” → 只看 TCP 的工作原理。 2. 略读和精读结合 略读：先快速翻阅目录和每章的开头，总结书的主要内容。 精读：挑选与项目或刷题直接相关的部分深入看，配合做笔记和练习。 3. 配合实践 边学边做：看完书中某个知识点，立即在项目或代码中实现。 例子：学完 Redis 的分布式锁，马上在银行项目中添加。 用书作为工具：书可以成为你的“随手参考”，遇到不懂的概念再翻阅相关章节，而不必一次性啃完。 4. 输出内容 写笔记：总结书中学到的知识，用自己的语言重新描述。 录制分享：试着用 3 分钟向别人讲解你刚学的内容，加深记忆。 5. 番茄工作法 每次阅读 25 分钟后，花 5 分钟总结这段时间的收获，然后休息片刻。效率会提升很多。 实践与看书的时间分配 每天早上&#x2F;晚上固定 1 小时阅读。 比如：早上看《高性能 MySQL》，晚上看《计算机网络》。 实践时遇到问题，马上查书解决。 例子：如果 Redis 配置缓存遇到问题，就查《Redis 实战》。 每周末专门安排 2 小时总结书中知识点，结合项目整理成笔记。 这样安排既能保持实践的节奏，又能让你从书中挖掘深层的原理。如果还有具体内容不理解，可以随时问我，我也可以帮你分解章节内容！"},{"title":"json的序列化与反序列化","date":"2024-12-20T13:07:48.555Z","updated":"2024-12-06T09:52:48.370Z","comments":true,"path":"archives/serialize.html","permalink":"https://whuichenggong.github.io/archives/serialize.html","excerpt":"","text":"序列化：将 Go 中的结构体、切片、map 等数据结构转换为 JSON 格式的字符串。 作用：方便数据在网络传输、文件保存等情境中使用。 反序列化：将 JSON 格式的字符串转换为 Go 的数据结构。 作用：方便从 JSON 中提取数据并在程序中使用。 JSON{“”： “”，“”： “”，“”： “”} Go中 使用 Marshal Unmarshal 进行序列化和反序列化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot;)type Person struct &#123; Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;`&#125;func main() &#123; p := Person&#123;Name: &quot;Alice&quot;, Age: 25&#125; // 序列化为 JSON jsonData, err := json.Marshal(p) if err != nil &#123; fmt.Println(&quot;Error:&quot;, err) return &#125; fmt.Println(string(jsonData)) // 输出: &#123;&quot;name&quot;:&quot;Alice&quot;,&quot;age&quot;:25&#125;&#125;---&#125;package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot;)type Person struct &#123; Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;`&#125;func main() &#123; jsonData := `&#123;&quot;name&quot;:&quot;Alice&quot;,&quot;age&quot;:25&#125;` var p Person // 反序列化为结构体 err := json.Unmarshal([]byte(jsonData), &amp;p) if err != nil &#123; fmt.Println(&quot;Error:&quot;, err) return &#125; fmt.Println(p.Name, p.Age) // 输出: Alice 25&#125; 类比一下进程间管道通信：在父子进程使用管道进行通信时，数据通常以字节流的形式传输。要传递复杂数据结构，需要将数据转换为字节流（序列化），并在另一端解析回来（反序列化）。 GO中实现 字符进程通信 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;os&quot;)type Message struct &#123; Content string `json:&quot;content&quot;`&#125;func main() &#123; r, w, err := os.Pipe() // 创建管道 if err != nil &#123; fmt.Println(&quot;Error creating pipe:&quot;, err) return &#125; if os.Getenv(&quot;IS_CHILD&quot;) == &quot;1&quot; &#123; // 子进程逻辑 r.Close() // 关闭写端 var msg Message decoder := json.NewDecoder(r) if err := decoder.Decode(&amp;msg); err != nil &#123; fmt.Println(&quot;Error decoding:&quot;, err) return &#125; fmt.Println(&quot;Child received:&quot;, msg.Content) &#125; else &#123; // 父进程逻辑 w.Close() // 关闭读端 cmd := os.Exec(os.Args[0], os.Args, os.Environ()) cmd.Env = append(os.Environ(), &quot;IS_CHILD=1&quot;) go func() &#123; encoder := json.NewEncoder(w) encoder.Encode(Message&#123;Content: &quot;Hello, Child!&quot;&#125;) &#125;() cmd.Wait() &#125;&#125;"},{"title":"小计划","date":"2024-12-20T13:07:48.559Z","updated":"2024-12-19T14:02:27.389Z","comments":true,"path":"archives/study_plan.html","permalink":"https://whuichenggong.github.io/archives/study_plan.html","excerpt":"","text":"兄弟，你的想法很清晰，我非常理解你想深入学习、夯实基础，而不是走捷径的决心。我们可以针对你的目标和现状制定一个更加实践导向的计划，同时保持学习过程有趣且充实。以下是我的建议和方案： 总体目标 短期（2025年3月前）：增强银行项目的实用性和技术深度，掌握后端开发的核心技能，为实习做好准备。 中长期（未来两年）：夯实计算机基础，深入理解系统设计、分布式系统及核心算法，逐步具备独立设计和开发复杂项目的能力。 学习模块规划1. 项目深度增强（每周一个主题，贯穿整个学习计划）目标：将现有银行项目提升到更贴近实际业务需求的水平，增加亮点功能。 Week 1: 数据一致性与事务 学习事务隔离级别（ACID），在项目中实现更加复杂的转账操作（如跨账户冻结和解冻）。 使用 SQLC 或 GORM，优化数据库操作。 Week 2: 引入 Redis 学习 Redis 基础知识，理解其在缓存和分布式锁中的应用。 在项目中实现： 用户信息缓存，优化频繁查询。 基于 Redis 的幂等性控制（防止转账操作重复）。 Week 3: RESTful API 和 JWT 身份验证 深化对 RESTful API 的理解，优化项目 API 设计。 引入 JWT 实现用户登录认证和权限管理。 Week 4: 日志和监控 集成日志框架（如 Logrus&#x2F;Zap），记录系统操作。 学习 Prometheus 基础知识，为项目添加简单监控。 Week 5: Docker 和部署优化 使用 Docker Compose 部署完整项目，模拟生产环境。 学习 Nginx 基础知识，优化项目访问流程。 Week 6: 微服务化 学习 Go 微服务框架（如 Gin、gRPC）。 将项目拆分成两个服务（如用户服务和交易服务），理解微服务架构基础。 2. 算法与数据结构（每天一题，逐渐深入）目标：构建扎实的算法基础，为今后面试和实际开发做准备。 题目选择顺序：简单 -&gt; 中等 -&gt; 困难，优先 BFS&#x2F;DFS、二分查找、动态规划等重要领域。 周主题： Week 1-2: 栈、队列、链表 Week 3-4: 二叉树与递归 Week 5-6: 动态规划与分治算法 Week 7+: 高频面试题复盘（重点记录和总结常见套路）。 3. 计算机基础与原理（每周一本书&#x2F;主题）目标：夯实后端开发的计算机科学基础。 Week 1: 计算机网络 阅读《计算机网络：自顶向下方法》或《图解HTTP》。 重点学习 HTTP、HTTPS、TCP&#x2F;IP 的工作原理，并理解抓包工具（如 Wireshark）的使用。 Week 2: 操作系统 阅读《现代操作系统》。 理解线程、进程、同步机制，以及如何在 Go 中实现简单的并发处理。 Week 3-4: 数据库系统 阅读《数据库系统概念》。 理解索引、事务原理、查询优化等内容。 Week 5: 系统设计 阅读《系统设计入门》或相关博客。 学习常见系统设计模式（如限流、负载均衡）和架构决策。 具体每日安排（样例） 上午： 刷一道 LeetCode 算法题，阅读相关解析，整理题解。 学习书籍相关章节，完成1-2页的读书笔记。 下午： 按周主题在银行项目中完成对应功能开发。 查看官方文档、博客或视频教程，记录学习中的关键点。 晚上： 复习当天内容，整理代码和笔记。 自测项目功能，尝试优化代码。 可实践性建议 建立个人技术博客：把每天的学习记录写成博客或日志，比如讲解项目中 Redis 的用法或总结某道算法题的思路。 参与开源项目：找一个简单的 Go 开源项目，阅读代码，尝试修复 bug 或贡献文档。 模拟面试：每两周自测一次，将银行项目作为核心，讲解架构设计和亮点功能。 最终成果展示 一个高度完善的银行项目： 支持分布式事务、JWT 身份验证、Redis 缓存与微服务架构。 提供完善的 Docker 部署文档。 一个 LeetCode 高质量题解库（至少 50 道题）。 一份扎实的基础知识笔记，涵盖网络、操作系统和数据库。 引入项目技术栈（2周）：在新项目中加入 SQLC 工具、中间件，理解每个技术的接入过程。 实现进阶功能（3周）：根据银行项目的转账逻辑，尝试自己独立实现一次。 重点学习 HTTP 和 RESTful API。 深入理解数据库 深入理解数据库 熟悉中间件的实现逻辑 Web开发 Go by example 三本书 两个项目 Memos Apache Answer 算法 gin-gonic.com 微服务进阶 gRPC"},{"title":"tags","date":"2024-12-29T05:30:45.000Z","updated":"2024-12-29T05:30:59.824Z","comments":true,"path":"tags/index.html","permalink":"https://whuichenggong.github.io/tags/index.html","excerpt":"","text":""},{"title":"友情鏈接","date":"2024-12-01T14:17:49.000Z","updated":"2024-12-29T05:17:43.338Z","comments":true,"path":"link/index.html","permalink":"https://whuichenggong.github.io/link/index.html","excerpt":"","text":""},{"title":"beijing_photo","date":"2024-12-29T06:12:44.000Z","updated":"2024-12-29T06:14:09.735Z","comments":true,"path":"picture/beijing-photo/index.html","permalink":"https://whuichenggong.github.io/picture/beijing-photo/index.html","excerpt":"","text":"[{\"url\":\"/beijing_photo/beijing4.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing5.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing6.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing7.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing8.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing9.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing11.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing12.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing13.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing14.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing15.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing16.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing17.jpg\",\"alt\":\"\"},{\"url\":\"/beijing_photo/beijing18.jpg\",\"alt\":\"\"}]"}],"posts":[{"title":"函数指针数组","slug":"go/函数指针数组","date":"2025-04-01T13:21:47.328Z","updated":"2025-05-11T07:12:22.734Z","comments":true,"path":"2025/04/01/go/函数指针数组/","permalink":"https://whuichenggong.github.io/2025/04/01/go/%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/","excerpt":"","text":"引用博文； (博客园)[https://www.cnblogs.com/tp-16b/p/7860491.html] 对于在xv6中看到的一个映射表关系 关于： 函数指针数组 12345678910111213141516171819202122232425static uint64 (*syscalls[])(void) = &#123;[SYS_fork] sys_fork,[SYS_exit] sys_exit,[SYS_wait] sys_wait,[SYS_pipe] sys_pipe,[SYS_read] sys_read,[SYS_kill] sys_kill,[SYS_exec] sys_exec,[SYS_fstat] sys_fstat,[SYS_chdir] sys_chdir,[SYS_dup] sys_dup,[SYS_getpid] sys_getpid,[SYS_sbrk] sys_sbrk,[SYS_sleep] sys_sleep,[SYS_uptime] sys_uptime,[SYS_open] sys_open,[SYS_write] sys_write,[SYS_mknod] sys_mknod,[SYS_unlink] sys_unlink,[SYS_link] sys_link,[SYS_mkdir] sys_mkdir,[SYS_close] sys_close,[SYS_trace] sys_trace,[SYS_sysinfo] sys_sysinfo,&#125;; 数组和指针是没关系的！ 数组指针int (*p)[4]; char (*p)[4]; 指针数组int *p[10]; char *p[10]; char **p[10] 它们都是大小为10元素的数组，里面分别存放着元素为 int，char, char** 类型的指针数组 函数指针示例： 1这里定义void (*p)()。一眼可知pfun1先和*结合，说明pfun1是指针，指针指向的是一个函数，指向的函数无参数，返回值类型为void。 这里定义void (p)()。一眼可知pfun1先和结合，说明pfun1是指针，指针指向的是一个函数，指向的函数无参数，返回值类型为void。 函数指针数组把函数的地址存到一个数组中，那这个数组就叫函数指针数组 int (*parr1[10])(); int *parr210; int (*)() parr3[10]; parr1 先和 [] 结合，说明parr1是数组，数组的内容是什么呢？ 是 int (*)() 类型的函数指针。","categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"}],"tags":[]},{"title":"总结一下最近","slug":"生活/总结一下最近","date":"2025-03-31T13:24:00.757Z","updated":"2025-05-11T07:15:01.704Z","comments":true,"path":"2025/03/31/生活/总结一下最近/","permalink":"https://whuichenggong.github.io/2025/03/31/%E7%94%9F%E6%B4%BB/%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B%E6%9C%80%E8%BF%91/","excerpt":"","text":"好久没有更新博客了，因为一些重要的笔记都移动到Obsidian上面写了，很方便 ，谈谈新的一年对于技术的追求 在大二上学期以及在大一的时候都觉得计算机基础是非常重要的，因为一些声音吧，也沉迷于如何快速做项目啊，背八股文啊，越来越觉得空虚没有得到什么，在大一的时候天真的以为只要学会一门语言就可以很强哈哈哈哈，到现在再看,语言真的只是一门工具，在想学习什么的时候，顺带学一下就可以研究自己更喜欢的领域，在本学期，我的思想发生了重大的转变，其实本来也是，我觉得要想学习计算机，你如果不去理解计算机那么算的上什么学习计算机呢？数据结构为什么重要？世界本来就是一个巨大的存储系统，如何存储数据？如何快速的存储数据是那么的重要!我们用的数据库，操作系统，不全都是数据结构和算法的功劳吗？学习计算机的乐趣对于我来说为什么跨越千里可以和对方聊天，每天坐在电脑前，为什么电脑可以这么工作，这就是一个黑盒，需要我们慢慢去挖掘，就是挖掘他们背后的黑盒，真的使我感到开心就像文杰老哥说的一样 在这个ai的时候上层应用的逻辑显得没有那么重要。 在学习中一定要结合实际，才能深刻的理解这些知识，也就是所谓的八股文，发自内心的去理解，现在才理解什么是带着问题去读书去看，那种带入疑问去阅读，最终疑问被解决的感觉是很爽的！ 没有走过的路，听了别人和你说那是一条做错的路，你可能不信，只有你真正体验到了才知道那到底是一条什么路，即使最终的结果不尽人意，但是过程才是最重要的对于结果呢？哈哈哈留下思考 过程与结果！可能每个人的看法也会不同吧，人都是生下来走一遭，自己的路一定要自己选自己走！那才是你的意义，别人会给你参考会给你建议，最终的路都是自己走出来的！ 也感谢我遇见的所有人！ 也希望自己能够坚持自己吧！ Trust but Verify","categories":[{"name":"生活","slug":"生活","permalink":"https://whuichenggong.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[]},{"title":"在这个时代，你是否过度依赖ai","slug":"文章分享/是否过度依赖ai","date":"2025-02-12T10:04:53.120Z","updated":"2025-05-11T07:14:37.165Z","comments":true,"path":"2025/02/12/文章分享/是否过度依赖ai/","permalink":"https://whuichenggong.github.io/2025/02/12/%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/%E6%98%AF%E5%90%A6%E8%BF%87%E5%BA%A6%E4%BE%9D%E8%B5%96ai/","excerpt":"","text":"越来越觉得做任何事都离开不了ai，任何报错只需要复制粘贴，原本看文档可以解决的错误，让ai可能很长时间，都无法解决，那种来回粘贴的感觉让我停止了思考，不想动脑，我好像成为了ai和代码之间的桥梁，ai让我在编码中也变得懒惰，那种空虚是真的！ 这种急性子，渴望答案快速出来的懒惰，必须要改了！ 自己看懂错误出在哪里 查阅文档，试着自己解决 做事之前，自己构思","categories":[{"name":"文章分享","slug":"文章分享","permalink":"https://whuichenggong.github.io/categories/%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/"}],"tags":[]},{"title":"系统思考","slug":"书后心得/系统思考","date":"2025-01-30T01:48:25.183Z","updated":"2025-05-11T07:20:03.589Z","comments":true,"path":"2025/01/30/书后心得/系统思考/","permalink":"https://whuichenggong.github.io/2025/01/30/%E4%B9%A6%E5%90%8E%E5%BF%83%E5%BE%97/%E7%B3%BB%E7%BB%9F%E6%80%9D%E8%80%83/","excerpt":"","text":"各个实体之间的联系构成了系统，当你在研究一个系统的时候，如果你切分了其中某一部分拿出来研究必定会切断，这部分与整体的联系，也就是破坏了整个系统！ 必须从整体式理解一个系统关于组件的知识对于整体上理解一个系统，作用非常有限，在某些情况下，这些知识甚至具有相反的效果 示例： 组件知识是局部的，而系统理解需要全局视角 组件是系统的一部分，但系统的行为不仅仅是组件的总和，还涉及它们之间的交互、架构模式、数据流、依赖关系等。只关注组件，容易忽略系统级别的设计，比如如何扩展、如何容错、如何保障一致性。局部最优 ≠ 全局最优 过度关注组件实现，可能会优化某个组件的性能或功能，但不一定符合整个系统的最佳实践。例如，一个高效的缓存组件如果没有考虑分布式一致性，可能会导致整个系统数据不一致。局部思维可能会误导系统设计 过分依赖某个组件，可能导致架构决策受限，比如：认为数据库事务可以解决所有一致性问题，而忽略了分布式事务的挑战。认为某个微服务框架很强大，而忽略了微服务本身的复杂性（如治理、监控等）。 关键是要有“系统思维”，知道什么时候关注细节，什么时候抬头看全局 系统展示出来的特性是做作为一个整体所拥有的特性，而不是任何一个部件所拥有的特性 自组织保持高度有序状态，具有能量流，","categories":[{"name":"书后心得","slug":"书后心得","permalink":"https://whuichenggong.github.io/categories/%E4%B9%A6%E5%90%8E%E5%BF%83%E5%BE%97/"}],"tags":[]},{"title":"新年新气象","slug":"生活/新的一年","date":"2025-01-28T14:42:05.561Z","updated":"2025-01-28T14:43:49.910Z","comments":true,"path":"2025/01/28/生活/新的一年/","permalink":"https://whuichenggong.github.io/2025/01/28/%E7%94%9F%E6%B4%BB/%E6%96%B0%E7%9A%84%E4%B8%80%E5%B9%B4/","excerpt":"","text":"辞旧迎新，改变最大的一年！ 新的一年开始了，我希望我能在新的一年里，不断的审视自己，关注自己的一言一行，一举一动，如果有哪些坏习惯，要去更改！ 希望自己变得越来越好吧！ 顺其自然的去做自己该去做的事，没有目的地！ Passion never fails！","categories":[{"name":"生活","slug":"生活","permalink":"https://whuichenggong.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[]},{"title":"I/O多路复用中的一些疑惑","slug":"计算机系统/IO多路复用","date":"2025-01-23T04:26:36.180Z","updated":"2025-05-11T07:15:33.205Z","comments":true,"path":"2025/01/23/计算机系统/IO多路复用/","permalink":"https://whuichenggong.github.io/2025/01/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","excerpt":"","text":"疑问：I&#x2F;O多路复用如何实现？这里面用到了什么数据结构吗？如果A先发起了请求在等待中然后去处理B的请求，当A的请求到达后，并处理完成后，还会继续处理B的请求吗？还有在后续处理A的过程中，B处在等待的过程中，有可能其他的服务去处理B吗？B在发送请求到A后，它在等待的过程中还会发送请求吗？ 解答：1如果 A 请求发起了并在等待中，处理 B 的请求后，A 的请求完成后，还会继续处理 B 吗？ A 的请求和 B 的请求是两个独立的 I&#x2F;O 操作。当 A 的请求进入等待状态后（比如等待数据库查询或等待网络响应），服务器会继续处理 B 的请求，甚至是 C、D 等其他请求。 当 A 的请求到达后，服务器会接到通知，处理 A 的请求。 在处理 A 请求时，如果 B 的请求仍然在等待状态，那么此时 B 并不会被继续处理，除非 B 的请求也准备好了。 处理完成 A 的请求后，服务器会继续处理下一个在等待队列中有数据准备好的请求（比如 B 的请求，如果它的数据已经准备好了）。 可以理解为 事件驱动，服务器并不会直接按顺序处理 A、B 请求，而是看哪个请求的 I&#x2F;O 操作准备好了，哪个就被处理。 2在后续处理 A 的过程中，B 在等待时，是否有可能其他服务去处理 B？ B 的请求一般会在服务器端的同一线程中等待，除非采取了 分布式架构 或 负载均衡，否则通常不会有其他服务去处理 B。B 依然在等待队列中，直到 I&#x2F;O 多路复用机制通知服务器有数据准备好，才会继续处理。 但是，在分布式场景下，B 的请求有可能会被路由到 其他节点 或 服务实例 去处理。例如，微服务架构中，某个请求可能会被负载均衡到另一个服务实例处理。 3B 在发送请求到 A 后，它在等待的过程中是否会发送请求？ 是的，B 可以继续发送请求到 其他服务。I&#x2F;O 多路复用的特点是 非阻塞，也就是说，B 在等待 A 的响应时，它可以继续进行其他 I&#x2F;O 操作，甚至发送新的请求到其他服务。 例如： B 在等待 A 的响应时，可能会继续向其他服务发起请求。 B 可以处理自己的其他任务，或继续等待其他 I&#x2F;O 操作。 这种 并发 和 非阻塞 的机制让多个请求可以并行进行，而每个请求不会阻塞其他请求的进程。 如何应用多路复用到实际生活中？虽然多路复用技术本身是一个操作系统层面的技术，但它的应用对于 高并发处理 和 性能优化 是至关重要的，在多个实际生活场景中都有体现： 网络服务：Web 服务器：当一个 Web 服务器需要同时处理多个客户端请求时，使用多路复用可以有效避免为每个请求创建一个线程的高昂开销。比如，现代 Web 服务器（如 Nginx）使用多路复用来管理大量的 HTTP 请求。数据库连接池：当多个客户端请求数据库时，连接池可以通过多路复用来共享连接池中的数据库连接，避免每个请求都创建新的连接。 实时通信应用：即时消息（IM）系统：例如，聊天应用的服务器需要同时处理大量用户的消息，使用多路复用技术可以提高服务器处理并发连接的效率。视频流服务：如直播平台需要同时处理大量用户的请求，多路复用技术可以有效管理所有用户的连接，确保数据流的稳定性。 操作系统中的 I&#x2F;O 管理：操作系统内核在管理文件系统和网络连接时，也会使用多路复用来提高磁盘和网络 I&#x2F;O 操作的效率。例如，Linux 内核的 epoll 就是在处理大规模的网络连接时非常高效的技术。硬件资源管理：设备管理：例如，在一些嵌入式系统中，多个硬件设备可能需要同时进行数据读写，操作系统可以通过多路复用的方式将数据的读写操作交给不同的设备驱动程序处理。","categories":[{"name":"计算机系统","slug":"计算机系统","permalink":"https://whuichenggong.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"Go中[]byte转换io.Reader","slug":"技术分享/[]byte_io.Reader","date":"2025-01-21T09:45:01.909Z","updated":"2025-05-11T07:13:39.944Z","comments":true,"path":"2025/01/21/技术分享/[]byte_io.Reader/","permalink":"https://whuichenggong.github.io/2025/01/21/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/[]byte_io.Reader/","excerpt":"","text":"[]byte 转 io.Reader 12345678910111213141516171819202122package mainimport ( &quot;bytes&quot; &quot;fmt&quot; &quot;log&quot;)func main() &#123; data := []byte(&quot;Hello AlwaysBeta&quot;) // byte slice to bytes.Reader, which implements the io.Reader interface reader := bytes.NewReader(data) // read the data from reader buf := make([]byte, len(data)) if _, err := reader.Read(buf); err != nil &#123; log.Fatal(err) &#125; fmt.Println(string(buf))&#125; io.Reader 转 []byte 1234567891011121314151617181920package mainimport ( &quot;bytes&quot; &quot;fmt&quot; &quot;strings&quot;)func main() &#123; ioReaderData := strings.NewReader(&quot;Hello AlwaysBeta&quot;) // creates a bytes.Buffer and read from io.Reader buf := &amp;bytes.Buffer&#123;&#125; buf.ReadFrom(ioReaderData) // retrieve a byte slice from bytes.Buffer data := buf.Bytes() // only read the left bytes from 6 fmt.Println(string(data[6:])) 1234567891011121314151617181920package mainimport ( &quot;bytes&quot; &quot;fmt&quot; &quot;os&quot;)func main() &#123; // 创建 Buffer 暂存空间，并将一个字符串写入 Buffer // 使用 io.Writer 的 Write 方法写入 var buf bytes.Buffer buf.Write([]byte(&quot;hello world , &quot;)) // 用 Fprintf 将一个字符串拼接到 Buffer 里 fmt.Fprintf(&amp;buf, &quot; welcome to golang !&quot;) // 将 Buffer 的内容输出到标准输出设备 buf.WriteTo(os.Stdout)&#125; o.Reader 接口：io.Reader 接口要求实现 Read(p []byte) (n int, err error) 方法，返回读取的字节数和错误信息。*bytes.Reader 就是通过实现这个方法来允许对 []byte 进行按块读取。","categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://whuichenggong.github.io/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"}],"tags":[]},{"title":"避免在Go中使用 io.ReadAll","slug":"go/Go_ReadAll","date":"2025-01-21T06:52:21.288Z","updated":"2025-05-11T07:20:03.592Z","comments":true,"path":"2025/01/21/go/Go_ReadAll/","permalink":"https://whuichenggong.github.io/2025/01/21/go/Go_ReadAll/","excerpt":"","text":"io.ReadAll 主要的作用是从一个 io.Reader 中读取所有数据，直到结尾。 虽然使用方便： 两个明显的缺点： 遇到大文件时，这个函数就会暴露出 性能问题，文件越大，性能越差。 文件过大的话，可能直接撑爆内存，导致程序崩溃。 示例： 12345678910111213func main() &#123; res, err := http.Get(&quot;http://www.google.com/robots.txt&quot;) if err != nil &#123; log.Fatal(err) &#125; robots, err := io.ReadAll(res.Body) res.Body.Close() if err != nil &#123; log.Fatal(err) &#125; fmt.Printf(&quot;%s&quot;, robots)&#125; io.ReadAll 的源码如下： &#x2F;&#x2F; src&#x2F;io&#x2F;io.gofunc ReadAll(r Reader) ([]byte, error) {b :&#x3D; make([]byte, 0, 512)for {n, err :&#x3D; r.Read(b[len(b):cap(b)])b &#x3D; b[:len(b)+n]if err !&#x3D; nil {if err &#x3D;&#x3D; EOF {err &#x3D; nil}return b, err} if len(b) &#x3D;&#x3D; cap(b) { &#x2F;&#x2F; Add more capacity (let append pick how much). b &#x3D; append(b, 0)[:len(b)] } }} 创建一个 512 字节的 buf； 不断读取内容到 buf，当 buf 满的时候，会追加一个元素，促使其重新分配内存； 直到结尾或报错，则返回； 了解 Go 切片的扩容策略，如下：如果期望容量大于当前容量的两倍就会使用期望容量； 如果当前切片的长度小于 1024 就会将容量翻倍； 如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量； 替换方案：可以使用 io.Copy 函数来代替，源码定义如下 123func Copy(dst Writer, src Reader) (written int64, err error) &#123; return copyBuffer(dst, src, nil)&#125; 其功能是直接从 src 读取数据，并写入到 dst 和io.ReadAll 最大的不同就是没有把所有数据一次性都取出来，而是不断读取，不断写入。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// src/io/io.gofunc copyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) &#123; // 如果源实现了 WriteTo 方法，则直接调用 WriteTo if wt, ok := src.(WriterTo); ok &#123; return wt.WriteTo(dst) &#125; // 同样的，如果目标实现了 ReaderFrom 方法，则直接调用 ReaderFrom if rt, ok := dst.(ReaderFrom); ok &#123; return rt.ReadFrom(src) &#125; // 如果 buf 为空，则创建 32KB 的 buf if buf == nil &#123; size := 32 * 1024 if l, ok := src.(*LimitedReader); ok &amp;&amp; int64(size) &gt; l.N &#123; if l.N &lt; 1 &#123; size = 1 &#125; else &#123; size = int(l.N) &#125; &#125; buf = make([]byte, size) &#125; // 循环读取数据并写入 for &#123; nr, er := src.Read(buf) if nr &gt; 0 &#123; nw, ew := dst.Write(buf[0:nr]) if nw &lt; 0 || nr &lt; nw &#123; nw = 0 if ew == nil &#123; ew = errInvalidWrite &#125; &#125; written += int64(nw) if ew != nil &#123; err = ew break &#125; if nr != nw &#123; err = ErrShortWrite break &#125; &#125; if er != nil &#123; if er != EOF &#123; err = er &#125; break &#125; &#125; return written, err&#125; 此函数执行步骤如下： 如果源实现了 WriteTo 方法，则直接调用 WriteTo 方法； 同样的，如果目标实现了 ReaderFrom 方法，则直接调用 ReaderFrom 方法； 如果 buf 为空，则创建 32KB 的 buf； 最后就是循环 Read 和 Write； io.Copy 函数不会一次性读取全部数据，也不会频繁进行切片扩容，显然在数据量大时是更好的选择。 最大区别：逐块读取：io.Copy 是按需读取数据并写入目标流。每次读取一小块数据（通常是缓冲区大小），然后将它写入目标，处理完后立即丢弃这部分数据，不会将它们保持在内存中。 一次性读取：io.ReadAll 会从源读取数据并将整个内容一次性加载到内存中，然后返回一个 []byte 切片。这意味着它会一直读取直到数据流结束，所有数据都存储在一个大的内存区域中。","categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"}],"tags":[]},{"title":"Go语言的学习资料","slug":"go/Golang","date":"2025-01-15T03:05:31.524Z","updated":"2025-05-11T07:20:03.542Z","comments":true,"path":"2025/01/15/go/Golang/","permalink":"https://whuichenggong.github.io/2025/01/15/go/Golang/","excerpt":"","text":"学习 Go 微服务开发的资料有很多，以下是一些推荐的资源，可以帮助你系统地掌握微服务相关的概念和实现方式： 1. 官方文档与教程 Go 官方文档：Go Documentation这是学习 Go 的基础，提供了完整的 Go 语言教程和标准库的文档。 gRPC 官方文档：gRPC Go如果你计划在微服务中使用 gRPC 进行高效的远程过程调用，gRPC 的官方 Go 文档会非常有帮助。 Go kit：Go Kit DocumentationGo kit 是一个适合构建分布式系统的 Go 微服务框架，官方文档详细介绍了如何使用该框架构建健壮的微服务。 Micro Framework：Micro DocumentationMicro 是一个现代化的微服务框架，支持服务发现、消息队列、RPC 通信等，适合快速构建微服务应用。 2. 视频教程与在线课程 Pluralsight - Building Microservices with Go链接这个课程介绍了如何使用 Go 构建可扩展和高效的微服务架构，包括通信机制、数据库、API 设计等。 3. 书籍推荐 《Go语言圣经》（The Go Programming Language）链接本书是学习 Go 语言的经典之作，虽然不专门讲解微服务，但它可以帮助你理解 Go 语言的基础和并发编程，为后续微服务开发打下坚实基础。 《Go微服务开发》（Microservices with Go）链接本书专注于 Go 在微服务中的应用，涵盖了服务发现、负载均衡、容器化等内容，非常适合想深入学习 Go 微服务架构的开发者。 《Go Web编程》（Go Web Programming）链接这本书详细介绍了如何使用 Go 进行 Web 开发，包括构建 RESTful API 和与数据库交互等内容，是微服务开发的良好起点。 4. 博客与社区 Go Micro Blog：Go Micro Blog这个博客是 Micro 框架的官方网站，内容涵盖 Go 微服务框架的最佳实践、教程和案例，适合深入学习。 Medium 上的 Go 微服务相关文章Go Microservices在 Medium 上有许多关于 Go 微服务的优秀文章，适合了解最新的开发趋势和实践。 Go 语言中文社区：Go 语言中文网这是一个专注于 Go 语言的中文社区，涵盖了大量关于 Go 语言及其应用的文章和讨论，其中也包括微服务相关的内容。 5. GitHub 项目与代码示例 Go 微服务项目示例Go Microservices Example这是一个完整的微服务示例项目，使用 Go 语言实现，涵盖了微服务中的常见功能，如服务注册、健康检查、API 网关等。 Go Kit 示例项目Go Kit ExampleGo kit 官方 GitHub 仓库，包含多个示例，演示了如何使用 Go kit 框架构建微服务。 gRPC Go 示例gRPC Go Examples这是 gRPC 官方的 Go 示例代码，适合需要使用 gRPC 进行微服务通信的开发者。 通过这些资料，你可以从基础到进阶学习 Go 语言在微服务架构中的应用，不仅可以掌握微服务的基本概念和技术，还能了解如何使用 Go 构建健壮的微服务系统。","categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"}],"tags":[]},{"title":"青训营开始","slug":"技术分享/青训营","date":"2025-01-14T11:03:27.871Z","updated":"2025-05-11T07:14:05.890Z","comments":true,"path":"2025/01/14/技术分享/青训营/","permalink":"https://whuichenggong.github.io/2025/01/14/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E9%9D%92%E8%AE%AD%E8%90%A5/","excerpt":"","text":"抖音商城： 简易抖音商城： Postgres Go（Hertz Kitex Gorm GoRedis Eino）（一）注册中心继承注册中心集成（etcd Consull Nacos） 自动注册服务数据 （二）身份认证 登录认证 权限认证（高级） (三) 可观测要求 日志记录与监控 (四) 可靠性要求 容错机制","categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://whuichenggong.github.io/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"}],"tags":[]},{"title":"Go工作池","slug":"backend/并发资源","date":"2025-01-14T04:19:13.371Z","updated":"2025-05-11T07:11:39.541Z","comments":true,"path":"2025/01/14/backend/并发资源/","permalink":"https://whuichenggong.github.io/2025/01/14/backend/%E5%B9%B6%E5%8F%91%E8%B5%84%E6%BA%90/","excerpt":"","text":"学习 Go 的工作池模式，你可以按照以下步骤系统掌握： 1. 理解工作池模式的概念 工作池是一种常见的并发模式，通过限制并发任务的数量，提高资源利用率，避免系统过载。 核心思想：创建固定数量的工作者（Worker），从任务队列中取任务处理，直到任务完成。 2. 学习基础知识 Goroutines：学习如何使用 Go 的轻量级线程 goroutines。 Go 官方文档 - Goroutines Channels：掌握 Go 的 channels 用于 goroutines 间通信。 Go 官方文档 - Channels WaitGroup：了解如何使用 sync.WaitGroup 等待所有 goroutines 完成。 WaitGroup 示例 3. 实践简单工作池先实现一个简单的工作池，熟悉基本流程。 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)func worker(id int, jobs &lt;-chan int, results chan&lt;- int, wg *sync.WaitGroup) &#123; defer wg.Done() for job := range jobs &#123; fmt.Printf(&quot;Worker %d processing job %d\\n&quot;, id, job) time.Sleep(1 * time.Second) // 模拟任务处理 results &lt;- job * 2 // 返回结果 &#125;&#125;func main() &#123; const numJobs = 5 const numWorkers = 2 jobs := make(chan int, numJobs) results := make(chan int, numJobs) var wg sync.WaitGroup for w := 1; w &lt;= numWorkers; w++ &#123; wg.Add(1) go worker(w, jobs, results, &amp;wg) &#125; for j := 1; j &lt;= numJobs; j++ &#123; jobs &lt;- j &#125; close(jobs) wg.Wait() close(results) for res := range results &#123; fmt.Println(&quot;Result:&quot;, res) &#125;&#125; 4. 深入理解工作池模式的应用 扩展任务类型：如 I&#x2F;O 密集型任务（网络请求）和 CPU 密集型任务。 实现动态调整任务队列大小。 学习如何优雅地退出工作池（使用 context 或带超时的 channels）。 5. 阅读优质资源 Go Concurrency Patterns (官方博客) 《Go Programming Blueprints》 Effective Go - Concurrency 6. 挑战真实项目实践是掌握模式的最佳方式，可以尝试： 爬取多个网页内容并解析数据。 并发处理文件或图片。 实现一个 URL 检查器（如我们之前讨论的例子）。 通过从基础到实战的学习，你会对 Go 的工作池模式有深刻的理解。如果有问题，可以随时向我求助！","categories":[{"name":"backend","slug":"backend","permalink":"https://whuichenggong.github.io/categories/backend/"}],"tags":[]},{"title":"Go天生的并发优势","slug":"backend/并发编程","date":"2025-01-14T03:03:02.091Z","updated":"2025-05-11T07:11:06.337Z","comments":true,"path":"2025/01/14/backend/并发编程/","permalink":"https://whuichenggong.github.io/2025/01/14/backend/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","excerpt":"","text":"借鉴文章： https://www.topgoer.com/ 1234func main() &#123; go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(&quot;main goroutine done!&quot;)&#125; 这一次的执行结果只打印了main goroutine done!，并没有打印Hello Goroutine!。为什么呢？ 例子：当main()函数返回的时候该goroutine就结束了，所有在main()函数中启动的goroutine会一同结束，main函数所在的goroutine就像是权利的游戏中的夜王，其他的goroutine都是异鬼，夜王一死它转化的那些异鬼也就全部GG了。 所以我们要想办法让main函数等一等hello函数，最简单粗暴的方式就是time.Sleep了 12345func main() &#123; go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(&quot;main goroutine done!&quot;) time.Sleep(time.Second)&#125; 启动多个goroutine1234567891011121314var wg sync.WaitGroupfunc hello(i int) &#123; defer wg.Done() // goroutine结束就登记-1 fmt.Println(&quot;Hello Goroutine!&quot;, i)&#125;func main() &#123; for i := 0; i &lt; 10; i++ &#123; wg.Add(1) // 启动一个goroutine就登记+1 go hello(i) &#125; wg.Wait() // 等待所有登记的goroutine都结束&#125; 123456789101112131415161718192021222324252627 package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; // 合起来写 go func() &#123; i := 0 for &#123; i++ fmt.Printf(&quot;new goroutine: i = %d\\n&quot;, i) //time.Sleep(time.Second) &#125; &#125;() i := 0 for &#123; i++ fmt.Printf(&quot;main goroutine: i = %d\\n&quot;, i) time.Sleep(time.Second) if i == 3 &#123; break &#125; &#125;&#125; 在这段程序中 如果 注释 &#x2F;&#x2F;time.Sleep(time.Second)这个语句： 新 goroutine 中的无限循环运行非常快，因为 time.Sleep 被注释掉了。 新 goroutine 的打印操作占据了 CPU 的大部分时间，导致主 goroutine 很少或者几乎没有机会运行。 Go 的 goroutine 是由 Go 运行时管理的轻量级线程，采用抢占式调度。 在你的代码中，新 goroutine 中的打印操作和循环执行非常快，没有阻塞点（比如 time.Sleep 或 I&#x2F;O 操作）。 没有阻塞点会让新 goroutine 占据大量的 CPU 时间，主 goroutine 反而无法得到足够的调度时间。 主 goroutine 需要与新 goroutine 竞争 CPU 时间。因为新 goroutine 的循环过于频繁（没有阻塞），主 goroutine 可能无法及时获得 CPU 调度机会。 Go中的调度函数使用runtime.Gosched 的作用：暂停当前 goroutine 的执行。将 CPU 的使用机会交还给调度器。调度器会决定下一个应该执行的 goroutine。 GPM是Go语言运行时（runtime）层面的实现， 在你提供的程序中，主 goroutine 是 main 函数中的代码执行流。具体来说，程序一开始会执行 main() 函数内的内容。然后，主 goroutine 会启动一个新的后台 goroutine，通过 go 关键字启动的匿名函数来执行，这个新 goroutine 会执行打印 “world” 的任务。 GPM G (Goroutine)：表示一个具体的 goroutine，包含要执行的任务信息，比如函数栈、指令等。G 是任务的最小单位。 P (Processor)：是一个逻辑处理器，用于管理 goroutine 的运行队列。P 和 CPU 核心的数量绑定（通过 GOMAXPROCS 控制），每个 P 会调度多个 G。 M (Machine)：表示一个操作系统线程。M 从 P 的队列中获取 G 并执行它。每个 M 会从 P 上获取一个或多个 G 来执行。 在 Go 的 GPM 调度模型中，P 和 M 之间的关系是 一对多，即每个 P（处理器）可以关联多个 M（操作系统线程），但同一时刻每个 P 只有一个 M 处于 活跃 状态，来执行调度的任务（即执行 G，即 goroutine）。 可增长的栈OS线程（操作系统线程）一般都有固定的栈内存（通常为2MB）,一个goroutine的栈在其生命周期开始时只有很小的栈（典型情况下2KB），goroutine的栈不是固定的，他可以按需增大和缩小，goroutine的栈大小限制可以达到1GB，虽然极少会用到这个大。所以在Go语言中一次创建十万左右的goroutine也是可以的。 异步异步执行的核心思想是让某些任务在后台运行，不阻塞主流程。 go a(ch) 启动 a 函数的执行，但不会阻塞主 goroutine，主 goroutine 可以继续执行后续代码。a(ch) 在后台运行，它执行完后通过 channel 通知主 goroutine。主 goroutine 等待 signal，通过 &lt;-ch 实现同步等待，确保 a 完成后才继续后续操作。因此，go a(ch) 启动的部分是异步的，意味着 a 会在后台执行，而主 goroutine 不会因调用 a 而阻塞或等待它完成。 channel单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行函数的意义。 虽然可以使用共享内存进行数据交换，但是共享内存在不同的goroutine中容易发生竞态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。 Go语言的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。 channel就是它们之间的连接。channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。 Go 语言中的通道（channel）是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型 关闭后的通道有以下特点： 12341.对一个关闭的通道再发送值就会导致panic。 2.对一个关闭的通道进行接收会一直获取值直到通道为空。 3.对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。 4.关闭一个已经关闭的通道会导致panic。 无缓冲的通道(同步通道)无缓冲的通道又称为阻塞的通道 启用一个goroutine去接收值 无缓冲通道上的发送操作会阻塞，直到另一个goroutine在该通道上执行接收操作，这时值才能发送成功，两个goroutine将继续执行。相反，如果接收操作先执行，接收方的goroutine将阻塞，直到另一个goroutine在该通道上发送一个值。 可以通过内置的close()函数关闭channel（如果你的管道不往里存值或者取值的时候一定记得关闭管道） 123456789101112131415161718192021package mainimport &quot;fmt&quot;func main() &#123; c := make(chan int) go func() &#123; for i := 0; i &lt; 5; i++ &#123; c &lt;- i &#125; close(c) &#125;() for &#123; if data, ok := &lt;-c; ok &#123; fmt.Println(data) &#125; else &#123; break &#125; &#125; fmt.Println(&quot;main结束&quot;)&#125;","categories":[{"name":"backend","slug":"backend","permalink":"https://whuichenggong.github.io/categories/backend/"}],"tags":[]},{"title":"go中的context","slug":"go/调用","date":"2025-01-02T09:34:59.595Z","updated":"2025-05-11T07:12:26.998Z","comments":true,"path":"2025/01/02/go/调用/","permalink":"https://whuichenggong.github.io/2025/01/02/go/%E8%B0%83%E7%94%A8/","excerpt":"","text":"首先理解同步调用与异步调用： 同步调用和异步调用是两种常见的函数调用方式，尤其在多线程、并发编程中，这两种方式对程序的执行流程和效率有着直接影响。 1. 同步调用（Synchronous Call）同步调用是指函数调用时，调用者会等待被调用的函数执行完毕并返回结果之后，才能继续执行后续操作。在同步调用过程中，函数的调用者会阻塞，直到函数执行完成。 特点： 阻塞：调用者会等待被调用的函数执行完成，才会继续执行后续代码。 执行顺序：代码按顺序执行，当前任务完成后，才能继续下一个任务。 举个例子： 12345678910111213141516package mainimport &quot;fmt&quot;import &quot;time&quot;// 模拟一个同步调用的函数func longTask() &#123; time.Sleep(2 * time.Second) fmt.Println(&quot;Long task finished&quot;)&#125;func main() &#123; fmt.Println(&quot;Start task&quot;) longTask() // 同步调用，调用者会等待该函数执行完 fmt.Println(&quot;End task&quot;)&#125; 输出： 123Start taskLong task finishedEnd task 在这个例子中，longTask() 函数执行时，程序会等待它执行完毕，然后才继续执行后面的 fmt.Println(&quot;End task&quot;)。 2. 异步调用（Asynchronous Call）异步调用是指调用者在调用函数时，不会等待函数执行完成，而是直接继续执行后续代码。异步调用通常会通过某种机制（比如回调函数、线程、goroutine等）来处理函数执行完成后的结果。 特点： 非阻塞：调用者不会等待被调用的函数执行完成，而是继续执行后续操作。 执行顺序：调用者继续执行，而被调用的函数可能在后台执行，执行顺序不确定。 举个例子（使用 Go 的 goroutine）： 1234567891011121314151617package mainimport &quot;fmt&quot;import &quot;time&quot;// 模拟一个异步调用的函数func longTask() &#123; time.Sleep(2 * time.Second) fmt.Println(&quot;Long task finished&quot;)&#125;func main() &#123; fmt.Println(&quot;Start task&quot;) go longTask() // 异步调用，goroutine 不会阻塞主线程 fmt.Println(&quot;End task&quot;) time.Sleep(3 * time.Second) // 等待 goroutine 执行完毕&#125; 输出： 123Start taskEnd taskLong task finished 在这个例子中，longTask() 被异步调用（通过 go 关键字），主线程并不会等待 longTask() 执行完毕，而是继续执行 fmt.Println(&quot;End task&quot;)。由于 longTask() 是在一个新的 goroutine 中执行的，所以它会在主线程打印完 &quot;End task&quot; 后才完成。 同步调用与异步调用的区别： 特性 同步调用 异步调用 执行方式 当前任务需要等待被调用函数执行完毕后才能继续 当前任务不会等待，被调用函数在后台执行 阻塞与非阻塞 阻塞：调用者会等待被调用函数完成 非阻塞：调用者不会等待被调用函数完成，继续执行 执行顺序 按顺序执行，当前任务完成后，继续下一个任务 执行顺序不确定，被调用函数可能稍后执行 适用场景 适用于需要等待函数执行完成后才能继续的情况 适用于可以并行处理，调用者不需要等待结果的情况 效率 效率较低，尤其在调用高延时操作时，调用者会被阻塞 效率较高，可以并行执行多个任务，不阻塞调用者 优缺点： 同步调用： 优点：简单，易于理解和调试，程序的执行顺序清晰。 缺点：当操作耗时较长时，调用者需要等待，造成性能瓶颈。例如，I&#x2F;O 密集型操作（如数据库查询、网络请求等）可能导致程序停滞。 异步调用： 优点：提高并发性能，特别适合处理 I&#x2F;O 密集型操作。调用者不需要等待操作完成，可以同时执行多个任务。 缺点：需要更多的设计和管理，比如回调函数、并发控制等；调试和错误处理可能比较复杂。 何时选择同步和异步？ 同步调用：适用于需要按顺序执行任务且任务之间有依赖关系的场景。例如，计算任务需要按顺序完成，或者需要等待数据库查询结果再执行下一步操作。 异步调用：适用于任务之间没有直接依赖关系，可以并行执行的场景。例如，网络请求、文件处理、并发计算等。 总结： 同步调用是阻塞的，调用者需要等待被调用函数执行完成后才能继续执行后续代码。 异步调用是非阻塞的，调用者不会等待被调用函数执行完成，而是继续执行后续操作，通常通过回调或并发机制处理结果。 并发相关能力：创建了一个异步的协程或者线程，如果你不知道它什么时候终止，最好不要创建它！ 做到心中有数，理解并发！什么时候该用 线程： 是cpu需要执行的任务 并发执行，看似在一起做实行，如果是一个cpu核心那么：实则是一个人在两个任务之间快速的切换！（本质还是一个人做两件事，只不过两件事都分别分配一点时间） 两个核心执行两个线程 就相当于并行执行两个任务，时间将会被大大缩短 但是实际情况还是会非常复杂： 锁机制： 即使有两个cpu可以工作，但是他们需要持有锁的那个才可以工作！这也就导致了实际的工作还是并发执行！ 高性能程序尽量避免使用锁 context之间形成多叉树的结构！ 父ctx派生 多个子ctx 感知生命周期","categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"}],"tags":[]},{"title":"软技能","slug":"书后心得/软技能","date":"2025-01-02T03:55:16.442Z","updated":"2025-05-11T07:13:05.521Z","comments":true,"path":"2025/01/02/书后心得/软技能/","permalink":"https://whuichenggong.github.io/2025/01/02/%E4%B9%A6%E5%90%8E%E5%BF%83%E5%BE%97/%E8%BD%AF%E6%8A%80%E8%83%BD/","excerpt":"","text":"书中的前言： 引用的几句名言！ “现在的困难可能会成为未来的趋势” “站在对方的角度，在说服对方的时候，为他准备好解决问题的方案” “不浪费任何一次危机，任何危机都是组织结构重新组合的重大契机” “作为听者，你能理解表达能力较弱的一方的言说，作为言说者，你能让理解力较弱的一方明白你的意思” 组合型思维： 我这里强，需要你那里强，互相配合，达到双赢， 多想： 你能为别人做什么，你能为圈子带来什么。为什么小的时候看什么都新奇，到那时长大后变得更加麻木了呢？对周围事物，没有了其他想法是不是思维被固定住了呢？ 保持孩童般的惊奇！ 主动创造不平凡： 有些人就是不甘于平凡！才会造就出一些令世人震惊的事物。 做事情的两种方法： 做减法：拿出一段时间，排除各种琐事的干扰，降低认知负荷，集中能量，完全自主就干这一件事 做加法主动给事情增加难度，你觉得没意思，可以去悬崖边看书哈哈哈，真的可以，但是要注意安全呢 但是，世界上有很多事情根本不需要去做，还有些事情是不能去做的！，被别人认可的事情就是一定是好的吗？可能你在你只是在一些无意义的事做了循环无用功 所以，如何判断哪些事需要做，哪些是不能做！这也是一个人的能力 有效的反馈系统： 一件事该不该做，通常是需要总结之前做事的结果，做一件事后产生的预期结果之后分析做成的原因， 运气？or 实力？自己心里要清楚没有达到预期的事情，花时间想问题出在了哪里？调整自己的行为 培养同理心：培养理解他人的能力，站在对方的角度思考问题， ”辛辛苦苦发明一样东西，却发现世界并不需要他“： 创新和实际需求之间的鸿沟 保持敬畏心： （愿意去学习、去探索，而不是自以为是或过于自信。承认自然界的复杂性和不确定性，推动自己不断探索。）愿意通过反思和努力去改进 技能是无限的，我们的时间和精力是有限的，造成结果就是，我们对一切事物只能做到一知半解，很多技能也掌握的二把刀水平，对于自己力所不能及的事情，不要去做力所能及的事情，做起来也要留三分（可以在完成的基础上保持精力和资源的余地，为未来的工作或挑战做好准备。） 剥离情感（但不等同于没有同理心）： 很多事，自己的情感卷进去就不好了，同理心要求我们摒弃以自我为中心的想法，剥离情感是让我们不要被情感牵着鼻子走，保持客观公正的判断力！ 改变模式而不是放弃机遇：","categories":[{"name":"书后心得","slug":"书后心得","permalink":"https://whuichenggong.github.io/categories/%E4%B9%A6%E5%90%8E%E5%BF%83%E5%BE%97/"}],"tags":[]},{"title":"你的灯还亮着吗","slug":"书后心得/看了一本书","date":"2024-12-28T10:40:19.406Z","updated":"2025-05-11T07:20:03.586Z","comments":true,"path":"2024/12/28/书后心得/看了一本书/","permalink":"https://whuichenggong.github.io/2024/12/28/%E4%B9%A6%E5%90%8E%E5%BF%83%E5%BE%97/%E7%9C%8B%E4%BA%86%E4%B8%80%E6%9C%AC%E4%B9%A6/","excerpt":"","text":"今天一下午的时间看了这本书，对我的感触很大，很有助于思考，对于一个问题的思考，一种问题不同的问法，产生不同的问题 文字游戏：一句话不同的停顿产生不同的问题 有些事情是不是简单的问题复杂化（这应该是普遍现象） 复杂的问题简单化（很少） 你是不是真的想要解决这问题？ 追溯本源，从一个婴儿视角重新审视这个问题！ 一生二，二生三，三生万物： 你对一个问题的解决（是否是真的解决？）一个问题的解决必然产生另一个问题的产生！ 看看你是否能从一个问题的解决，来想到它产生了3个其他的问题？","categories":[{"name":"书后心得","slug":"书后心得","permalink":"https://whuichenggong.github.io/categories/%E4%B9%A6%E5%90%8E%E5%BF%83%E5%BE%97/"}],"tags":[]},{"title":"一位老哥的分享给了我一些启发","slug":"生活/live3","date":"2024-12-18T12:43:19.542Z","updated":"2025-01-21T07:09:45.201Z","comments":true,"path":"2024/12/18/生活/live3/","permalink":"https://whuichenggong.github.io/2024/12/18/%E7%94%9F%E6%B4%BB/live3/","excerpt":"","text":"学习方法：老哥的思维方式也给了我一些启发 以下是老哥的分享： 当知识点量大起来时, 我觉得”写作”的意义应该在于辅助思考 因为短时间内可能我们能记得很好, 但是对于长时间的庞大知识体系的学习, 就容易忘记一些分支内容 所以第一步我做的是把长长的博客尽量拆解为小的讨论主题 作为”词条”存在 比如我写了个k8s主题的词条 写道”容器”这个词会自动链接到我之前写过的容器相关的内容 里面的内容是否符合当下我需要的定义 如果是, 那么可以知识复用 如果不是, 那么我需不需要创建新的词条来讨论这个主题然后关联知识形成网络 比如一个使用mysql + reids搭建的系统, 即用到了mysql, 又用到了redis, 同时它本身还是个系统设计就会难以归类 但是 一个文章可以同时带有mysql, redis, 系统设计三种tag 让知识形成网络！ 先把书的标题提取出来 建立一个词条 然后去网上查, 这个东西包含哪些东西 然后去网上查, 这个东西包含哪些东西 等熟悉了基于零散信息的网络后 再去快速浏览权威书籍 迭代网络 听了老哥的分享！ 我觉得自己再生活中真的缺乏太多的思考了！什么事知道他困难，不想办法，应该去思考一些东西才能让东西变得更活！","categories":[{"name":"生活","slug":"生活","permalink":"https://whuichenggong.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[]},{"title":"学习数据库","slug":"计算机系统/Database","date":"2024-12-16T01:12:34.566Z","updated":"2025-05-11T07:15:27.292Z","comments":true,"path":"2024/12/16/计算机系统/Database/","permalink":"https://whuichenggong.github.io/2024/12/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/Database/","excerpt":"","text":"参考书籍： 数据库设计 我先从事务入手： 事务概念 ： 与单个用户或者程序执行，完成读取或者更新数据库内容的一个或一串操作 应用程序的一次执行就是一个事务或者多个事务 示例： 简单事务： 更新x员工的工资（涉及：数据库的读和写，和非数据库操作） 复杂事务：删除x的员工记录，并把x员工的事务交付给其他人去做。 （过程中若并非所有的操作都被执行，那么数据库的引用完整性将遭到破坏）（数据库也处于不一致状态） 尽管一致性暂时遭到破坏，但是数据库总是可以从一种一致状态转换到另一种一致的状态 数据库最终的结果 COMMIT：执行成功，事务最终被提交 （数据库也达到了一种新的状态） ABORTED：事务没有执行成功 （事务被撤销）则数据库必须要还原事务开始之前的一致状态 已经提交的事务不能被撤销，只能通过（补偿事务）进行覆盖 消除事务产生的影响 DBMS将在程序正确结束后自动执行COMMIT操作，若不能成功执行则 ROBACK PARTIALLY COMITTED：若在最后一条语句被执行时产生了 破坏了可串行化或违反了完整约束 因此事务必须被撤销 或者系统出现故障，事务更新的事务没有被安全的写到二级存储设备上（部分提交） 以上两种情况最终都会进入 FAILED（失败状态） 事务无法被提交，或者事务处于ACTIVE状态就被撤销 则 处于FAILED状态 事务性质ACID 原子性： 一致性： 隔离性： 持久性： 事务的隔离级别事务隔离级别控制了事务之间的可见性和并发行为。常见的隔离级别包括： 读未提交（Read Uncommitted）：在这个隔离级别下，一个事务可以读取其他事务尚未提交的数据。这可能导致脏读（读取了未提交的数据）、不可重复读（同一查询在事务执行期间返回不同结果）和幻读（事务在同一查询中看到不同的数据行）等问题。读未提交的隔离级别最不严格，可能会引发数据不一致问题 读已提交（Read Committed）：在这个隔离级别下，一个事务只能读取已经提交的数据，避免了脏读问题。但是，不可重复读和幻读问题仍然可能出现。因为其他事务可能在事务进行期间提交新的数据，导致不同时间点的查询结果不一致。 可重复读（Repeatable Read）：可重复读隔离级别确保在同一事务内，同一个查询的结果保持一致。这意味着一个事务中的查询不会受到其他事务的修改影响。这可以防止脏读和不可重复读问题，但幻读问题仍然可能出现，因为其他事务可能插入新数据，导致新数据行的出现。 串行化（Serializable）：串行化是最严格的隔离级别，它确保每个事务都在独立的时间段内执行，防止了并发问题。事务按照顺序一个接一个地执行，这可以解决脏读、不可重复读和幻读问题。然而，串行化可能会对性能产生较大的影响，因为事务需要依次执行。 事务的隔离级别可以解决脏读、幻读、不可重复读的问题。 脏读： 脏读指的是在一个事务中读取了另一个事务未提交的数据。假设事务 A 修改了某一行数据，但还没有提交。同时，事务 B 尝试读取了事务 A 修改的数据。如果事务 A 最终回滚了，那么事务 B 读取的数据就是不存在的，这就是脏读。脏读会导致不准确的数据展示，因为读取的数据可能是临时的未经验证的。、 不可重复读：不可重复读是指在同一个事务内，多次读取同一数据时，得到不同的结果。这可能是因为在事务执行期间，其他事务修改了数据。例如，事务 A 在读取某一行数据后，事务 B 修改了这行数据，并提交了。现在事务 A 再次读取相同的数据，注重数据：发现数据已经不同了，造成了不一致的现象。 幻读： 幻读是指在同一个事务内，多次查询同一范围的数据时，得到不同的结果。这与不可重复读类似，但幻读关注的是数据的数量变化。例如，事务 A 在查询某个范围内的所有数据时，事务 B 插入了新数据，并提交了。现在事务 A 再次查询同一范围的数据，注重：发现数据行的数量增加了，这就是幻读。 22.2 并发控制 讲解了数据库中的一些问题 幻读等 [点击这里查看PDF文件] (https://github.com/Whuichenggong/Knowledge-network/blob/main/docs/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BD%91%E7%BB%9C.pdf)","categories":[{"name":"计算机系统","slug":"计算机系统","permalink":"https://whuichenggong.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"关于我学习的一些资源和方法","slug":"技术分享/resource","date":"2024-12-15T07:45:03.995Z","updated":"2025-05-11T07:13:50.108Z","comments":true,"path":"2024/12/15/技术分享/resource/","permalink":"https://whuichenggong.github.io/2024/12/15/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/resource/","excerpt":"","text":"兄弟，我理解你的心态，觉得实践的收获更直观，看书反而有点慢。但实际上，看书和实践结合，效果会倍增。下面我不仅推荐优质资源，还会分享高效阅读的方法，帮你更好地平衡学习时间。 学习资料推荐1. 数据库相关 书籍：《高性能 MySQL》 重点阅读：索引优化、事务机制、查询优化。 免费在线教程： SQL 教程（w3schools） MySQL 官方文档 2. 计算机网络 书籍：《计算机网络：自顶向下方法》或《图解HTTP》 重点章节：HTTP、TCP&#x2F;IP、DNS、HTTPS。 免费资源： HTTP 协议详解 Wireshark 网络分析教程 3. 操作系统 书籍：《现代操作系统》 重点章节：进程、线程、同步、内存管理。 免费资源： Operating Systems: Three Easy Pieces Linux 操作系统入门 4. 系统设计 书籍：《系统设计入门》（Grokking the System Design Interview） 重点学习：缓存、负载均衡、限流。 博客： 系统设计基础 5. Redis 书籍：《Redis 实战》 重点章节：缓存机制、分布式锁。 免费资源： Redis 官方文档 6. 算法与数据结构 书籍：《算法（第4版）》或《编程珠玑》 重点章节：常用数据结构（栈、队列、二叉树）、动态规划。 网站： LeetCode 官方 VisuAlgo（算法可视化） 高效看书方法1. 目的导向阅读 明确目标：每次看书前，明确你要解决的问题。比如： “我需要理解事务是怎么实现的” → 阅读事务相关章节，跳过其他部分。 “我需要掌握 TCP 的连接过程” → 只看 TCP 的工作原理。 2. 略读和精读结合 略读：先快速翻阅目录和每章的开头，总结书的主要内容。 精读：挑选与项目或刷题直接相关的部分深入看，配合做笔记和练习。 3. 配合实践 边学边做：看完书中某个知识点，立即在项目或代码中实现。 例子：学完 Redis 的分布式锁，马上在银行项目中添加。 用书作为工具：书可以成为你的“随手参考”，遇到不懂的概念再翻阅相关章节，而不必一次性啃完。 4. 输出内容 写笔记：总结书中学到的知识，用自己的语言重新描述。 录制分享：试着用 3 分钟向别人讲解你刚学的内容，加深记忆。 5. 番茄工作法 每次阅读 25 分钟后，花 5 分钟总结这段时间的收获，然后休息片刻。效率会提升很多。 实践与看书的时间分配 每天早上&#x2F;晚上固定 1 小时阅读。 比如：早上看《高性能 MySQL》，晚上看《计算机网络》。 实践时遇到问题，马上查书解决。 例子：如果 Redis 配置缓存遇到问题，就查《Redis 实战》。 每周末专门安排 2 小时总结书中知识点，结合项目整理成笔记。 这样安排既能保持实践的节奏，又能让你从书中挖掘深层的原理。如果还有具体内容不理解，可以随时问我，我也可以帮你分解章节内容！","categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://whuichenggong.github.io/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"}],"tags":[]},{"title":"聊聊最近","slug":"生活/current","date":"2024-12-12T12:57:12.010Z","updated":"2025-05-11T07:20:03.575Z","comments":true,"path":"2024/12/12/生活/current/","permalink":"https://whuichenggong.github.io/2024/12/12/%E7%94%9F%E6%B4%BB/current/","excerpt":"","text":"最近的日子在想着达到就业的水平，不断地提升额，嗯然后今天手机掉水里了，烘干24小时，看看能不能复活吧，突然觉得之前手机不是那么重要，回想起它占用我的时间，好像都不是什么重要的事情，近期来，感觉是为了让自己舒服一点，白天学完，晚上回去就刷手机而且就是 12点 1点，恶性循环，本想着晚上回去看会书，自己却暗示自己，学一天了，玩吧哈哈哈。好像都没做，但是确实没有那么重要，吃饭可以让同学帮我付，哈哈，还是得学习呢，反省一下，是不是你想要的太多了而导致你很累，那种精神上的压迫自己，反思~ 今天12.12日试着实现将单片机的数据传输到数据库中交互先简单的使用按钮的高低电平0 1 实现交互试试看 后端服务代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;log&quot; &quot;net/http&quot; &quot;context&quot; &quot;github.com/jackc/pgx/v4&quot;)type ButtonPress struct &#123; DeviceID string `json:&quot;device_id&quot;` Button int `json:&quot;button&quot;` Timestamp string `json:&quot;timestamp&quot;`&#125;const ( dbHost = &quot;localhost&quot; dbPort = 5432 dbUser = &quot;root&quot; dbPassword = &quot;secret&quot; dbName = &quot;data&quot;)func main() &#123; // Set up the database connection connStr := fmt.Sprintf(&quot;postgresql://%s:%s@%s:%d/%s&quot;, dbUser, dbPassword, dbHost, dbPort, dbName) conn, err := pgx.Connect(context.Background(), connStr) if err != nil &#123; log.Fatalf(&quot;Unable to connect to the database: %v&quot;, err) &#125; defer conn.Close(context.Background()) // Set up the HTTP server http.HandleFunc(&quot;/receive&quot;, func(w http.ResponseWriter, r *http.Request) &#123; if r.Method != http.MethodPost &#123; http.Error(w, &quot;Only POST requests are supported&quot;, http.StatusMethodNotAllowed) return &#125; var data ButtonPress if err := json.NewDecoder(r.Body).Decode(&amp;data); err != nil &#123; http.Error(w, &quot;Invalid JSON format&quot;, http.StatusBadRequest) return &#125; log.Printf(&quot;Received data: %+v&quot;, data) if data.Button == 1 &#123; // Store the data in the database query := &quot;INSERT INTO button_presses (device_id, button, timestamp) VALUES ($1, $2, $3)&quot; _, err := conn.Exec(context.Background(), query, data.DeviceID, data.Button, data.Timestamp) if err != nil &#123; http.Error(w, &quot;Failed to store data in the database&quot;, http.StatusInternalServerError) return &#125; log.Println(&quot;Data successfully stored in the database&quot;) &#125; w.WriteHeader(http.StatusOK) w.Write([]byte(&quot;Data received and processed&quot;)) &#125;) log.Println(&quot;Starting server on 192.168.111.1:8080&quot;) if err := http.ListenAndServe(&quot;192.168.111.1:8080&quot;, nil); err != nil &#123; log.Fatalf(&quot;Server failed: %v&quot;, err) &#125;&#125; 这是简单的实现 单片机端代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;ESP8266WiFi.h&gt;#include &lt;ESP8266HTTPClient.h&gt;const char* ssid = &quot;Your_SSID&quot;; // Wi-Fi 名称const char* password = &quot;Your_PASSWORD&quot;; // Wi-Fi 密码const char* serverUrl = &quot;http://8.222.186.212:8080/send&quot;; // 后端服务器地址void setup() &#123; Serial.begin(115200); // 初始化串口 WiFi.begin(ssid, password); // 连接到 Wi-Fi Serial.print(&quot;Connecting to Wi-Fi&quot;); while (WiFi.status() != WL_CONNECTED) &#123; delay(1000); Serial.print(&quot;.&quot;); &#125; Serial.println(&quot;\\nConnected to Wi-Fi&quot;);&#125;void loop() &#123; if (WiFi.status() == WL_CONNECTED) &#123; HTTPClient http; http.begin(serverUrl); // 设置服务器 URL http.addHeader(&quot;Content-Type&quot;, &quot;application/json&quot;); // 设置请求头 // 示例 JSON 数据 String jsonData = &quot;&#123;\\&quot;sensor\\&quot;: \\&quot;temperature\\&quot;, \\&quot;value\\&quot;: 25.5&#125;&quot;; // POST 请求 int httpResponseCode = http.POST(jsonData); // 检查响应状态 if (httpResponseCode &gt; 0) &#123; String response = http.getString(); Serial.println(&quot;Response: &quot; + response); &#125; else &#123; Serial.println(&quot;Error on sending POST: &quot; + String(httpResponseCode)); &#125; http.end(); // 关闭连接 &#125; else &#123; Serial.println(&quot;Wi-Fi not connected&quot;); &#125; delay(5000); // 每 5 秒发送一次数据&#125; HTTP就是那么的神奇","categories":[{"name":"生活","slug":"生活","permalink":"https://whuichenggong.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[]},{"title":"分布式系统学习","slug":"计算机系统/Distributed","date":"2024-12-09T12:53:55.062Z","updated":"2025-05-11T07:15:29.909Z","comments":true,"path":"2024/12/09/计算机系统/Distributed/","permalink":"https://whuichenggong.github.io/2024/12/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/Distributed/","excerpt":"","text":"go build -buildmode=plugin ../mrapps/wc.go这个指令是什么意思 : 这个命令的作用是编译 ..&#x2F;mrapps&#x2F;wc.go 文件，并将其生成一个 Go 插件文件。生成的插件文件通常是一个 .so（共享库文件）文件，它可以在运行时被其他 Go 程序通过 plugin 包加载和调用。 例如： 你可以在主程序中使用 plugin 包动态加载 wc.so 插件，并调用插件中的函数。 go run mrsequential.go wc.so pg*.txt： go run：用于编译并运行 Go 程序。它会在内存中临时编译指定的 Go 文件，并立即执行。 mrsequential.go：这是要执行的 Go 源文件，Go 编译器会先编译这个文件并运行它。这个文件应该包含 main 函数，通常是程序的入口点。 wc.so：这是一个 Go 插件文件（共享库）。它通常是通过 go build -buildmode&#x3D;plugin 命令生成的。该文件包含 Go 代码，可能定义了一个插件接口，在运行时可以被主程序（mrsequential.go）动态加载和调用。wc.so 可能提供某些功能，mrsequential.go 将加载并使用这些功能。 pg*.txt：这是一个通配符表达式，表示所有以 pg 开头，后面跟任意字符，且以 .txt 结尾的文件。例如，pg1.txt, pg42.txt, pgfile.txt 都会被匹配并作为参数传递给程序。 more mr-out-0 将会输出很多文本 这是因为： mrsequential.go 将其输出保留在文件 mr-out-0 中。输入来自名为 pg-xxx.txt 的文本文件","categories":[{"name":"计算机系统","slug":"计算机系统","permalink":"https://whuichenggong.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"为什么别人写项目知道用什么？","slug":"我的困惑/confusion","date":"2024-12-07T09:19:23.441Z","updated":"2025-05-11T07:20:03.556Z","comments":true,"path":"2024/12/07/我的困惑/confusion/","permalink":"https://whuichenggong.github.io/2024/12/07/%E6%88%91%E7%9A%84%E5%9B%B0%E6%83%91/confusion/","excerpt":"","text":"同样来自GPT的回答： 你的疑惑非常好！许多人在学习编程时都会有类似的感受，尤其是在学习阶段，看到博主轻松选择某些包或者工具来解决问题时，会觉得他们似乎“无所不知”。事实上，这背后是经验和积累的结果。以下几点可以帮助你理解和逐步建立这种能力： 1. 经验的积累 博主的背景：他们可能已经解决过类似问题，因此知道哪些包是高效的选择。这是经验的体现。 类比：就像一位厨师在做菜时，很容易知道用什么调料，而新手可能需要查配方。 你可以这样做： 多看、多学：通过模仿优秀项目和学习文档，积累对常用库和框架的了解。 练习总结：每次解决问题后，记录用到的包和方法，慢慢形成自己的“工具箱”。 2. 文档与生态 语言和框架的生态：每种语言或框架都有一些社区公认的、常用的库。 比如，Go 语言处理配置时，大家常用 viper 或 yaml。 HTTP 请求：net/http（原生）或社区的 gin（框架）。 社区推荐：很多库被推荐使用，是因为它们： 功能齐全。 易于使用。 社区活跃，有长期维护。 你可以这样做： 了解生态：多逛 GitHub、Go 的标准库文档以及社区资源（比如 Go 的官方博客）。 参考优秀代码：通过学习开源项目，你可以快速了解哪些包解决了哪些问题。 3. 搜索能力 很多开发者的知识并不是“记住的”，而是“查到的”。他们遇到问题时，会： 搜索问题：查找类似场景的解决方案。 评估方案：根据实际需求选择合适的库或框架。 搜索时的技巧： 用精准关键词，比如“Go JWT authentication package”。 看社区推荐，比如 Stack Overflow、Reddit、GitHub 等。 你可以这样做： 当不知道用哪个包时，搜索类似场景的关键词，看看其他开发者用了什么库。 慢慢熟悉常用的社区推荐来源，比如： Awesome Go：列出了 Go 的优秀库。 Go Packages：Go 的官方包文档和搜索平台。 4. 理解需求，选择工具 博主并不是“盲选”包，而是基于需求选工具。 例如：需要读取配置文件，就会选择支持多种格式的 viper。 需要快速搭建 Web 服务框架，就会用 gin 或 echo。 你可以这样做： 学会分析问题：问自己——“这个问题需要解决什么？”“有没有原生支持？” 学会看库文档： 比如，在 GitHub 项目中，看 ReadMe 和示例代码，理解库的功能。 5. 你的问题如何转换为实践 明确目标：先理解你要解决的问题，比如“实现一个 JWT 登录功能”。 学习思路：看看博主怎么解决的，模仿过程并分析他们选择的工具是否合理。 尝试自己实现：不要依赖博主的方案，尝试用其他库或者原生代码实现。 总结：知识的形成是一个积累过程博主看似“知道一切”，实际上是基于： 经验积累：长期的项目经验让他们知道常用包。 良好工具链：对语言生态了解，知道优秀的社区推荐。 高效搜索：遇到新问题时，他们可以快速找到解决方案。 行动建议： 多积累项目经验，模仿优秀代码，逐渐形成自己的“工具箱”。 学会分解问题和尝试不同工具，在实践中找到更适合的解决方案。坚持下去，你也会越来越“有经验”！ 😊","categories":[{"name":"困惑","slug":"困惑","permalink":"https://whuichenggong.github.io/categories/%E5%9B%B0%E6%83%91/"}],"tags":[]},{"title":"理解鉴权，权限等名词的区别","slug":"技术分享/authority","date":"2024-12-07T09:13:14.230Z","updated":"2025-05-11T07:20:03.572Z","comments":true,"path":"2024/12/07/技术分享/authority/","permalink":"https://whuichenggong.github.io/2024/12/07/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/authority/","excerpt":"","text":"GPT很好的给出了答案问： 用户通过了身份验证，但是不具有访问资源所需的权限。 这句话我应该怎么理解，我还有的疑惑是Cookie，Token，鉴权，权限等这几个名词都是什么意思，我现在对他们的理解有点模糊 答： 这些概念是 Web 安全和权限管理的核心部分。让我们分两步：先理解句子的含义，再深入解析相关概念（Cookie、Token、鉴权、权限等）。 1. 句子的含义 “用户通过了身份验证，但是不具有访问资源所需的权限。” 这句话分为两个阶段： 身份验证（Authentication）：系统确认了用户的身份（比如你用正确的用户名和密码登录）。 说明：你确实是你声称的那个人。 类比：这就像进入公司时，你刷卡证明你是公司的员工。 权限检查（Authorization）：系统检查用户是否有权访问某些特定资源。 说明：通过身份验证并不代表你可以访问所有东西。例如： 普通用户可能无法访问管理员界面。 销售部门员工可能无法查看财务报表。 类比：在公司内部，即使你刷卡进门，也可能需要额外权限才能进入某些区域（比如机房）。 总结：身份验证是“你是谁”，权限检查是“你是否被允许做某件事”。通过身份验证 ≠ 获得所有权限。 2. 概念解析(1) Cookie 定义：一种小型数据，存储在用户浏览器中，由服务器生成，用来记录用户的会话状态或其他信息。 用途： 会话管理：比如记录你是否已登录。 个性化：比如保存语言设置。 追踪：用于广告和分析。 类比：Cookie 就像一个身份证明牌，浏览器每次请求时带上它，服务器根据这个证明牌识别你的身份。 (2) Token 定义：类似于数字化的通行证，通常由服务器生成并发放给用户，用户每次请求时带上 Token，证明自己已通过身份验证。 常见类型： **JWT (JSON Web Token)**：一种格式化的 Token，常用于现代 Web 应用。 区别于 Cookie： Cookie 是浏览器特有的存储机制，而 Token 是一个通用的凭证。 Cookie 通常自动附加在请求中，Token 需要开发者手动附加（如放在请求头中）。 类比：Token 就像一个“通行证”，你需要用它向服务器证明你有访问权限。 (3) 鉴权 定义：确定用户是否具有访问资源或执行操作的权限。 过程： 用户发起请求时，系统会验证用户提供的凭证（比如 Token 或 Cookie）。 系统根据用户的角色、组或策略，判断是否允许操作。 类比：鉴权就像安保检查，你拿着门卡，安保会检查你的权限，决定你是否可以进入某些区域。 (4) 权限 定义：指用户被允许执行的操作范围或访问的资源类型。 示例： 读权限：允许查看文件内容。 写权限：允许修改文件内容。 管理权限：允许管理其他用户。 类比：权限就像不同的钥匙，钥匙决定了你能打开哪些门。 3. 总结关系和区别 Cookie：存储用户会话信息，让服务器识别用户是谁。 Token：携带用户身份信息，用于证明用户已通过身份验证。 鉴权：判断用户是否有权访问特定资源。 权限：用户可以做的事情或访问的资源范围。 4. 一个完整的例子 用户访问网站，输入用户名和密码（身份验证）。 服务器验证用户名和密码正确，生成一个 Token 返回给用户。 Token 或者对应的 Session ID 会存储在用户的 Cookie 中。 用户请求资源时，浏览器自动带上 Cookie（或你自己带上 Token）。 服务器接收到请求后，验证 Token 或 Cookie 的合法性。 服务器检查权限（鉴权）。 如果你有权限，资源返回给你。 如果你没有权限，服务器返回 “403 Forbidden”。 你可以将这些过程看成一道流水线：身份验证 -&gt; 带凭证发请求 -&gt; 权限检查 -&gt; 返回结果。 就是我是 赵忠鹤 检查 赵忠鹤是不是有权限访问这个内容，大体就是这个意思","categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://whuichenggong.github.io/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"}],"tags":[]},{"title":"json的序列化与反序列化","slug":"go/serialize","date":"2024-12-06T09:21:57.665Z","updated":"2025-05-11T07:17:59.356Z","comments":true,"path":"2024/12/06/go/serialize/","permalink":"https://whuichenggong.github.io/2024/12/06/go/serialize/","excerpt":"","text":"序列化：将 Go 中的结构体、切片、map 等数据结构转换为 JSON 格式的字符串。 作用：方便数据在网络传输、文件保存等情境中使用。 反序列化：将 JSON 格式的字符串转换为 Go 的数据结构。 作用：方便从 JSON 中提取数据并在程序中使用。 JSON{“”： “”，“”： “”，“”： “”} Go中 使用 Marshal Unmarshal 进行序列化和反序列化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot;)type Person struct &#123; Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;`&#125;func main() &#123; p := Person&#123;Name: &quot;Alice&quot;, Age: 25&#125; // 序列化为 JSON jsonData, err := json.Marshal(p) if err != nil &#123; fmt.Println(&quot;Error:&quot;, err) return &#125; fmt.Println(string(jsonData)) // 输出: &#123;&quot;name&quot;:&quot;Alice&quot;,&quot;age&quot;:25&#125;&#125;---&#125;package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot;)type Person struct &#123; Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;`&#125;func main() &#123; jsonData := `&#123;&quot;name&quot;:&quot;Alice&quot;,&quot;age&quot;:25&#125;` var p Person // 反序列化为结构体 err := json.Unmarshal([]byte(jsonData), &amp;p) if err != nil &#123; fmt.Println(&quot;Error:&quot;, err) return &#125; fmt.Println(p.Name, p.Age) // 输出: Alice 25&#125; 类比一下进程间管道通信：在父子进程使用管道进行通信时，数据通常以字节流的形式传输。要传递复杂数据结构，需要将数据转换为字节流（序列化），并在另一端解析回来（反序列化）。 GO中实现 字符进程通信 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;os&quot;)type Message struct &#123; Content string `json:&quot;content&quot;`&#125;func main() &#123; r, w, err := os.Pipe() // 创建管道 if err != nil &#123; fmt.Println(&quot;Error creating pipe:&quot;, err) return &#125; if os.Getenv(&quot;IS_CHILD&quot;) == &quot;1&quot; &#123; // 子进程逻辑 r.Close() // 关闭写端 var msg Message decoder := json.NewDecoder(r) if err := decoder.Decode(&amp;msg); err != nil &#123; fmt.Println(&quot;Error decoding:&quot;, err) return &#125; fmt.Println(&quot;Child received:&quot;, msg.Content) &#125; else &#123; // 父进程逻辑 w.Close() // 关闭读端 cmd := os.Exec(os.Args[0], os.Args, os.Environ()) cmd.Env = append(os.Environ(), &quot;IS_CHILD=1&quot;) go func() &#123; encoder := json.NewEncoder(w) encoder.Encode(Message&#123;Content: &quot;Hello, Child!&quot;&#125;) &#125;() cmd.Wait() &#125;&#125;","categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"}],"tags":[]},{"title":"Go语法学习","slug":"go/Go_Program","date":"2024-12-02T06:10:19.416Z","updated":"2025-05-11T07:12:06.544Z","comments":true,"path":"2024/12/02/go/Go_Program/","permalink":"https://whuichenggong.github.io/2024/12/02/go/Go_Program/","excerpt":"","text":"12345678910111213whatAmI := func(i interface&#123;&#125;) &#123; switch t := i.(type) &#123; case bool: fmt.Println(&quot;I&#x27;m a bool&quot;) case int: fmt.Println(&quot;I&#x27;m an int&quot;) default: fmt.Printf(&quot;Don&#x27;t know type %T\\n&quot;, t) &#125;&#125;whatAmI(true)whatAmI(1)whatAmI(&quot;hey&quot;) 这是一个函数whatAmI，它接受一个interface{}类型的参数。interface{}是 Go 语言中的一种空接口，可以存储任何类型的值。这个switch语句实际上是一个类型switch，它检查接口变量i的具体类型，而不是它的值。根据i的类型，switch将执行不同的case分支。 1234// If you specify the index with `:`, the elements in // between will be zeroed. b = [...]int&#123;100, 3: 400, 500&#125; fmt.Println(&quot;idx:&quot;, b) 3: 400 指定了下标为 3 的位置的值是 400。这意味着索引 1 和 2 的值将被初始化为 0（因为:操作符指定了一个新的下标，并初始化之前未指定的下标对应的元素为 0）。 12var s []string fmt.Println(&quot;uninit:&quot;, s, s == nil, len(s) == 0) uninit: [] true true 12345678910twoD := make([][]int, 3) for i := 0; i &lt; 3; i++ &#123; innerLen := i + 1 twoD[i] = make([]int, innerLen) for j := 0; j &lt; innerLen; j++ &#123; twoD[i][j] = i + j &#125; &#125; fmt.Println(&quot;2d: &quot;, twoD)&#125; 2d: [[0] [1 2] [2 3 4]] 12.3日 map操作： 123456789101112 m[&quot;k1&quot;] = 7m[&quot;k2&quot;] = 13fmt.Println(&quot;map:&quot;, m)fmt.Println(&quot;len:&quot;, len(m))//clear(m)val, prs := m[&quot;k2&quot;] //k2的值， 一个是判断k2是否存在于m中的bool值fmt.Println(&quot;val：&quot;, val, &quot;prs:&quot;, prs)n := map[string]int&#123;&quot;foo&quot;: 1, &quot;bar&quot;: 2&#125;fmt.Println(&quot;&quot;, n)if maps.Equal(n, n2) &#123; fmt.Println(&quot;n == n2&quot;)&#125; 使用变长参数函数（variadic function），即可以接收任意数量参数的函数。这里的 … 标记表示 nums 参数是可变长的，可以接收零个或多个 int 类型的参数 nums 被当作切片使用，可以进行切片相关的操作，例如使用 len(nums) 获取长度，或者用 range 遍历切片元素。 12345678910111213141516171819202122232425262728func sum(nums ...int) &#123; fmt.Print(nums, &quot; &quot;) total := 0 // Within the function, the type of `nums` is // equivalent to `[]int`. We can call `len(nums)`, // iterate over it with `range`, etc. for _, num := range nums &#123; total += num &#125; fmt.Println(total)&#125;func main() &#123; // Variadic functions can be called in the usual way // with individual arguments. sum(1) sum(1, 2) sum(1, 2, 3) // If you already have multiple args in a slice, // apply them to a variadic function using // `func(slice...)` like this. //第二种调用nums的方法使用 nums 切片，通过 sum(nums...) 的方式将切片中的每个元素作为单独的参数传递给 sum 函数。 nums := []int&#123;1, 2, 3, 4&#125; sum(nums...)&#125; 错误示范 123456789101112func allArticles(w http.ResponseWriter, r *http.Request) &#123; articles := Articles&#123; Title: &quot;Test Title&quot;, Desc: &quot;Test Descrption&quot;, Content: &quot;hello world&quot;, &#125;,fmt.Println(&quot;endpoint hit: allArticles&quot;) json.NewEncoder(w).Encode(articles)&#125; 这里的问题是 Articles 类型实际上是一个切片（[]Article），而你试图将一个单独的 Article 结构体实例赋值给 articles 变量。根据 Go 语言的语法，Articles 类型需要的是一个 Article 类型的切片。 要解决这个问题，你需要将 Article 实例放入一个切片中。可以将你的代码修改为： 123456789101112articles := Articles&#123;&#123;Title: &quot;Test Title&quot;,Desc: &quot;Test Descrption&quot;,Content: &quot;hello world&quot;,&#125;,&#125;CopyInsert这里的修改是把 Article 结构体实例用 &#123;&#125; 包围起来，表示这是一个切片中的一个元素。最终的 allArticles 函数应如下所示： 第二种方法： 123456789// 创建Article的实例 newArticle := Article&#123; Title: &quot;Test Title&quot;, Desc: &quot;Test Description&quot;, Content: &quot;hello world&quot;, &#125; // 创建Articles切片并添加上面的实例 articles := Articles&#123;newArticle&#125; go fmt 包的导入者将使用名称来引用其内容，因此包中的导出名称可以使用该事实来避免重复。 （不要使用 import . 表示法，它可以简化必须在正在测试的包外部运行的测试，但应该避免。）例如，bufio 包中的缓冲读取器类型称为 Reader，而不是 BufReader，因为用户将其视为 bufio.Reader，这是一个清晰、简洁的名称。此外，由于导入的实体始终使用其包名称进行寻址，因此 bufio.Reader 不会与 io.Reader 冲突。类似地，创建ring.Ring新实例的函数（Go中构造函数的定义）通常被称为NewRing，但由于Ring是包导出的唯一类型，并且由于包被称为ring，所以它是称为“New”，包的客户端将其视为“ring.New”。使用包结构来帮助您选择好的名称。 另一个简短的例子是once.Do; Once.Do(setup) 读起来很好，并且不会通过编写 Once.DoOrWaitUntilDone(setup) 来改进。长名称不会自动使内容更具可读性。有用的文档注释通常比超长的名称更有价值。 闭包1234567func intSeq() func() int &#123; i := 0 // i 是一个局部变量，用于 intSeq 函数。 return func() int &#123; // 返回一个匿名函数，这个函数可以访问 intSeq 函数的局部变量 i。 i++ // 每次调用这个匿名函数时，i 的值都会增加。 return i // 返回增加后的 i 的值。 &#125;&#125; 返回结果 ：1231 这是因为闭包允许匿名函数捕获并记住 i 变量的状态。这就是闭包的 “魔力” 所在，即使外部函数已经返回，内部函数仍然能够访问和修改外部函数的变量。 stack :&#x3D; []rune{} 与 make :&#x3D; []string{} 的区别：stack :&#x3D; []rune{}：这段代码创建了一个 rune 类型的切片（空切片）。rune 是 Go 中专门用来表示单个字符的类型，适用于你处理字符（尤其是 Unicode 字符）时，能够确保每个元素是一个完整的 Unicode 字符。 make :&#x3D; []string{}：这段代码创建了一个 string 类型的切片。每个元素是一个字符串，字符串通常用于表示一系列字符构成的文本数据。 在 Go 程序中，通过 os.Args 可以访问命令行参数，而 go run main.go file1.txt file2.txt 的执行过程如下： 为什么·go语言 &gt; go run main.go file1.txt file2.txt 在这里执行之后可以读取到文件1 2 1. 命令行参数的解析 命令： go run main.go file1.txt file2.txt go run 会编译并执行 main.go。 命令行中，main.go 后面的 file1.txt 和 file2.txt 被传递给程序作为命令行参数。 在程序中，os.Args 是一个字符串切片（[]string），包含了命令行中的参数： 123os.Args[0] // 包含程序的名字，如 &quot;main.go&quot;os.Args[1] // 第一个参数 &quot;file1.txt&quot;os.Args[2] // 第二个参数 &quot;file2.txt&quot; 例子：假如命令为： 1go run main.go file1.txt file2.txt 则： 1fmt.Println(os.Args) 输出： 1[main file1.txt file2.txt] 2. 打开文件进行读取你的代码解析命令行参数后，会尝试打开这些文件： 1files := os.Args[1:] // 获取命令行参数列表（除程序本身外的部分） files 现在是一个切片：[&quot;file1.txt&quot;, &quot;file2.txt&quot;]。 然后通过循环处理每个文件： 123456789for _, arg := range files &#123; f, err := os.Open(arg) // 打开文件 if err != nil &#123; fmt.Fprintf(os.Stderr, &quot;dup2: %v\\n&quot;, err) // 错误处理 continue &#125; defer f.Close() // 确保文件被正确关闭 countLines(f, counts)&#125; 这段代码中： **os.Open(arg)**： 打开文件（如 file1.txt），返回一个文件指针 *os.File。 如果文件打开失败（文件不存在或权限问题），返回错误并跳过。 **countLines(f, counts)**： 将文件指针传递给 countLines，扫描文件的内容并统计每行的出现次数。 3. 执行结果的输出统计完成后，程序会输出所有出现次数大于 1 的行： 12345for line, n := range counts &#123; if n &gt; 1 &#123; fmt.Printf(&quot;%d\\t%s\\n&quot;, n, line) &#125;&#125; 这会将文件中所有重复的行及其出现次数打印到控制台。 4. 为什么能够读取多个文件这是因为你的代码通过 for _, arg := files 遍历了 os.Args[1:] 中的所有文件，并依次处理它们。程序对每个文件重复以下流程： 打开文件。 按行扫描内容，统计出现次数。 将结果合并到 counts 映射中。 这样，即使你提供多个文件，程序依然可以逐个读取并处理它们。 运行流程示例假设有以下文件内容： file1.txt:123helloworldhello file2.txt:123worldhellogo 执行命令： 1go run main.go file1.txt file2.txt 程序会： 读取 file1.txt： 统计结果：&#123;&quot;hello&quot;: 2, &quot;world&quot;: 1&#125;。 读取 file2.txt，继续更新 counts： 最终统计结果：&#123;&quot;hello&quot;: 3, &quot;world&quot;: 2, &quot;go&quot;: 1&#125;。 打印重复行：123 hello2 world 总结你可以读取多个文件是因为程序通过 os.Args 获取了命令行中的文件名列表，并通过循环逐个打开和读取文件的内容。这种设计使得你的程序能够动态处理任意数量的文件，而无需修改代码。 12.14 日 更考完4级一.Errors “errors” 包 使用给定的错误消息构造一个基本错误值。 errors.New(“can’t work with 42”) nil 表示没有错误 哨兵错误是一个预先声明的变量，用于表示特定的错误情况。 var ErrOutOfTea &#x3D; fmt.Errorf(“no more tea available”)var ErrPower &#x3D; fmt.Errorf(“can’t boil water”) 更高级别的错误来包装错误以添加上下文 最简单的方法是使用 fmt.Errorf 中的 %w 动词。包装错误创建一个逻辑链（A 包装 B，B 包装 C 等），可以使用 error.Is 和 error.As 等函数进行查询。 return fmt.Errorf(“making tea: %w”, ErrPower) if 行中使用内联错误检查 if r, e :&#x3D; f(i); e !&#x3D; nil {fmt.Println(“f failed:”, e)} else {fmt.Println(“f worked:”, r)} error.Is 检查给定错误（或其链中的任何错误）是否与特定错误值匹配。 if errors.Is(err, ErrOutOfTea) {fmt.Println(“We should buy new tea!”)} else if errors.Is(err, ErrPower) {fmt.Println(“Now it is dark.”)} else {fmt.Printf(“unknown error: %s\\n”, err)} 将err和我们自定义的哨兵错误或者特定错误做对比 二.自定义错误 12345678910type argError struct &#123; arg int message string&#125;func (e *argError) Error() string &#123; return fmt.Sprintf(&quot;%d - %s&quot;, e.arg, e.message)&#125; Error 方法并没有直接调用，但 &amp;argError{arg, “can’t work with it”} 被返回为 error 类型时，Error 方法已经在幕后实现了对错误消息的封装。 error.As 是errors.Is 的更高级版本。它检查给定错误（或其链中的任何错误）是否与特定错误类型匹配，并转换为该类型的值，返回 true。如果没有匹配，则返回 false。 Goroutines轻量级的执行线程 go f(s)。这个新的 goroutine 将与调用的 goroutine 同时执行。 12345678func f(from string) &#123; for i := 0; i &lt; 3; i++ &#123; fmt.Println(from, &quot;:&quot;, i) &#125;&#125; go f(&quot;goroutine&quot;) 启动一个 goroutine 来进行匿名函数调用。 123go func(msg string) &#123; fmt.Println(msg) &#125;(&quot;going&quot;) goroutine 是由 Go 运行时同时运行的。 通道通道是连接并发 goroutine 的管道。您可以将值从一个 Goroutine 发送到通道，并将这些值接收到另一个 Goroutine。 messages :&#x3D; make(chan string) 通道 &lt;- 语法将值发送到通道 go func() { messages &lt;- “ping” }() msg :&#x3D; &lt;-messages &lt;-channel 语法从通道接收值。在这里，我们将收到上面发送的“ping”消息并将其打印出来。 发送和接收会阻塞，直到发送者和接收者都准备好为止。此属性允许我们在程序结束时等待“ping”消息，而无需使用任何其他同步。 通道缓冲： messages :&#x3D; make(chan string, 2) 字符串通道，最多缓冲 2 个值 因此我们可以将这些值发送到通道中，而无需相应的并发接收。 12345678 messages := make(chan string, 2)messages &lt;- &quot;buffered&quot;messages &lt;- &quot;channel&quot; fmt.Println(&lt;-messages) fmt.Println(&lt;-messages) 断言和switch用法:1234567891011121314var t interface&#123;&#125;t = functionOfSomeType()switch t := t.(type) &#123;default: fmt.Printf(&quot;unexpected type %T\\n&quot;, t) // %T prints whatever type t hascase bool: fmt.Printf(&quot;boolean %t\\n&quot;, t) // t has type boolcase int: fmt.Printf(&quot;integer %d\\n&quot;, t) // t has type intcase *bool: fmt.Printf(&quot;pointer to boolean %t\\n&quot;, *t) // t has type *boolcase *int: fmt.Printf(&quot;pointer to integer %d\\n&quot;, *t) // t has type *int&#125; 类型断言用于从接口类型值中提取其底层的具体类型。如果断言成功，程序可以安全地将该接口值转换为目标类型并使用。 value, ok :&#x3D; x.(T) x 是一个接口类型的变量。T 是目标类型（可以是具体类型或其他接口类型）。如果 x 的动态类型是 T：value 是 x 转换为 T 后的值。ok 为 true。如果 x 的动态类型不是 T：value 是 T 的零值。ok 为 false，表示断言失败。 12345678var x interface&#123;&#125; = 42 // 空接口存储了一个 int 值value, ok := x.(int) // 断言 x 是 int 类型if ok &#123; fmt.Printf(&quot;x is an int, value: %d\\n&quot;, value)&#125; else &#123; fmt.Println(&quot;x is not an int&quot;)&#125; 空interface空interface(interface{})不包含任何的method，正因为如此，所有的类型都实现了空interface。空interface对于描述起不到任何的作用(因为它不包含任何的method），但是空interface在我们需要存储任意类型的数值的时候相当有用，因为它可以存储任意类型的数值。它有点类似于C语言的void*类型。 1234567// 定义a为空接口var a interface&#123;&#125;var i int = 5s := &quot;Hello world&quot;// a可以存储任意类型的数值a = ia = s 一个函数把interface{}作为参数，那么他可以接受任意类型的值作为参数，如果一个函数返回interface{},那么也就可以返回任意类型的值。是不是很有用啊！ Go并发","categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"}],"tags":[{"name":"Go语法","slug":"Go语法","permalink":"https://whuichenggong.github.io/tags/Go%E8%AF%AD%E6%B3%95/"}]},{"title":"小计划","slug":"技术分享/study_plan","date":"2024-12-02T02:47:34.759Z","updated":"2025-05-11T07:13:57.138Z","comments":true,"path":"2024/12/02/技术分享/study_plan/","permalink":"https://whuichenggong.github.io/2024/12/02/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/study_plan/","excerpt":"","text":"兄弟，你的想法很清晰，我非常理解你想深入学习、夯实基础，而不是走捷径的决心。我们可以针对你的目标和现状制定一个更加实践导向的计划，同时保持学习过程有趣且充实。以下是我的建议和方案： 总体目标 短期（2025年3月前）：增强银行项目的实用性和技术深度，掌握后端开发的核心技能，为实习做好准备。 中长期（未来两年）：夯实计算机基础，深入理解系统设计、分布式系统及核心算法，逐步具备独立设计和开发复杂项目的能力。 学习模块规划1. 项目深度增强（每周一个主题，贯穿整个学习计划）目标：将现有银行项目提升到更贴近实际业务需求的水平，增加亮点功能。 Week 1: 数据一致性与事务 学习事务隔离级别（ACID），在项目中实现更加复杂的转账操作（如跨账户冻结和解冻）。 使用 SQLC 或 GORM，优化数据库操作。 Week 2: 引入 Redis 学习 Redis 基础知识，理解其在缓存和分布式锁中的应用。 在项目中实现： 用户信息缓存，优化频繁查询。 基于 Redis 的幂等性控制（防止转账操作重复）。 Week 3: RESTful API 和 JWT 身份验证 深化对 RESTful API 的理解，优化项目 API 设计。 引入 JWT 实现用户登录认证和权限管理。 Week 4: 日志和监控 集成日志框架（如 Logrus&#x2F;Zap），记录系统操作。 学习 Prometheus 基础知识，为项目添加简单监控。 Week 5: Docker 和部署优化 使用 Docker Compose 部署完整项目，模拟生产环境。 学习 Nginx 基础知识，优化项目访问流程。 Week 6: 微服务化 学习 Go 微服务框架（如 Gin、gRPC）。 将项目拆分成两个服务（如用户服务和交易服务），理解微服务架构基础。 2. 算法与数据结构（每天一题，逐渐深入）目标：构建扎实的算法基础，为今后面试和实际开发做准备。 题目选择顺序：简单 -&gt; 中等 -&gt; 困难，优先 BFS&#x2F;DFS、二分查找、动态规划等重要领域。 周主题： Week 1-2: 栈、队列、链表 Week 3-4: 二叉树与递归 Week 5-6: 动态规划与分治算法 Week 7+: 高频面试题复盘（重点记录和总结常见套路）。 3. 计算机基础与原理（每周一本书&#x2F;主题）目标：夯实后端开发的计算机科学基础。 Week 1: 计算机网络 阅读《计算机网络：自顶向下方法》或《图解HTTP》。 重点学习 HTTP、HTTPS、TCP&#x2F;IP 的工作原理，并理解抓包工具（如 Wireshark）的使用。 Week 2: 操作系统 阅读《现代操作系统》。 理解线程、进程、同步机制，以及如何在 Go 中实现简单的并发处理。 Week 3-4: 数据库系统 阅读《数据库系统概念》。 理解索引、事务原理、查询优化等内容。 Week 5: 系统设计 阅读《系统设计入门》或相关博客。 学习常见系统设计模式（如限流、负载均衡）和架构决策。 具体每日安排（样例） 上午： 刷一道 LeetCode 算法题，阅读相关解析，整理题解。 学习书籍相关章节，完成1-2页的读书笔记。 下午： 按周主题在银行项目中完成对应功能开发。 查看官方文档、博客或视频教程，记录学习中的关键点。 晚上： 复习当天内容，整理代码和笔记。 自测项目功能，尝试优化代码。 可实践性建议 建立个人技术博客：把每天的学习记录写成博客或日志，比如讲解项目中 Redis 的用法或总结某道算法题的思路。 参与开源项目：找一个简单的 Go 开源项目，阅读代码，尝试修复 bug 或贡献文档。 模拟面试：每两周自测一次，将银行项目作为核心，讲解架构设计和亮点功能。 最终成果展示 一个高度完善的银行项目： 支持分布式事务、JWT 身份验证、Redis 缓存与微服务架构。 提供完善的 Docker 部署文档。 一个 LeetCode 高质量题解库（至少 50 道题）。 一份扎实的基础知识笔记，涵盖网络、操作系统和数据库。 引入项目技术栈（2周）：在新项目中加入 SQLC 工具、中间件，理解每个技术的接入过程。 实现进阶功能（3周）：根据银行项目的转账逻辑，尝试自己独立实现一次。 重点学习 HTTP 和 RESTful API。 深入理解数据库 深入理解数据库 熟悉中间件的实现逻辑 Web开发 Go by example 三本书 两个项目 Memos Apache Answer 算法 gin-gonic.com 微服务进阶 gRPC","categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://whuichenggong.github.io/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"}],"tags":[]},{"title":"11.26日字节直播总结","slug":"技术分享/Dance_live2","date":"2024-11-26T12:20:49.917Z","updated":"2025-05-11T07:13:53.172Z","comments":true,"path":"2024/11/26/技术分享/Dance_live2/","permalink":"https://whuichenggong.github.io/2024/11/26/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/Dance_live2/","excerpt":"","text":"字节结营直播答疑revue 项目 性能优化 ci&#x2F;cd流程 （ star法则来描述一件事情) 准备找实习 写好简历 zt： 服务端： 计算机基础知识（字节：计算机网络 tcp&#x2F;ip 腾讯：操作系统 阿里： 组成原理） 技术： （数据结构 高阶算法 链表 堆栈 树（面试重点）） leetcode 100 150 200 项目： 烂大街的（入门） 改进一些项目（做优化 项目存在的意义 解决了什么问题？ 带来了什么？ 项目亮点在哪里） 实习经历：（做了什么需求 需求是（谁给的 自己还是别人？）通过实现了什么？ 解决了什么？ 团队收益还是小组收益？） 专业能力： 小厂一门语言 ＋数据库存储 会就ok 大数据 架构数据 微服务层面 八股扎实稳固 算法 中等难度题很快弄出来 项目亮点：能让面试官和你聊下去 如何提升亮点和竞争力 开源社区！ 抄项目 然后手写 尝试自己理解 前端（vue）（react） 数据结构 计算机基础知识 面试官想看你的亮点（你牛逼在哪里？） 做过什么会什么？ 服务端是一些思维 而不是纠结你是用什么语言 从0-1 有没有调研 各行各业的优秀作业 合作项目 责任意识 技术探索：遇到什么问题 怎么解决的？ 业务理解能力 项目受众是谁 项目模块 最重要是哪个模块 怎么优化这个模块 12“开源社区新手入门该参与什么内容，有哪些社区比较活跃”可以看看类似于开源之夏这类的活动往年都是做什么的 多逛github 12“在github中新手怎么找项目”，你用vue就去看VUE文档仓库，看看有没有错别字，有的话修一下 项目的含金量 和自己从0-1实现 组件多 中间件多 新奇的做法等 可以被称为含金量（） 核心能力 技术深度 在广度的前提下 一定要有一个深度 项目一样 面试官能问什么？ 12老哥们 大二第一次找实习的话一般要什么程度我正在跟着别人做一个项目 但是不知道什么时候才够格去投简历”看看面经别人被问了什么你能不能回答 平地起项目 是有条件的： 大厂实习 项目经历&gt;&#x3D;3 等经历 否则不要平地起 对于项目的理解一定是从头到尾的 对项目改造 新增功能 优化 才能体现你的亮点 思考 ： 多人协作是否有沟通 是否涉及复杂逻辑 新颖的想法！ 创造力！ 投简历的方式 如何面对八股 算法 找开源项目：熟悉流程 寻找错别字熟悉流程哈哈哈 看issue bug（解决issue） 知乎 蔚来 比亚迪 从小厂到大厂 循序渐进 字节 99%go 语言是基础无所谓 培养独立解决问题的能力 做出一个合格的项目 （不断回顾自己的项目 查找不足） 后端开发实习生（简历） 数据库的课（掘金的） 《Redis深度历险：核心原理和应用实践》 服务端开源： 不建议新手就去找开源 学习成本很大 2~3段实习之后尝试开源 知名项目源码： 前提一定要熟悉使用这个项目的源码 项目的使用环境 如何启动它 例如：熟练使用docker ， kubernets istio了，再去看源码 i 写出一个对源码理解的文章 对于源码：一步一步慢慢来 该学的东西就学 不要纠结没用的例如学历 没法改变就不去改变 .md .sh 依赖那些中间件 中间件是否具备？ 如何去不使用中间件如何启动这个项目 分析目录结构（单体 还是微服务）包的作用 模块之间的耦合关系 利用isue 项目常见报错解决方式 组队开发的群聊看看能不能找到","categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://whuichenggong.github.io/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"}],"tags":[]},{"title":"UDP socket的ack机制和丢包重传","slug":"backend/UDP_socket","date":"2024-11-23T09:15:42.999Z","updated":"2025-05-11T07:20:03.583Z","comments":true,"path":"2024/11/23/backend/UDP_socket/","permalink":"https://whuichenggong.github.io/2024/11/23/backend/UDP_socket/","excerpt":"","text":"参考连接： https://juejin.cn/post/7263378772040122429 Go语言实现UDP socket的ack机制和丢包重传UDP 在通讯之前不需要建立连接 可以直接发送数据包 是一种无连接协议（常用于音视频传输） 但是在有些场景 即需要UDP传输也需要向TCP一样（TCP的可靠传输） 解决丢包问题： 1.添加 seq&#x2F;ack机制 确保数据发送到对端 什么是 seq&#x2F;ack机制 123456789101112131415在TCP（传输控制协议）中，序号（Sequence Number，简称seq）和确认应答号（Acknowledgment Number，简称ack）是协议头部非常关键的字段，它们共同确保了TCP的可靠性和数据按顺序传输的特性。** Sequence Number **含义：序号是指一个TCP报文段中第一个字节的数据序列标识。它表示在一个TCP连接中，该报文段所携带的数据的开始位置。序号是用来保证数据传输的顺序性和完整性的。作用：在TCP连接建立时，双方各自随机选择一个初始序列号（ISN）。随后传输的每个报文段的序号将基于这个初始值递增，其增量为该报文段所携带的数据量（字节数）。通过这种方式，接收方可以根据序号重组乱序到达的数据片段，确保数据的正确顺序和完整性。如果接收到的报文段不连续，接收方可以通过TCP的重传机制请求发送方重新发送缺失的数据。**Acknowledgment Number**含义：确认应答号是接收方期望从发送方接收到的下一个报文段的序号。它实质上是接收方告诉发送方：“我已经成功接收到了哪个序号之前的所有数据，请从这个序号开始发送后续的数据。”作用：确认应答号用于实现可靠性传输。当一个报文段被接收方正确接收时，接收方会发送一个ACK报文，其中包含的确认应答号是接收到的数据加上1（即接收方期望接收的下一个数据的序号）。通过检查这个确认应答号，发送方能够知道其发送的数据是否已被接收方正确接收，并据此决定是否需要重传某些数据段。 ack和seq 保证了： 确保数据的顺序性：即使数据片段在网络中的传输过程中顺序被打乱，接收方也能根据序号正确地重组这些数据。 检测丢包：如果发送方发送的数据长时间未被确认（即没有收到对应的ACK报文），它会判断这些数据可能已丢失，并将其重新发送。 实现流量控制和拥塞控制：通过调整发送未被确认数据的量（即控制窗口大小），TCP可以根据网络条件动态调整数据发送的速率，避免网络拥塞。 Golang的socket编程：Go语言通过标准库中的net包来实现UDP和TCP的socket编程。net包提供了用于创建和管理网络连接的函数，以及用于进行数据传输的相关类型和方法，不同于C++需要手动设置和管理socket API，不论实现UDP还是TCP都可以直接使用封装好的方法进行操作，大大简化了socket编程： 使用net包实现UDP通信1.client.go1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;net&quot; &quot;os&quot;)func main() &#123; // 创建UDP连接到服务器的地址和端口号 c, err := net.DialUDP(&quot;udp&quot;, nil, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Println(&quot;dial err: %v\\n&quot;, err) return &#125; defer c.Close() // 将 defer 放在 if 语句外面 // 从标准输入读取用户输入的数据 input := bufio.NewReader(os.Stdin) for &#123; // 读取用户输入知道遇见换行符 s, err := input.ReadString(&#x27;\\n&#x27;) if err != nil &#123; fmt.Printf(&quot;read from stdin failed, err: %v\\n&quot;, err) return &#125; // 将用户输入的数据转换为字节数组并通过UDP连接发送给服务器 _, err = c.Write([]byte(s)) if err != nil &#123; fmt.Printf(&quot;send to server failed, err: %v\\n&quot;, err) return &#125; // 接收来自服务器的数据 var buf [1024]byte n, addr, err := c.ReadFromUDP(buf[:]) if err != nil &#123; fmt.Printf(&quot;recv from udp failed, err: %v\\n&quot;, err) return &#125; // 打印来自服务器的数据 fmt.Printf(&quot;服务器 %v, 响应数据: %v\\n&quot;, addr, string(buf[:n])) &#125;&#125; 2.server.go首先创建UDP监听器监听指定IP和端口，等待连接客户端，连接后会读取客户端发来的数据并打印收到的数据，并将接收的响应信息返回发送给客户端，使用死循环使其能够持续获取客户端数据，同样实现了UDP的数据接收和发送，实现了简单的UDP服务器； 1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( &quot;fmt&quot; &quot;net&quot;)// udp serverfunc main() &#123; // 创建一个UDP监听器，监听本地IP地址的端口 listen, err := net.ListenUDP(&quot;udp&quot;, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;listen failed,err:%v\\n&quot;, err) return &#125; defer listen.Close() for &#123; var buf [1024]byte // 从UDP连接中读取数据到buf中，n为读取到的字节数，addr为数据发送者的地址 n, addr, err := listen.ReadFromUDP(buf[:]) if err != nil &#123; fmt.Printf(&quot;read from udp failed,err:%v\\n&quot;, err) return &#125; // 打印接收到的数据 fmt.Println(&quot;接收到的数据：&quot;, string(buf[:n])) // 将接收到的数据原样发送回给数据发送者 _, err = listen.WriteToUDP(buf[:n], addr) if err != nil &#123; fmt.Printf(&quot;write to %v failed,err:%v\\n&quot;, addr, err) return &#125; &#125;&#125; 效果：（好有趣） 12345678&gt; go run client.gohello服务器 127.0.0.1:8282, 响应数据: helloworld服务器 127.0.0.1:8282, 响应数据: world 123456 go run server.go接收到的数据： hello接收到的数据： world 基于seq&#x2F;apkclient 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package mainimport ( &quot;fmt&quot; &quot;net&quot; &quot;strconv&quot; &quot;strings&quot; &quot;time&quot;)type Message struct &#123; Seq int Msg string&#125;func main() &#123; c, err := net.DialUDP(&quot;udp&quot;, nil, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;dail err:%v\\n&quot;, err) &#125; defer c.Close() input := []string&#123;&quot;Message1&quot;, &quot;Message2&quot;, &quot;Message3&quot;, &quot;Message4&quot;, &quot;Message5&quot;&#125; seq := 0 for _, msg := range input &#123; seq++ message := Message&#123;Seq: seq, Msg: msg&#125; fmt.Printf(&quot;Sending seq=%d: %s\\n&quot;, message.Seq, message.Msg) // 发送带有序列号的数据包 _, err = c.Write(encodeMessage(message)) if err != nil &#123; fmt.Printf(&quot;send to server failed,err:%v\\n&quot;, err) return &#125; &#125; // 等待ACK，设置超时时间 buf := make([]byte, 1024) c.SetReadDeadline(time.Now().Add(5 * time.Second)) n, _, err := c.ReadFromUDP(buf) if err != nil &#123; fmt.Println(&quot;ACK not received. Timeout or Error.&quot;) return &#125; else &#123; ack := decodeMessage(buf[:n]) if ack.Seq == seq+1 &#123; fmt.Printf(&quot;ACK = %d\\n&quot;, ack.Seq) &#125; else &#123; fmt.Println(&quot;Invalid ACK received. Retry.&quot;) return &#125; &#125;&#125;func encodeMessage(msg Message) []byte &#123; // 将序列号和消息文本编码成字节数据 return []byte(fmt.Sprintf(&quot;%d;%s&quot;, msg.Seq, msg.Msg))&#125;func decodeMessage(data []byte) Message &#123; // 解码收到的数据，提取序列号和消息文本 parts := strings.Split(string(data), &quot;;&quot;) seq, _ := strconv.Atoi(parts[0]) msg := parts[1] return Message&#123;Seq: seq, Msg: msg&#125;&#125; server 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package mainimport ( &quot;fmt&quot; &quot;net&quot; &quot;strconv&quot; &quot;strings&quot;)type Message2 struct &#123; Seq int Msg string&#125;func main() &#123; listen, err := net.ListenUDP(&quot;udp&quot;, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;listen failed,err:%v\\n&quot;, err) return &#125; defer listen.Close() for &#123; var buf [1024]byte n, addr, err := listen.ReadFromUDP(buf[:]) if err != nil &#123; fmt.Printf(&quot;read from udp failed,err:%v\\n&quot;, err) return &#125; // 处理接收到的数据，提取序列号和消息文本 message := decodeMessage1(buf[:n]) fmt.Printf(&quot;Received seq=%d from %v: %s\\n&quot;, message.Seq, addr, message.Msg) // 发送ACK回复给客户端，ACK=Seq+1 ack := Message2&#123;Seq: message.Seq + 1, Msg: &quot;ACK&quot;&#125; _, err = listen.WriteToUDP(encodeMessage1(ack), addr) if err != nil &#123; fmt.Printf(&quot;write to %v failed,err:%v\\n&quot;, addr, err) return &#125; &#125;&#125;func encodeMessage1(msg Message2) []byte &#123; // 将序列号和消息文本编码成字节数据 return []byte(fmt.Sprintf(&quot;%d;%s&quot;, msg.Seq, msg.Msg))&#125;func decodeMessage1(data []byte) Message2 &#123; // 解码收到的数据，提取序列号和消息文本 parts := strings.Split(string(data), &quot;;&quot;) seq, _ := strconv.Atoi(parts[0]) msg := parts[1] return Message2&#123;Seq: seq, Msg: msg&#125;&#125;&#125; 问题核心：在同一文件夹内，Go 默认将所有文件视为同一包的一部分，可能导致重复定义或未定义的错误。推荐解决方法：分文件夹运行。提取共享逻辑到单独的文件。运行时显式指定所有 .go 文件。额外改进：通过参数区分服务端和客户端运行模式，进一步优化程序结构。 ，服务器监听的端口可能是某个固定端口（例如 12345），而客户端的UDP数据包来自 127.0.0.1:59653。这意味着：UDP允许客户端选择任意可用的端口号作为源端口，并将数据包发送到服务器的监听端口。这也是为什么你看到不同的端口号。 4.实现超时重传最简单的方法就是当超时没有收到ack回复或者ack回复错误乱序时，阻塞后续发包，先进行重传，把丢失的包重传后再继续发包，因此主要是在客户端更改一些发包的逻辑，服务端则没有变化； client.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package mainimport ( &quot;fmt&quot; &quot;net&quot; &quot;strconv&quot; &quot;strings&quot; &quot;time&quot;)type Message struct &#123; Seq int Msg string&#125;func main() &#123; c, err := net.DialUDP(&quot;udp&quot;, nil, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;dial,err:%v\\n&quot;, err) return &#125; defer c.Close() // 示例数据 input := []string&#123;&quot;Message 1&quot;, &quot;Message 2&quot;, &quot;Message 3&quot;, &quot;Message 4&quot;, &quot;Message 5&quot;&#125; for seq, msg := range input &#123; for &#123; message := Message&#123;Seq: seq + 1, Msg: msg&#125; fmt.Printf(&quot;Sending seq=%d: %s\\n&quot;, message.Seq, message.Msg) // 发送带有序列号的数据包 _, err := c.Write(encodeMessage(message)) if err != nil &#123; fmt.Printf(&quot;send to server failed,err:%v\\n&quot;, err) return &#125; // 开始等待ACK，设置超时时间 buf := make([]byte, 1024) c.SetReadDeadline(time.Now().Add(5 * time.Second)) // 循环等待ACK，直到收到正确的ACK或超时 n, _, err := c.ReadFromUDP(buf) if err != nil &#123; // 超时或发生错误，需要重传 fmt.Println(&quot;ACK not received. Timeout or Error. Retrying...&quot;) continue &#125; else &#123; //解码从服务器传来的ack ack := decodeMessage(buf[:n]) if ack.Seq == seq+2 &#123; fmt.Printf(&quot;ACK = %d\\n&quot;, ack.Seq) // 收到正确的ACK，跳出内部循环，继续发送下一个消息 break &#125; else &#123; // 收到错误的ACK，继续等待，内部循环会重发相同的消息 fmt.Println(&quot;Invalid ACK received. Waiting for correct ACK...&quot;) continue &#125; &#125; &#125; &#125;&#125;func encodeMessage(msg Message) []byte &#123; // 将序列号和消息文本编码成字节数据 return []byte(fmt.Sprintf(&quot;%d;%s&quot;, msg.Seq, msg.Msg))&#125;func decodeMessage(data []byte) Message &#123; // 解码收到的数据，提取序列号和消息文本 parts := strings.Split(string(data), &quot;;&quot;) seq, _ := strconv.Atoi(parts[0]) msg := parts[1] return Message&#123;Seq: seq, Msg: msg&#125;&#125; server.go 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;net&quot; &quot;strconv&quot; &quot;strings&quot;)type Message struct &#123; Seq int Msg string&#125;func main() &#123; listen, err := net.ListenUDP(&quot;udp&quot;, &amp;net.UDPAddr&#123; IP: net.IPv4(127, 0, 0, 1), Port: 8282, &#125;) if err != nil &#123; fmt.Printf(&quot;listen failed,err:%v\\n&quot;, err) return &#125; defer listen.Close() for &#123; var buf [1024]byte n, addr, err := listen.ReadFromUDP(buf[:]) if err != nil &#123; fmt.Printf(&quot;read from udp failed,err:%v\\n&quot;, err) return &#125; // 以20%的概率模拟丢包 if rand.Float32() &lt; 0.2 &#123; fmt.Printf(&quot;From %v lost package\\n&quot;, addr) continue &#125; // 处理接收到的数据，解码字节流 提取序列号和消息文本 message := decodeMessage(buf[:n]) fmt.Printf(&quot;Received seq=%d from %v: %s\\n&quot;, message.Seq, addr, message.Msg) // 发送ACK回复给客户端，ACK=Seq+1 ack := Message&#123;Seq: message.Seq + 1, Msg: &quot;ACK&quot;&#125; //写入ack向UDP连接中 _, err = listen.WriteToUDP(encodeMessage(ack), addr) if err != nil &#123; fmt.Printf(&quot;write to %v failed,err:%v\\n&quot;, addr, err) return &#125; &#125;&#125;func encodeMessage(msg Message) []byte &#123; // 将序列号和消息文本编码成字节数据 return []byte(fmt.Sprintf(&quot;%d;%s&quot;, msg.Seq, msg.Msg))&#125;func decodeMessage(data []byte) Message &#123; // 解码收到的数据，提取序列号和消息文本 parts := strings.Split(string(data), &quot;;&quot;) seq, _ := strconv.Atoi(parts[0]) msg := parts[1] return Message&#123;Seq: seq, Msg: msg&#125;&#125; 上述方法实现的丢包重传虽然能够正常工作，但是发送端使用双层循环嵌套，并且每次丢包都阻塞了后续发包，这样会导致重传的效率很低，只适用于小宽带低延时的情况，而且超时重传容易产生误判，主要有以下两种情况： 对方收到了数据包，但是ack发送途中丢失，其实就是我服务器模拟丢包的情况，服务器可能收到了数据，但是因为某种原因ack没能正确发送；ack在回传的途中，但是时间已经超过了发送端的ack等待时间即超过了一次RTO，这样也会导致接收端收到数据却仍然重传的问题。 学习 滑动窗口 拥塞控制 优化一些东西 深入理解seq&#x2F;ack的原理和超时重传的逻辑 Go语言进行socket编程的方法 UDP和TCP的一些知识 借鉴文章：https://blog.csdn.net/weixin_41500064/article/details/135119715 流量控制：作用：为了解决发送方和接收方速度不同而导致的数据丢失问题,当发送方发送的太快,接收方来不及接受就会导致数据丢失； 方式：由接收端采用滑动窗口的形式，告知发送方允许&#x2F;停止发包解决TCP丢包问题。 拥塞控制：作用：为了解决过多的数据注入到网络导致网络崩溃和超负荷问题； 方式：由发送方采用拥塞窗口的形式去判断网络状态，从而采取不同算法执行TCP动态发包解决网络整体质量问题。 典型的场景如以太网场景中10G设备向1G设备发TCP包：10G网卡 10Gbps 持续发送TCP包 交换机 以 1Gbps每秒接收TCP包TCP 提供一种机制可以让发送端根据接收端的实际接收能力控制发送的数据量。这就是所谓的流控制。接收端主机向发送端主机通知自已可以接收数据的大小；是发送端会发送不超过这个限度的数据，该大小限度就被称作窗口大小。窗口大小的值由接收端主机决定，而在TCP 首部中，专门有一个字段用来通知窗口大小：接收主机将自己可以接收的缓冲区大小放入这个字段中通知给发送端，这个字段的值越大，说明网络的吞吐量越高。发送端主机会根据接收端主机的指示，对发送数据的量进行控制。这也就形成了一个完整的TCP流控制(流量控制)。当Window&#x3D;0时，即告知发送方停止发送数据。 慢开始发送方先探测网络拥塞程度，并不是一开始就发送大量的数据，发送方会根据拥塞程度增大拥塞窗口cwnd。拥塞窗口cwnd值是几就能发送几个数据段 拥塞避免继上图达到cwnd≥ssthresh后采用该算法用来控制拥塞窗口的增长速率。 计算方法：每经过一个传输轮次cwnd值加1，让cwnd值呈线性缓慢增大 拥塞发生当网络发生拥塞丢包时（如图假定cwnd&#x3D;24），会有两种情况： 超时重传（1988年TCP Tahoe版本，已废弃不用） 更新后的 ssthresh 值变为 12(即为出现超时时的窗口数值 24 的一半)，拥窗口再重新设置为1并执行慢开始算法。当cwnd &#x3D; ssthresh &#x3D; 12 时改为执行拥塞避免算法拥塞窗口按线性规律增长，每经过一个往返时间增加一个MSS的大小。在TCP拥塞控制的文献中经常可看见“乘法减小”(Multiplicative Decrease)和“加法增大”(Additive Increase)这样的提法。“乘法减小”是指不论在开始阶段还是拥塞避免阶段，只要出现超时(即很可能出现了网络拥塞)，就把慢开始门限值 ssthresh 减半，即设置为当前的拥塞窗口的一半(与此同时，执行慢开始算法)。而“加法增大”是指执行拥塞避免算法后，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。上面两种算法合起来常称为 AIMD算法(加法增大乘法减小)。 快重传与快恢复超时重传算法直接把cwnd减小到1太过强烈，若还能收到连续3个ACK说明网络质量没那么差。同时采用快重传和快恢复算法，过程如下： （1）当发送方连续收到3个重复确认时即执行“乘法减小”算法，把慢开始门限ssthresh 减半； （2）由于发送方现在认为网络不那么差，于是把cwnd值设置为开始门限ssthresh 减半后的数值； （3）开始执行拥塞避免算法 (“加法增大”)使拥塞窗口缓慢地线性增大。 12.25 日根据计算机网络这本书，深入了解UDP套接字编程： 整体的一个过程： 进程间彼此通过向套接字发送报文来进行通信 一个主机-》多个进程 1个进程-》多个套接字 帮助记忆： 进程是一间房子 而 套接字是房子门 还需要一个 端口 来识别我具体要将信息发送到哪间房子，也就是具体的房间号（端口） 客户从键盘键入数据，并向服务器发送数据（将数据编码成字节流）， 服务器接收数据（接收字节流）-》并将其解码为原始客户端输入的数据 （并把小写转换为大写） 服务器将修改的数据（编码为字节流）发送回客户端 客户端接收数据后解码 并显示在屏幕上 接收源地址（ip+端口号）和分组","categories":[{"name":"backend","slug":"backend","permalink":"https://whuichenggong.github.io/categories/backend/"}],"tags":[]},{"title":"操作系统学习","slug":"计算机系统/computer_operate","date":"2024-11-16T13:26:55.040Z","updated":"2025-01-21T07:07:10.627Z","comments":true,"path":"2024/11/16/计算机系统/computer_operate/","permalink":"https://whuichenggong.github.io/2024/11/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/computer_operate/","excerpt":"","text":"6.cs081os学习 感谢： 参考资料： https://www.geeksforgeeks.org/pipe-system-call/ 很好的文章： https://swtch.com/~rsc/thread/ 同步机制：https://zybtree.github.io/2020/08/12/%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/ 参考答案： https://github.com/relaxcn/xv6-labs-2022-solutions/blob/main/doc/utils.md 学习链接： https://pdos.csail.mit.edu/6.828/2021/schedule.html 直接从进程与线程入手 进程与线程单独的CPU变换成多个虚拟的CPU 进程当网页请求进入的时候 先查看 网页是否在缓存中 如果不是启动一个磁盘请求用来获取网页 磁盘请求会花费很多时间 等待的过程中会有更多的请求进入每个进程有它自己的虚拟的CPU 真正的CPU在进程之间来回切换需要一些方法例如多个磁盘 模拟控制并发 进程就能发挥作用来回切换称： 多道程序设计 支持多进程的多道程序系统一个核一次也只能运行一个进程 12.1日一.进程的并发执行 并发 进程的执行是间断的 每个进程的生命周期期间CPU执行 由于某种原因暂停 每个进程执行是间断性的 进程的执行速度是不可预测的 进程调度，有其他事件的发生，每个进程上cpu执行坑你一点时间听着再接着运行 共享 进程线程之间的制约性在一个并发环境下多个进程或者线程之间会共享某些资源，在这些资源的使用过程中会产生进程之间的一种制约性。比如当一个进程享用打印机这个资源，另外一个进程在第一个进程没有释放这个资源的前提之下就得不到这个资源，那就得等待。 不确定性 进程执行的结果与其执行的相对速度有关 进程执行的结果和它的相对执行速度是有关系的，因此在不同的执行顺序的情况下，进程的执行结果也是不确定的。 二.进程互斥由于各进程要求使用共享资源(变量、文件等)， 而这些资源需要排他性使用，各进程之间竞争使用这些资源，这一关系称为进程互斥。 临界资源系统中某些资源一次只允许一个进程使用，称这样的资源为临界资源或互斥资源或共享变量。这些程序片段，分散在不同的进程里，它们的共同的特点是对同一个共享变量进行一些操作这一段代码，和另外一个进程的这一段代码互为临界区，互为互斥区 冯诺依曼模型计算机基本结构：运算器 控制器 存储器 输入设备 输出设备 内存程序和数据都是存储在内存，存储区域是线性的 存储数据的基本单位是 字节 每一个字节对应一个内存地址 最后一个地址为内存总字节数 -1 结构就像数序中的数据 中央处理器也就是cpu：32位cpu一次可以计算4个字节64位cpu一次可以计算8个字节 位数也就是cpu的位宽 代表cpu一次可以计算的数据量 8 位的 CPU，那么一次只能计算 1 个字节也就是0~255 范围内的数值 那么 32位也就是一次可以计算出 2的32次方这么大的数值cpu内部组件：寄存器，控制单元和逻辑运算单元 为什么有了内存还需要寄存器？ 寄存器种类（通用寄存器）（程序计数器）（指令寄存器） 因为： 内存离 CPU 太远了，而寄存器就在 CPU 里，紧挨着控制单元和逻辑运算单元，自然计算时速度会很快。 总线总线用于cpu和内存以及其他设备之前的通信 （地址总线）：指定CPU将要操作的内存地址 （数据总线）：用于读写内存的数据 （控制总线）： 发送和接收信号，比如中断，设备复位等信号 CPU 要读写内存数据的时候： 首先要通过「地址总线」来指定内存的地址； 然后通过「控制总线」控制是读或写命令； 最后通过「数据总线」来传输数据； 输入输出设备输入设备向计算机输入数据，计算机经过计算后，把数据输出给输出设备。如果输入设备是键盘，按下按键时是需要和 CPU 进行交互的，这时就需要用到控制总线了。 线路位宽与CPU位宽数据是如何通过线路传输的呢操作电压，低电压表示 0，高压电压则表示 1 101 二进制数据，十进制则表示 5，如果只有一条线路，就意味着每次只能传递 1 bit 的数据， 那么传输 101 这个数据，就需要 3 次才能传输完成，这样的效率非常低。 增加线路，数据并行传输 CPU 想要操作「内存地址」就需要「地址总线」： 地址总线只有 1 条，那每次只能表示 「0 或 1」这两种地址 最大数量为 2（2^1）个 如果地址总线有 2 条，那么能表示 00、01、10、11 这四种地址 最大数量为 4（2^2）个 CPU 操作 4G 大的内存，那么就需要 32 条地址总线，因为 2 ^ 32 &#x3D; 4G CPU位宽最好不要小于线路位宽 a little operater systerm链接 ： https://lwn.net/Articles/250967/ 所有 CPU（前面的示例中为两个，但可以有更多）都通过公共总线（前端总线，FSB）连接到北桥。除其他外，北桥还包含内存控制器，其实现决定了计算机使用的 RAM 芯片的类型。不同类型的 RAM，例如 DRAM、Rambus 和 SDRAM，需要不同的内存控制器。 要访问所有其他系统设备，北桥必须与南桥进行通信。南桥通常称为 I&#x2F;O 桥，通过各种不同的总线处理与设备的通信。如今，PCI、PCI Express、SATA 和 USB 总线最为重要，但南桥也支持 PATA、IEEE 1394、串行和并行端口。较旧的系统具有连接到北桥的 AGP 插槽。这样做是出于与北桥和南桥之间的连接速度不够快相关的性能原因。然而，如今 PCI-E 插槽全部连接到南桥。 让终端显示出自己说的话1234567cd ~root@xiaoxinxiaohao:~# vim .bashrcroot@xiaoxinxiaohao:~# source ~/.bashrc赵忠鹤闪亮登场Today is: Fri Dec 6 05:12:09 PM CST 2024今天也要充满活力哇咔咔听从了一些学习的建议，带着问题去读书，想学什么，去书中学，带着问题去读书 12.16日 看到了b站的一个关于Go并发设计了解协程： 协程是一种用户级的轻量级线程。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈 主流语言基本上都选择了多线程作为并发设施 线程相关的概念就是抢占式多任务（Preemptive multitasking），而与协程相关的是协作式多任务 多线程编程是比较困难的， 因为调度程序任何时候都能中断线程， 必须记住保留锁， 去保护程序中重要部分， 防止多线程在执行的过程中断 协程默认会做好全方位保护， 以防止中断 协程相比于多线程的优点无需系统内核的上下文切换，减小开销； 因为：协程它不像线程和进程那样，需要进行系统内核上的上下文切换，协程的上下文切换是由开发人员决定的 无需原子操作锁定及同步的开销，不用担心资源共享的问题 单线程即可实现高并发，单核 CPU 即便支持上万的协程都不是问题，所以很适合用于高并发处理，尤其是在应用在网络爬虫中 缺点 无法使用 CPU 的多核 因为： 协程的本质是个单线程 写协程就意味着你要一值写一些非阻塞的代码，使用各种异步版本的库，比如后面的异步爬虫教程中用的 aiohttp 协程的概念最核心的点其实就是函数或者一段程序能够被挂起（说暂停其实也没啥问题），待会儿再恢复","categories":[],"tags":[{"name":"计算机系统","slug":"计算机系统","permalink":"https://whuichenggong.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"}]},{"title":"20岁生日","slug":"生活/live","date":"2024-11-16T12:06:31.864Z","updated":"2025-01-21T07:09:45.198Z","comments":true,"path":"2024/11/16/生活/live/","permalink":"https://whuichenggong.github.io/2024/11/16/%E7%94%9F%E6%B4%BB/live/","excerpt":"","text":"生活的意义就是在于享受每一天，有开心，有难过，有惊喜！ 享受它，生活就是这样！有了博客可以让时间更具象化，留住每一刻，想看的时候翻一翻 感受真的不一样！ 本来不想过生日的，但还是被寝室的兄弟们发现了哈哈哈哈好开心呢上大学的两年都收到了寝室5个兄弟给我送的蛋糕感谢你们啦，尽管离开了家还是有人陪你过生日，非常开心，还是你们陪我走完大学四年上高中的时候也没怎么正经过过生日，到了大学是你们让我的今天变得过呢更有意义，尽管在生活中有磕碰，但那是难以避免的！希望你们每个人以后路越来越好 也是收到家里人的好多红包啊哈哈啊哈好开心！ 感谢家人时刻牵挂着我！ 2023年的今天 2024年的今天 每年的生日许愿都是很广泛的 我姐说那是没有意义的哈哈哈一定要为自己许个愿望在新的一年实现它！ 小彩蛋 11.16日","categories":[{"name":"生活","slug":"生活","permalink":"https://whuichenggong.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[]},{"title":"7_days_golang学习","slug":"go/Goalng_Framework","date":"2024-11-16T11:46:47.251Z","updated":"2025-05-11T07:20:03.546Z","comments":true,"path":"2024/11/16/go/Goalng_Framework/","permalink":"https://whuichenggong.github.io/2024/11/16/go/Goalng_Framework/","excerpt":"","text":"通过学习项目 7_days_golang搭建各种自己的框架了解一些网络工作原理和知识学习geektutu源代码：https://github.com/geektutu/7days-golang 跟着学习的项目代码已经放在: https://github.com/Whuichenggong/Study_Go 1.gee.go关键代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package geeimport ( &quot;fmt&quot; &quot;net/http&quot;)//首先定义了类型HandlerFunc，这是提供给框架用户的，用来定义路由映射的处理方法type HandlerFunc func(http.ResponseWriter, *http.Request)// 在Engine中，添加了一张路由映射表router// key 由请求方法和静态路由地址构成，例如GET-/、GET-/hello、POST-/hello// 如果请求方法不同,可以映射不同的处理方法(Handler)，value 是用户映射的处理方法type Engine struct &#123; router map[string]HandlerFunc&#125;// New is the constructor of gee.Enginefunc New() *Engine &#123; return &amp;Engine&#123;router: make(map[string]HandlerFunc)&#125;&#125;func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123; key := method + pattern engine.router[key] = handler&#125;// 用户调用(*Engine).GET()方法时，会将路由和处理方法注册到映射表 router 中，(*Engine).Run()方法，是 ListenAndServe 的包装。func (engine *Engine) GET(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;GET&quot;, pattern, handler)&#125;func (engine *Engine) POST(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;POST&quot;, pattern, handler)&#125;func (engine *Engine) Run(addr string) (err error) &#123; return http.ListenAndServe(addr, engine)&#125;// Engine实现的 ServeHTTP 方法的作用就是，解析请求的路径，查找路由映射表，如果查到，就执行注册的处理方法。如果查不到，就返回 404 NOT FOUND 。func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; key := req.URL.Path if handler, ok := engine.router[key]; ok &#123; handler(w, req) &#125; else &#123; fmt.Fprintf(w, &quot;404 Not Found: %s\\n&quot;, req.URL) &#125;&#125; 2.go.mod代码12345678module github.com/Whuichenggonggo 1.22.1require gee v0.0.0replace gee =&gt; ./gee replace gee &#x3D;&gt; .&#x2F;gee 这是一个替换指令，它告诉 Go 工具链用本地相对路径 .&#x2F;gee 中的 gee 包替换远程需要的 gee 包。这意味着，尽管 require 指令可能指向一个特定的远程版本或分支，这个 replace 指令实际上将使用当前目录下的 gee 文件夹中的代码。 2.1初始化 Go 模块：如果你的项目还没有被初始化为 Go 模块，你需要先在项目的根目录下运行以下命令来初始化它： go mod init &lt;module-name&gt; 替换 为你的模块名称。例如，如果你的项目名称是 example，你会运行： go mod init example 3.main.go1234567891011121314151617181920212223242526package mainimport ( &quot;fmt&quot; &quot;net/http&quot; &quot;gee&quot;)func main() &#123; r := gee.New() r.GET(&quot;/&quot;, func(w http.ResponseWriter, req *http.Request) &#123; fmt.Fprintf(w, &quot;URL.Path = %q\\n&quot;, req.URL.Path) &#125;) r.GET(&quot;/hello&quot;, func(w http.ResponseWriter, req *http.Request) &#123; for k, v := range req.Header &#123; fmt.Fprintf(w, &quot;Header[%q] = %q\\n&quot;, k, v) &#125; &#125;) r.Run(&quot;:9999&quot;)&#125; 新增：测试 POST 请求启动服务器后，测试 POST 请求可以使用以下工具： 方法 1: 使用 curl执行以下命令发送 POST 请求： curl -X POST http://localhost:8080/submit 12345678910111213141516171819202122232425262728293031323334353637383940package mainimport (&quot;fmt&quot;&quot;io/ioutil&quot;&quot;net/http&quot;)type HandlerFunc func(http.ResponseWriter, *http.Request)type Engine struct &#123;router map[string]HandlerFunc&#125;func New() *Engine &#123;return &amp;Engine&#123;router: make(map[string]HandlerFunc)&#125;&#125;func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123;key := method + patternengine.router[key] = handler&#125;func (engine *Engine) POST(pattern string, handler HandlerFunc) &#123;engine.addRoute(&quot;POST&quot;, pattern, handler)&#125;func (engine *Engine) Run(addr string) error &#123;return http.ListenAndServe(addr, engine)&#125;func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123;key := req.Method + req.URL.Pathif handler, ok := engine.router[key]; ok &#123;handler(w, req)&#125; else &#123;http.NotFound(w, req)&#125;&#125; func main() {engine :&#x3D; New() // 注册一个 POST 路由 engine.POST(&quot;/submit&quot;, func(w http.ResponseWriter, req *http.Request) &#123; // 读取请求体数据 body, err := ioutil.ReadAll(req.Body) if err != nil &#123; http.Error(w, &quot;Failed to read request body&quot;, http.StatusInternalServerError) return &#125; // 响应请求体内容 fmt.Fprintf(w, &quot;Received: %s&quot;, string(body)) &#125;) // 启动服务器 engine.Run(&quot;:8080&quot;) }测试：启动程序后，用 curl 发送 POST 请求并附带数据： bcurl -X POST -d “data&#x3D;HelloWorld” http://localhost:8080/submit服务器返回： kotlin Received: data&#x3D;HelloWorld ServeHTTP好像有点问题main.go附带了对代码的理解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package geeimport ( &quot;fmt&quot; &quot;net/http&quot;)//首先定义了类型HandlerFunc，这是提供给框架用户的，用来定义路由映射的处理方法type HandlerFunc func(http.ResponseWriter, *http.Request)// 在Engine中，添加了一张路由映射表router// key 由请求方法和静态路由地址构成，例如GET-/、GET-/hello、POST-/hello// 如果请求方法不同,可以映射不同的处理方法(Handler)，value 是用户映射的处理方法type Engine struct &#123; router map[string]HandlerFunc&#125;// New is the constructor of gee.Enginefunc New() *Engine &#123; return &amp;Engine&#123;router: make(map[string]HandlerFunc)&#125;&#125;// 这段代码的作用将HTTP请求的路由和对应的处理函数注册到路由表中的核心方法// pattern路由路径func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123; //将HTTp方法和路径拼接成唯一一个键 作为路由表的router的键 key := method + pattern //将处理函数 handler 存入路由表中，关联到对应的路由键。 engine.router[key] = handler&#125;// 用户调用 addRoute(&quot;GET&quot;, &quot;/home&quot;, someHandlerFunc) 在 engine.router 映射表中，会存储一个键值对：// 调用engine.GET(&quot;/home&quot;, someHandlerFunc)： 实际是 等价 engine.addRoute(&quot;GET&quot;, &quot;/home&quot;, someHandlerFunc)func (engine *Engine) GET(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;GET&quot;, pattern, handler)&#125;func (engine *Engine) POST(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;POST&quot;, pattern, handler)&#125;// 这段代码隐藏了调用ServeHTTPfunc (engine *Engine) Run(addr string) (err error) &#123; return http.ListenAndServe(addr, engine)&#125;// Engine实现的 ServeHTTP 方法的作用就是，解析请求的路径，查找路由映射表，如果查到，就执行注册的处理方法。如果查不到，就返回 404 NOT FOUND 。// 不需要显式调用 ServeHTTP// 在 Go 的 HTTP 框架中，ServeHTTP 是 http.Handler 接口的约定方法。当你把 Engine 作为服务器的处理器传递时，它会被 ListenAndServe 自动调用。func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; key := req.URL.Path if handler, ok := engine.router[key]; ok &#123; handler(w, req) &#125; else &#123; fmt.Fprintf(w, &quot;404 Not Found: %s\\n&quot;, req.URL) &#125;&#125; 问题在 ServeHTTP 中，当前只从 req.URL.Path 获取路径，而没有结合 req.Method，会导致不同的 HTTP 方法（如 GET 和 POST）冲突或无法正确匹配。addRoute 方法仅使用了路径（pattern）和方法（method）拼接为路由键，例如：GET&#x2F;home。 1234func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123; key := method + &quot;-&quot; + pattern // 区分 HTTP 方法和路径 engine.router[key] = handler&#125; 修改的这段代码原来只使用了路径（req.URL.Path）作为路由键。例如： 请求路径 &#x2F;hello 的键为 &#x2F;hello。不区分 GET &#x2F;hello 和 POST &#x2F;hello，它们会共用同一个路由键 &#x2F;hello。建议的代码使用 HTTP 方法和路径 拼接成路由键。例如： GET &#x2F;hello 的键为 GET-&#x2F;hello。POST &#x2F;hello 的键为 POST-&#x2F;hello。这样可以区分不同方法对应的路由处理函数。 与gin框架启动很相似 对Web服务来说，无非是根据请求*http.Request，构造响应http.ResponseWriter。但是这两个对象提供的接口粒度太细，比如我们要构造一个完整的响应，需要考虑消息头(Header)和消息体(Body)，而 Header 包含了状态码(StatusCode)，消息类型(ContentType)等几乎每次请求都需要设置的信息。因此，如果不进行有效的封装， 那么框架的用户将需要写大量重复，繁杂的代码且容易出错。针对常用场景，能够高效地构造出 HTTP 响应是一个好的框架必须考虑的点。 代码要学会封装 否则代码整洁度看起来还是会差很多的 对于别人理解一会更方便 为什么要添加context 对于框架来说，还需要支撑额外的功能。例如，将来解析动态路由&#x2F;hello&#x2F;:name，参数:name的值放在哪呢？再比如，框架需要支持中间件，那中间件产生的信息放在哪呢？ contxet保留了你想寻找的一些东西拓展性和复杂性留在内部对外简化了接口。 Context 的作用是为每个 HTTP 请求提供一个上下文对象，方便操作请求和响应，并提供了一些简化开发的工具方法。通过 Context 统一管理 HTTP 请求和响应的逻辑。 可以把 Context 看作是： 一个请求的容器： 它封装了与 HTTP 请求相关的所有信息，并提供了一些方法让你更轻松地操作这些信息。 开发者和 HTTP 请求的桥梁： 开发者通过 Context 与客户端通信，包括读取请求信息和发送响应。 123456789101112func handler(c *Context) &#123;// 获取查询参数name := c.Query(&quot;name&quot;) // 构造 JSON 响应 if name != &quot;&quot; &#123; c.JSON(http.StatusOK, H&#123;&quot;message&quot;: &quot;Hello &quot; + name&#125;) &#125; else &#123; c.String(http.StatusBadRequest, &quot;Name is required&quot;) &#125;&#125; 深入框架原理：阅读 Gin、Echo 等框架的源码，了解它们如何设计和扩展 Context。 尝试扩展功能：在 Context 上添加自定义方法，比如记录日志、追踪请求 ID 等。 http.ResponseWriter 和 *http.Request 的实际意义http.ResponseWriter 作用：代表服务端用来写入 HTTP 响应的接口。开发者通过它向客户端返回数据（如响应头、响应状态码、响应体等）。实际应用：在服务端，http.ResponseWriter 将生成的 HTTP 响应数据写入 TCP 连接的输出流，客户端会接收到这些数据并解析呈现。*http.Request 作用：表示客户端发来的 HTTP 请求，包含了所有请求相关的信息（如 URL、方法、头部、表单数据、Cookie、Body 等）。实际应用：服务端根据 *http.Request 的内容（路径、方法等），判断客户端的需求并生成相应的响应。 12345678910111213141516171819202122package mainimport ( &quot;fmt&quot; &quot;net/http&quot;)func handler(w http.ResponseWriter, req *http.Request) &#123; // 设置响应头 w.Header().Set(&quot;Content-Type&quot;, &quot;text/plain&quot;) // 设置状态码 w.WriteHeader(http.StatusOK) // 写入响应体 fmt.Fprintf(w, &quot;Hello, %s!\\n&quot;, req.URL.Query().Get(&quot;name&quot;))&#125;func main() &#123; http.HandleFunc(&quot;/&quot;, handler) http.ListenAndServe(&quot;:8080&quot;, nil)&#125; 客户端请求示例： 浏览器访问 http://localhost:8080/?name=zhaozhonghe 服务端响应： HTTP&#x2F;1.1 200 OK &#x2F;&#x2F;设置的状态码 200Content-Type: text&#x2F;plain &#x2F;&#x2F;设置的请求头 响应过来了 并且返回到了 客户端页面Content-Length: 12 Hello, zhaozhonghe! &#x2F;&#x2F; 读取 HTTP 请求 将数据写入响应体，通过 w 发送给客户端。 第二天1.添加context1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package geeimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;net/http&quot;)//对Web服务来说，无非是根据请求*http.Request，构造响应http.ResponseWriter// 给map[string]interface&#123;&#125;起了一个别名gee.H，构建JSON数据时，显得更简洁。type H map[string]interface&#123;&#125;// Context目前只包含了http.ResponseWriter和*http.Request，另外提供了对 Method 和 Path 这两个常用属性的直接访问。type Context struct &#123; Writer http.ResponseWriter Req *http.Request Path string Method string StatusCode int&#125;func newContext(w http.ResponseWriter, req *http.Request) *Context &#123; return &amp;Context&#123; Writer: w, Req: req, Path: req.URL.Path, Method: req.Method, &#125;&#125;// 提供了访问Query和PostForm参数的方法。func (c *Context) PostForm(key string) string &#123; return c.Req.FormValue(key)&#125;func (c *Context) Query(key string) string &#123; return c.Req.URL.Query().Get(key)&#125;func (c *Context) Status(code int) &#123; c.StatusCode = code c.Writer.WriteHeader(code)&#125;func (c *Context) SetHeader(key string, value string) &#123; c.Writer.Header().Set(key, value)&#125;// 提供了快速构造String/Data/JSON/HTML响应的方法。func (c *Context) String(code int, format string, values ...interface&#123;&#125;) &#123; c.SetHeader(&quot;Content-Type&quot;, &quot;text/plain&quot;) c.Status(code) c.Writer.Write([]byte(fmt.Sprintf(format, values...)))&#125;func (c *Context) JSON(code int, obj interface&#123;&#125;) &#123; c.SetHeader(&quot;Content-Type&quot;, &quot;application/json&quot;) c.Status(code) encoder := json.NewEncoder(c.Writer) if err := encoder.Encode(obj); err != nil &#123; http.Error(c.Writer, err.Error(), 500) &#125;&#125;func (c *Context) Data(code int, data []byte) &#123; c.Status(code) c.Writer.Write(data)&#125;func (c *Context) HTML(code int, html string) &#123; c.SetHeader(&quot;Content-Type&quot;, &quot;text/html&quot;) c.Status(code) c.Writer.Write([]byte(html))&#125; 2.添加router想 路由需要的参数 路径 方法 处理函数 12345678910111213141516171819202122232425262728293031package geeimport ( &quot;log&quot; &quot;net/http&quot;)type router struct &#123; handlers map[string]HandlerFunc&#125;func newRouter() *router &#123; return &amp;router&#123;handlers: make(map[string]HandlerFunc)&#125;&#125;func (r *router) addRoute(method string, pattern string, handler HandlerFunc) &#123; log.Printf(&quot;Route %4s - %s&quot;, method, pattern) key := method + &quot;-&quot; + pattern r.handlers[key] = handler&#125;func (r *router) handle(c *Context) &#123; key := c.Method + &quot;-&quot; + c.Path if handler, ok := r.handlers[key]; ok &#123; handler(c) &#125; else &#123; c.String(http.StatusNotFound, &quot;404 NOT FOUND: %s\\n&quot;, c.Path) &#125;&#125; r.handlers[key] &#x3D; handler 这段代码将key也就是路径 和 处理函数关连到了一起 post用终端请求1.Invoke-WebRequest -Uri “http://localhost:9999/login“ -Method POST -Body “username&#x3D;zhaozhonghe&amp;password&#x3D;zzh123456” curl.exe -X POST -d “username&#x3D;zhaozhonghe&amp;password&#x3D;zzh123456” http://localhost:9999/login返回结果1&#123;&quot;password&quot;:&quot;zzh123456&quot;,&quot;username&quot;:&quot;zhaozhonghe&quot;&#125; 测试第二天的gee第一种返回结果 123456789101112131415161718StatusCode : 200StatusDescription : OKContent : &#123;&quot;password&quot;:&quot;zzh123456&quot;,&quot;username&quot;:&quot;zhaozhonghe&quot;&#125;RawContent : HTTP/1.1 200 OKContent-Length: 50Content-Type: application/jsonDate: Tue, 26 Nov 2024 13:43:37 GMT &#123;&quot;password&quot;:&quot;zzh123456&quot;,&quot;username&quot;:&quot;zhaozhonghe&quot;&#125;Forms : &#123;&#125;Headers : &#123;[Content-Length, 50], [Content-Type, application/json], [Date, Tue, 26 Nov 2024 13:43:37 GMT]&#125;Images : &#123;&#125;InputFields : &#123;&#125;Links : &#123;&#125;ParsedHtml : mshtml.HTMLDocumentClassRawContentLength : 50 gee.go1234567891011121314151617181920212223242526272829303132333435363738394041package geeimport &quot;net/http&quot;// HandlerFunc defines the request handler used by geetype HandlerFunc func(*Context)// Engine implement the interface of ServeHTTPtype Engine struct &#123; router *router&#125;// New is the constructor of gee.Enginefunc New() *Engine &#123; return &amp;Engine&#123;router: newRouter()&#125;&#125;func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) &#123; engine.router.addRoute(method, pattern, handler)&#125;// GET defines the method to add GET requestfunc (engine *Engine) GET(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;GET&quot;, pattern, handler)&#125;// POST defines the method to add POST requestfunc (engine *Engine) POST(pattern string, handler HandlerFunc) &#123; engine.addRoute(&quot;POST&quot;, pattern, handler)&#125;// Run defines the method to start a http serverfunc (engine *Engine) Run(addr string) (err error) &#123; return http.ListenAndServe(addr, engine)&#125;func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; c := newContext(w, req) engine.router.handle(c)&#125; 第三天我们用了一个非常简单的map结构存储了路由表，使用map存储键值对，索引非常高效，但是有一个弊端，键值对的存储的方式，只能用来索引静态路由。那如果我们想支持类似于&#x2F;hello&#x2F;:name这样的动态路由怎么办呢？所谓动态路由，即一条路由规则可以匹配某一类型而非某一条固定的路由。例如&#x2F;hello&#x2F;:name，可以匹配&#x2F;hello&#x2F;geektutu、hello&#x2F;jack等。请等待~~~ 11.21日看到了字节的课 是关于动态路由的设计 前缀匹配树 router.go前缀树路由： 重点学习这个数据结构 bilibili: https://www.bilibili.com/video/BV1wT4y1x7xm?t=45.6 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package geeimport ( &quot;net/http&quot; &quot;strings&quot;)type router struct &#123; roots map[string]*node //增加的 handlers map[string]HandlerFunc&#125;func newRouter() *router &#123; return &amp;router&#123; roots: make(map[string]*node), handlers: make(map[string]HandlerFunc), &#125;&#125;// Only one * is allowedfunc parsePattern(pattern string) []string &#123; vs := strings.Split(pattern, &quot;/&quot;) parts := make([]string, 0) for _, item := range vs &#123; if item != &quot;&quot; &#123; parts = append(parts, item) if item[0] == &#x27;*&#x27; &#123; break &#125; &#125; &#125; return parts&#125;func (r *router) addRoute(method string, pattern string, handler HandlerFunc) &#123; parts := parsePattern(pattern) key := method + &quot;-&quot; + pattern _, ok := r.roots[method] if !ok &#123; r.roots[method] = &amp;node&#123;&#125; &#125; r.roots[method].insert(pattern, parts, 0) r.handlers[key] = handler&#125;func (r *router) getRoute(method string, path string) (*node, map[string]string) &#123; searchParts := parsePattern(path) params := make(map[string]string) root, ok := r.roots[method] if !ok &#123; return nil, nil &#125; n := root.search(searchParts, 0) if n != nil &#123; parts := parsePattern(n.pattern) for index, part := range parts &#123; if part[0] == &#x27;:&#x27; &#123; params[part[1:]] = searchParts[index] &#125; if part[0] == &#x27;*&#x27; &amp;&amp; len(part) &gt; 1 &#123; params[part[1:]] = strings.Join(searchParts[index:], &quot;/&quot;) break &#125; &#125; return n, params &#125; return nil, nil&#125;func (r *router) getRoutes(method string) []*node &#123; root, ok := r.roots[method] if !ok &#123; return nil &#125; nodes := make([]*node, 0) root.travel(&amp;nodes) return nodes&#125;func (r *router) handle(c *Context) &#123; n, params := r.getRoute(c.Method, c.Path) if n != nil &#123; c.Params = params key := c.Method + &quot;-&quot; + n.pattern r.handlers[key](c) &#125; else &#123; c.String(http.StatusNotFound, &quot;404 NOT FOUND: %s\\n&quot;, c.Path) &#125;&#125; parsePattern 函数的作用是解析路由路径，将路径按 &#x2F; 分隔成各个部分。比如 &#x2F;user&#x2F;:id 会被分解成 [“user”, “:id”]。如果路径中出现了 *（通常用于匹配任意多的路径部分），解析会在遇到 * 时停止。比如 &#x2F;files&#x2F;*filepath 会解析成 [“files”, “*filepath”]。parts 数组存储了路由路径的各个部分（如静态部分、动态部分、通配符部分） tire.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package geeimport ( &quot;fmt&quot; &quot;strings&quot;)type node struct &#123; pattern string part string children []*node isWild bool&#125;func (n *node) String() string &#123; return fmt.Sprintf(&quot;node&#123;pattern=%s, part=%s, isWild=%t&#125;&quot;, n.pattern, n.part, n.isWild)&#125;func (n *node) insert(pattern string, parts []string, height int) &#123; if len(parts) == height &#123; n.pattern = pattern return &#125; part := parts[height] children := n.matchChildren(part) var child *node if len(children) == 0 &#123; child = &amp;node&#123;part: part, isWild: part[0] == &#x27;:&#x27; || part[0] == &#x27;*&#x27;&#125; n.children = append(n.children, child) &#125; else &#123; child = children[0] // 假设我们总是取第一个匹配的子节点 &#125; child.insert(pattern, parts, height+1)&#125;func (n *node) search(parts []string, height int) *node &#123; if len(parts) == height || strings.HasPrefix(n.part, &quot;*&quot;) &#123; if n.pattern == &quot;&quot; &#123; return nil &#125; return n &#125; part := parts[height] children := n.matchChildren(part) for _, child := range children &#123; result := child.search(parts, height+1) if result != nil &#123; return result &#125; &#125; return nil&#125;func (n *node) travel(list *([]*node)) &#123; if n.pattern != &quot;&quot; &#123; *list = append(*list, n) &#125; for _, child := range n.children &#123; child.travel(list) &#125;&#125;func (n *node) matchChild(part string) *node &#123; for _, child := range n.children &#123; if child.part == part || child.isWild &#123; return child &#125; &#125; return nil&#125;func (n *node) matchChildren(part string) []*node &#123; nodes := make([]*node, 0) for _, child := range n.children &#123; if child.part == part || child.isWild &#123; nodes = append(nodes, child) &#125; &#125; return nodes&#125; 先学习一下前缀树 定义树结点结构体12345type trieNode struct &#123; nexts [26]*trieNode PassCnt int //用来记录中途是否有途径某个节点的个数 end bool //匹配某个单词是否是结尾 比如seat的结尾是t&#125; 树 123type Trie struct &#123; root *trieNode&#125; 12345func Newtrie *Trie&#123; return &amp;Trie&#123; root: &amp;trieNode&#123;&#125;,&#125;&#125; 查询12345 func (t *Trie) Search(word string) bool &#123; //查找目标节点，使根节点开始抵达目标节点沿路跟字符串恰好等于word node := t.search(word) return node != nil &amp;&amp; node.end&#125; Tire.search 方法源码字符➖a如果返回的单词是 前缀树中的别的单词的前缀判断 123456789101112131415161718192021222324func (t *Trie)search(target string)*trieNode&#123;//移动指针从根节点出发move :t.root/依次追历target中的每个字符for_, ch:range target&#123;//倘若nexts中不存在对应于这个字符的节点，说明该单词没插入过，返回ni1if move.nexts[ch-&#x27;a&#x27;]==nil&#123;return nil&#125;//指针向着子节点移动movemove.nexts [ch-&#x27;a&#x27;]&#125;//来到末尾，说明已经完全匹配好单词，直接返回这个节点//需要注意，找到目标节点不一定代表单词存在，因为该节点的end标识未必为true//比如我们之前往trie中插入了apple这个单词，但是查找app这个单词时，预期的返回return move&#125;&#125; 前缀匹配1234//前缀树做前缀匹配很简单 func (t *Trie) StartWith(prefix(string)) bool &#123; return t.search(prefix) != nil&#125; 前缀统计123456789func (t *Trie) PassCnt(prefix string) int&#123; node := t.search(prefix) if node == nil &#123; return 0 &#125; return node.PassCnt&#125; 插入单词例子： 要插入apple 树中app可以复用 则插入 l e 1234567891011121314151617181920 func (t *Trie) Insert(word string) &#123;//如果单词存在直接返回 if t.Search(word)&#123; return&#125; move := t.root for _,ch := range word &#123;//如果不存在创建出来 if move.nexts[ch-&#x27;a&#x27;] == nil &#123; move.nexts[ch-&#x27;a&#x27;] = &amp;trieNode&#123;&#125;&#125; move.nexts[ch-&#x27;a&#x27;].passCnt++ move = move.nexts[ch-&#x27;a&#x27;]move.end =true&#125; 删除流程12345678910111213141516171819func (t *Trie) Erase(word string) bool &#123; if !t.Search(word)&#123;return false&#125; move := t.root for _, ch := range word &#123; move.nexts[ch-&#x27;a&#x27;].passCnt --if move.nexts[ch-&#x27;a&#x27;].passCnt == 0 &#123; move.nexts[ch-&#x27;a&#x27;] = nil return true&#125; move = move.nexts[ch-&#x27;a&#x27;]&#125; move.end = false return true&#125; 整段代码下来还是有点看不懂啊呜呜 11.25日拖了几天感谢tutu 分组控制分组控制是Web框架的基础功能之一，路由的分组，往往某一组路由需要相似的处理 以&#x2F;post开头的路由匿名可访问。以&#x2F;admin开头的路由需要鉴权。以&#x2F;api开头的路由是 RESTful 接口，可以对接第三方平台，需要三方平台鉴权。 &#x2F;post是一个分组&#x2F;post&#x2F;a和&#x2F;post&#x2F;b可以是该分组下的子分组作用在&#x2F;post分组上的中间件(middleware)，也都会作用在子分组，子分组还可以应用自己特有的中间件。 中间件可以给框架提供无限的扩展能力用在分组上的效果也更明显&#x2F;admin的分组，可以应用鉴权中间件；&#x2F;分组应用日志中间件，&#x2F;是默认的最顶层的分组，也就意味着给所有的路由，即整个框架增加了记录日志的能力。 一个 Group 对象需要具备哪些属性呢？首先是前缀(prefix)，比如&#x2F;，或者&#x2F;api；要支持分组嵌套，那么需要知道当前分组的父亲(parent)是谁；中间件是应用在分组上的，那还需要存储应用在该分组上的中间件(middlewares)。 12345r := gee.New()v1 := r.Group(&quot;/v1&quot;)v1.GET(&quot;/&quot;, func(c *gee.Context) &#123; c.HTML(http.StatusOK, &quot;&lt;h1&gt;Hello Gee&lt;/h1&gt;&quot;)&#125;) 好好看看仓库中的代码 梳理思路 感觉好有意思但是看不懂哈哈哈哈 11.26日 回看前三天的代码 增加一些自己的理解和修改 再继续向下学习！","categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"}],"tags":[]},{"title":"计算机网络持续学习中~","slug":"计算机系统/computer_network","date":"2024-11-14T12:05:18.911Z","updated":"2025-05-11T07:20:03.561Z","comments":true,"path":"2024/11/14/计算机系统/computer_network/","permalink":"https://whuichenggong.github.io/2024/11/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/computer_network/","excerpt":"","text":"记录一下自己在黑皮书中的学习记录下有用的部分 非常好的学习HTTP RESTFUL API 链接链接1： https://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html 链接2： https://www.ruanyifeng.com/blog/2016/08/http.html 链接3： https://florimond.dev/en/posts/2018/08/restful-api-design-13-best-practices-to-make-your-users-happy应用层2.1应用层协议原理：Web应用程序中两个互相通讯的不同程序： 运行在用户主机上浏览器程序 运行在Web服务器主机上 网络上的核心设备并不在应用层起作用， 这将应用软件限制在了端系统，这促进了大量网络应用程序的迅速研发与部署 2.1.1网络应用程序体系结构应用层的体系结构 明显 不同于网络的体系结构（网络的体系结构是固定的，提供了特定的服务集合） 应用层体系结构（大体两个）： 客户-服务器体系结构 p2p体系结构 1.客户-服务器体系结构：有一个总打开的主机被称为：服务器（它服务于许多其他称为客户的主机请求） 例子： Web应用服务器：（Web服务器服务于浏览器（运行在客户机）的请求） 在这个体系结构中 客户之间并不直接通信 而是 客户通过向该服务器的ip地址发送分组 用来取得联系 著名的Web应用： Web FTP Telent 电子邮箱 在这个体系中 如果只有一台服务器 在某些情况（大量的所有请i去）会导致服务器变得不堪重负，因此-配备大量主机的 数据中心 流行的因特网服务： 搜索引擎（Google，bing，百度）等 应用了一个或多个数据中心（1个数据中心 可以有数十万台服务器） 2. p2p体系结构主机对之间使用直接通信（对等方），引人入胜的特性（自扩展性）， 面临挑战： 高度非集中式，面临安全性，性能和可靠性等挑战 应用： 文件共享，对等方协助下载器（迅雷）因特网电话和视频会议 有的应用具有两种的混合体系： 服务器被用来跟踪用户的ip地址 但 用户到用户的报文在用户到主机之间 直接发送 2.1.2进程通信运行在多个端系统上的程序如何互相通信，进行通信实际上是进程而不是程序进程可以被认为是运行在端系统的一个程序。 多个进程运行在相同的端系统时使用进程间通信机制互相通信（通信规则由 _端系统上的操作系统制定_） 关注的是 运行在不同端系统上的进程间的通信在不同的端系统上的进程 通过 跨越进程通过网络互相发送报文 发送进程 生成并 向网络中 发送报文 -》接收进程接收报文并通过回送报文响应 1.客户和服务器进程网络应用程序由 成对的进程组成 进程之间 通过网路互相发送报文 例子： 客户浏览器进程 与 Web服务器进程交换报文 在p2p中： 文件从一个对等方中的进程 传输到 另一个对等放进程 其中一个进程被表示为客户 另一个进程被标记为服务器 2.进程与计算机网络之间的接口（api）进程 通过一个称为套接字（socket） 的软件接口 向网络发送报文和从网络接收报文 套接字： 是同一台主机被应用层与传输层之间的接口 套接字被称为 应用进程 和 网络之间的（api） 我们可以控制套接字在应用端的一切 但是 对运输层几乎没有控制权 仅限于：选择运输层协议 也能设定几个运输层协议（最大缓存，最大报文长度） 3.进程寻址主机由ip地址标识， ip地址： 是32比特的量它能够标识该主机 端口号： 众所周知的端口号列表： http://www.iana.org 2.1.3 可供应用程序使用的运输服务运输层协议负责从接收进程的套接字得到该报文 开发应用时还要选择根基情况 选择合适的协议 选择服务 服务： 可靠数据传输 吞吐量 定时 安全性 1.可靠数据传输因为 分组可能在计算机网络中丢失， 例子： 分组能够使路由器中的缓存溢出， 分组中的某些比特损坏后可能被丢弃 在某些特定情况下： 电子邮件，文件传输，远程主机访问如果数据丢失可能会造成灾难性的损失， 因此 当运输层协议提供一种可靠传输， 发送进程只需要将数据传递到套接字中 就可以完全相信数据无差别的到达接收进程但是也有一些东西可以容忍数据的丢失（不适用可靠数据传输时） 音频&#x2F;视频 2.吞吐量吞吐量就是发送进程能够向接收进程交付比特的速率 会话 将共享沿着网络路径的带宽 运输层协议能够确保可用吞吐量为至少r&#x2F;bit&#x2F;s当（应用程序请求r&#x2F;bit&#x2F;s） 示例：电话需要固定的bit进行编码 如果不能提供这中吞吐量或者较小 造成放弃发送（因为接收一半可能是没用的）弹性应用：可以根据 可用的宽带或多或少来利用可供使用的吞吐量当然 吞吐量越高越好哈哈哈 3.定时运输层协议也能提供定时保证 因为在特定情况下 电话，虚拟环境 多方游戏（对时间有严格的限制） 否则会造成停顿， 较长的时延但 端到端的时延没有严格的约束 4，安全性运输协议为应用提供 一种或多种安全性服务 能加密发送进程传输的所有数据 防止数据以某种方式 在两个进程之间被观察 2.1.4 因特网提供的运输服务因特网（TCp&#x2F;IP网络）为应用程序提供两个运输层协议（TCP&#x2F;UDP） 1.TCP服务特点： 面向连接服务和可靠数据传输服务 面向连接： 在应用层数据报文开始流动之前， TCP使 客户 和 服务器 之前相互交换 运输层控制信息（握手过程） 让它们提前做好准备握手之后 TCP连接就建立了 连接时双工的： 双方可以连接上 同时进行报文的收发 当收发结束后 必须拆除连接 可靠的数据传送服务： 通信进程依靠TCP 无差错的按照顺序交付所有的发送数据 当一方将字节流传入套接字时 依靠TCP将相同的字节流交付给接收方的套接字 没有字节的丢失和冗余 TCP具有拥塞控制机制 当发送方和接收方之间网络出现问题堵塞 TCP的机制可以抑制发送进程 也试图限制每个TCP连接 达到公平共享网络宽带目的 原文链接： https://github.com/wolverinn/Waking-Up/blob/master/Computertree-way-handshake 简单理解： 三次握手（三报文握手）第一次握手：Client将SYN置1，随机产生一个初始序列号seq发送给Server，进入SYN_SENT状态；第二次握手：Server收到Client的SYN&#x3D;1之后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number&#x3D;sequence number+1，并随机产生一个自己的初始序列号，发送给客户端；进入SYN_RCVD状态；第三次握手：客户端检查acknowledge number是否为序列号+1，ACK是否为1，检查正确之后将自己的ACK置为1，产生一个acknowledge number&#x3D;服务器发的序列号+1，发送给服务器；进入ESTABLISHED状态；服务器检查ACK为1和acknowledge number为序列号+1之后，也进入ESTABLISHED状态；完成三次握手，连接建立。 目的： 建立 TCP连接 两次握手呢？只发送前两次报文 不会有 最后一次的客户端同步状态报文这就会导致超时重传把问题想象成发送报文就好理解了：一段时间后，之前滞留在网络中的那个失效的TCP连接请求报文段到达了TCP服务器进程，TCP 服务器进程会误认为这是TCP客户进程又发起了一个新的TCP连接请求，于是给TCP客户进程发送TCP连接请求确认报文段并进入连接已建立状态。该报文段到达TCP客户进程，由于TCP客户进程并没有发起新的TCP连接请求，并且处于关闭状态，因此不会理会该报文段。 不可以！ 如果不是用三次握手 那么只要client发出确认报文段， server发出确认新的连接就建立了因为第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了延误到连接释放以后的某个时间才到达但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。 四次握手？可以。但是会降低传输的效率。 四次握手是指：第二次握手：Server只发送ACK和acknowledge number；而Server的SYN和初始序列号在第三次握手时发送；原来协议中的第三次握手变为第四次握手。出于优化目的，四次握手中的二、三可以合并。 了解名词ACK acknowledge number SYN 初始序列号 参考链接： https://juejin.cn/post/7028003193502040072 确认标志位ACK： 取值为1时确认号字段才有效；取值为0时确认号字段无效。TCP规定，在连接建立后所有传送的TCP报文段都必须把ACK置1。 源端口：16bit 目的端口： 16bit序号：32bit 同步标志位SYN： 在TCP连接建立时用来同步序号。终止标志位FIN： 用来释放TCP连接。复位标志位RST： 用来复位TCP连接。 推送标志位PSH： 接收方的TCP收到该标志位为1的报文段会尽快上交应用进程，而不必等到接收缓存都填满后再向上交付。 TCP建立需要解决的问题： 1、使TCP双方能够确知对方的存在 。 2、使TCP双方能够协商一些参数（ 最大窗口值是否使用窗口扩大选项和时间戳选项，以及服务质量等）。 3、使TCP双方能够对运输实体资源（例如缓存大小连接表中的项目等）进行分配。 TCP规定SYN被设置为1的报文段不能携带数据但要消耗掉一个序号。 TCP服务器进程收到TCP连接请求报文段后，如果同意建立连接，则向TCP客户进程发送TCP连接请求确认报文段，并进入同步已接收状态 总结：如果没有第三次握手告诉服务器客户端能否收到服务器传输的数据的话，服务器端的端口就会一直开着，等到客户端因超时重新发出请求时，服务器就会重新开启一个端口连接。长此以往， 这样的端口越来越多，就会造成服务器开销的浪费。 探测报文检测 确认客户端是否出现故障 然后关闭连接 四次挥手第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入FIN_WAIT_1状态；第二次挥手：Server收到FIN之后，发送一个ACK&#x3D;1，acknowledge number&#x3D;收到的序列号+1；进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。第三次挥手：Server将FIN置1，发送一个序列号给Client；进入LAST_ACK状态；第四次挥手：Client收到服务器的FIN后，进入TIME_WAIT状态；接着将ACK置1，发送一个acknowledge number&#x3D;序列号+1给服务器；服务器收到后，确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。 还有些不太理解学习一下这些名字之后再来理解 2.UDP服务UDP是 轻量级运输协议仅提供最小服务 状态：无连接的，两个进程通信没有握手过程， 提供：不可靠传输协议：不保证报文到达接收进程报文也可能是乱序到达 也没有拥塞控制机制 因特网运输协议所不提供的服务TCP在应用层 用SSL加强提供安全服务 漏掉了 吞吐量，和定时保证 2.1.5 应用层协议定义了： 交换的报文类型 如：请求报文，响应报文 报文类型语法 如：报文字段是如何描述的 字段的语义 就是信息含义 确定进程何时发送报文 Web的应用层协议是HTTP： 因特网电子邮件应用：包括 电子邮件报文结构的标准 以及 定义报文如何在服务器之间以及如何在服务器与邮件客户程序之间传递的应用层协议 2.2Web和HTTP2.2.1HTTP概况Web层应用层协议是超文本传输协议 HTTP由两个程序实现（客户程序）（服务器程序） 通过交换HTTP报文进行会话 Web界面它是由文档组成的也就是（对象）： 一个对象是一个文件 例如： HTML文件 JPEG图形 例如： 如果一个HTML文件＋五个图片 也就是 Web页面有6个对象 URL地址两部分组成：服务器主机名 和 对象 URL：http://www/someSchool.edu/someDepartment/picture.gif 到edu是主机名后面是路径名 Web服务器 实现了HTTP服务器端 用于存储Web对象 流行的Web服务器：Apache等 2.2.2非持续连接和持续链接两个问题： 每个请求&#x2F;响应是 经 一个单独的TCP连接： 这称为（非持续连接）还是 经相同的TCP连接发送： 这称为（持续链接） 1.采用非持续连接的HTTP过程： 每个TCP只传输一个请求报文和一个响应报文 串行TCP： 并行TCP： 浏览器可以设置并行数 如果设为1 那么就会变化串行连接 并行连接可以减少响应时间 往返时间（RTT） RTT包括： 分组传播时延 分组在（中间路由器）（交换机）的排队时延 分组时延 三次握手过程 客户向服务器发送小TCP报文 服务器用小TCP报文做出确认和响应 客户向服务器返回确认 这三次握手中 前两部分花费 一个RTT握手后向该TCP连接发送HTTP请求报文 一旦请求报文到达服务器 服务器就在TCP连接上发送HTML文件该HTTP的请求和响应用了一个HTTP 服务器传输HTML花费了时间一共为 2RTT+传输时间 2.采用持续连接的HTTP 非持续链接的缺点： 每次连接都需要： 分配TCP缓存区和保持TCP变量 这给Web服务器造成了很大的负担 每一个对象都会造成上面的时延时间 HTTP1.1 在服务器响应后 保持TCP打开 用单个TCP进行传送 在一定的时间间隔没有被使用HTTP服务器再关闭连接HTTP2 它允许再相同连接中多个请求和回答错误 增加了连接中优化HTTP报文请i去和回答机制 2.2.3 HTTP请求报文格式1.HTTP 请求报文12345GET /somedir/page.html HTTP/1.1HOST: www.someschool.eduConnection: closeUser-agent: Mozilla/5.0Accept-language: fr 第一行：请求行后继行：首部行 2.HTTP 响应报文真实的HTTP响应报文：用Telnet 登录到喜欢的Web服务器上 请求报文请求放在该服务器上的某些对象 123456789101112131415161718telnet gaia.cs.umass.edu 80Trying 128.119.245.12...Connected to gaia.cs.umass.edu.Escape character is &#x27;^]&#x27;.GET /kurose_ross/interactive/index.php HTTP/1.1Host: gaia.cs.umass.eduHTTP/1.1 200 OKDate: Wed, 27 Nov 2024 13:06:02 GMTServer: Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips PHP/7.4.33 mod_perl/2.0.11 Perl/v5.16.3X-Powered-By: PHP/7.4.33Set-Cookie: DevMode=0Transfer-Encoding: chunkedContent-Type: text/html; charset=UTF-8&lt;!DOCTYPE HTML&gt;&lt;html&gt; 这里的GET &#x2F;kurose_ross&#x2F;interactive&#x2F;index.php HTTP&#x2F;1.1Host: gaia.cs.umass.edu格式很重要 回车必不可少 只想看HTTP协议的报文行 用HEAD代替GET上述简短的两行代码 打开了主机 .edu的80端口的TCP连接 发送了一个HTTP请求报文 1234567891011121314telnet gaia.cs.umass.edu 80Trying 128.119.245.12...Connected to gaia.cs.umass.edu.Escape character is &#x27;^]&#x27;.HEAD /kurose_ross/interactive/index.php HTTP/1.1Host: gaia.cs.umass.eduHTTP/1.1 200 OKDate: Wed, 27 Nov 2024 13:11:35 GMTServer: Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips PHP/7.4.33 mod_perl/2.0.11 Perl/v5.16.3X-Powered-By: PHP/7.4.33Set-Cookie: DevMode=0Content-Type: text/html; charset=UTF-8 插入GT方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，可以对GET请求的数据做缓存，这个缓存可以做到浏览器本身上(彻底避免浏览器发请求)，也可以做到代理上（如gix)，而且在浏览器中GET请求可以保存为书签。 POST因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。所以，浏览器一般不会缓存POST请求，也不能把POST请求保存为书签。 减少HTTP请求次数1.减少重定向请求次数 重定向请求越多，那么客户端就要多次发起 HTTP 请求 每一次的 HTTP 请求都得经过网络，这无疑会越降低网络性能 重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了代理服务器知晓了重定向规则后，可以进一步减少消息传递次数 2.2.4用户与服务器的交互 cookieHTTP服务器是无状态的 不需要验证。但是站点是希望能够标识用户， 因为服务器可能需要限制用户的访问，这就需要把内容和用户关联到一起HTTP使用了 cookie cookie的四个组件 HTTP响应报文的一个cookie首部行 HTTP请求报文的一个cookie首部行 用户端系统保留一个cookie文件浏览器进行管理 位于WEB站点的后端数据库 这样当Susan再次访问一个站点的时候 浏览器放入首部行 就不用再输入一些信息了实行了”点击购物“ 2.2.5 Web缓存 还需要 深入理解缓存器带来的好处 HTTP中的 强制缓存和协商缓存 强制缓存定义：强制缓存是指客户端直接使用本地缓存的数据，而不会向服务器发送请求验证数据的有效性。 工作方式： HTTP 头部中：使用 Cache-Control 指定缓存策略（例如 max-age）。或使用 Expires（HTTP&#x2F;1.0，已逐步被 Cache-Control 替代）指定缓存失效时间。如果缓存未过期，浏览器会直接从本地缓存读取数据，而不会与服务器通信。特点： 节约资源：不需要请求服务器。时效性：受 max-age 或 Expires 的约束，可能存在缓存失效时间的误差。 协商缓存 (Conditional Cache)定义： 协商缓存是指客户端向服务器发送请求，验证本地缓存是否有效。如果有效，服务器返回一个状态码（如 304 Not Modified），客户端可以继续使用本地缓存的数据；否则，服务器返回最新的数据。 工作方式： HTTP 头部中：请求头：使用 If-Modified-Since 或 If-None-Match。响应头：服务器返回 Last-Modified（表示资源最后修改时间）或 ETag（资源的唯一标识符）。客户端会将缓存中记录的 ETag 或 Last-Modified 发送到服务器进行验证：如果验证通过（服务器认为缓存未修改），返回 304。如果验证失败（资源已更新），返回新的资源数据（200 OK）。特点： 相对准确：确保缓存数据的有效性。需要通信：每次都需要向服务器发送请求进行验证。 缓存命中率内容分发网络（CDN）：多个共享CDN 专用CDN 条件GET方法问题： 存放在混村其中的对象副本是旧的，或者再保存到服务器中的对象再缓存到客户上之后 就被修改了HTTP协议机制： 允许缓存器证实它的对象是最新的 也就是（条件GET） If-modified-since: Wed, 9 Sep 2015 09:23:24 ”If-Modified-Since“首部行 这个请求报文就是条件GET请求报文 缓存器在存储对象的同时也存储了最后的修改日期 缓存器通过一个条件GET执行最新查询这条语句告诉服务器 仅当指定日期后该对象被修改过 才发送对象 如果没有修改过 则相应的时候没有body 因为再次返回一样的body会浪费宽带 插入 数据流在实践中，客户端指定数据流的优先级通常是在使用 HTTP&#x2F;2 时实现的。HTTP&#x2F;2 引入了流优先级（Stream Priority）机制，允许客户端为每个流指定一个优先级值，这个值会影响服务器在资源争用时对请求的处理顺序。 流优先级机制优先级参数：每个 HTTP&#x2F;2 流都可以有一个权重值（weight），范围是 1 到 256，数字越大，优先级越高。依赖关系：每个流还可以声明依赖于另一个流（dependency）。如果一个流依赖于另一个流，服务器会优先完成被依赖的流。服务器根据这些参数决定如何分配带宽和计算资源。 实现流优先级的例子客户端的实现（使用 cURL）我们可以用支持 HTTP&#x2F;2 的工具，如 curl，来演示流优先级的使用。 发送两个并发请求（模拟流） curl –http2 -o output1.html https://example.com/slow-response &amp;curl –http2 -o output2.html https://example.com/fast-response &amp;wait默认情况下，这两个流的优先级相同，服务器会尽力均匀分配资源来处理它们。 设置优先级 使用 –http2-prioritize 选项来设置优先级。例如： curl –http2 –http2-prioritize-weight 256 -o fast.html https://example.com/fast-response &amp;curl –http2 –http2-prioritize-weight 1 -o slow.html https://example.com/slow-response &amp;wait这里： fast-response 的优先级为 256（最高）。slow-response 的优先级为 1（最低）。服务器会优先响应 fast-response 流。 2.3 因特网中的电子邮件3个主体组成部分 用户代理 邮件服务器 简单邮件传输协议 SMTP： 应用层协议 使用TCP可靠数据传输 每台邮件服务器上：既运行SMTP的客户端也运行SMTP的服务器端因为： SMTP发送邮件的时候 表现为： 客户端 SMTP接收邮件的时候 表现为： 服务器端 使用7bit ASCII标识 2.3.1 SMTP 12.18 日 套接字编程： UDP套接字： TCP套接字","categories":[{"name":"计算机系统","slug":"计算机系统","permalink":"https://whuichenggong.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"青训营直播总结","slug":"技术分享/Dance_live","date":"2024-11-13T12:05:27.817Z","updated":"2025-05-11T07:20:03.568Z","comments":true,"path":"2024/11/13/技术分享/Dance_live/","permalink":"https://whuichenggong.github.io/2024/11/13/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/Dance_live/","excerpt":"","text":"听了前端文杰老哥分享 总结：计算机基础很重要必须要持续学习： 例如：计算机原理，操作系统等，在工作中有些人问题你需要定位到它的问题出在了那里，这个问题的对应着是哪个方面的问题学习ai提示词，提高学习效率，练好基本功，多写代码，多用大模型 前期多学习如何编码而不是太多关于工程化的问题 建议：解决问题:事实是，就业环境中大概率没人把你当学生般保护着，别人没有义务要解决你的问题(不合理，不科学)，请务必提升自己解决问题的能力。 学习:工作中，很难找到手把手教你做事的团队，多数时候都是靠自学，没有课本，没有老师，没有标准答案，全凭自己，所以务必提升独立学习能力; 二极化:世界不是非黑即白，代码也是，职业也是，接受、包容多样性吧，多从不同角度思考问题，从不同渠道了解解决问题的方法，学会更体系化地思考; LLM:非常值得花很多时间学习，用好这个工具，提升你个人效率;但它不是魔法，不要幻想着学会了就能怎么这么样; (目前只停留在问题的复制粘贴 效率很低)","categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://whuichenggong.github.io/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"}],"tags":[]},{"title":"Go语言进阶","slug":"go/Go_Advanced","date":"2024-11-11T11:47:00.753Z","updated":"2025-05-11T07:20:03.552Z","comments":true,"path":"2024/11/11/go/Go_Advanced/","permalink":"https://whuichenggong.github.io/2024/11/11/go/Go_Advanced/","excerpt":"","text":"字节青训营学习一.入门篇学习实战篇： 1.猜数字游戏运用 1234567891011121314151617181920212223242526”math/rand“maxNum := 100调用 Intn（maxNum）//注意这并不能使每一次都用都产生不同的值需要加 时间戳 才能每次产生不同的值应该是：maxNum := 100ran.Seed(time.Now().UnixNano())然后调用 ran.Intn（maxNum） 用 &quot;bufio&quot; 这个特别的包以后可以用到 这里读取一行输入用的是 reader := bufo.NewReader(os.Stdin)//调用这个可以更加灵活 input， err := reader.ReadString(&#x27;\\n&#x27;) if err != nil&#123;...&#125; input = strings.TrimSuffix(intput,&quot;\\n&quot;)//去掉换行符 guess,err := strconv.Atoi(input)//转换成数字 菜值逻辑 2.在线词典介绍12345678910go run simpledict/v4/main.go hello//意思是查询hello这个功能//会输出以下内容hello UK:[&#x27;he&#x27;lau]US:[ha&#x27;lo]int.喂；哈罗n.引人注意的呼声V.向人呼（喂调用第三方api 生成请求 https://curlconverter.com/ 写入curl 自动生成代码 示例： 会输出一些列bilibili的东西 json序列化 衍生出以下 1结构体 1234request ：= DicRequest&#123;Trans Type：&quot;en2zh&quot;,Source:&quot;good&quot;&#125;buf, err := json.Marshal(request)//序列化request 变成byte数组if~~~var data = bytes.NewReader(buf) //因为buf返回的是bytes数组所以我们应该 bytes.NewReader 解析response 进行反序列化 json转golang 结构体 https://oktools.net/json2go 反序列化 12345err = json.Unmarshal(bodytext,&amp;dictResponse)//传入结构体fmt.Println(&quot;%#v&quot;,dicResponse) Go进阶1.并发编程并发：多线程在一个核运行 时间碎片 并行： 多核 并行是并发的手段 2.协程 协程：轻量级线程 线程本身重量级 Goroutine：可以实现上万个携程 例子:协程 go关键字开启协程 通过通信来共享内存 channel make创建channel 有缓冲： 无缓冲：进行通信时（两个goroutine同步）也称同步通道 示例： 先make创建通道 把数字放入第一个通道里 然后b把src做平方运算 并发安全 Lock Lock（）临界区 3.依赖管理1.GOPATH bin pkg src（项目源码） 无法实现package 的多版本控制 2.vendor存放依赖副本 也有弊端 3.go module 管理 解决了问题 indirect关键词 b（选择最低兼容版本） 4.依赖分发Github SVN … ​ Developer 无法保证构建稳定性 无法保证依赖可用性 增加第三方压力 Go proxy （）缓存内容版本 从proxy拉取依赖 减少第三方压力 Proxy1 -》 proxy2 -》 Direct 依次进行 5.工具 go getgo mod init tidy download 6.测试事故： 测试的重要性：避免事故的最后一道屏障 单元测试 mock测试 回归测试 集成测试 1.单元测试 保证代码整体覆盖率 提升效率 2. 规则 3例子： go test 【flags】 【packages】 4.assert 5.覆盖率 提升覆盖率 对各个分支测试 使函数代码都经过完备的测试 提升覆盖率 减少事故 6.依赖 7.文件处理 一旦文件被别人篡改 在特定场景下就无法运行！ 8.Mock replacement 打桩函数 通过mock 不对 文件有强依&#x2F;study_photo&#x2F;70.png 优化： fastrand 10.项目实践 话题id -》 获取所有post 初始化话题内存索引 逻辑层： 并行处理 三.高质量编程与实践如何编写更简洁和跟清晰的代码 熟悉GO程序性能分析工具 常用Go语言程序优化手段 了解工程性能优化的原则和流程 :性能调优 性能分析工具 性能调优案例 算法效率 1.高质量编程正确可靠 简洁清晰 各种边界条件是否考虑完备 异常情况处理 稳定性保证 易读易维护 团队合作保证容易读 维护 使其增加和调整更加快速 更加清晰 主要是给人看 让人可以看懂 对已有的功能改善 优化 容易添加功能 2.编码规范代码格式 注释 命名规范 控制流程 错误和异常处理 不需要注释实现接口的方法 这种注释可以删除 1.gofmt推荐使用gofmt 自动格式化代码为官方统一风格 2.注释注释应该解释代码的作用 注释应该解释代码如何做的 注释应该解释代码实现的原因 注释应该解释代码什么情况会错 下面的根本不需要注释没有什么必要 函数名字已经说明了 最后一条语句是很难理解的 如果没有注释 一定要会看英文呵呵 此时的t就减少了很多东西 例如http中调用 Server 是 http.Server 若用 ServerHTTP http.ServerHTTP这样感觉就变得冗余了没有必要 避免if else嵌套 包含同样语句可以去掉 重复语句 这样看起来比较复杂 调整后： 控制流程 ： 线性原理 尽量走直线 避免复杂的嵌套分支 3.错误和异常处理 性能调优原则：1.依靠数据而不是猜测2.定位到最大瓶颈（也就是影响最大的部分），3.不要过早优化4.不要过度优化 性能调优工具：pprofpprof：可视化和性能分析数据的工具 pprof实战项目：下载项目 并且运行： GIthub：https://github.com/wolfogre/go-pprof-practice go run main.go 等待编译 等待一段时间 输入：http://localhost:6060/debug/pprof/ 在浏览器中 此时的cpu 内存状态： 以下输出： 思考： 什么情况下 Flat &#x3D;&#x3D; Cum Flat&#x3D;&#x3D;0 分别为1. 函数中没有调用其他函数 都是本函数使用的时间2. 函数中只有其他函数调用并且时间占用也很少可以忽略不计 在查看到tiger中有一部分占用了很大的时间 把相关的代码注释后 内存方面并没有解决什么 Heap：堆内存分析： 在终端使用这个指令go tool pprof -http=:8080 &quot;http://localhost:6060/debug/pprof/heap&quot;…没有下载工具先放一下 先截屏 锁：go tool pprof -http=:8080 &quot;http://localhost:6060/debug/pprof/mutex&quot; 性能优化GO语言优化内存管理优化 编译器优化 什么是性能优化 ，为什么要做性能优化？ ：提升软件系统处理能力，减少不必要的消耗 ：用户体验，让用户刷抖音不卡顿 ：资源高效利用，成低成本，提高效率 业务代码：处理用户请i去 SDK：go的SDK 基础库： 这两部分提供抽象逻辑（数据结构 网络库 io库） 语言运行时： gc 调度器（go语言） OS 性能分析工具：pprof 依靠数据而非猜测 优化最大瓶颈 Go的SDK 接口 命令 APIs 测试 来 驱动开发 隔离： 通过选择控制是否开启优化 可观测： 静态分析： 自动内存管理基于追踪的垃圾回收 GC 动态内存 malloc 自动内存回收： 避免手动内存管理 专注于实现业务逻辑 保证内存使用的正确性和安全性 为新对象分配空间 偷懒了：实在不知道怎么记了 留着以后学的更深入一些再看吧 四.数据库数据库database&#x2F;sql GORM ： 业务需求驱动开发 基本用法 规定 数据库约束 Select实现级联删除 数据结构与算法1.经典排序算法为什么要用数据结构和算法： 最快的排序算法：Go ： introsort 1.19的默认排序算法：如何设计的 生产环境和课本上的排序算法有什么区别 1.插入排序：（洗牌） 时间复杂度：最好O（n）有序 平均O（n^2） 最坏 （n^2） 缺点：太慢 优点：最好 2。快速排序： 时间复杂度；最好 O（nlogn） 平均O（nlogn）最坏O（n^2） 缺点 最坏太慢 优点 平均的挺好 3.堆排序 网络与部署《负载均衡 高并发网关原理与实践》 协议基础 协议分析（自学） 熟悉tcp&#x2F;ip 熟悉计算机网络 抖音视频 加载出来 会有什么交互（网络是如何交互的）（为什么刷抖音又快又稳）（计算机网络要解决什么问题 发现什么问题） 应用层： 域名解析（DNS） 图片下载 视频下载（HTTP）评论API&#x2F;HTTP 网络接入 网络传输 手机要先访问抖音服务器 终端（pc pad） 通过 4g &#x2F;wifi 通过有线网络 接入 四大运营商网络 -》 接通抖音的机房（服务器） 还用通过光缆（海底） 接通 美国网络 网络接入 （路由）交换机&#x2F;逻辑交换机&#x2F;网络虚拟化 路由一定对称吗？ 路由是工作在哪一层协议？ 路由协议（ip层） 本身不是ip层 动态路由协议（传输层协议bgp）（基于tcp udp）可能 不是很简单 路由改的是ip地址吗？ 不是改ip地址 而是mac地址 路由是为了找到目标ip 怎么找下一跳（网络中间节点）的MAC 通过 ARP协议 跨网段 不能发送ARP 同网段可以发送ARP 否则需要一级一级的发送 免费ARP：（）新加入机器（向其中发送免费ARP ： 防止ip冲突 在同一局域网里有两个同一个ip ） ARP：本质是查找下一跳MAC 而不是目标请求地址 ARP 代理： 中间设备抢先应答 （） IP协议 唯一标识 为什么Mac（2层）（以太网） 地址不能代替ip协议 ： IP协议把MAC地址问题 解决了 ipv4不够用 怎么解决：如果不支持ipv6 ， 用NAT（原理 内部用户 通过NAT） 问题2 ： （NAT ip＋端口）一起改变 解决第二个问题 网络打通视频怎么下载 也就是服务的封装与拆解 如何把域名映射到ip （DNS基于UDP协议（端口＋校验）） 避免分片 丢包丢了UDP也不知道 TCP连接 三次握手TCP连接状态 如果拔了网线，连接会断吗（没有什么关系） keep-alive ：保活机制（不会一定断开在一定场景下） TCP传输 很复杂的协议 Timewait？（） 状态复杂 TCP丢包 滑动窗口 流量控制 网络传输 HTTP&#x2F;HTTP1.1 HTTPS 解密 出来仍然是HTTP 防止中间者偷听一些东西 加密之后中间人听不懂 SSL&#x2F;TLS握手 非对称加密 对称加密 网络架构网络提速 HTTP 2.0 （多路复用） 并行下载 并行访问 一次性加载了多个图片 （并行请求 一次性发送了） 多路复用： TCP （丢包 其他包等待（对头阻塞）） 协议优化： TCP本身协议不可插拔 UDP（基于UDP扩展） kernel （windows mac 安卓 ios ）是否都要去实现呢？ Google实现在了用户态（方便） RTT QUIC（实现了UDP的扩展）(弱网优势) （解决了队头堵塞）（优化了HTTp2.0的多路复用） 路径优化 服务器集合（数据中心） POP接入（核心机房） 边缘机房（靠近用户（上海电信 上海移动……）） 同运营商访问 （访问客户端ip 电信 解析到 电信） 电信 访问 电信 移动 访问 移动 若要使两者跨网访问（丢包率较高） 路径优化（CDN） 网络提速-静态资源 （边缘机房（缓存）直接从缓存中取出资源 如果找不到 -》 核心机房） 动态API （播放 &#x2F; 评论接口）（因为信息不一样） DSA（路径优化算法） 直连最快 机房延迟探测 （做成表（通过算法 找到最优路径）） 网络提速的优化之路几天就挂了怎么办？？ 抖音稳定性如何调高？ 专线： 内部字节机房-》没有走外部internet（如果走internet 如果从北京 访问 上海 可能会造成中间去到江苏再回到上海这样会很慢 并且丢包等）-》自己拉线连接两个机房（通过交换机等）（这样速度更快） b -》 c 外网：机房内部专线以外的网络通过internet连接 （如果专线挂了）需要走外网容灾 微服务可能跨机房 全局容灾系统 ： A机房不可用了 （自动容灾） 探测机房b的容量可以承载 a机房的容量 自动降级&#x2F;容灾 云到端 SDK告诉端，不要访问，崩了的A机房 云控 什么场景云控控制不到（Web服务器 字节搜索&#x2F;百度搜索 ） 故障明确 沟通： 明确是什么业务 什么接口故障 故障体现在哪？ 其他目标是否访问正常（业务A有故障 接口A有问题 其他的是否有问题？） 是否是修改导致的异常？（如果是就回退） 如果你上传导致的错误（找是谁 ） 先止损 再 排查（debug） 如何止损 分段排查 常用指令 最后一个是抓包工具 误判断 摘除了 好的服务器 线上debug（p0级别事故） 抓包： 快速发包（路由对称）实际路由并不是对称的（找下一跳） 故障预防真的很重要 课后作业 企业级输入网页到内容加载出来 中间都经历了什么 （TCP握手 SSL 域名解析） 浏览器抓包 看第一条请求了什么 网络卡 还是服务器满 还是什么？ 企业接入： 域名系统 自建DNS服务器 HTTPS 接入全站加速 四层负载均衡 七层负载均衡 example公司 Host -》 ip映射 问题： 流量和负载 名称冲突 时效性（） 使用域名系统使用域名系统 替换hosts 域名购买 购买二级域名 example.com 域名备案防止从事非法运动 建设外部网站： 自建DNS： 取代云厂商 先访问 本地DNS服务器 -》 根 -》 顶级 -》权威-》本地缓存 DNS查询过程 权威DNS系统架构 接入HTTPS协议HTTP明文传输 被抓去后 信息很容易被暴露出来 加密算法： 对称加密： 一份密钥 非对称加密 ： 公钥和私钥 （公钥加密私钥解密 或者 对调）（锁头和钥匙） SSL 通信过程： 证书链： 公钥是不是可信的 会不会被劫持？ 数字签名 外网访问站点一定是一帆风顺的吗： 1.源站（网站） 容量第 可承载的并发请求数低 容易打跨 2.报文经过的网络设备越多 出问题概率越大 丢包 劫持 3.自主选择网络链路长 时延高 整体看来：就是响应慢 卡顿 优化： 增加后端机器扩容 静态内容 全站加速： 静态加速：CDN cpu访问 （缓存） 动态加速： DCDN原理 ： RTT： 用户到核心 用户到边缘 边缘到汇聚 汇聚到核心 全站加速 消息队列 kafka用户行为： 搜索 点赞 评论 收藏 使用场景： 搜索服务， 直播服务 订单服务 支付服务 如何使用Kafka： 创建集群 新增topic 编写生产者逻辑 编写消费之逻辑 Kafka架构： Zookeeper Producer 批量发送 数据压缩 Broker 数据存储 消息文件结构 磁盘结构 ​ 操作系统： 顺序写： 提高写入效率 Broker 偏移量索引文件 二分查找 Broker 时间戳索引文件 传统数据拷贝： 操作系统层面： 数据的内存拷贝（开销很大） Broker零拷贝 Consumer-消息接收端 通过手动分配 哪一个Consumer消费哪一个Partition 完全由业务决定 缺点 不能自动容灾 优点： 快 自动分配 High-level 存储与数据库数据的持久化 1.校验数据的合法行 （名字是否存在） （修改内存 用高效的数据结构组织数据）（写入存储介质 以寿命 性能友好写入硬件）（） 什么是存储系统？ 一个提供了 读写 控制类接口 能够安全有效的 把 数据持久化的软件 称为 存储系统 user Medium Memory Network(把原有的单机 升级到分布式系统) 还可能与这些有关 特点： 性能敏感 容易受硬件影响 代码既简单又复杂（考虑到多种异常情况） 存储器层级结构： Persistent Memory 数据怎么从应用到存储介质 数据拷贝 消耗cpu 如果cpu全部用来拷贝 软件性能就会降低（减少拷贝的使用） Disk（） RAID技术： 单机存储怎么做到 高性能&#x2F;高性价比&#x2F;高可靠性 背景： 大容量磁盘价格》 多块小容量磁盘 单块磁盘的写入性能 《 多块磁盘的并发写入性能 RAID0 多块磁盘的简单组合 数据条带化存储 调高磁盘带宽 没有额外的容错设计 RAID1 一块磁盘对应一块额外镜像盘 真是空间利用率50% 容错能力强 上面是两个极端 RAID 0 + 1 RAID 0 和 RAID 1 数据库和存储系统不一样吗？关系型数据库（是存储系统） 非关系型数据库 关系是什么： 关系模型（EFCodd）&#x3D; 集合 反映了事务间的关系 关系代数 &#x3D; 运算的抽象查询语句 SQL &#x3D; 一种DSL （方便人类阅读的 关系代数表达式） 关系型数据库：结构化数据友好 支持事务（ACID）支持复杂的查询语言（sql 全集 子集） 非关系型数据库（也是存储系统）： 半结构化数据友好 可能支持事务（ACID） 可能支持复杂查询语言 数据库 vs 经典存储 - 结构化数据管理 事务能力：要么全做 要么全不做 数据状态是一致的 可以隔离多个并发事务 避免影响 事务一旦提交成功 数据保持持久性 复杂查询能力：复杂查询： 请查询出以xiao开头 密码提示问题小于10个字的人 并按照性别分组统计人数 左边灵活简介 右边复杂 支流产品剖析单机存储系统单个计算机节点上的存储软件系统 一般不涉及网络交互 key-value存储 本地文件系统 本地文件系统 一切皆文件： 文件系统管理单元： 文件 文件系统接口： 文件系统繁多 Ext2 遵循VFS统一抽象接口 linux 文件系统的两大数据结构 ：Index Node Directory Entry innode 记录文件元数据 如id 大小 权限 磁盘位置 innode 是一个文件的唯一标识 会被存储到磁盘上 innode总数在格式化文件系统时就固定了 ​ 1：1 1.Directory Entry 记录文件名 innode指针 层级关系 dentry时内存结构 与innode 关系时N：1 key-value存储 put(k,v) get(k) LSM-Tree 某种程度上牺牲读性能 追求写入性能（） 拳头产品： RocksDB 分布式存储： 在单机存储基础上实现了分布式协议，实际大量网络交互 分布式文件系统 分布式对象存储系统 HDFS ： 核心： 支持海量数据存储（使用普通硬件堆叠） 高容错性 弱POSIX语义 使用普通x86服务器-极高性价比高 DataNode Ceph- （分布式存储）开源分布式存储系统里的【万金油】 里面的算法很好 一切皆对象； 数据写入采用主备复制模型 数据分布模型采用CRUSH算法 单机数据库 单个计算机节点上的数据库系统 事务在单机内执行 通过网络交互实现分布式事务 关系数据库 商业产品Oracle 开源产品 MySQL PostgreSQL Page Redo Log 临时文件 内存 与 磁盘之间的交互 非关系型数据库 没有准则 交互方式各不相同 schema相对灵活 SQL查询语言的统治地位很重视 模糊搜索 Query： match 编程语言 好 难度 模糊匹配到小明的帖子 ES天然能够做 模糊搜索 还能自动算出关联程度 传统关系型无法做到这一点 分布式数据库（引入分布式架构）： 容量 弹性 性价比 解决单机时代遇到的问题 解决容量问题： 存储池 动态扩缩容 弹性问题： 随着业务的变化而变化 1t如何搬到200g？ 池化！ 性价比问题 硬件disk不需要怎么准备 什么不够用Storge Pool 分布式存储池来解决这个问题 磁盘池化 内存池化（降低成本） 单写vs多写 从磁盘弹性到内存弹性 分布式事务优化 新技术演进软件架构变更（依赖于操作系统内核） AI增强（智能存储格式转换） 新硬件革命（存储介质变更 计算单元变更 网络硬件变更） cpu中断 使性能降低 与之替换的是用轮询替换 数据存储格式的转换 左边是二维表由 多个行与列 行存 列存 （优势 劣势） ai决策-》行列混存（动态性强） 硬件反推软件变革 课后作业 材料引用 深入理解RDBMS（关系型数据库）存储系统: 块存储 文件存储 对象存储 key-value存储 数据库系统： 大型关系数据库 非关系型数据库 抖音红包雨 从抖音账号扣除1个亿 事务ACID 红包雨与ACID 事务要同时成功与同时失败 账户的钱不能为复数 操作一定要是合法的 隔离性问题 ： 两个操作同时进行 有相互影响的关系 刚开始抢了一个亿（成功） 但是服务器挂了 高并发 10亿人 同时抢红包 一定 数据要有处理高并发的能力 每秒处理事务的请求 高可靠 在关键时间和结点上 保证后台服务可靠 从 纸 到 磁盘文件 第一个数据库 网状数据库（W.Bachman） ​ Collage English computer Maths 多对多 没有交叉 结点 网络结构 父节点可以有多个子节点 层次模型（IBM） 用树形结构描述实体 与 网状结构相似 但是并不交叉树状 每个子节点只有一个父节点 （1对多） 关系模型（IBM）（EFCodd博士） 关键技术一条SQL的一生 ： 解析SQL（语法解析器） 语法树AST 优化器 Plan Executor（执行器） 写入数据 写入日志 分析 为什么还要优化器？（Optimizer） 类比于 （高德地图路线优化） 快 慢 红绿灯 基于规则的优化 条件简化…… Scan优化 基于代价优化： 时间是代价 最少时间到目的地 io cpu NET MEM也是代价 火山模型： 向量化： 每次返回是一批数据 而不是一行数据 优点： 函数调用次数降低为1&#x2F;N CPU cache命中率更高 可以利用CPU提供SIMD机制 一次加法（可以操作多个数据） 编译执行： 存储引擎-InnoDB内存态（做一点内存缓存） 存储引擎-Buffer Pool instance0 instance1 HashMap管理 LRU 算法 保留最近最常使用的保存在内存 其他的 淘汰 内存放不下？ 放磁盘 从磁盘访问数据 存储引擎-Page B+Tree索引 B树的扩展（二分查找树） 事务引擎：原子性 与 Undo Log 同步失败或成功 如何将数据库回退到修改之前的状态？ Undo日志： 逻辑日志 进行事务回滚 保证原子性 isolation 与 锁 如果两个操作同时发生 发生冲突怎么办 锁机制 Share Lock 共享锁 读读 两个人都有共享锁 Exclusice Lock 写锁 读写 一个有写锁另一个不能有 读写 -》 MVCC数据的多版本 一致性： 对数据的修改 永久保存 方案一 事务提交前页面写盘 随机io 写放大 方案二 WAL","categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"}],"tags":[]},{"title":"后端项目学习","slug":"项目/Simple_bank","date":"2024-11-09T13:19:10.454Z","updated":"2025-05-11T06:58:58.729Z","comments":true,"path":"2024/11/09/项目/Simple_bank/","permalink":"https://whuichenggong.github.io/2024/11/09/%E9%A1%B9%E7%9B%AE/Simple_bank/","excerpt":"","text":"重新开启simplebank学习！！！一.创建数据库表https://dbdiagram.io 可视化数据库工具 1.创建账户表1234567Table accounts as A &#123; //A作为account的别名 id bigserisal [pk] //pk作为主键 自增的id列 owner varchar balance bigint currency varchar created_at timestamp [default: `now()`] //自动获取时间&#125; 2.创建条目表&#x2F;&#x2F;记录账户余额的变化 123456Table entries &#123; id bigint [pk] // account_id bigint [ref : &gt; A.id] //外键 账户和条目之间是1对多关系 amount bigint [not null note:`可以是负或者正`] //正负取决于取出还是存入 note是添加注释 created_at timestamp [default: `now()`] //记录条目的创建时间&#125; 3.创建 转账表1234567Table transfers &#123; id bigint [pk] from_account_id bigint [ref : &gt; A.id] to_account_id bigint [ref : &gt; A.id] amount bigint [not null note: `一定不能为空`]//note为注释 created_at timestamp [default: `now()`]&#125; 在此之后向列中添加非空约束 例如 ： balance bigint [not null] &#x2F;&#x2F; 非空约束是一种用于限制数据库表中某列不能为空的约束 枚举 1234Enum Currency&#123;USDEUR&#125; 向表中添加索引 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Use DBML to define your database structure// Docs: https://dbml.dbdiagram.io/docsTable accounts as A &#123; id bigserisal [pk] owner varchar [not null] balance bigint [not null] currency varchar [not null] created_at timestamp [default: `now()`] Indexes &#123; owner &#125;&#125;Table entries &#123; id bigint [pk] account_id bigint [ref : &gt; A.id] amount bigint [not null] created_at timestamp [default: `now()`] //列出特定账户的所有条目Indexes &#123; account_id&#125; &#125;Table transfers &#123; id bigint [pk] from_account_id bigint [ref : &gt; A.id] to_account_id bigint [ref : &gt; A.id] amount bigint [not null] created_at timestamp [default: `now()`] Indexes &#123; from_account_id to_account_id (from_account_id,to_account_id)&#125;&#125; 这些做好之后使用导出功能 生成代码 123456789101112131415161718192021222324252627282930313233343536373839404142CREATE TABLE &quot;accounts&quot; ( &quot;id&quot; bigserisal PRIMARY KEY, &quot;owner&quot; varchar NOT NULL, &quot;balance&quot; bigint NOT NULL, &quot;currency&quot; varchar NOT NULL, &quot;created_at&quot; timestamp DEFAULT (now()));CREATE TABLE &quot;entries&quot; ( &quot;id&quot; bigint PRIMARY KEY, &quot;account_id&quot; bigint, &quot;amount&quot; bigint NOT NULL, &quot;created_at&quot; timestamp DEFAULT (now()));CREATE TABLE &quot;transfers&quot; ( &quot;id&quot; bigint PRIMARY KEY, &quot;from_account_id&quot; bigint, &quot;to_account_id&quot; bigint, &quot;amount&quot; bigint NOT NULL, &quot;created_at&quot; timestamp DEFAULT (now()));CREATE INDEX ON &quot;accounts&quot; (&quot;owner&quot;);CREATE INDEX ON &quot;entries&quot; (&quot;account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;from_account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;to_account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;from_account_id&quot;, &quot;to_account_id&quot;);//将外键添加到表中ALTER TABLE &quot;entries&quot; ADD FOREIGN KEY (&quot;account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);ALTER TABLE &quot;transfers&quot; ADD FOREIGN KEY (&quot;from_account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);ALTER TABLE &quot;transfers&quot; ADD FOREIGN KEY (&quot;to_account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;); 二.Docker用指令创建容器的时候 一定要注意-p参数 将容器的端口映射到主机上 一定要保证端口不要被占用 否则将会产生问题 拉取镜像语法 1docker pull &lt;image&gt;:&lt;tag&gt; 开始一个容器指令 1234567891011121314151617181920212223242526272829303132333435361.docker run --name &lt;container_name&gt; -e &lt;environment_variable&gt; -d &lt;image&gt;:tag:2.docker run --name some-postgres -e POSTGRES_PASSWORD=mysecret -d postgres #！！！端口映射 -p 5432:5432 //注意防止端口冲突自行更改示例：docker run --name postgres12 -e POSTGRES_USER=root -e POSTGRES_PASSWORD=secret -d postgres:12-alpine 3. docker exec -it &lt;contain_name_or_id&gt; &lt;comman&gt; [args]示例：#进入psql控制台docker exec -it postgres12 psql -U root4.显示容器日志docker logs &lt;container_name_or_id&gt;示例:docker logs postgres125.连接shell指令：docker exec -it postgres12 /bin/sh#创建新的数据库createdb --username=root --owner=root simple_bank#使用psql连接 psql simple_bank #删除数据库 dropdb [名称] exit退出shell #指令结合 docker exec -it postgres12 createdb --username=root --owner=root simple_bank docker exec -it postgres12 psql -U root simple_bank #查找指令 history | grep &quot;docker run&quot; //linux history | Select-String &quot;docker run&quot;//windows 区分 docker中的 镜像和容器 docker image中包含多个运行 容器的应用实例 类似结构： - docker image ├── container1 ├──container2 ├──container3 三.Tableplus将sql文件导入到tableplus中 在tableplus中删除表 使用sql指令 1DROP TABLE accounts CASCADE; //注意替换表名称 四.DB migration迁移指令： 1migrate create -ext sql -dir db/migration -seq init_schema up&#x2F;down migration：理解迁移 类比栈结构 向上新数据表 向下 旧数据表 使用migrate up指令时 Old DB 在文件中 一次按照 1.up.sql 2.up.sql 3.up.sql 依次运行到New DB 使用migrate down指令时 New DB 在文件中依次按照 3.up.sql 2.up.sql 1.up.sql 依次运行到Old DB old DB schema —–&gt; migrate up —––&gt; x.up.sql —–&gt;New DB schema ​ &lt;—————————- x.down.sql &lt;———migrate down&lt;————- 将最开始的.sql文件放入 .up.sql中 五.Makefile文件创建规则后使用 make指令 快速创建 如果你是萌新开始给到你一个项目 你可以通过makefile文件快速构建 12345678910migrate -help#通过看日志 知道使用什么指令来工作#迁移指令migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank&quot; -verbose up#出现ssl错误添加sslmode=disabled#出现了一系列的迁移错误 解决方案强制更改版本migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; -verbose force 1 六.数据库的CRUDDATAVASE&#x2F;SQL库 GORM sqlx（兼容多） sqlc（最好的 融合了以上两者的优点） 七.使用sqlc1sqlc init 介绍: sqlc 从 SQL 生成类型安全的代码。以下是它的工作原理： 您使用 SQL 编写查询。 运行 sqlc 来生成具有这些查询的类型安全接口的代码。 编写调用生成的代码的应用程序代码。 查看一个交互式示例来了解它的实际应用，以及 sqlc 背后的动机的介绍性博客文章。 八.sqlc.yaml123456789101112131415161718version: &quot;2&quot;sql:- schema: &quot;simplebank/db/migration&quot; //数据库表 queries: &quot;db/query&quot; //数据库查询 首先要编写数据库查询 engine: &quot;postgresql&quot; //使用的数据库 gen: go: package: &quot;db&quot; out: &quot;simplebank/db/sqlc&quot; sql_package: &quot;pgx/v5&quot; emit_json_tags: true emit_interface: false emit_empty_slices: true overrides: - db_type: &quot;timestamptz&quot; go_type: &quot;time.Time&quot; - db_type: &quot;uuid&quot; go_type: &quot;github.com/google/uuid.UUID&quot; account.sql 12345678-- name: CreateAccount :oneINSERT INTO accounts ( owner, balance, currency) VALUES ( $1, $2, $3) RETURNING *; make sqlc 生成代码1.account.sql.go2.db.go3.models.go在生成之后由于没有 初始化项目 使得项目报红 12go mod init project/simplebankgo mod tidy 九.编写单元测试用例1.导入未使用的包在前面添加_可以防止系统自动将它删除 例如： _ “github.com&#x2F;lib&#x2F;pq “ 错误 12345cannot use conn (variable of type *sql.DB) as DBTX value in argument to New: *sql.DB does not implement DBTX (wrong type for method Exec) have Exec(string, ...any) (sql.Result, error) want Exec(context.Context, string, ...interface&#123;&#125;) (pgconn.CommandTag, 你遇到的错误信息表明，你尝试将 *sql.DB 类型的 conn 变量用作 DBTX 类型的参数，但 *sql.DB 并不满足 DBTX 接口的要求。具体来说，DBTX 接口期望的 Exec 方法签名是 (context.Context, string, ...interface&#123;&#125;) (pgconn.CommandTag, error)，而 *sql.DB 提供的 Exec 方法签名是 (string, ...any) (sql.Result, error)。 目前不理解 方法和接口 开始学习 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687//这是接口type DBTX interface &#123; Exec(context.Context, string, ...interface&#123;&#125;) (pgconn.CommandTag, error) Query(context.Context, string, ...interface&#123;&#125;) (pgx.Rows, error) QueryRow(context.Context, string, ...interface&#123;&#125;) pgx.Row&#125;string, ...interface&#123;&#125;//的含义这是可变参数的声明方式。它表示可以接收零个或多个任意类型的参数。在函数内部，这些参数被视为一个 []interface&#123;&#125;（一个接口类型的切片）。例如，如果有一个函数接受一个字符串和任意数量的其他参数：func myFunction(s string, args...interface&#123;&#125;) &#123; // 函数体&#125;可以这样调用这个函数：myFunction(&quot;hello&quot;, 1, &quot;world&quot;, true)/* 在这段代码中有一个这样的错误我不知道怎么修改cannot use conn (variable of type *sql.DB) as DBTX value in argument to New: *sql.DB does not implement DBTX (wrong type for method Exec) have Exec(string, ...any) (sql.Result, error) want Exec(context.Context, string, ...interface&#123;&#125;) (pgconn.CommandTag,要解决这个问题，你需要确保你的 DBTX 接口的方法签名与 *sql.DB 的实现匹配。具体来说，你需要修改 DBTX 接口的 Exec 方法，使其接受 context.Context 参数。以下是一个可能的解决方案：修改 DBTX 接口，使其 Exec 方法的签名为：type DBTX interface &#123; Exec(ctx context.Context, query string, args ...interface&#123;&#125;) (pgconn.CommandTag, error) // 其他方法...&#125;在你的 New 函数中，确保它接受符合 DBTX 接口的类型。例如，使用 sql.DB 时，你可以创建一个适配器来实现 DBTX 接口。这里是一个适配器示例：type DBAdapter struct &#123; *sql.DB&#125;func (db *DBAdapter) Exec(ctx context.Context, query string, args ...interface&#123;&#125;) (pgconn.CommandTag, error) &#123; result, err := db.DB.ExecContext(ctx, query, args...) return result, err&#125;然后在 TestMain 中使用这个适配器：testQueries = New(&amp;DBAdapter&#123;conn&#125;)这样就能确保 *sql.DB 能正确实现 DBTX 接口，从而解决你遇到的错误。*/!!!!!!!!!!!!!!!!!!!!!!gpt给出解决问题的方法在我不知道用pgx的情况下 gpt给出用pgx连接给gpt看完接口定义之后由于你的 DBTX 接口使用了 pgx 库，你可以使用 pgx 的 Conn 类型而不是 *sql.DB。这里是一个简单的解决方案：使用 pgx 连接：确保在代码中使用 pgx 的连接，而不是 *sql.DB。修改你的数据库连接部分：import ( &quot;context&quot; &quot;log&quot; &quot;os&quot; &quot;testing&quot; &quot;github.com/jackc/pgx/v4&quot;)const ( dbDriver = &quot;pgx&quot; dbSource = &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot;)var testQueries *Queriesfunc TestMain(m *testing.M) &#123; conn, err := pgx.Connect(context.Background(), dbSource) if err != nil &#123; log.Fatal(&quot;cannot connect to db:&quot;, err) &#125; testQueries = New(conn) // 确保 New 函数接收 pgx.Conn os.Exit(m.Run())&#125;确保 New 函数接受 pgx.Conn：在你的 New 函数中，确保它接受 pgx.Conn 而不是 *sql.DB。这样，你的 DBTX 接口与 pgx 的连接就能正常工作，避免了类型不匹配的问题。这样也简化了代码，直接使用了 pgx 连接而不需要适配器。 10.8日 解决目前为止遇见的一个问题遇见的第一个大问题 在account_test.go中和main_test.go中出现的一些问题 *和姐聊了一下 解决了 **testQueries &#x3D; New(conn)*中的问题 main_test.go使用 pgx来连接数据库 而不是视频中讲解的sql.open 他们的返回值类型不同造成了错误 测试函数的拼写错误 可能也影响了一大部分 还有最后一处问题 require.NotEmpty(t, err)这一行存在问题。这里应该是检查account是否不为空，而不是检查错误err是否不为空。正确的应该是require.NotEmpty(t, account)。 不熟悉的地方go语言的包 接口 方法 1.最终的account_test.go代码12345678910111213141516171819202122232425262728package dbimport ( &quot;context&quot; &quot;testing&quot; &quot;github.com/stretchr/testify/require&quot;)func TestCreateAccount(t *testing.T) &#123; arg := CreateAccountParams&#123; Owner: &quot;xiaozhao&quot;, Balance: 100, Currency: &quot;USD&quot;, &#125; account, err := testQueries.CreateAccount(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, account) require.Equal(t, arg.Owner, account.Owner) require.Equal(t, arg.Balance, account.Balance) require.Equal(t, arg.Currency, account.Currency) require.NotZero(t, account.ID) require.NotZero(t, account.CreatedAt)&#125; 2.最终的main_test.go代码12345678910111213141516171819202122232425262728293031package dbimport ( &quot;context&quot; &quot;fmt&quot; &quot;os&quot; &quot;testing&quot; &quot;github.com/jackc/pgx/v5&quot;)var testQueries *Queriesconst ( DATABASE_URL = &quot;postgres://root:secret@localhost:5432/simple_bank?sslmode=disable&quot;)func TestMain(m *testing.M) &#123; conn, err := pgx.Connect(context.Background(), DATABASE_URL) if err != nil &#123; fmt.Fprintf(os.Stderr, &quot;Unable to connect to database: %v\\n&quot;, err) os.Exit(1) &#125; defer conn.Close(context.Background()) testQueries = New(conn) os.Exit(m.Run())&#125;//测试通过！！！！！！！ 上面是指定了一个一个账户 我们想让账户的主人 货币 钱是随机的 编写util中的random代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package utilimport ( &quot;math/rand&quot; &quot;strings&quot; &quot;time&quot;)const alphabet = &quot;abcdefghijklmnopqrstuvwxyz&quot;var rng *rand.Randfunc init() &#123; source := rand.NewSource(time.Now().UnixNano()) rng = rand.New(source)&#125;// 返回一个介于 min max 之间的随机的 int64 数字func RandomInt(min, max int64) int64 &#123; return min + rng.Int63n(max-min+1)&#125;// 生成 n 个字符的随机字符串func RandomString(n int) string &#123; var sb strings.Builder k := len(alphabet) for i := 0; i &lt; n; i++ &#123; c := alphabet[rng.Intn(k)] sb.WriteByte(c) &#125; return sb.String()&#125;//随机生成ownerfunc RandomOwner() string&#123; return RandomString(6)&#125;//随机生成钱的数量func RandomMoney() int64&#123; return RandomInt(0,1000 )&#125;//随机产生一种货币func RandowCurrency() string&#123; currencies := []string&#123;&quot;RMB&quot;,&quot;USD&quot;,&quot;CAD&quot;&#125; n := len(currencies) return currencies[rand.Intn(n)]&#125; **学会如何把自己写的包导入到别的文件夹下 这个需要看go mod下的 module project&#x2F;simplebank ** 把moudle中的包作为起始路径 导入到别的文件夹下 就是：”project&#x2F;simplebank&#x2F;util” ok 截止到 10.8日随机生成的数据生成功 问题2 makefile文件中的下面这个指令 test: go test -v -cover .&#x2F;… 这个指令必须在当前目录下找到go的测试文件 就是go.mod文件应该和makefile保持在一起 解决方法在本地的go.mod文件夹下又创建了一个makefile 用来测试 make test 类型断言 interface代表为止类型 使用前需要 转换为具体类型 (从未知类型转为已知类型) 如： 12var i interface&#123;&#125; = 2num1， ok ：= i.(int)//断言 3.account_test.go代码：全部测试通过！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package dbimport ( &quot;context&quot; &quot;project/simplebank/util&quot; &quot;testing&quot; &quot;time&quot; &quot;github.com/stretchr/testify/require&quot;)func createRandomAccount(t *testing.T) Account &#123; arg := CreateAccountParams&#123; Owner: util.RandomOwner(), Balance: util.RandomMoney(), Currency: util.RandomCurrency(), &#125; account, err := testQueries.CreateAccount(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, account) require.Equal(t, arg.Owner, account.Owner) require.Equal(t, arg.Balance, account.Balance) require.Equal(t, arg.Currency, account.Currency) require.NotZero(t, account.ID) require.NotZero(t, account.CreatedAt) return account&#125;func TestCreateAccount(t *testing.T) &#123; createRandomAccount(t)&#125;func TestGetAccount(t *testing.T) &#123; account1 := createRandomAccount(t) account2, err := testQueries.GetAccount(context.Background(), account1.ID) require.NoError(t, err) require.NotEmpty(t, account2) require.Equal(t, account1.ID, account2.ID) require.Equal(t, account1.Owner, account2.Owner) require.Equal(t, account1.Balance, account2.Balance) require.Equal(t, account1.Currency, account2.Currency) require.WithinDuration(t, account1.CreatedAt.Time, account2.CreatedAt.Time, time.Second)&#125;func TestUpdateAccount(t *testing.T) &#123; account1 := createRandomAccount(t) arg := UpdateAccountParams&#123; ID: account1.ID, Balance: util.RandomMoney(), &#125; account2, err := testQueries.UpdateAccount(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, account2) require.Equal(t, account1.ID, account2.ID) require.Equal(t, account1.Owner, account2.Owner) require.Equal(t, arg.Balance, account2.Balance) require.Equal(t, account1.Currency, account2.Currency) require.WithinDuration(t, account1.CreatedAt.Time, account2.CreatedAt.Time, time.Second)&#125;func TestDeleteAccount(t *testing.T) &#123; account1 := createRandomAccount(t) err := testQueries.DeleteAccount(context.Background(), account1.ID) require.NoError(t, err) account2, err := testQueries.GetAccount(context.Background(), account1.ID) require.Error(t, err) // require.EqualError(t, err, sql.ErrNoRows.Error()) require.Empty(t, account2)&#125;func TestListAccount(t *testing.T) &#123; var lastAccount Account for i := 0; i &lt; 10; i++ &#123; lastAccount = createRandomAccount(t) &#125; arg := ListAccountsParams&#123; Owner: lastAccount.Owner, Limit: 5, //返回五条记录 Offset: 0, //设置偏移量 返回后五条记录 这里出现了问题！！！！ &#125; accounts, err := testQueries.ListAccounts(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, accounts) for _, account := range accounts &#123; require.NotEmpty(t, account) require.Equal(t, lastAccount.Owner, account.Owner) &#125;&#125; 4.entry_test.go条目上的account.id要和account表单上的di相对应 问题 id为null 在 PostgreSQL 中，如果一个表的 id 字段没有设置为自增序列（如 bigserial），并且你在插入数据时没有显式地为 id 字段指定值，那么 id 字段的值将会是 NULL，除非该字段设置了默认值。 解决办法 12创建一个序列：首先，你需要创建一个序列，这个序列将用于生成 id 列的值。 CREATE SEQUENCE entries_id_seq; 12设置序列的所有权：将序列与 id 列关联起来。 ALTER SEQUENCE entries_id_seq OWNED BY entries.id; 123设置 id 列的默认值为序列的下一个值：这样，每当你插入新行而没有指定 id 值时，PostgreSQL 会自动使用序列的下一个值。 ALTER TABLE entries ALTER COLUMN id SET DEFAULT nextval(&#x27;entries_id_seq&#x27;); 4确保 id 列是主键：从你提供的信息来看，id 列已经是主键。确保这一点很重要，因为主键约束可以保证 id 列的值是唯一的。 12测试：插入一条新记录，不指定 id 值，检查是否自动生成了 id。 INSERT INTO entries (account_id, amount, created_at) VALUES (1, 100, now()); 1DELETE FROM entries WHERE id=4; 删除特定行的指令 创建账单成功！ 但是只能生成一个数据？？？ 我发现了输出的区别 Running tool: D:\\Go\\bin\\go.exe test -timeout 30s -run ^TestCreateEntry$ project&#x2F;simplebank&#x2F;db&#x2F;sqlc ok project&#x2F;simplebank&#x2F;db&#x2F;sqlc (cached) 这是第二次输出 第一次输出没有cached字样 数据正确的加载到了数据库 但是这个带有cached的数据没有加载到数据库 因为 cached 是因为两次的数据相同 所以才没有被加载到数据库 这个可能是随机数代码的问题 5.transfer_test.go1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package dbimport ( &quot;context&quot; &quot;time&quot; &quot;project/simplebank/util&quot; &quot;testing&quot; &quot;github.com/stretchr/testify/require&quot;)func createRandomTransfer(t *testing.T, account1, account2 Account) Transfer &#123; arg := createTransferParams&#123; FromAccountID: account1.ID, ToAccountID: account2.ID, Amount: util.RandomMoney(), &#125; transfer, err := testQueries.createTransfer(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, transfer) require.Equal(t, arg.FromAccountID, transfer.FromAccountID) require.Equal(t, arg.ToAccountID, transfer.ToAccountID) require.Equal(t, arg.Amount, transfer.Amount) require.NotZero(t, transfer.ID) require.NotZero(t, transfer.CreatedAt) return transfer&#125;func TestCreateTransfer(t *testing.T) &#123; account1 := createRandomAccount(t) account2 := createRandomAccount(t) createRandomTransfer(t, account1, account2)&#125;func TestGetTransfer(t *testing.T) &#123; account1 := createRandomAccount(t) account2 := createRandomAccount(t) transfer1 := createRandomTransfer(t, account1, account2) transfer2, err := testQueries.GetTransfer(context.Background(), transfer1.ID) require.NoError(t, err) require.NotEmpty(t, transfer2) require.Equal(t, transfer1.ID, transfer2.ID) require.Equal(t, transfer1.FromAccountID, transfer2.FromAccountID) require.Equal(t, transfer1.ToAccountID, transfer2.ToAccountID) require.Equal(t, transfer1.Amount, transfer2.Amount) require.WithinDuration(t, transfer1.CreatedAt.Time, transfer2.CreatedAt.Time, time.Second)&#125;func TestListTransfer(t *testing.T) &#123; account1 := createRandomAccount(t) account2 := createRandomAccount(t) for i := 0; i &lt; 5; i++ &#123; createRandomTransfer(t, account1, account2) createRandomTransfer(t, account2, account1) &#125; arg := ListTransfersParams&#123; FromAccountID: account1.ID, ToAccountID: account1.ID, Limit: 5, Offset: 5, &#125; transfers, err := testQueries.ListTransfers(context.Background(), arg) require.NoError(t, err) require.Len(t, transfers, 5) for _, transfer := range transfers &#123; require.NotEmpty(t, transfer) require.True(t, transfer.FromAccountID == account1.ID || transfer.ToAccountID == account1.ID) &#125;&#125; 十.db transactionBEGIN语句启动事务 成功 则更新数据库 失败 则回滚事务（保持原来的状态） ​ 代码对不上了 决定先复制粘贴 学习数据库中的知识点 先从config.go开始 十一.config.go使用viper 创建app.env文件存储配置信息 config.go 12345678910111213141516171819202122232425262728package utilimport ( &quot;github.com/spf13/viper&quot;)// Config stores all configuration of the application.// The values are read by viper from a config file or environment variable.type Config struct &#123; DATABASE_URL string `mapstructure:&quot;DATABASE_URL&quot;`&#125;// LoadConfig reads configuration from file or environment variables.func LoadConfig(path string) (config Config, err error) &#123; viper.AddConfigPath(path) viper.SetConfigName(&quot;app&quot;) viper.SetConfigType(&quot;env&quot;) viper.AutomaticEnv() err = viper.ReadInConfig() if err != nil &#123; return &#125; err = viper.Unmarshal(&amp;config) return&#125; 使用接口来简化一些操作好好学接口 目前为止更正了大部分问题接着往下学。。。。 store.test.go出现了大问题 报错： **Running tool: D:\\Go\\bin\\go.exe test -timeout 30s -run ^TestTransferTx$ project&#x2F;simplebank&#x2F;db&#x2F;sqlc &gt;&gt; before: 1984 3906 — FAIL: TestTransferTx (0.03s) e:\\projects\\simplebank\\db\\sqlc\\store_test.go:83: Error Trace: e:&#x2F;projects&#x2F;simplebank&#x2F;db&#x2F;sqlc&#x2F;store_test.go:83 Error: Should NOT be empty, but was {0 0 {0001-01-01 00:00:00 +0000 UTC finite false}} Test: TestTransferTx FAIL FAIL project&#x2F;simplebank&#x2F;db&#x2F;sqlc **0.571s 因为还没编写代码。。。。。草草草草操操操操哦哦操操操这视频叫我看的 十二.需要仔细处理并发 交易 以避免死锁数据库事务 12345678910111213141516Running tool: D:\\Go\\bin\\go.exe test -timeout 30s -run ^TestTransferTx$ project/simplebank/db/sqlc&gt;&gt; before: 6892 6969&gt;&gt; tx: 6882 6979&gt;&gt; tx: 6882 6989--- FAIL: TestTransferTx (0.04s) e:\\projects\\simplebank\\db\\sqlc\\store_test.go:102: Error Trace: e:/projects/simplebank/db/sqlc/store_test.go:102 Error: Not equal: expected: 10 actual : 20 Test: TestTransferTxFAILFAIL project/simplebank/db/sqlc 0.602sFAIL 这个问题出在 account.sql.go他无法阻止一些东西 123-- name: GetAccount :oneSELECT * FROM accountsWHERE id = $1 LIMIT 1; 在两个终端中并行运行两个事务来观察这个问题 BEGIN；开始事务 ROLLBACK；回滚事务 ：第一个终端 1234567891011121314simple_bank=# BEGIN;BEGINsimple_bank=# BEGIN;WARNING: there is already a transaction in progressBEGINsimple_bank=# ROLLBACK;ROLLBACKsimple_bank=# BEGIN;BEGINsimple_bank=# SELECT * FROM accounts WHERE id=1 FOR UPDATE; id | owner | balance | currency | created_at----+----------+---------+----------+---------------------------- 1 | xiaozhao | 100 | USD | 2024-10-08 09:03:03.272176(1 row) 第二个终端 12345simple_bank=# BEGIN;BEGINsimple_bank=# SELECT * FROM accounts WHERE id=1 FOR UPDATE;这里会被阻止 并且必须等待第一个事务提交或回滚 纠正方法1： 在sql中添加 ： 重新用make sqlc生成 1234-- name: GetAccountForUpdate :oneSELECT * FROM accountsWHERE id = $1 LIMIT 1FOR UPDATE; 但是接下来出现了死锁错误： 添加日志寻找错误 12345678910111213141516171819202122232425262728293031323334353637Running tool: D:\\Go\\bin\\go.exe test -timeout 30s -run ^TestTransferTx$ project/simplebank/db/sqlc&gt;&gt; before: 1826 5993tx 5 Create transfertx 5 Create entry 1tx 5 Create entry 2tx 5 get account 1tx 2 Create transfertx 5 update account 1tx 5 get account 2tx 4 Create transfertx 5 update account 2tx 3 Create transfertx 2 Create entry 1tx 4 Create entry 1tx 3 Create entry 1tx 1 Create transfertx 2 Create entry 2tx 4 Create entry 2tx 3 Create entry 2tx 2 get account 1tx 4 get account 1tx 3 get account 1&gt;&gt; tx: 1816 6003tx 1 Create entry 1tx 1 Create entry 2tx 1 get account 1--- FAIL: TestTransferTx (0.95s) e:\\projects\\simplebank\\db\\sqlc\\store_test.go:52: Error Trace: e:/projects/simplebank/db/sqlc/store_test.go:52 Error: Received unexpected error: ERROR: deadlock detected (SQLSTATE 40P01) Test: TestTransferTxFAILFAIL project/simplebank/db/sqlc 1.470sFAIL 终端事务出现错误： 1INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *; 第一个错误 INSERT INFO transfers 是语法错误，正确的语法是 INSERT INTO transfers。 第二个错误 INSERT INTO transfers (from_account_id to_account_id amount) 也存在语法错误，缺少逗号分隔列名。正确的写法是 INSERT INTO transfers (from_account_id, to_account_id, amount)。 当前事务已中止： 由于之前的 SQL 语句（可能是第一条插入语句）出错，事务被标记为 “aborted”。这意味着在该事务中的所有后续 SQL 命令都将失败，直到事务被回滚。 解决方法 结束当前事务： 在 PostgreSQL 中，你可以通过以下命令结束当前事务并回滚更改： 1ROLLBACK 终端阻塞 事务状态1234561. 确认当前事务状态在 PostgreSQL 中，如果一个事务因为某种原因（例如错误或未处理的异常）而中断，那么所有后续的 SQL 语句将会被忽略，直到你执行 ROLLBACK 或 COMMIT。首先，确保没有事务在进行中。你可以使用以下命令查看当前活动的事务：SELECT * FROM pg_stat_activity WHERE state = &#x27;active&#x27;; 1234567891011121314simple_bank=# INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *;^CCancel request sentERROR: canceling statement due to user requestCONTEXT: SQL statement &quot;SELECT 1 FROM ONLY &quot;public&quot;.&quot;accounts&quot; x WHERE &quot;id&quot; OPERATOR(pg_catalog.=) $1 FOR KEY SHARE OF x&quot;simple_bank=# SELECT * FROM pg_stat_activity WHERE state = &#x27;active&#x27;; datid | datname | pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | xact_start | query_start | state_change | wait_event_type | wait_event | state | backend_xid | backend_xmin | query | backend_type-------+-------------+-----+----------+---------+------------------+-------------+-----------------+-------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------+---------------+--------+-------------+--------------+---------------------------------------------------------------------------------------------+---------------- 16385 | simple_bank | 810 | 10 | root | psql | | | -1 | 2024-10-10 12:58:51.115963+00 | 2024-10-10 13:00:09.094842+00 | 2024-10-10 13:00:09.094842+00 | 2024-10-10 13:00:09.094867+00 | | | active | | 935 | SELECT * FROM pg_stat_activity WHERE state = &#x27;active&#x27;; | client backend 16385 | simple_bank | 802 | 10 | root | psql | | | -1 | 2024-10-10 12:58:07.854964+00 | 2024-10-10 12:58:09.850035+00 | 2024-10-10 12:58:09.850035+00 | 2024-10-10 12:58:09.850039+00 | Lock | tuple | active | 965 | 935 | INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *; | client backend 16385 | simple_bank | 782 | 10 | root | psql | | | -1 | 2024-10-10 12:51:58.685461+00 | 2024-10-10 12:57:47.014409+00 | 2024-10-10 12:57:47.014409+00 | 2024-10-10 12:57:47.014413+00 | Lock | tuple | active | 963 | 935 | INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *; | client backend 16385 | simple_bank | 775 | 10 | root | psql | | | -1 | 2024-10-10 12:51:51.971697+00 | 2024-10-10 12:52:16.478898+00 | 2024-10-10 12:57:54.280622+00 | 2024-10-10 12:57:54.280627+00 | Lock | tuple | active | 964 | 935 | INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1,2,10) RETURNING *; | client backend 16385 | simple_bank | 556 | 10 | root | psql | | | -1 | 2024-10-10 11:29:44.776508+00 | 2024-10-10 11:56:11.909182+00 | 2024-10-10 11:56:24.551023+00 | 2024-10-10 11:56:24.551027+00 | Lock | transactionid | active | | 935 | SELECT * FROM accounts WHERE id=1 FOR UPDATE; | client backend 16385 | simple_bank | 638 | 10 | root | psql 从你提供的 pg_stat_activity 的查询结果来看，有多个活跃的事务正在等待锁。这可能是导致你无法执行 INSERT 操作的原因。以下是一些步骤，可以帮助你诊断并解决这个问题： 1. 识别并终止阻塞的事务你的查询结果显示了多个 INSERT 操作在等待锁。可以尝试强制终止这些阻塞的事务，以释放锁并允许你的操作继续进行。首先，记录下阻塞的 pid（进程 ID），然后使用以下命令终止它们： 1SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE pid IN (802, 782, 775); 在这个例子中，802、782 和 775 是阻塞的 pid。请根据你的实际情况调整这条命令。 2. 确认事务的状态如果终止了这些连接，确保你没有其他活跃的事务在运行。你可以再次运行以下命令确认： 1SELECT * FROM pg_stat_activity WHERE state = &#x27;active&#x27;; 3. 尝试再次执行插入在确保没有其他事务阻塞后，尝试重新执行你的插入操作： 1234567BEGIN; -- 开始新的事务INSERT INTO transfers (from_account_id, to_account_id, amount) VALUES (1, 2, 10) RETURNING *; -- 执行插入COMMIT; -- 提交事务指令；SELECT * FROM accounts WHERE id=1 FOR UPDATE;UPDATE accounts SET balance = 600 WHERE id=1; 4. 如果问题依然存在如果问题依然存在，建议检查数据库的锁状态： 1SELECT * FROM pg_locks WHERE granted = false; 又产生错误 123456simple_bank=# SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE pid IN (802, 782, 775,556,638,810);FATAL: terminating connection due to administrator commandserver closed the connection unexpectedly This probably means the server terminated abnormally before or while processing the request.The connection to the server was lost. Attempting reset: Succeeded. 回答： 看起来你在尝试终止阻塞的连接时，PostgreSQL 服务器意外关闭了连接。这可能是由于以下几个原因： 服务器崩溃：可能是因为在终止连接时，某个后台进程遇到了问题，导致服务器崩溃。 资源不足：如果你的 PostgreSQL 服务器资源不足（例如内存或 CPU），在处理请求时可能会出现这种情况。 12345678910111213由于服务器崩溃，重启 Docker 容器可能会帮助你恢复连接：docker restart postgres12在重启后检查连接：重启后，尝试重新连接到数据库，并检查活动连接：SELECT * FROM pg_stat_activity;再次终止阻塞的连接：如果连接正常，尝试再次运行终止命令：SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE pid IN (802, 782, 775, git上传一个项目没有共同历史 12检查是否有共同历史git log --oneline --graph --all 12强制合并冲突git pull origin main --allow-unrelated-histories 终端1：在没有阻塞的情况下 1234567891011121314simple_bank=# BEGIN;BEGINsimple_bank=# SELECT * FROM accounts WHERE id=1 FOR UPDATE; id | owner | balance | currency | created_at----+----------+---------+----------+---------------------------- 1 | xiaozhao | 100 | USD | 2024-10-08 09:03:03.272176(1 row)simple_bank=# UPDATE accounts SET balance = 600 WHERE id=1;UPDATE 1simple_bank=# COMMIT;COMMITsimple_bank=# 在终端一提交事务时 终端二会显示出结果 1234567891011simple_bank=# BEGIN;BEGINsimple_bank=# SELECT * FROM accounts WHERE id=1 FOR UPDATE; id | owner | balance | currency | created_at----+----------+---------+----------+---------------------------- 1 | xiaozhao | 600 | USD | 2024-10-08 09:03:03.272176(1 row)simple_bank=# sql QUERIER 1234567891011121314BEGIN;INSERT INTO transfers (from_account_id,to_account_id,amount) VALUE (1,2,10) RETURNING *;INSERT INTO entries (account_id,amount) VALUES (1,-10) RETURNING *;INSERT INTO entries (account_id,amount) VALUES (2,10) RETURNING *;SELECT * FROM accounts WHERE id=1 FOR UPDATE;UPDATE accounts SET balance = 90 WHERE id = 1 RETURNING *;SELECT * FROM accounts WHERE id =2 FOR UPDATE;UPDATE accounts SET balance = 110 WHERE id = 2 RETURNING *;ROLLBACK; 5.postgres lock：帮助查询哪里有锁The following query may be helpful to see what processes are blocking SQL statements (these only find row-level locks, not object-level locks). 1234567891011121314151617181920212223SELECT blocked_locks.pid AS blocked_pid, blocked_activity.usename AS blocked_user, blocking_locks.pid AS blocking_pid, blocking_activity.usename AS blocking_user, blocked_activity.query AS blocked_statement, blocking_activity.query AS current_statement_in_blocking_process FROM pg_catalog.pg_locks blocked_locks JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid AND blocking_locks.pid != blocked_locks.pid JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid WHERE NOT blocked_locks.granted; 1SELECT * FROM accounts WHERE id=1 FOR UPDATE; 这条语句阻塞了 12345678910111213141516Here&#x27;s an alternate view of that same data that includes an idea how old the state is# 列出所有锁SELECT a.datname, l.relation::regclass, l.transactionid, //事务id l.mode, 锁的mod l.GRANTED, a.usename, who a.query, a.query_start, age(now(), a.query_start) AS &quot;age&quot;, a.pidFROM pg_stat_activity aJOIN pg_locks l ON l.pid = a.pidORDER BY a.query_start; 死锁是由外键约束引起的 1.删除约束 修改sql 1234-- name: GetAccountForUpdate :oneSELECT * FROM accountsWHERE id = $1 LIMIT 1FOR NO KEY UPDATE;//这步时解决死锁的关键 避免死锁是关键：微调事务中的查询 十三.隔离级别数据库事务必须满足 ACID 原子性 一致性 隔离性 持久性 Read Phenomenaa1.脏读当一个事务读取了 其他并发事务写入的尚未提交的数据（导致 如果尚未提交的数据 最终回滚 可能导致用到错误的数据 ） 2.不可重复读当一个事务两次读取到同一记录并看到不同的值 因为第一次读取后提交的其他事务修改 3.幻读影响多行 4.四种隔离级别READ UNCOMMITMED： 可以看到其他未提交事务写入的数据 READ COMMITED：只能看到其他事务已经提交的数据 REPEATABLE READ: SERIALIZABLE: 5.mysql选择隔离级别123set sexxion transaction isolation level read commited;select @@一种隔离级别 6.postgresql选择隔离级别 只有三个12345在postgresql中 未提交和已提交是一个级别show transaction isolation levelset transaction isolation level read uncommited 十四.持续集成或CI自动化构建和测试流程进行验证 1.Github Action首先上传项目到github时如果出现了连接问题 就切换成ssh连接 1234git remote set-url origin git@github.com:Whuichenggong/projects.gitPS E:\\projects&gt; git pull origin main --tagsFrom github.com:Whuichenggong/projects * branch main -&gt; FETCH_HEAD 创建文件 1echo. &gt; .github\\workflows\\ci.yml 安装工具 1golang migrate 但是目前我看不到页面我的action 十五.RESTful HEEP API1.创建api文件夹account.go 12345678910111213141516171819202122232425262728293031323334package apiimport ( &quot;net/http&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;github.com/gin-gonic/gin&quot;)type CreateAccountRequest struct &#123; Owner string `json:&quot;owner&quot; binding:&quot;required&quot;` Currency string `json:&quot;currency&quot; binding:&quot;required,oneof= USD EUR&quot;`&#125;func (server *Server) createAccount(ctx *gin.Context) &#123; var req CreateAccountRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; arg := db.CreateAccountParams&#123; Owner: req.Owner, Currency: req.Currency, Balance: 0, &#125; account, err := server.store.CreateAccount(ctx, arg) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; ctx.JSON(http.StatusOK, account)&#125; server.go 123456789101112131415161718192021222324252627282930313233343536package apiimport ( db &quot;project/simplebank/db/sqlc&quot; &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot;)type Server struct &#123; config util.Config store db.Store router *gin.Engine&#125;func NewServer(config util.Config, store db.Store) (*Server, error) &#123; server := &amp;Server&#123; config: config, store: store, &#125; router := gin.Default() router.POST(&quot;/accounts&quot;, server.createAccount) server.router = router return server, nil&#125;func errorResponse(err error) gin.H &#123; return gin.H&#123;&quot;error&quot;: err.Error()&#125;&#125;func (server *Server) Start(address string) error &#123; return server.router.Run(address)&#125; main.go 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( &quot;context&quot; &quot;log&quot; &quot;project/simplebank/api&quot; &quot;project/simplebank/util&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;github.com/jackc/pgx/v5/pgxpool&quot;)func main() &#123; config, err := util.LoadConfig(&quot;.&quot;) if err != nil &#123; log.Fatal(&quot;cannot load config:&quot;, err) &#125; connPool, err := pgxpool.New(context.Background(), config.DATABASE_URL) if err != nil &#123; log.Fatal(&quot;cannot connect to db:&quot;, err) &#125; //初始化数据库服务 store := db.NewStore(connPool) //运行gin框架 runGinServer(config, store) if err != nil &#123; log.Fatal(&quot;cannot start server:&quot;, err) &#125;&#125;func runGinServer(config util.Config, store db.Store) &#123; server, err := api.NewServer(config, store) if err != nil &#123; log.Fatalf(&quot;cannot create server: %v&quot;, err) &#125; err = server.Start(config.HTTPServerAddress) if err != nil &#123; log.Fatalf(&quot;cannot start server: %v&quot;, err) &#125;&#125; 数据库重置 1234567891011MySQL 数据库：使用 TRUNCATE TABLE 语句： TRUNCATE TABLE table_name; PostgreSQL 数据库：使用 TRUNCATE TABLE 语句： TRUNCATE TABLE table_name RESTART IDENTITY; TRUNCATE TABLE accounts, entries RESTART IDENTITY; 同时截断两个表 listaccount.go 用postman请求时：&#x2F;&#x2F;查询参数 page_id 1 page_size 5 在使用多组查找的时候没有找到用户？？？ 目前为止还是无法解决 找了喜春学哥帮我找到了问题的所在在ListAccounts中 传进去的arg.Owner是个空值导致了出现了问题 把arg.Owner改成一个数据库中具体的值 就能找到问题的所在 12func (q *Queries) ListAccounts(ctx context.Context, arg ListAccountsParams) ([]Account, error) &#123; rows, err := q.db.Query(ctx, listAccounts, arg.Owner/*问题所在*/, arg.Limit, arg.Offset) 2.模拟数据库测试1234使用mock go get github.com/golang/mock/mockgen@v1.6.0 PS E:\\projects\\simplebank\\db\\mock&gt; mockgen -destination db/mock/store.go project/simplebank/db/sqlc Store 3.account_test.go出现的问题 你提到的问题是由于 mock_sqlc.MockStore 未完全实现 db.Store 接口，特别是缺少 createTransfer 方法。为了解决这个问题，您可以采取以下步骤： 解决步骤： 确认 db.Store 接口的定义： 首先，确保 db.Store 接口定义了所有需要的方法。特别是，确认接口中是否包含 createTransfer 方法。 也就是： 1234567891011121314在你当前的测试代码中，store := mockdb.NewMockStore(ctrl) 返回的确实是 *mockdb.MockStore 类型，而 NewServer 需要的参数是 db.Store 接口类型。那么为什么没有类型错误呢？这是因为在 Go 中，接口是基于方法集实现的，而 *mockdb.MockStore 实现了 db.Store 接口中的所有方法。具体原因分析：接口实现方式：在 Go 语言中，接口并不关心你传递的具体类型（如 *mockdb.MockStore），它只关心该类型是否实现了接口中定义的所有方法。如果 *mockdb.MockStore 实现了 db.Store 接口的所有方法，那么它就可以被赋值给 db.Store 类型的变量。gomock 的自动生成：你使用 gomock 生成了 *mockdb.MockStore，这个 mock 类型会模拟 db.Store 接口的所有方法。因为它是通过 gomock 自动生成的，并且已经包含了 db.Store 中的所有方法，所以它实际上是符合 db.Store 接口的实现。类型匹配：在 Go 中，赋值 *mockdb.MockStore 给 db.Store 类型是可以的，因为 *mockdb.MockStore 实现了 db.Store 接口。即便 *mockdb.MockStore 是一个具体类型，只要它的方法集与 db.Store 接口的方法集匹配，Go 会认为它是一个合法的接口实现。为什么没有错误？由于 *mockdb.MockStore 实现了 db.Store 接口的所有方法，Go 编译器允许将 *mockdb.MockStore 传递给 NewServer 这个需要 db.Store 类型的函数参数。具体的原因是：NewMockStore 生成的 mock 类型实现了 db.Store 的所有方法，因此符合 db.Store 接口。在 Go 语言中，接口实现是隐式的，不需要显式声明实现接口，只要结构体的方法集与接口匹配即可。 方法 1：使用类型断言验证 在 Go 中，你可以通过静态类型检查来验证一个类型是否实现了某个接口。具体方法是使用以下代码： 1var _ db.Store = (*mockdb.MockStore)(nil) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package apiimport ( &quot;bytes&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;io&quot; &quot;net/http&quot; &quot;net/http/httptest&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;project/simplebank/util&quot; &quot;testing&quot; mockdb &quot;project/simplebank/db/mock&quot; &quot;github.com/golang/mock/gomock&quot; &quot;github.com/stretchr/testify/require&quot;)func TestGetAccountAPI(t *testing.T) &#123; config, err := util.LoadConfig(&quot;.&quot;) if err != nil &#123; fmt.Println(&quot;配置文件出错&quot;) &#125; //user, _ := randomUser(t) account := randomAccount() testCases := []struct &#123; name string accountID int64 //setupAuth func(t *testing.T, request *http.Request, tokenMaker token.Maker) buildStubs func(store *mockdb.MockStore) checkResponse func(t *testing.T, recoder *httptest.ResponseRecorder) &#125;&#123; &#123; name: &quot;OK&quot;, accountID: account.ID, // setupAuth: func(t *testing.T, request *http.Request, tokenMaker token.Maker) &#123; // addAuthorization(t, request, tokenMaker, authorizationTypeBearer, user.Username, user.Role, time.Minute) // &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT(). GetAccount(gomock.Any(), gomock.Eq(account.ID)). Times(1). Return(account, nil) &#125;, checkResponse: func(t *testing.T, recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusOK, recorder.Code) requireBodyMatchAccount(t, recorder.Body, account) &#125;, &#125;, &#125; for i := range testCases &#123; tc := testCases[i] t.Run(tc.name, func(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() store := mockdb.NewMockStore(ctrl) tc.buildStubs(store) server, _ := NewServer(config, store) recorder := httptest.NewRecorder() url := fmt.Sprintf(&quot;/accounts/%d&quot;, tc.accountID) request, err := http.NewRequest(http.MethodGet, url, nil) require.NoError(t, err) //tc.setupAuth(t, request, server.tokenMaker) server.router.ServeHTTP(recorder, request) tc.checkResponse(t, recorder) &#125;) &#125;&#125;func randomAccount() db.Account &#123; return db.Account&#123; ID: util.RandomInt(1, 1000), //Owner: owner, Balance: util.RandomMoney(), Currency: util.RandomCurrency(), &#125;&#125;func requireBodyMatchAccount(t *testing.T, body *bytes.Buffer, account db.Account) &#123; data, err := io.ReadAll(body) require.NoError(t, err) var gotAccount db.Account err = json.Unmarshal(data, &amp;gotAccount) require.NoError(t, err) require.Equal(t, account, gotAccount)&#125; 在这段代码中有不懂的地方 123456789store := mockdb.NewMockStore(ctrl) tc.buildStubs(store) server, _ := NewServer(config, store)store是 *mockdb.MockStore类型而func NewServer(config util.Config, store db.Store) (*Server, error) 需要的是db.store类型server, _ := NewServer(config, store)//我觉得这是自相矛盾 切片 123456789101112131415161718192021222324252627282930313233343536373839testCases := []struct &#123; name string accountID int64 //setupAuth func(t *testing.T, request *http.Request, tokenMaker token.Maker) buildStubs func(store *mockdb.MockStore) checkResponse func(t *testing.T, recoder *httptest.ResponseRecorder) &#125;&#123; &#123; name: &quot;OK&quot;, accountID: account.ID, // setupAuth: func(t *testing.T, request *http.Request, tokenMaker token.Maker) &#123; // addAuthorization(t, request, tokenMaker, authorizationTypeBearer, user.Username, user.Role, time.Minute) // &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT(). GetAccount(gomock.Any(), gomock.Eq(account.ID)). Times(1). Return(account, nil) &#125;, checkResponse: func(t *testing.T, recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusOK, recorder.Code) requireBodyMatchAccount(t, recorder.Body, account) &#125;, &#125;, &#123; name: &quot;NotFound&quot;, accountID: account.ID, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT(). GetAccount(gomock.Any(), gomock.Eq(account.ID)). Times(1). Return(db.Account&#123;&#125;, sql.ErrNoRows) &#125;, checkResponse: func(t *testing.T, recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusNotFound, recorder.Code) &#125;, &#125;, &#125; 目前的问题是notfound处理不符合预期 1234567891011121314151617&#123; name: &quot;NotFound&quot;, accountID: account.ID, setupAuth: func(t *testing.T, request *http.Request, tokenMaker token.Maker) &#123; addAuthorization(t, request, tokenMaker, authorizationTypeBearer, user.Username, user.Role, time.Minute) &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT(). GetAccount(gomock.Any(), gomock.Eq(account.ID)). Times(1). Return(db.Account&#123;&#125;, db.ErrRecordNotFound) &#125;, checkResponse: func(t *testing.T, recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusNotFound, recorder.Code)//我手动把 recorder.Code换成404jiu&#x27;cheng&#x27;gogn &#125;, &#125;, 4.transfer.goCurrency string json:&quot;currency&quot; binding:&quot;required,currency&quot; 添加了currency验证器 因为正常json不能识别USD等货币 实现思路 在go run mian.go后使用gin框架请求路由前 使用自己添加的数字验证器 在server.go中添加如下内容 12345678910111213141516171819202122232425262728293031323334353637383940// 自定义验证函数，检查 currency 是否为 &quot;USD&quot;func validCurrency(fl validator.FieldLevel) bool &#123; currency := fl.Field().String() return currency == &quot;USD&quot;&#125;// 注册自定义验证器func (server *Server) setupValidator() &#123; if v, ok := binding.Validator.Engine().(*validator.Validate); ok &#123; v.RegisterValidation(&quot;currency&quot;, validCurrency) &#125;&#125;func NewServer(config util.Config, store db.Store) (*Server, error) &#123; server := &amp;Server&#123; config: config, store: store, &#125; // 注册自定义验证器 server.setupValidator() router := gin.Default() router.POST(&quot;/accounts&quot;, server.createAccount) router.GET(&quot;/accounts/:id&quot;, server.getAccount) router.GET(&quot;/accounts&quot;, server.listAccount) router.POST(&quot;transfers&quot;, server.createTransfer) server.router = router return server, nil&#125;func errorResponse(err error) gin.H &#123; return gin.H&#123;&quot;error&quot;: err.Error()&#125;&#125;func (server *Server) Start(address string) error &#123; return server.router.Run(address)&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package apiimport ( &quot;errors&quot; &quot;fmt&quot; &quot;net/http&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;github.com/gin-gonic/gin&quot;)type transferRequest struct &#123; FromAccountID int64 `json:&quot;from_account&quot; binding:&quot;required,min=1&quot;` ToAccountID int64 `json:&quot;to_account&quot; binding:&quot;required,min=1&quot;` Amount int64 `json:&quot;amount&quot; binding:&quot;required,gt=0&quot;` Currency string `json:&quot;currency&quot; binding:&quot;required,currency&quot;`&#125;func (server *Server) createTransfer(ctx *gin.Context) &#123; var req transferRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; // 获取并处理 FromAccount fromAccount, valid := server.validAccount(ctx, req.FromAccountID, req.Currency) if !valid &#123; return &#125; // 获取并处理 ToAccount toAccount, valid := server.validAccount(ctx, req.ToAccountID, req.Currency) if !valid &#123; return &#125; arg := db.TransferTxParams&#123; FromAccountID: fromAccount.ID, ToAccountID: toAccount.ID, Amount: req.Amount, &#125; result, err := server.store.TransferTx(ctx, arg) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; ctx.JSON(http.StatusOK, result)&#125;// 检查id和货币func (server *Server) validAccount(ctx *gin.Context, accountID int64, currency string) (db.Account, bool) &#123; account, err := server.store.GetAccount(ctx, accountID) if err != nil &#123; if errors.Is(err, db.ErrRecordNotFound) &#123; ctx.JSON(http.StatusNotFound, errorResponse(err)) return account, false &#125; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return account, false &#125; if account.Currency != currency &#123; err := fmt.Errorf(&quot;account [%d] currency mismatch: %s vs %s&quot;, account.ID, account.Currency, currency) ctx.JSON(http.StatusBadRequest, errorResponse(err)) return account, false &#125; return account, true&#125; 用postman测试得到的内容 1234567891011121314151617181920212223242526272829303132333435&#123; &quot;transfer&quot;: &#123; &quot;id&quot;: 35, &quot;from_account_id&quot;: 3, &quot;to_account_id&quot;: 5, &quot;amount&quot;: 12, &quot;created_at&quot;: &quot;2024-10-20T04:53:01.433988Z&quot; &#125;, &quot;from_account&quot;: &#123; &quot;id&quot;: 3, &quot;owner&quot;: &quot;afmxtl&quot;, &quot;balance&quot;: 103, &quot;currency&quot;: &quot;USD&quot;, &quot;created_at&quot;: &quot;2024-10-13T13:33:43.423875Z&quot; &#125;, &quot;to_account&quot;: &#123; &quot;id&quot;: 5, &quot;owner&quot;: &quot;bdupue&quot;, &quot;balance&quot;: 119, &quot;currency&quot;: &quot;USD&quot;, &quot;created_at&quot;: &quot;2024-10-13T13:37:04.113466Z&quot; &#125;, &quot;from_entry&quot;: &#123; &quot;id&quot;: 45, &quot;account_id&quot;: 3, &quot;amount&quot;: -12, &quot;created_at&quot;: &quot;2024-10-20T04:53:01.433988Z&quot; &#125;, &quot;to_entry&quot;: &#123; &quot;id&quot;: 46, &quot;account_id&quot;: 5, &quot;amount&quot;: 12, &quot;created_at&quot;: &quot;2024-10-20T04:53:01.433988Z&quot; &#125;&#125; 十六.用户身份验证和授权1.建user数据库表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// Use DBML to define your database structure// Docs: https://dbml.dbdiagram.io/docsTable user as U&#123; username carchar [pk] hashed_paassword varchar [not null] full_name varchar [not null] email varchar [unique, not null] password_changed_at timestamp [not null, default: `0001-01-01 00:00:00Z`] create_at timestamptz [not null,default: `now()`]&#125;Table accounts as A &#123; id bigser [pk] owner varchar [ref:&gt; U.username,not null] balance bigint [not null] currency varchar [not null] created_at timestamp [not null,default: `now()`] Indexes &#123; (owner, currency) [unique] &#125;&#125;Table entries &#123; id bigint [pk] account_id bigint [ref : &gt; A.id,not null] amount bigint [not null] created_at timestamp [not null,default: `now()`] Indexes &#123; account_id&#125;&#125;Table transfers &#123; id bigint [pk] from_account_id bigint [ref : &gt; A.id,not null] to_account_id bigint [ref : &gt; A.id,not null] amount bigint [not null] created_at timestamp [not null,default: `now()`] Indexes &#123; from_account_id to_account_id (from_account_id,to_account_id)&#125;&#125; 新建数据库迁移： 1migrate create -ext sql -dir db/migration -seq add_users 出现了错误 12345678910111213141516171819make migrateupmigrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; -verbose up2024/10/20 15:11:16 Start buffering 2/u add_users2024/10/20 15:11:16 Read and execute 2/u add_users2024/10/20 15:11:16 error: migration failed: syntax error at or near &quot;00&quot; (column 69) in line 6: CREATE TABLE &quot;user&quot; ( &quot;username&quot; carchar PRIMARY KEY, &quot;hashed_paassword&quot; varchar NOT NULL, &quot;full_name&quot; varchar NOT NULL, &quot;email&quot; varchar UNIQUE NOT NULL, &quot;password_changed_at&quot; timestamp NOT NULL DEFAULT (0001-01-01 00:00:00Z), &quot;create_at&quot; timestamptz NOT NULL DEFAULT (now()));ALTER TABLE &quot;accounts&quot; ADD FOREIGN KEY (&quot;owner&quot;) REFERENCES &quot;user&quot; (&quot;username&quot;);--CREATE UNIQUE INDEX ON &quot;accounts&quot; (&quot;owner&quot;, &quot;currency&quot;);ALTER TABLE &quot;acounts&quot; ADD CONSTRAINT &quot;owner_currency-unique&quot; UNIQUE (&quot;owner&quot;, &quot;currency&quot;) (details: pq: syntax error at or near &quot;00&quot;)make: *** [migrateup] 错误 1 原因：违反了外键约束 十七.迁移失败原因sql语句写错了 IF写成ID **理解去除外键等 ** 2.问题：在执行数据库迁移时，出现的错误是因为在 accounts 表上有外键依赖 (transfers 表中的 transfers_from_account_id_fkey 和 transfers_to_account_id_fkey 约束依赖于 accounts 表)。当你尝试删除 accounts 表时，PostgreSQL 不允许删除这个表，因为还有其他表（如 transfers）依赖它。 但是执行了migrateup指令就会出现脏读现象 使得数据库版本变为2 所以我们要先回退到1版本 1234567make migratedownmigrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; -verbose down2024/10/20 15:15:34 Are you sure you want to apply all down migrations? [y/N]y2024/10/20 15:15:36 Applying all down migrations2024/10/20 15:15:36 error: Dirty database version 2. Fix and force version.make: *** [migratedown] 错误 1 修改迁移表的值为 FALSE：没管用 1234567891011执行migratedown操作时失败，并出现错误信息 “cannot drop table accounts because other objects depend on it”，这表明accounts表有其他数据库对象依赖于它。原因包括：transfers表中的外键约束引用了accounts表。直接删除含外键的表会引发错误。建议：修改迁移脚本，先删除依赖的对象，如约束、触发器、视图等。使用CASCADE选项强制删除所有依赖的对象。在 makefile 中为migrate命令添加条件检查。可能的迁移修正示例：DROP TABLE IF EXISTS transfers CASCADE;DROP TABLE IF EXISTS accounts; 3.解除外键约束1234567891011解决方案：你可以按以下步骤修改你的迁移文件，确保先删除外键约束，再删除相关的表。删除外键约束： 在迁移文件中，先删除 transfers 表中的外键约束：ALTER TABLE transfers DROP CONSTRAINT IF EXISTS transfers_from_account_id_fkey;ALTER TABLE transfers DROP CONSTRAINT IF EXISTS transfers_to_account_id_fkey;删除表： 然后，按顺序删除表：DROP TABLE IF EXISTS transfers;DROP TABLE IF EXISTS entries;DROP TABLE IF EXISTS accounts; migrate 出现的错误可能就是 把外键依赖删除然后在执行数据库迁移语句 有没有可能你在写数据库迁移的时候就没有在migratedown中加入 删除外键约束的语句呢从而导致这么麻烦？？？ 编写migratedown时操作是和migrateup相反的 1 4.问题：1234make migratedown1migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; -verbose down 12024/10/20 17:22:21 error: Dirty database version 1. Fix and force version.make: *** [migratedown1] 错误 1 这个错误信息表明数据库处于 “dirty” 状态，通常意味着上一次的迁移未成功完成，导致数据库的迁移版本与实际执行情况不一致。要解决这个问题，你可以尝试以下步骤： 5.解决：检查数据库的迁移状态 使用 migrate 查看当前的迁移状态，以确认哪个版本是 dirty： 1migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; version 这将显示当前数据库的版本号以及 dirty 状态。 强制迁移版本 使用 migrate force 命令将数据库状态恢复为干净的版本。你可以将其设置为版本 1，这样可以清除 “dirty” 标志，同时保留当前的版本号。 执行以下命令： 1migrate -path simplebank/db/migration -database &quot;postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable&quot; force 1 这个命令不会运行任何迁移，它只是将数据库的迁移版本重置为 1，同时将脏状态清除。 6.检查当前数据库中的约束名如果不确定数据库中的约束名，可以通过以下 SQL 查询当前表中的约束名称： 1SELECT conname FROM pg_constraint WHERE conrelid = &#x27;accounts&#x27;::regclass; 每条语句后面要写分号啊啊啊啊！！！！！ 十八. user_test.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package dbimport ( &quot;context&quot; util &quot;project/simplebank/util&quot; &quot;testing&quot; &quot;time&quot; &quot;github.com/stretchr/testify/require&quot;)func createRandomUser(t *testing.T) User &#123; arg := CreateUserParams&#123; Username: util.RandomOwner(), HashedPassword: &quot;secret&quot;, FullName: util.RandomOwner(), Email: util.RandomEmail(), &#125; user, err := testStore.CreateUser(context.Background(), arg) require.NoError(t, err) require.NotEmpty(t, user) require.Equal(t, arg.Username, user.Username) require.Equal(t, arg.HashedPassword, user.HashedPassword) require.Equal(t, arg.FullName, user.FullName) require.Equal(t, arg.Email, user.Email) require.NotZero(t, user.CreateAt) return user&#125;func TestCreateUser(t *testing.T) &#123; createRandomUser(t)&#125;func TestGetUser(t *testing.T) &#123; user1 := createRandomUser(t) user2, err := testStore.GetUser(context.Background(), user1.Username) require.NoError(t, err) require.NotEmpty(t, user2) require.Equal(t, user1.Username, user2.Username) require.Equal(t, user1.HashedPassword, user2.HashedPassword) require.Equal(t, user1.FullName, user2.FullName) require.Equal(t, user1.Email, user2.Email) require.WithinDuration(t, user1.PasswordChangedAt.Time, user2.PasswordChangedAt.Time, time.Second) require.WithinDuration(t, user1.CreateAt.Time, user2.CreateAt.Time, time.Second)&#125; 在第29行代码有一个断言语句判断 ： 1require.True(t, user.PasswordChangedAt.Time.IsZero()) 这个语句目前不能通过测试 往后看吧看看是么时候找到问题 1. 10.23外键约束问题运行真个包测试出现的问题 1这个外键错误提示 &quot;ERROR: insert or update on table&quot;accounts&quot;violates foreign key constraint&quot;accounts_owner_fkey&quot;(SQLSTATE 23503)&quot; 意味着在尝试往 &quot;accounts&quot; 表中插入或更新数据时违反了名为 &quot;accounts_owner_fkey&quot; 的外键约束。 应该是 一个用户链接到账户 这就是主表与副表的关系 设置外键 将两个表链接到一起 2.数据库表出现错误数据库语句就写错了 正常每个表的 id序列都应该是自增的 如果不是这样将会出现以下错误 1ERROR: null value in column &quot;id&quot; violates not-null constraint (SQLSTATE 23502) 我们要重新修改数据库迁移语句 12345678910111213141516171819202122232425262728293031323334353637383940414243CREATE TABLE &quot;accounts&quot; ( &quot;id&quot; bigserial PRIMARY KEY, &quot;owner&quot; varchar NOT NULL, &quot;balance&quot; bigint NOT NULL, &quot;currency&quot; varchar NOT NULL, &quot;created_at&quot; timestamptz NOT NULL DEFAULT (now()));CREATE TABLE &quot;entries&quot; ( &quot;id&quot; bigserial PRIMARY KEY, &quot;account_id&quot; bigint NOT NULL, &quot;amount&quot; bigint NOT NULL, &quot;created_at&quot; timestamptz NOT NULL DEFAULT (now()));CREATE TABLE &quot;transfers&quot; ( &quot;id&quot; bigserial PRIMARY KEY, &quot;from_account_id&quot; bigint NOT NULL, &quot;to_account_id&quot; bigint NOT NULL, &quot;amount&quot; bigint NOT NULL, &quot;created_at&quot; timestamptz NOT NULL DEFAULT (now()));ALTER TABLE &quot;entries&quot; ADD FOREIGN KEY (&quot;account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);ALTER TABLE &quot;transfers&quot; ADD FOREIGN KEY (&quot;from_account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);ALTER TABLE &quot;transfers&quot; ADD FOREIGN KEY (&quot;to_account_id&quot;) REFERENCES &quot;accounts&quot; (&quot;id&quot;);CREATE INDEX ON &quot;accounts&quot; (&quot;owner&quot;);CREATE INDEX ON &quot;entries&quot; (&quot;account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;from_account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;to_account_id&quot;);CREATE INDEX ON &quot;transfers&quot; (&quot;from_account_id&quot;, &quot;to_account_id&quot;);COMMENT ON COLUMN &quot;entries&quot;.&quot;amount&quot; IS &#x27;can be negative or positive&#x27;;COMMENT ON COLUMN &quot;transfers&quot;.&quot;amount&quot; IS &#x27;must be positive&#x27;; 修改过后 正常运行account_test.go 3.修改状态码12345678910111213141516account, err := server.store.CreateAccount(ctx, arg)if err != nil &#123; if pqErr, ok := err.(*pq.Error); ok &#123; switch pqErr.Code.Name() &#123; case &quot;foreign_key_violation&quot;, &quot;unique_violation&quot;: ctx.JSON(http.StatusForbidden, errorResponse(err)) return default: log.Println(pqErr.Code.Name()) &#125; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; ctx.JSON(http.StatusOK, account)&#125; 出现错误了 等待明天修改 10.24 将上述代码语句修改为 123456if err != nil &#123; errCode := db.ErrorCode(err) if errCode == db.ForeignKeyViolation || errCode == db.UniqueViolation &#123; ctx.JSON(http.StatusForbidden, errorResponse(err)) return &#125; 成功解决了问题 。 这是为什么呢？？ 应该是: 1if errCode == db.ForeignKeyViolation || errCode == db.UniqueViolation 这段代码起到了主要i作用 在error.go中 1234const ( ForeignKeyViolation = &quot;23503&quot; UniqueViolation = &quot;23505&quot;) 这代表了： 123ForeignKeyViolation 常量的值是 &quot;23503&quot;，它代表 PostgreSQL 中的一个错误代码。当执行的数据库操作违反外键约束时，会触发这个错误。外键约束保证了不同表之间的关系，如果尝试插入、更新或删除的数据并不能被其他表中的相关记录引用，就会抛出这个错误。UniqueViolation 常量的值是 &quot;23505&quot;，这也是一个 PostgreSQL 错误代码。当向需要唯一值的字段插入了重复的值时，会引发这个错误。违反唯一性约束意味着这样的操作将导致两个记录含有相同的值，这在数据库规则中通常是不允许的，因为唯一约束保护了记录唯一识别数据的能力。 十九.在数据库中安全的存储密码1.password.go1234567891011121314151617181920212223package utilimport ( &quot;fmt&quot; &quot;golang.org/x/crypto/bcrypt&quot;)func HashPassword(password string) (string, error) &#123; hashedPassword, err := bcrypt.GenerateFromPassword([]byte(password), bcrypt.DefaultCost) if err != nil &#123; return &quot;&quot;, fmt.Errorf(&quot;哈希加密失败:%w&quot;, err) &#125; return string(hashedPassword), nil&#125;// checkPasswordfunc CheckPassword(password string, hashedPassword string) error &#123; return bcrypt.CompareHashAndPassword([]byte(hashedPassword), []byte(password))&#125; 2.password_test.go1234567891011121314151617181920212223package utilimport ( &quot;testing&quot; &quot;github.com/stretchr/testify/require&quot; &quot;golang.org/x/crypto/bcrypt&quot;)func TestPassword(t *testing.T) &#123; password := RandomString(6) hashPassword, err := HashPassword(password) require.NoError(t, err) err = CheckPassword(password, hashPassword) require.NoError(t, err) wrongPassword := RandomString(6) err = CheckPassword(wrongPassword, hashPassword) require.EqualError(t, err, bcrypt.ErrMismatchedHashAndPassword.Error())&#125; 3.user.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package apiimport ( &quot;net/http&quot; db &quot;project/simplebank/db/sqlc&quot; util &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot;)type CreateUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,alphanum&quot;` FullName string `json:&quot;fullname&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot; binding:&quot;required,email&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6&quot;`&#125;func (server *Server) createUser(ctx *gin.Context) &#123; var req CreateUserRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; hashedPassword, err := util.HashedPassword(req.Password) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; arg := db.CreateUserParams&#123; Username: req.Username, FullName: req.FullName, Email: req.Email, HashedPassword: hashedPassword, &#125; account, err := server.store.CreateUser(ctx, arg) if err != nil &#123; errCode := db.ErrorCode(err) //此处只保留一个外键约束 if errCode == db.UniqueViolation &#123; ctx.JSON(http.StatusForbidden, errorResponse(err)) return &#125; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; ctx.JSON(http.StatusOK, account)&#125; 返回结果 12345678&#123; &quot;username&quot;: &quot;ZhongHe&quot;, &quot;hashed_password&quot;: &quot;$2a$10$RRGhHuYmPf9tRVPDckNI5.q6VJ1TzG9aFJ12edZglg7kp97vGwtKO&quot;, &quot;full_name&quot;: &quot;ZhongHe Zhao&quot;, &quot;email&quot;: &quot;zhaozhonghe40@gmail.com&quot;, &quot;password_changed_at&quot;: &quot;2024-10-24T07:14:46.169687Z&quot;, &quot;create_at&quot;: &quot;2024-10-24T07:14:46.169687Z&quot;&#125; 想让返回结果没有 这个字段 1&quot;hashed_password&quot;: &quot;$2a$10$RRGhHuYmPf9tRVPDckNI5.q6VJ1TzG9aFJ12edZglg7kp97vGwtKO&quot;, 添加 12345678type CreateUserResponse struct &#123; Username string `json:&quot;username&quot;` FullName string `json:&quot;full_name&quot;` Email string `json:&quot;email&quot;` PasswordChangedAt time.Time `json:&quot;password_changed_at&quot;` CreateAt time.Time `json:&quot;create_at&quot;`&#125; 123456789rsp := CreateUserResponse&#123; Username: user.Username, FullName: user.FullName, Email: user.Email, PasswordChangedAt: user.PasswordChangedAt.Time, CreateAt: user.CreateAt.Time, &#125; ctx.JSON(http.StatusOK, rsp) 二十.user_test.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package apiimport ( &quot;bytes&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;io&quot; &quot;net/http&quot; &quot;net/http/httptest&quot; &quot;reflect&quot; &quot;testing&quot; mockdb &quot;project/simplebank/db/mock&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot; &quot;github.com/golang/mock/gomock&quot; &quot;github.com/stretchr/testify/require&quot;)type eqCreateUserParamsMatcher struct &#123; arg db.CreateUserParams password string&#125;func (e eqCreateUserParamsMatcher) Matches(x interface&#123;&#125;) bool &#123; arg, ok := x.(db.CreateUserParams) if !ok &#123; return false &#125; err := util.CheckPassword(e.password, arg.HashedPassword) if err != nil &#123; return false &#125; e.arg.HashedPassword = arg.HashedPassword return reflect.DeepEqual(e.arg, arg)&#125;func (e eqCreateUserParamsMatcher) String() string &#123; return fmt.Sprintf(&quot;matches arg %v and password %v&quot;, e.arg, e.password)&#125;func EqCreateUserParams(arg db.CreateUserParams, password string) gomock.Matcher &#123; return eqCreateUserParamsMatcher&#123;arg, password&#125;&#125;func TestCreateUserAPI(t *testing.T) &#123; user, password := randomUser(t) testCases := []struct &#123; name string body gin.H buildStubs func(store *mockdb.MockStore) checkResponse func(recoder *httptest.ResponseRecorder) &#125;&#123; &#123; name: &quot;OK&quot;, body: gin.H&#123; &quot;username&quot;: user.Username, &quot;password&quot;: password, &quot;full_name&quot;: user.FullName, &quot;email&quot;: user.Email, &#125;, buildStubs: func(store *mockdb.MockStore) &#123; arg := db.CreateUserParams&#123; Username: user.Username, FullName: user.FullName, Email: user.Email, HashedPassword: user.HashedPassword, &#125; store.EXPECT(). CreateUser(gomock.Any(), EqCreateUserParams(arg, password)). Times(1). Return(user, nil) &#125;, checkResponse: func(recorder *httptest.ResponseRecorder) &#123; fmt.Printf(&quot;Response code: %d\\n&quot;, recorder.Code) require.Equal(t, http.StatusOK, recorder.Code) requireBodyMatchUser(t, recorder.Body, user) &#125;, &#125;, &#125; for i := range testCases &#123; tc := testCases[i] t.Run(tc.name, func(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() store := mockdb.NewMockStore(ctrl) tc.buildStubs(store) server := newTestServer(t, store) recorder := httptest.NewRecorder() // Marshal body data to JSON data, err := json.Marshal(tc.body) require.NoError(t, err) fmt.Printf(&quot;Request body: %s\\n&quot;, string(data)) // 打印请求体 url := &quot;/users&quot; request, err := http.NewRequest(http.MethodPost, url, bytes.NewReader(data)) require.NoError(t, err) server.router.ServeHTTP(recorder, request) tc.checkResponse(recorder) fmt.Printf(&quot;Request body: %v\\n&quot;, tc.body) &#125;) &#125;&#125;func randomUser(t *testing.T) (user db.User, password string) &#123; password = util.RandomString(6) hashedPassword, err := util.HashedPassword(password) require.NoError(t, err) user = db.User&#123; Username: util.RandomOwner(), HashedPassword: hashedPassword, FullName: util.RandomOwner(), Email: util.RandomEmail(), &#125; return&#125;func requireBodyMatchUser(t *testing.T, body *bytes.Buffer, user db.User) &#123; data, err := io.ReadAll(body) require.NoError(t, err) var gotUser db.User err = json.Unmarshal(data, &amp;gotUser) require.NoError(t, err) require.Equal(t, user.Username, gotUser.Username) require.Equal(t, user.FullName, gotUser.FullName) require.Equal(t, user.Email, gotUser.Email) require.Empty(t, gotUser.HashedPassword)&#125; gomock.Any()这个验证的 准确度太低 任何测试基本都能通过 解决方法 使用 新的自定义匹配器 1234567891011121314151617181920212223242526272829 type eqCreateUserParamsMatcher struct &#123; arg db.CreateUserParams password string&#125;func (e eqCreateUserParamsMatcher) Matches(x interface&#123;&#125;) bool &#123; arg, ok := x.(db.CreateUserParams) if !ok &#123; return false &#125; err := util.CheckPassword(e.password, arg.HashedPassword) if err != nil &#123; return false &#125; e.arg.HashedPassword = arg.HashedPassword return reflect.DeepEqual(e.arg, arg)&#125;func (e eqCreateUserParamsMatcher) String() string &#123; return fmt.Sprintf(&quot;matches arg %v and password %v&quot;, e.arg, e.password)&#125;func EqCreateUserParams(arg db.CreateUserParams, password string) gomock.Matcher &#123; return eqCreateUserParamsMatcher&#123;arg, password&#125;&#125; 1.问题长记性 json的字段名错误 我测试了一下午 123456type CreateUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,alphanum&quot;` FullName string `json:&quot;full_name&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot; binding:&quot;required,email&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6&quot;`&#125; FullName string json:&quot;full_name&quot; binding:&quot;required&quot;这里的json标签我把full_name 写成了fullname 二十一.JWT1.JSON Web令牌密钥算法 服务器一般使用RSA 和 RS256来验证令牌 对称算法 非对称算法 必须在服务器代码中 检查令牌的算法标头 JWT令牌的很多问题： RASETO作为替代JWT的安全方案 2.基于令牌的身份验证的工作原理是什么？基于令牌的身份验证从用户登录至系统、设备或应用程序开始，通常使用密码或安全问题。授权服务器验证初始身份验证，然后发放访问令牌，访问令牌是一小段数据，允许客户端应用程序向 API 服务器发出安全调用或信号。 基于令牌的身份验证的工作原理是为服务器提供第二种高度可靠的方式来验证用户的身份和请求的真实性。 完成该基于令牌的初始身份验证协议后，令牌就像盖了章的票据一样：用户可以在令牌生命周期内连续无缝访问相关资源，而无需重新进行身份验证。 该生命周期在用户注销或退出应用程序时结束，也可由设定的超时协议触发。 3.基于令牌的身份验证有何益处？基于令牌的身份验证能为多个利益相关者提供许多便利： 即时的用户体验：用户无需在每次返回系统、应用程序或网页时重新输入凭据并重新进行身份验证，只要令牌仍然有效（通常会持续到会话因注销或退出而结束），用户就可以保持即时访问。 增加了数字安全性：基于令牌的身份验证在传统的基于密码或基于服务器的身份验证之上又增加了一道安全保护。通常，令牌比密码更难被窃取、被黑客入侵或以其他方式泄露。 管理员控制：基于令牌的身份验证为管理员提供了对每个用户操作和事项的更精细的控制和可见性。 减轻技术负担：由于令牌生成可以与令牌验证完全分离，因此验证可以由辅助服务（如 Entrust 身份和访问管理解决方案提供的服务）来处理。这将显著减少内部服务器和设备上的负载。 二十二.编写令牌make.go123456789101112131415package tokenimport ( &quot;time&quot;)// Maker is an interface for managing tokenstype Maker interface &#123; // CreateToken creates a new token for a specific username and duration CreateToken(username string, role string, duration time.Duration) (string, *Payload, error) // VerifyToken checks if the token is valid or not VerifyToken(token string) (*Payload, error)&#125; payload.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package tokenimport ( &quot;errors&quot; &quot;time&quot; &quot;github.com/google/uuid&quot;)// Different types of error returned by the VerifyToken functionvar ( ErrInvalidToken = errors.New(&quot;token is invalid&quot;) ErrExpiredToken = errors.New(&quot;token has expired&quot;))// Payload contains the payload data of the tokentype Payload struct &#123; ID uuid.UUID `json:&quot;id&quot;` Username string `json:&quot;username&quot;` Role string `json:&quot;role&quot;` IssuedAt time.Time `json:&quot;issued_at&quot;` ExpiredAt time.Time `json:&quot;expired_at&quot;`&#125;// NewPayload creates a new token payload with a specific username and durationfunc NewPayload(username string, role string, duration time.Duration) (*Payload, error) &#123; tokenID, err := uuid.NewRandom() if err != nil &#123; return nil, err &#125; payload := &amp;Payload&#123; ID: tokenID, Username: username, Role: role, IssuedAt: time.Now(), ExpiredAt: time.Now().Add(duration), &#125; return payload, nil&#125;// Valid checks if the token payload is valid or notfunc (payload *Payload) Valid() error &#123; if time.Now().After(payload.ExpiredAt) &#123; return ErrExpiredToken &#125; return nil&#125; jwt_maker.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package tokenimport ( &quot;errors&quot; &quot;fmt&quot; &quot;time&quot; &quot;github.com/dgrijalva/jwt-go&quot;)const minSecretKeySize = 32// JWTMaker is a JSON Web Token makertype JWTMaker struct &#123; secretKey string&#125;// NewJWTMaker creates a new JWTMakerfunc NewJWTMaker(secretKey string) (Maker, error) &#123; if len(secretKey) &lt; minSecretKeySize &#123; return nil, fmt.Errorf(&quot;invalid key size: must be at least %d characters&quot;, minSecretKeySize) &#125; return &amp;JWTMaker&#123;secretKey&#125;, nil&#125;// CreateToken creates a new token for a specific username and durationfunc (maker *JWTMaker) CreateToken(username string, role string, duration time.Duration) (string, *Payload, error) &#123; payload, err := NewPayload(username, role, duration) if err != nil &#123; return &quot;&quot;, payload, err &#125; jwtToken := jwt.NewWithClaims(jwt.SigningMethodHS256, payload) token, err := jwtToken.SignedString([]byte(maker.secretKey)) return token, payload, err&#125;// VerifyToken checks if the token is valid or notfunc (maker *JWTMaker) VerifyToken(token string) (*Payload, error) &#123; keyFunc := func(token *jwt.Token) (interface&#123;&#125;, error) &#123; _, ok := token.Method.(*jwt.SigningMethodHMAC) if !ok &#123; return nil, ErrInvalidToken &#125; return []byte(maker.secretKey), nil &#125; jwtToken, err := jwt.ParseWithClaims(token, &amp;Payload&#123;&#125;, keyFunc) if err != nil &#123; verr, ok := err.(*jwt.ValidationError) if ok &amp;&amp; errors.Is(verr.Inner, ErrExpiredToken) &#123; return nil, ErrExpiredToken &#125; return nil, ErrInvalidToken &#125; payload, ok := jwtToken.Claims.(*Payload) if !ok &#123; return nil, ErrInvalidToken &#125; return payload, nil&#125; jwt_test.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package tokenimport ( &quot;testing&quot; &quot;time&quot; &quot;project/simplebank/util&quot; &quot;github.com/dgrijalva/jwt-go&quot; &quot;github.com/stretchr/testify/require&quot;)func TestJWTMaker(t *testing.T) &#123; maker, err := NewJWTMaker(util.RandomString(32)) require.NoError(t, err) username := util.RandomOwner() role := util.DepositorRole duration := time.Minute issuedAt := time.Now() expiredAt := issuedAt.Add(duration) token, err := maker.CreateToken(username, duration) require.NoError(t, err) require.NotEmpty(t, token) payload, err := maker.VerifyToken(token) require.NoError(t, err) require.NotEmpty(t, payload) require.NotZero(t, payload.ID) require.Equal(t, username, payload.Username) require.Equal(t, role, payload.Role) require.WithinDuration(t, issuedAt, payload.IssuedAt, time.Second) require.WithinDuration(t, expiredAt, payload.ExpiredAt, time.Second)&#125;func TestExpiredJWTToken(t *testing.T) &#123; maker, err := NewJWTMaker(util.RandomString(32)) require.NoError(t, err) token, err := maker.CreateToken(util.RandomOwner(), -time.Minute) require.NoError(t, err) require.NotEmpty(t, token) payload, err := maker.VerifyToken(token) require.Error(t, err) require.EqualError(t, err, ErrExpiredToken.Error()) require.Nil(t, payload)&#125;func TestInvalidJWTTokenAlgNone(t *testing.T) &#123; payload, err := NewPayload(util.RandomOwner(), time.Minute) require.NoError(t, err) jwtToken := jwt.NewWithClaims(jwt.SigningMethodNone, payload) token, err := jwtToken.SignedString(jwt.UnsafeAllowNoneSignatureType) require.NoError(t, err) maker, err := NewJWTMaker(util.RandomString(32)) require.NoError(t, err) payload, err = maker.VerifyToken(token) require.Error(t, err) require.EqualError(t, err, ErrInvalidToken.Error()) require.Nil(t, payload)&#125; 作者说 passeto是比JWT更简洁更好用 passeto_maker.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package tokenimport ( &quot;fmt&quot; &quot;time&quot; &quot;github.com/aead/chacha20poly1305&quot; &quot;github.com/o1egl/paseto&quot;)// PasetoMaker is a PASETO token makertype PasetoMaker struct &#123; paseto *paseto.V2 symmetricKey []byte&#125;// NewPasetoMaker creates a new PasetoMakerfunc NewPasetoMaker(symmetricKey string) (Maker, error) &#123; if len(symmetricKey) != chacha20poly1305.KeySize &#123; return nil, fmt.Errorf(&quot;invalid key size: must be exactly %d characters&quot;, chacha20poly1305.KeySize) &#125; maker := &amp;PasetoMaker&#123; paseto: paseto.NewV2(), symmetricKey: []byte(symmetricKey), &#125; return maker, nil&#125;// CreateToken creates a new token for a specific username and durationfunc (maker *PasetoMaker) CreateToken(username string, duration time.Duration) (string, error) &#123; payload, err := NewPayload(username, duration) if err != nil &#123; return &quot;&quot;, err &#125; return maker.paseto.Encrypt(maker.symmetricKey, payload, nil)&#125;// VerifyToken checks if the token is valid or notfunc (maker *PasetoMaker) VerifyToken(token string) (*Payload, error) &#123; payload := &amp;Payload&#123;&#125; err := maker.paseto.Decrypt(token, maker.symmetricKey, payload, nil) if err != nil &#123; return nil, ErrInvalidToken &#125; err = payload.Valid() if err != nil &#123; return nil, err &#125; return payload, nil&#125; paseto_make_test.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package tokenimport ( &quot;testing&quot; &quot;time&quot; &quot;project/simplebank/util&quot; &quot;github.com/stretchr/testify/require&quot;)func TestPasetoMaker(t *testing.T) &#123; maker, err := NewJWTMaker(util.RandomString(32)) require.NoError(t, err) username := util.RandomOwner() duration := time.Minute issuedAt := time.Now() expiredAt := issuedAt.Add(duration) token, err := maker.CreateToken(username, duration) require.NoError(t, err) require.NotEmpty(t, token) payload, err := maker.VerifyToken(token) require.NoError(t, err) require.NotEmpty(t, payload) require.NotZero(t, payload.ID) require.Equal(t, username, payload.Username) require.WithinDuration(t, issuedAt, payload.IssuedAt, time.Second) require.WithinDuration(t, expiredAt, payload.ExpiredAt, time.Second)&#125;func TestExpiredPasetoToken(t *testing.T) &#123; maker, err := NewPasetoMaker(util.RandomString(32)) require.NoError(t, err) token, err := maker.CreateToken(util.RandomOwner(), -time.Minute) require.NoError(t, err) require.NotEmpty(t, token) payload, err := maker.VerifyToken(token) require.Error(t, err) require.EqualError(t, err, ErrExpiredToken.Error()) require.Nil(t, payload)&#125;//None算法 10.28学习如何用令牌登录api1.server.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package apiimport ( &quot;fmt&quot; db &quot;project/simplebank/db/sqlc&quot; &quot;project/simplebank/token&quot; &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot; &quot;github.com/gin-gonic/gin/binding&quot; &quot;github.com/go-playground/validator/v10&quot;)type Server struct &#123; config util.Config store db.Store router *gin.Engine tokenMaker token.Maker&#125;// 自定义验证函数，检查 currency 是否为 &quot;USD&quot;func validCurrency(fl validator.FieldLevel) bool &#123; currency := fl.Field().String() return currency == &quot;RMB&quot;&#125;// 注册自定义验证器func (server *Server) setupValidator() &#123; if v, ok := binding.Validator.Engine().(*validator.Validate); ok &#123; v.RegisterValidation(&quot;currency&quot;, validCurrency) &#125;&#125;func NewServer(config util.Config, store db.Store) (*Server, error) &#123; tokenMaker, err := token.NewPasetoMaker(config.TokenSymmetricKey) if err != nil &#123; fmt.Printf(&quot;Key length in bytes: %d\\n&quot;, len([]byte(config.TokenSymmetricKey))) return nil, fmt.Errorf(&quot;cannot create token maker: %w&quot;, err) &#125; server := &amp;Server&#123; config: config, store: store, tokenMaker: tokenMaker, &#125; // 注册自定义验证器 server.setupValidator() server.setupRouter() return server, nil&#125;func (server *Server) setupRouter() &#123; router := gin.Default() router.POST(&quot;/users/login&quot;, server.loginUser) router.POST(&quot;transfers&quot;, server.createTransfer) router.POST(&quot;/accounts&quot;, server.createAccount) router.GET(&quot;/accounts/:id&quot;, server.getAccount) router.POST(&quot;/users&quot;, server.createUser) router.GET(&quot;/accounts&quot;, server.listAccounts) server.router = router&#125;func errorResponse(err error) gin.H &#123; return gin.H&#123;&quot;error&quot;: err.Error()&#125;&#125;func (server *Server) Start(address string) error &#123; return server.router.Run(address)&#125; 2.user.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package apiimport ( &quot;errors&quot; &quot;fmt&quot; &quot;net/http&quot; &quot;time&quot; db &quot;project/simplebank/db/sqlc&quot; util &quot;project/simplebank/util&quot; &quot;github.com/gin-gonic/gin&quot; //&quot;github.com/jackc/pgtype&quot;)type CreateUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,alphanum&quot;` FullName string `json:&quot;full_name&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot; binding:&quot;required,email&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6&quot;`&#125;type UserResponse struct &#123; Username string `json:&quot;username&quot;` FullName string `json:&quot;full_name&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot;` PasswordChangedAt time.Time `json:&quot;password_changed_at&quot;` CreateAt time.Time `json:&quot;create_at&quot;`&#125;func newUserResponse(user db.User) UserResponse &#123; return UserResponse&#123; Username: user.Username, FullName: user.FullName, Email: user.Email, PasswordChangedAt: user.PasswordChangedAt.Time, CreateAt: user.CreateAt.Time, &#125;&#125;func (server *Server) createUser(ctx *gin.Context) &#123; var req CreateUserRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; fmt.Printf(&quot;Received request: %+v\\n&quot;, req) // 打印请求体 hashedPassword, err := util.HashedPassword(req.Password) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(fmt.Errorf(&quot;failed to hash password: %v&quot;, err))) return &#125; arg := db.CreateUserParams&#123; Username: req.Username, FullName: req.FullName, Email: req.Email, HashedPassword: hashedPassword, &#125; user, err := server.store.CreateUser(ctx, arg) if err != nil &#123; fmt.Printf(&quot;Error creating user: %v\\n&quot;, err) // 打印错误 errCode := db.ErrorCode(err) //此处只保留一个外键约束 if errCode == db.UniqueViolation &#123; return &#125; ctx.JSON(http.StatusForbidden, errorResponse(err)) return &#125; rsp := newUserResponse(user) ctx.JSON(http.StatusOK, rsp)&#125;type loginUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,alphanum&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6&quot;`&#125;type loginUserResponse struct &#123; AccessToken string `json:&quot;access_token&quot;` User UserResponse `json:&quot;user&quot;`&#125;func (server *Server) loginUser(ctx *gin.Context) &#123; var req loginUserRequest if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, errorResponse(err)) return &#125; user, err := server.store.GetUser(ctx, req.Username) if err != nil &#123; if errors.Is(err, db.ErrRecordNotFound) &#123; ctx.JSON(http.StatusNotFound, errorResponse(err)) return &#125; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; err = util.CheckPassword(req.Password, user.HashedPassword) if err != nil &#123; ctx.JSON(http.StatusUnauthorized, errorResponse(err)) return &#125; accessToken, err := server.tokenMaker.CreateToken( user.Username, server.config.AccessTokenDuration, ) if err != nil &#123; ctx.JSON(http.StatusInternalServerError, errorResponse(err)) return &#125; rsp := loginUserResponse&#123; AccessToken: accessToken, User: newUserResponse(user), &#125; ctx.JSON(http.StatusOK, rsp)&#125; 3.问题1为什么运行transfer_text.go出现了很多错误： 4.解决1在学习的时候图方便把作者的代码全部拉了下来 在transfer_test.go中 有很多情况 在transfer中并没有实现 导致无法对应这些情况 正常时作者留给你的任务 让你去课后实现这些功能 重新回顾第13集： 模拟数据库进行测试： 确保模拟数据库实现与真是数据库相同的接口 出问题的两段代码： 123456789101112131415161718192021222324252627282930313233343536&#123; name: &quot;UnauthorizedUser&quot;, body: gin.H&#123; &quot;from_account_id&quot;: account1.ID, &quot;to_account_id&quot;: account2.ID, &quot;amount&quot;: amount, &quot;currency&quot;: util.RandomCurrency(), &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT().GetAccount(gomock.Any(), gomock.Eq(account1.ID)).Times(1).Return(account1, nil) store.EXPECT().GetAccount(gomock.Any(), gomock.Eq(account2.ID)).Times(0) store.EXPECT().TransferTx(gomock.Any(), gomock.Any()).Times(0) &#125;,checkResponse: func(recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusUnauthorized, recorder.Code) &#125;,&#125;,&#123; name: &quot;NoAuthorization&quot;, body: gin.H&#123; &quot;from_account_id&quot;: account1.ID, &quot;to_account_id&quot;: account2.ID, &quot;amount&quot;: amount, &quot;currency&quot;: util.USD, &#125;, buildStubs: func(store *mockdb.MockStore) &#123; store.EXPECT().GetAccount(gomock.Any(), gomock.Any()).Times(0) store.EXPECT().TransferTx(gomock.Any(), gomock.Any()).Times(0)&#125;, checkResponse: func(recorder *httptest.ResponseRecorder) &#123; require.Equal(t, http.StatusUnauthorized, recorder.Code) &#125;,&#125;, 5.问题2为什么得到分组用户出错 6.解决21234567891011121314151617181920212223242526//为什么得到分页的时候用户为空 错误出现在这里func (q *Queries) ListAccounts(ctx context.Context, arg ListAccountsParams) ([]Account, error) &#123; rows, err := q.db.Query(ctx, listAccounts, arg.Owner, arg.Limit, arg.Offset) if err != nil &#123; return nil, err &#125; defer rows.Close() items := []Account&#123;&#125; for rows.Next() &#123; var i Account if err := rows.Scan( &amp;i.ID, &amp;i.Owner, &amp;i.Balance, &amp;i.Currency, &amp;i.CreatedAt, ); err != nil &#123; return nil, err &#125; items = append(items, i) &#125; if err := rows.Err(); err != nil &#123; return nil, err &#125; return items, nil&#125; rows, err :&#x3D; q.db.Query(ctx, listAccounts, arg.Owner, arg.Limit, arg.Offset) 这里查询的条件有arg.owner 但是我们在测试的时候并没有设置owner 可以显示尝试把owner去掉 11.6日 二十二.身份验证中间件 授权API请求使用make sqlc 和 make mock 重新为listAccount增加 Owner字段 搞了半天 app.env配置错了 应该是 ACCESS_TOKEN_DURATION&#x3D;15m 我写成别的了 二十三.部署目前的程序1.对程序进行docker化运用git部署 注意：永远不要将更改直接推送到主分支 1.创建新分支-》推送分支-》产生以下结果-》复制url-》创建标题-》创建拉取请求-》从而可以看到 Files changed 文件的更改 1234567remote: Resolving deltas: 100% (2/2), completed with 2 local objects.remote: remote: Create a pull request for &#x27;ft/docker&#x27; on GitHub by visiting:remote: https://github.com/Whuichenggong/projects/pull/new/ft/dockerremote:To github.com:Whuichenggong/projects.git * [new branch] ft/docker -&gt; ft/docker 重新回看第10集 配置工作流 最近这两天了解到了工作流有了更深的理解 1234567891011121314151617181920212223242526272829# This workflow will build a golang project# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-goname: Goon: push: branches: [ &quot;main&quot; ] pull_request: branches: [ &quot;main&quot; ]jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Set up Go uses: actions/setup-go@v4 with: go-version: &#x27;1.20&#x27; - name: Build run: go build -v ./... - name: Test run: go test -v ./... go语言的工作流模板 giuthub action 相当于将一些列配置放到了github上的一个服务器上 也就是相当于将东西放进了github的服务器 11.10日还是github action问题 终于把 Install golang-migrate解决了 因为： 在最开始推送项目到github的时候 就是因为把项目结构推送错了 ，导致推送到github上的项目根目录没有go.mod文件这造成了很大的错误 导致一直失败 今天又解决了 install golang-migrate问题 因为sudo mv migrate &#x2F;usr&#x2F;bin&#x2F;migrate 把之前的 名称换成 migrate就好用了 问题2： make migratedown migrate -path &#x2F;db&#x2F;migration -database “postgresql:&#x2F;&#x2F;root:secret@localhost:5432&#x2F;simple_bank?sslmode&#x3D;disable” -verbose down 2024&#x2F;11&#x2F;10 13:30:17 error: open &#x2F;db&#x2F;migration.: The system cannot find the path specified. make: *** [migratedown] 错误 1 在Makefile中的指令的 路径又弄错了 必须让指令能找到位置所在 卧槽：成功了 绿了 妈的 牛逼 Dockerfile官方镜像 Dockerfile 123456789# Build stageFROM golang:1.16-alpine3.13 WORKDIR /appCOPY .. .RUN go build -o main main.goEXPOSE 8080 CMD [ &quot;/app/main&quot; ] docker build -t simplebank:latest 使用这个指令构建镜像 images的大小很大 123docker images REPOSITORY TAG IMAGE ID CREATED SIZEsimplebank latest 48621dad3f4d 5 minutes ago 656MB 分阶段构建可以减少体积 也就是 123456789101112131415# Build stage 构建二进制文件FROM golang:1.23-alpine3.20 AS buildWORKDIR /appCOPY . .RUN go build -o main main.go# Production stage 生产环境FROM alpine:3.20WORKDIR /appCOPY --from=build /app/main .EXPOSE 8080 CMD [ &quot;/app/main&quot; ] 最终体积 123docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEsimplebank latest f64691fae70e 7 seconds ago 27.1MB 123456789101112131415161718192021222324252627282930313233docker ps -a列出容器状态docker rmi f64691fae70eUntagged: simplebank:latestDeleted: sha256:f64691fae70e516b799ed846bbeef10045388dae1932ecafc8b93fb208b403f0//运行这条指令便启动了容器 监听8080端口 docker run --name simplebank -p 8080:8080 simplebank:latest[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production. - using env: export GIN_MODE=release - using code: gin.SetMode(gin.ReleaseMode)[GIN-debug] POST /users --&gt; project/simplebank/api.(*Server).createUser-fm (3 handlers)[GIN-debug] POST /users/login --&gt; project/simplebank/api.(*Server).loginUser-fm (3 handlers)[GIN-debug] GET /accounts/:id --&gt; project/simplebank/api.(*Server).getAccount-fm (4 handlers)[GIN-debug] POST /accounts --&gt; project/simplebank/api.(*Server).createAccount-fm (4 handlers)[GIN-debug] GET /accounts --&gt; project/simplebank/api.(*Server).listAccounts-fm (4 handlers)[GIN-debug] POST /transfers --&gt; project/simplebank/api.(*Server).createTransfer-fm (4 handlers)[GIN-debug] [WARNING] You trusted all proxies, this is NOT safe. We recommend you to set a value.Please check https://pkg.go.dev/github.com/gin-gonic/gin#readme-don-t-trust-all-proxies for details.[GIN-debug] Listening and serving HTTP on 127.0.0.1:1124//重新启动镜像PS E:\\projects\\simplebank&gt; docker rm simplebanksimplebankPS E:\\projects\\simplebank&gt; docker run --name simplebank -p 8080:8080 -e GIN_MODE=release simplebank:latest这样启动就不会有上面的输出了 docker container inspect postgres12 检查网络设置 11.13日问题：解决用docker启动后 无法用postman测试接口的问题 1docker run --name simplebank -p 8083:8083 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simplebank?sslmode=disable&quot; simplebank:latest 每次修改完dockerfiles或者什么 要记住重新构建镜像 1docker build --no-cache -t simplebank:latest . 关键：先使用调试功能 查看是否正确监听端口 12345678910111213141516docker run --name simplebank -p 8080:8080 simplebank:latest[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production. - using env: export GIN_MODE=release - using code: gin.SetMode(gin.ReleaseMode)[GIN-debug] POST /users --&gt; project/simplebank/api.(*Server).createUser-fm (3 handlers)[GIN-debug] POST /users/login --&gt; project/simplebank/api.(*Server).loginUser-fm (3 handlers)[GIN-debug] GET /accounts/:id --&gt; project/simplebank/api.(*Server).getAccount-fm (4 handlers)[GIN-debug] POST /accounts --&gt; project/simplebank/api.(*Server).createAccount-fm (4 handlers)[GIN-debug] GET /accounts --&gt; project/simplebank/api.(*Server).listAccounts-fm (4 handlers)[GIN-debug] POST /transfers --&gt; project/simplebank/api.(*Server).createTransfer-fm (4 handlers)[GIN-debug] [WARNING] You trusted all proxies, this is NOT safe. We recommend you to set a value.Please check https://pkg.go.dev/github.com/gin-gonic/gin#readme-don-t-trust-all-proxies for details.[GIN-debug] Listening and serving HTTP on 0.0.0.0:8080 这次在测试的时候 有了反应 12PS E:\\projects\\simplebank&gt; docker run --name simplebank -p 8080:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simplebank?sslmode=disable&quot; simplebank:latest[GIN] 2024/11/13 - 01:17:23 | 401 | 39.567µs | 172.17.0.1 | GET &quot;/accounts/1&quot; 此更改导致了postgres连接出错 #####不使用ip地址使用用户定义的网络 连接到postrges docker network ls 1234567NETWORK ID NAME DRIVER SCOPEca0046b2c82c bank-network bridge localcf35f34026f7 bridge bridge local1500c05159ef host host local074a556122c6 none null localfafb76e1721e start_gvb-network bridge local 桥接网络 查看更详细的网络信息docker network inspect bridge 删除网络: docker network rm 0fd871187ef1 创建自己的网络&#96;&#96;docker network create bank_network&#96; 1`0fd871187ef1e3b3bee37ac898e895cf54615e267bd6af9d7b2c045fc5178a14 连接创建的网络docker network connect bank-network 将postrges12 连接到我们创建的网络 docker network connect bank-network postgres12 docker network inspect bank-network 得先启动 postrges12验证 postgres12 容器是否正在运行： 检查 named 的容器是否正在运行：postgres12 1docker ps -a 查找具有名称的容器并检查其状态。如果容器未运行，请启动容器：postgres12 1docker start postgres12 再次将 postgres12 连接到网络： 现在，尝试将容器连接到 ：postgres12``bank-network 1docker network connect bank-network postgres12 现在已经成功添加了postrges12 12345678&quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;7ba14f6dd2f7a81db9264c0814e9686e921b0d86c01b2df325dad4a1cca35c40&quot;: &#123; &quot;Name&quot;: &quot;postgres12&quot;, &quot;EndpointID&quot;: &quot;b3dc1614431f2f11f2b0d6c8bb7f33b529baacefa39521bf522c84a7f526a882&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; 此时查看 docker container inspect postgres12 这个容器将会有两段网络 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&quot;NetworkSettings&quot;: &#123; &quot;Bridge&quot;: &quot;&quot;, &quot;SandboxID&quot;: &quot;2ea1e674576863a5e20fe6dda2a3ea265dd11b0223dc4a94bbfa23c57adc66d9&quot;, &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/2ea1e6745768&quot;, &quot;Ports&quot;: &#123; &quot;5432/tcp&quot;: [ &#123; &quot;HostIp&quot;: &quot;0.0.0.0&quot;, &quot;HostPort&quot;: &quot;5432&quot; &#125; ] &#125;, &quot;HairpinMode&quot;: false, &quot;LinkLocalIPv6Address&quot;: &quot;&quot;, &quot;LinkLocalIPv6PrefixLen&quot;: 0, &quot;SecondaryIPAddresses&quot;: null, &quot;SecondaryIPv6Addresses&quot;: null, &quot;EndpointID&quot;: &quot;d85289ea4f7ca088375523781a14955e1b1fc58e5af731fe7f4c48fecba470e6&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;Networks&quot;: &#123; &quot;bank-network&quot;: &#123; &quot;IPAMConfig&quot;: &#123;&#125;, &quot;Links&quot;: null, &quot;Aliases&quot;: [ &quot;7ba14f6dd2f7&quot; ], &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;NetworkID&quot;: &quot;ca0046b2c82ccb1fe4c996950a815d9c374c58514921c9b919899d8169cb9881&quot;, &quot;EndpointID&quot;: &quot;b3dc1614431f2f11f2b0d6c8bb7f33b529baacefa39521bf522c84a7f526a882&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot;, &quot;IPAddress&quot;: &quot;172.18.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;DriverOpts&quot;: &#123;&#125;, &quot;DNSNames&quot;: [ &quot;postgres12&quot;, &quot;7ba14f6dd2f7&quot; ] &#125;, &quot;bridge&quot;: &#123; &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;NetworkID&quot;: &quot;cf35f34026f787fe91864d7e7a2ab23d482b6a6b956a10d596ae0d9818aa7e16&quot;, &quot;EndpointID&quot;: &quot;d85289ea4f7ca088375523781a14955e1b1fc58e5af731fe7f4c48fecba470e6&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;DriverOpts&quot;: null, &quot;DNSNames&quot;: null &#125; &#125; &#125; 重新使用指令 docker run --name simplebank --network bank-network -p 8080:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simplebank?sslmode=disable&quot; simplebank:latest 此时 simplebank容器将与postgres12运行在同一个网络上 将172.17.0.2替换成postgres12 因为可以通过名称访问网络 启动容器指令： 12docker run --name simplebank --network bank-network -p 8080:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@postgres12:5432/simplebank?sslmode=disable&quot; simplebank:latest[GIN] 2024/11/13 - 02:06:27 | 400 | 105.754µs | 172.18.0.1 | POST &quot;/users/login&quot; docker network inspect bank-network 1234567891011121314151617181920212223242526272829303132333435363738394041424344[ &#123; &quot;Name&quot;: &quot;bank-network&quot;, &quot;Id&quot;: &quot;ca0046b2c82ccb1fe4c996950a815d9c374c58514921c9b919899d8169cb9881&quot;, &quot;Created&quot;: &quot;2024-05-10T13:32:42.557489581Z&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;7ba14f6dd2f7a81db9264c0814e9686e921b0d86c01b2df325dad4a1cca35c40&quot;: &#123; &quot;Name&quot;: &quot;postgres12&quot;, &quot;EndpointID&quot;: &quot;b3dc1614431f2f11f2b0d6c8bb7f33b529baacefa39521bf522c84a7f526a882&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;a76e19ef1c210d1cc4f458ed9b2238db810872417e0a1072e8467dda82663a2a&quot;: &#123; &quot;Name&quot;: &quot;simplebank&quot;, &quot;EndpointID&quot;: &quot;487f3ec81ada3bf84e44af700d0ae930075ce8c683755d789c27cadc7f95ed06&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125; 目前有两个容器在自定义的网络中运行 之后的postrges就可以正常使用了 更改Makefile文件 12postgres: docker run --name postgres12 --network bank-network -p 5432:5432 -e POSTGRES_USER=root -e POSTGRES_PASSWORD=secret -d postgres:12-alpine 在github中 pullrequest中可以查看更改 并且 merge 分支到主分支-》然后确认合并—》Delete branch 二十四.docker-composehttps://docs.docker.com 创建docker-compose.yaml文件 123456789101112131415161718192021 version: &quot;3.9&quot;services: postgres: image: postgres:12-alpine environment: - POSTGRES_USER=root - POSTGRES_PASSWORD=secret - POSTGRES_DB=simple_bank ports: - &quot;5432:5432&quot; api: build: context: . dockerfile: Dockerfile ports: - &quot;8080:8080&quot; environment: - DB_SOURCE=postgresql://root:secret@postgres:5432/simple_bank?sslmode=disable docker compose up 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 docker compose up[+] Running 1/0 ✔ Container simplebank-api-1 Created 0.0s Attaching to api-1, postgres-1api-1 | [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.api-1 |api-1 | [GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production.api-1 | - using env: export GIN_MODE=releaseapi-1 | - using code: gin.SetMode(gin.ReleaseMode)api-1 |api-1 | [GIN-debug] POST /users --&gt; project/simplebank/api.(*Server).createUser-fm (3 handlers)api-1 | [GIN-debug] POST /users/login --&gt; project/simplebank/api.(*Server).loginUser-fm (3 handlers)api-1 | [GIN-debug] GET /accounts/:id --&gt; project/simplebank/api.(*Server).getAccount-fm (4 handlers)api-1 | [GIN-debug] POST /accounts --&gt; project/simplebank/api.(*Server).createAccount-fm (4 handlers)api-1 | [GIN-debug] GET /accounts --&gt; project/simplebank/api.(*Server).listAccounts-fm (4 handlers)api-1 | [GIN-debug] POST /transfers --&gt; project/simplebank/api.(*Server).createTransfer-fm (4 handlers)api-1 | [GIN-debug] [WARNING] You trusted all proxies, this is NOT safe. We recommend you to set a value.api-1 | Please check https://pkg.go.dev/github.com/gin-gonic/gin#readme-don-t-trust-all-proxies for details.api-1 | [GIN-debug] Listening and serving HTTP on 0.0.0.0:8080postgres-1 | The files belonging to this database system will be owned by user &quot;postgres&quot;.postgres-1 | This user must also own the server process.postgres-1 |postgres-1 | The database cluster will be initialized with locale &quot;en_US.utf8&quot;.postgres-1 | The default database encoding has accordingly been set to &quot;UTF8&quot;.postgres-1 | The default text search configuration will be set to &quot;english&quot;.postgres-1 |postgres-1 | Data page checksums are disabled.postgres-1 |postgres-1 | fixing permissions on existing directory /var/lib/postgresql/data ... okpostgres-1 | creating subdirectories ... okpostgres-1 | selecting dynamic shared memory implementation ... posixpostgres-1 | selecting default max_connections ... 100postgres-1 | selecting default shared_buffers ... 128MBpostgres-1 | selecting default time zone ... UTCpostgres-1 | creating configuration files ... okpostgres-1 | running bootstrap script ... okpostgres-1 | sh: locale: not foundpostgres-1 | 2024-11-13 06:50:42.795 UTC [30] WARNING: no usable system locales were foundpostgres-1 | performing post-bootstrap initialization ... okpostgres-1 | syncing data to disk ... okpostgres-1 |postgres-1 |postgres-1 | Success. You can now start the database server using:postgres-1 |postgres-1 | pg_ctl -D /var/lib/postgresql/data -l logfile startpostgres-1 |postgres-1 | initdb: warning: enabling &quot;trust&quot; authentication for local connectionspostgres-1 | You can change this by editing pg_hba.conf or using the option -A, orpostgres-1 | --auth-local and --auth-host, the next time you run initdb.postgres-1 | waiting for server to start....2024-11-13 06:50:43.144 UTC [36] LOG: starting PostgreSQL 12.18 on x86_64-pc-linux-musl, compiled by gcc (Alpine 13.2.1_git20231014) 13.2.1 20231014, 64-bitpostgres-1 | 2024-11-13 06:50:43.146 UTC [36] LOG: listening on Unix socket &quot;/var/run/postgresql/.s.PGSQL.5432&quot;postgres-1 | 2024-11-13 06:50:43.160 UTC [37] LOG: database system was shut down at 2024-11-13 06:50:43 UTCpostgres-1 | 2024-11-13 06:50:43.164 UTC [36] LOG: database system is ready to accept connectionspostgres-1 | donepostgres-1 | server startedpostgres-1 | CREATE DATABASEpostgres-1 |postgres-1 |postgres-1 | /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*postgres-1 |postgres-1 | waiting for server to shut down....2024-11-13 06:50:43.315 UTC [36] LOG: received fast shutdown requestpostgres-1 | 2024-11-13 06:50:43.316 UTC [36] LOG: aborting any active transactionspostgres-1 | 2024-11-13 06:50:43.318 UTC [36] LOG: background worker &quot;logical replication launcher&quot; (PID 43) exited with exit code 1postgres-1 | 2024-11-13 06:50:43.318 UTC [38] LOG: shutting downpostgres-1 | 2024-11-13 06:50:43.330 UTC [36] LOG: database system is shut downpostgres-1 | donepostgres-1 | server stoppedpostgres-1 |postgres-1 | PostgreSQL init process complete; ready for start up.postgres-1 |postgres-1 | 2024-11-13 06:50:43.447 UTC [1] LOG: starting PostgreSQL 12.18 on x86_64-pc-linux-musl, compiled by gcc (Alpine 13.2.1_git20231014) 13.2.1 20231014, 64-bitpostgres-1 | 2024-11-13 06:50:43.447 UTC [1] LOG: listening on IPv4 address &quot;0.0.0.0&quot;, port 5432postgres-1 | 2024-11-13 06:50:43.447 UTC [1] LOG: listening on IPv6 address &quot;::&quot;, port 5432postgres-1 | 2024-11-13 06:50:43.450 UTC [1] LOG: listening on Unix socket &quot;/var/run/postgresql/.s.PGSQL.5432&quot;postgres-1 | 2024-11-13 06:50:43.461 UTC [51] LOG: database system was shut down at 2024-11-13 06:50:43 UTCpostgres-1 | 2024-11-13 06:50:43.465 UTC [1] LOG: database system is ready to accept connections 构建镜像完成后 1234docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEsimplebank-api latest eb772c9e932f 6 hours ago 27.1MBsimplebank latest 9f145f0ce89f 6 hours ago 27.1MB 查看占用端口的进程 1234567891011121314`netstat -ano | findstr :5432` TCP 0.0.0.0:5432 0.0.0.0:0 LISTENING 30352 TCP [::]:5432 [::]:0 LISTENING 30352 TCP [::1]:5432 [::]:0 LISTENING 35464PS E:\\projects\\simplebank&gt; `tasklist /FI &quot;PID eq 30352&quot;``映像名称 PID 会话名 会话# 内存使用========================= ======== ================ =========== ============com.docker.backend.exe 30352 Console 2 117,104 KPS E:\\projects\\simplebank&gt; `tasklist /FI &quot;PID eq 35464&quot;``映像名称 PID 会话名 会话# 内存使用========================= ======== ================ =========== ============wslrelay.exe 35464 Console 2 8,328 K 在 Windows 上（终止进程）： 12taskkill /PID 30352 /Ftaskkill /PID 35464 /F docker ps 123CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESdab18d564f9c postgres:12-alpine &quot;docker-entrypoint.s…&quot; About an hour ago Up 7 minutes 0.0.0.0:5432-&gt;5432/tcp simplebank-postgres-1c4c37a8a870a simplebank-api &quot;/app/main&quot; About an hour ago Up 7 minutes 0.0.0.0:8080-&gt;8080/tcp simplebank-api-1 docker network inspect simplebank_default 两个服务容器实际在同一个网络上运行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 docker network inspect simplebank_default[ &#123; &quot;Name&quot;: &quot;simplebank_default&quot;, &quot;Id&quot;: &quot;fab69439b1a55525d81fa70d9e789c3b6d51ba8d7899924deb8413fb724ca951&quot;, &quot;Created&quot;: &quot;2024-11-13T05:28:49.358856507Z&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.20.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.20.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;c4c37a8a870a75e9fa626c7034dd935c8f3afdb86c5e2c37b012503bff9c7ab7&quot;: &#123; &quot;Name&quot;: &quot;simplebank-api-1&quot;, &quot;EndpointID&quot;: &quot;8a247db55db70983d6b2d619caef09bf2593964daa02be5773448fbd74f9d791&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:14:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.20.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;dab18d564f9c4554ef255e50205be2f4dd9c1fada3391dde698d7717d0e642ff&quot;: &#123; &quot;Name&quot;: &quot;simplebank-postgres-1&quot;, &quot;EndpointID&quot;: &quot;2b9220ab1bcc031b29631a2ecb462a48a475a722b10592c478124c03d95e29df&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:14:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.20.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123; &quot;com.docker.compose.network&quot;: &quot;default&quot;, &quot;com.docker.compose.project&quot;: &quot;simplebank&quot;, &quot;com.docker.compose.version&quot;: &quot;2.24.6&quot; &#125; &#125;] docker compose down 删除现在所有网络 Dockerfile 1234567891011121314151617# Build stage 构建二进制文件FROM golang:1.23-alpine3.20 AS buildWORKDIR /appCOPY . .RUN go build -o main main.go# Run stage FROM alpine:3.20WORKDIR /appCOPY --from=build /app/main .COPY app.env .# 这一步可以解决2024/11/13 08:08:06 cannot load config:Config File &quot;app&quot; Not Found in &quot;[/app]&quot;EXPOSE 8080 CMD [ &quot;/app/main&quot; ] 操 最后一刻验证成功了 用终端输入指令 带入参数 172.17.0.2 这样 viper可以自动读取配置 1234docker run --name simplebank -p 8080:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simple_bank?sslmode=disable&quot; simplebank:latestReceived request: &#123;Username:Zhonghe FullName:zhaohzonghe Email:3041322213@qq.com Password:zzh123456&#125;[GIN] 2024/11/13 - 12:54:07 | 200 | 57.106456ms | 172.17.0.1 | POST &quot;/users&quot; app.env中的配置 12345DATABASE_URL=postgres://root:secret@localhost:5432/simple_bank?sslmode=disableMIGRATION_URL=project/simplebank/db/migrationHTTPServerAddress=0.0.0.0:8080TOKEN_SYMMETRIC_KEY=12345678901234567890123456789012ACCESS_TOKEN_DURATION=15m 11.18日docker ps docker network inspect simplebank_default 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES81aa7c463a58 postgres:12-alpine &quot;docker-entrypoint.s…&quot; About a minute ago Up About a minute 0.0.0.0:5432-&gt;5432/tcp simplebank-postgres-1047f0bb9fbc8 simplebank-api &quot;/app/main&quot; About a minute ago Up About a minute 0.0.0.0:8080-&gt;8080/tcp simplebank-api-1PS E:\\projects\\simplebank&gt; [ &#123; &quot;Name&quot;: &quot;simplebank_default&quot;, &quot;Id&quot;: &quot;9afc6c5d5e9252f2161f204008596b067fceecd49ac5a9171910c58f4717e205&quot;, &quot;Created&quot;: &quot;2024-11-18T11:05:59.526768414Z&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;047f0bb9fbc8fdbe07cc311b134c00ff27cb0a2cbcb4322746a6b30cbbb404bf&quot;: &#123; &quot;Name&quot;: &quot;simplebank-api-1&quot;, &quot;EndpointID&quot;: &quot;b607176500386abe6ac7ad27f31d9c453a3f2087dacade426d50a72b1e30b585&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;81aa7c463a58ad777dd3d99f9ba3c442c024c02d0f91be924903ffa423f99426&quot;: &#123; &quot;Name&quot;: &quot;simplebank-postgres-1&quot;, &quot;EndpointID&quot;: &quot;ce4ec4fda5631c27ba1e8c96503ef86f1bfea3bc8f563ecf7528c75ca91f1bb6&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123; &quot;com.docker.compose.network&quot;: &quot;default&quot;, &quot;com.docker.compose.project&quot;: &quot;simplebank&quot;, &quot;com.docker.compose.version&quot;: &quot;2.24.6&quot; &#125; &#125;] 两个服务器运行在同一个网络 通过名字彼此发现自己 123456789101112131415&quot;Containers&quot;: &#123; &quot;047f0bb9fbc8fdbe07cc311b134c00ff27cb0a2cbcb4322746a6b30cbbb404bf&quot;: &#123; &quot;Name&quot;: &quot;simplebank-api-1&quot;, &quot;EndpointID&quot;: &quot;b607176500386abe6ac7ad27f31d9c453a3f2087dacade426d50a72b1e30b585&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;81aa7c463a58ad777dd3d99f9ba3c442c024c02d0f91be924903ffa423f99426&quot;: &#123; &quot;Name&quot;: &quot;simplebank-postgres-1&quot;, &quot;EndpointID&quot;: &quot;ce4ec4fda5631c27ba1e8c96503ef86f1bfea3bc8f563ecf7528c75ca91f1bb6&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; 目前是链接不上数据库的因为没有执行数据库迁移 重新构建docker-compose docker files文件 docker compose down[+] Running 3&#x2F;3✔ Container simplebank-postgres-1 Removed 0.7s✔ Container simplebank-api-1 Removed 0.6s✔ Network simplebank_default Removed 删除目前所有容器和网络 使用docker rmi …. 删除simplebank_api镜像 出错ERROR [api internal] load metadata for docker.io&#x2F;library&#x2F;builder:latest 错误的核心在于 tar 解压的文件名与你 mv 命令中期望的文件名不匹配。具体表现为 tar 解压生成的文件名并不是 migrate.linux-amd64，而是 migrate。 解决方法1. 修改 RUN 命令中的文件名引用 根据错误日志，tar 解压后生成的文件名是 migrate，而非 migrate.linux-amd64。因此，mv 命令应改为直接操作 migrate： 12dockerfile复制代码RUN curl -L https://github.com/golang-migrate/migrate/releases/download/v4.17.0/migrate.linux-amd64.tar.gz \\ | tar -xz &amp;&amp; mv migrate /app/migrate 这将确保正确地将解压出的 migrate 文件移动到 /app/migrate。 2. 验证文件解压和路径 为了确保过程正确，可以在 RUN 指令中加入调试信息以打印文件列表： 12dockerfile复制代码RUN curl -L https://github.com/golang-migrate/migrate/releases/download/v4.17.0/migrate.linux-amd64.tar.gz \\ | tar -xz &amp;&amp; ls -l &amp;&amp; mv migrate /app/migrate 原因：要保持 builer同意 我写成了一个build 另一个builder 因该换成build 12COPY --from=build /app/main .COPY --from=build /app/migrate /usr/bin/migrate 欧克解决了 完整的 dockerfile 1234567891011121314151617181920212223# Build stageFROM golang:1.23-alpine3.20 AS buildWORKDIR /appCOPY . .RUN go build -o main main.goRUN apk add curlRUN curl -L https://github.com/golang-migrate/migrate/releases/download/v4.17.0/migrate.linux-amd64.tar.gz | tar xvz &amp;&amp; mv migrate /app/migrate # Run stageFROM alpine:3.20WORKDIR /appCOPY --from=build /app/main .COPY --from=build /app/migrate /usr/bin/migrateCOPY app.env .COPY start.sh . COPY db/migration ./migrationEXPOSE 8080 CMD [ &quot;/app/main&quot; ]ENTRYPOINT [ &quot;/app/start.sh&quot; ] 完整的 docker-compose.yaml 12345678910111213141516171819202122version: &quot;3.9&quot;services: postgres: image: postgres:12-alpine environment: - POSTGRES_USER=root - POSTGRES_PASSWORD=secret - POSTGRES_DB=simple_bank ports: - &quot;5432:5432&quot; api: build: context: . dockerfile: Dockerfile ports: - &quot;8080:8080&quot; environment: - DB_SOURCE=postgresql://root:secret@postgres:5432/simple_bank?sslmode=disable depends_on: - postgres 下载wait-for工具 mv &quot;C:\\Users\\30413\\Downloads\\wait-for&quot; ./wait-for.sh 目前测试api问题： 123&#123; &quot;error&quot;: &quot;failed to connect to `user=root database=simple_bank`:\\n\\t127.0.0.1:5432 (localhost): dial error: dial tcp 127.0.0.1:5432: connect: connection refused\\n\\t[::1]:5432 (localhost): dial error: dial tcp [::1]:5432: connect: cannot assign requested address&quot;&#125; 二.11.22日解决上次的问题无论怎么样构建无法用postman接口调试 这是因为 你在 star.sh中 12345678910#!/bin/shset -eecho &quot;run db migrations&quot;/app/migrate -path /app/migration -database &quot;$DB_SOURCE&quot; -verbose upecho &quot;start the app&quot;exec &quot;$@&quot; 解决 使用的连接数据库的 参数是 $DB_SOURCE” 但是你在app.env中配置的名字不是DB_SOURCE 是DATABASE_URL 这种错误造成的原因可能是目前你并不了解一些列的工具是如何真正使用的没有真正了解 之前的配置 都是用DATABASE_URL来配置的 12345DATABASE_URL=postgres://root:secret@localhost:5432/simple_bank?sslmode=disableMIGRATION_URL=project/simplebank/db/migrationHTTPServerAddress=0.0.0.0:8080TOKEN_SYMMETRIC_KEY=12345678901234567890123456789012ACCESS_TOKEN_DURATION=15m 更改为 DB_SOURCE后api测试成功 三.11.23日部署应用程序 创建AWS(最大的云提供商)账户部署应用程序地址 https://aws.amazon.com/free/ emmm不知道银行卡的cvv 自动构建docker镜像并推送到AWS ECR1.创建一个存储库存储docker镜像 将docker 镜像推送到CLI每当新代码合并到主分支时 我们将使用 Github Actions自动构建标记和推送镜像 deploy.yml 关键 目前没有招商卡无法使用AWS 先使用快过期的aliyun试一试 添加go到linux环境 12345678echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin[root@iZt4nbaeq7uzlvq978l1xqZ simplebank]# ^C[root@iZt4nbaeq7uzlvq978l1xqZ simplebank]# export PATH=$PATH:/usr/local/go/bin[root@iZt4nbaeq7uzlvq978l1xqZ simplebank]# go run main.gogo: downloading github.com/jackc/pgx/v5 v5.7.1go: downloading github.com/gin-gonic/gin v1.10.0 四.11.29日 尝试在仅剩5个月的服务器中 把这个简单的项目部署到服务器上 配置服务器的docker的yum源 否则下载东西很费劲 设置国内镜像【不设置可能会导致拉取镜像失败】进入&#x2F;etc&#x2F;docker文件夹下，修改daemon.json。如果文件不存在则，创建该文件。 daemon.json文件内容如下 123456789101112131415&#123;&quot;registry-mirrors&quot; : [ &quot;https://jkfdsf2u.mirror.aliyuncs.com&quot;, &quot;https://registry.docker-cn.com&quot; ], &quot;insecure-registries&quot; : [ &quot;docker-registry.zjq.com&quot; ], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;10m&quot;, &quot;max-file&quot;: &quot;10&quot; &#125;, &quot;data-root&quot;: &quot;/data/docker&quot;&#125; 拉取docker pull镜像 123docker pull postgres:12-alpine 。。。。 配置不够cpu直接干到100% 看看有没有 简化的方法 11.30日 还是执着一点 弄了一台2核2gb的服务器 用docker部署 首先是源的配置 安装docker 安装docker-compose 然后是构建项目中出现的问题 反复构建 赋予权限等 权限问题在ubuntu中也是一个很重要的问题 哪个用户使用ubuntu也会导致不同的结果 123456789从 ls -ld 命令的输出可以看到，/home/ubuntu/projects/simplebank 目录的所有者和所属组都是 ubuntu，权限也允许当前用户进行访问。这意味着该目录的所有权和权限没有问题。但根据 Git 提示的错误信息，Git 依然检测到目录的所有权问题，因此需要添加该目录到 安全目录 列表中。解决方案：运行以下命令，将该目录添加到 Git 的安全目录列表中：git config --global --add safe.directory /home/ubuntu/projects/simplebank 看到希望了 12345root@VM-12-4-ubuntu:/home/ubuntu/projects/simplebank# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESroot@VM-12-4-ubuntu:/home/ubuntu/projects/simplebank# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES758e9432d178 e054039bb12c &quot;/app/start.sh /app/…&quot; 27 minutes ago Created 0.0.0.0:8080-&gt;8080/tcp, :::8080-&gt;8080/tcp simplebank 还需要配置数据库吗？？我有点蒙了 docker run与docker start的区别 五.2024年 11.30日 21：27分 成了把项目成功部署到了云服务器上太不容易了 12345678root@VM-12-4-ubuntu:/home/ubuntu/projects/simplebank# docker run --name simplebank -p 80:8080 -e GIN_MODE=release -e DB_SOURCE=&quot;postgresql://root:secret@172.17.0.2:5432/simple_bank?sslmode=disable&quot; simplebank:latestrun db migrations2024/11/30 13:25:56 no change2024/11/30 13:25:56 Finished after 977.24µs2024/11/30 13:25:56 Closing source and databasestart the appReceived request: &#123;Username:Zhonghe FullName:zhaohzonghe Email:3041322213@qq.com Password:zzh123456&#125;[GIN] 2024/11/30 - 13:26:07 | 200 | 75.179039ms | 202.97.179.126 | POST &quot;/users&quot; 为什么把端口8080:8080改成 80:8080就好用了 啊啊啊啊好兴奋 感谢老哥们 从把项目移动到 ubuntu 配置dockers环境 使用docker build构建项目 然后就是用postman测试 这期间 多次使用的 Docker 指令docker run docker images docker ps -a docekr pull docker build -t simplebank:latest . docker network create bank_network docker network rm 0fd871187ef1 docker rm simplebank docker rmi docker network connect bank-network postgres12 docker network ls docker container inspect postgres12 目前服务器中的 postgres12大体网络模式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485root@VM-12-4-ubuntu:/home/ubuntu/projects/simplebank# docker container inspect postgres12[ &#123; &quot;Id&quot;: &quot;100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47&quot;, &quot;Created&quot;: &quot;2024-11-30T09:24:02.785101065Z&quot;, &quot;Path&quot;: &quot;docker-entrypoint.sh&quot;, &quot;Args&quot;: [ &quot;postgres&quot; ], &quot;State&quot;: &#123; &quot;Status&quot;: &quot;running&quot;, &quot;Running&quot;: true, &quot;Paused&quot;: false, &quot;Restarting&quot;: false, &quot;OOMKilled&quot;: false, &quot;Dead&quot;: false, &quot;Pid&quot;: 315509, &quot;ExitCode&quot;: 0, &quot;Error&quot;: &quot;&quot;, &quot;StartedAt&quot;: &quot;2024-11-30T11:54:14.985494404Z&quot;, &quot;FinishedAt&quot;: &quot;2024-11-30T11:35:40.792853655Z&quot; &#125;, &quot;Image&quot;: &quot;sha256:486566ce0ca8f59e321b2b5999de4b50237b2c60bcc3414d8a602fb96cb12c6f&quot;, &quot;ResolvConfPath&quot;: &quot;/data/docker/containers/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47/resolv.conf&quot;, &quot;HostnamePath&quot;: &quot;/data/docker/containers/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47/hostname&quot;, &quot;HostsPath&quot;: &quot;/data/docker/containers/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47/hosts&quot;, &quot;LogPath&quot;: &quot;/data/docker/containers/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47/100ff1a5f0bf6e1f0447fff800aaa00ba54edc2cf19826eef512a442c2ec3a47-json.log&quot;, &quot;Name&quot;: &quot;/postgres12&quot;, &quot;RestartCount&quot;: 0, &quot;Driver&quot;: &quot;overlay2&quot;, &quot;Platform&quot;: &quot;linux&quot;, &quot;MountLabel&quot;: &quot;&quot;, &quot;ProcessLabel&quot;: &quot;&quot;, &quot;AppArmorProfile&quot;: &quot;docker-default&quot;, &quot;ExecIDs&quot;: null, &quot;HostConfig&quot;: &#123; &quot;Binds&quot;: null, &quot;ContainerIDFile&quot;: &quot;&quot;, &quot;LogConfig&quot;: &#123; &quot;Type&quot;: &quot;json-file&quot;, &quot;Config&quot;: &#123; &quot;max-file&quot;: &quot;10&quot;, &quot;max-size&quot;: &quot;10m&quot; &quot;Networks&quot;: &#123; &quot;bank_network&quot;: &#123; &quot;IPAMConfig&quot;: &#123;&#125;, &quot;Links&quot;: null, &quot;Aliases&quot;: [], &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;DriverOpts&quot;: &#123;&#125;, &quot;NetworkID&quot;: &quot;c2a3ada685148d5607a5a6fc39e1690e5fbd161f0607df5a3a189f74ced100fa&quot;, &quot;EndpointID&quot;: &quot;07a57c58250657bf968d33d1f93cea6e9225d0cae314648d1b1c639c3811c9c1&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot;, &quot;IPAddress&quot;: &quot;172.18.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;DNSNames&quot;: [ &quot;postgres12&quot;, &quot;100ff1a5f0bf&quot; ] &#125;, &quot;bridge&quot;: &#123; &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;DriverOpts&quot;: null, &quot;NetworkID&quot;: &quot;83e7fddfe207131e6199fb11fb5daa38bf044b67817fba2de02bd7f1639d4bb8&quot;, &quot;EndpointID&quot;: &quot;d9449d910f4e7be735031acb301f0e418999b091bb8c75450fecf983eca2aa24&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;DNSNames&quot;: null &#125; &#125; &#125; &#125;] 还是看跟着课程走一走吧 AWS的EKS 将工作节点 添加到EKS集群 使用 kubectl 连接到集群 如何创建新的EKS集群并向其中添加工作节点大多都是用AWS目前没有卡还是先不要弄了 学习一下其他的知识 进阶后端master haha 管理用户会话 用PASETO JWT作为基于令牌的身份验证 因为这些是无状态设计 这些令牌不会存储到数据库中 寿命应该很短 他们的过期时间通常为10~15分钟 如果token每次都在这么短时间过期重新输入用户名和密码一定不是一个好的体验 刷新令牌 在服务器上维护有状态的会话 它将存储在数据库中 生命周期长 创建一个新的字段添加到app.env中 REFRESH_TOKEN_DURATION&#x3D;24h 同时config中添加新字段 RefreshTokenDuration time.Duration mapstructure:&quot;REFRESH_TOKEN_DURATION&quot; 使用指令 migrate create -ext sql -dir db&#x2F;migration -seq 1，用于创建一个新的迁移文件。该指令参数的意义如下：&lt;migration_name&gt;表示迁移文件的名称；-ext sql指定迁移文件的扩展名；-dir db/migration定义了迁移文件的存储路径；-seq代表创建顺序迁移文件，并在文件名前加上序号。这个命令会在指定目录下生成两个文件，一个用于执行迁移（.up.sql），另一个用于回滚迁移（.down.sql），以实现数据库的版本控制和变更管理。 add_sessions.up.sql12345678910111213CREATE TABLE &quot;sessions&quot; ( &quot;id&quot; uuid PRIMARY KEY, &quot;username&quot; varchar NOT NULL, &quot;refresh_token&quot; varchar NOT NULL, &quot;user_agent&quot; varchar NOT NULL, &quot;client_ip&quot; varchar NOT NULL, &quot;is_blocked&quot; boolean NOT NULL DEFAULT false, &quot;expires_at&quot; timestamptz NOT NULL, &quot;created_at&quot; timestamptz NOT NULL DEFAULT (now()));ALTER TABLE &quot;sessions&quot; ADD FOREIGN KEY (&quot;username&quot;) REFERENCES &quot;users&quot; (&quot;username&quot;); “is_blocked” boolean NOT NULL DEFAULT false, 添加bool列来阻止会话 以防止刷新令牌被泄露 “expires_at” timestamptz NOT NULL, 刷新令牌的过期时间 ALTER TABLE “sessions” ADD FOREIGN KEY (“username”) REFERENCES “users” (“username”); 外键约束 11.30日理清楚sqlc generate 到底是什么意思 依赖于sqlc.yml文件 123456789101112131415161718version: &quot;2&quot;sql:- schema: &quot;./db/migration&quot; queries: &quot;./db/query&quot; engine: &quot;postgresql&quot; gen: go: package: &quot;db&quot; out: &quot;./db/sqlc&quot; sql_package: &quot;pgx/v5&quot; emit_json_tags: true emit_interface: true emit_empty_slices: true overrides: - db_type: &quot;timestamptz&quot; go_type: &quot;time.Time&quot; - db_type: &quot;uuid&quot; go_type: &quot;github.com/google/uuid.UUID&quot; 指定一些列路径 自动生成代码到哪个位置 依赖的是.sql文件自动生成 相关的代码 12.2日加入更多的响应","categories":[{"name":"项目","slug":"项目","permalink":"https://whuichenggong.github.io/categories/%E9%A1%B9%E7%9B%AE/"}],"tags":[]},{"title":"数据结构的实现","slug":"计算机系统/data_structure","date":"2024-11-09T12:05:05.297Z","updated":"2025-05-11T07:20:03.579Z","comments":true,"path":"2024/11/09/计算机系统/data_structure/","permalink":"https://whuichenggong.github.io/2024/11/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/data_structure/","excerpt":"","text":"双链表的实现基于go语言实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package mainimport &quot;fmt&quot;// Node 定义双链表节点type Node struct &#123; data interface&#123;&#125; prev *Node next *Node&#125;// DoublyLinkedList 定义双链表type DoublyLinkedList struct &#123; head *Node tail *Node size int&#125;// InsertTail 向链表尾部插入节点func (dll *DoublyLinkedList) InsertTail(data interface&#123;&#125;) &#123; newNode := &amp;Node&#123;data: data&#125; if dll.size == 0 &#123; dll.head = newNode dll.tail = newNode &#125; else &#123; dll.tail.next = newNode newNode.prev = dll.tail dll.tail = newNode &#125; dll.size++&#125;// InsertHead 向链表头部插入节点func (dll *DoublyLinkedList) InsertHead(data interface&#123;&#125;) &#123; newNode := &amp;Node&#123;data: data&#125; if dll.size == 0 &#123; dll.head = newNode dll.tail = newNode &#125; else &#123; newNode.next = dll.head dll.head.prev = newNode dll.head = newNode &#125; dll.size++&#125;// Remove 删除节点func (dll *DoublyLinkedList) Remove(node *Node) &#123; if node.prev != nil &#123; node.prev.next = node.next &#125; else &#123; dll.head = node.next &#125; if node.next != nil &#123; node.next.prev = node.prev &#125; else &#123; dll.tail = node.prev &#125; node.prev = nil node.next = nil dll.size--&#125;// Display 打印双链表func (dll *DoublyLinkedList) Display() &#123; curr := dll.head for curr != nil &#123; fmt.Print(curr.data, &quot; &quot;) curr = curr.next &#125; fmt.Println()&#125;func main() &#123; dll := DoublyLinkedList&#123;&#125; dll.InsertTail(1) dll.InsertTail(2) dll.InsertHead(0) dll.Display() // 应该输出：0 1 2 // 删除节点 headNode := dll.head dll.Remove(headNode) dll.Display() // 应该输出：1 2&#125; 基于c语言实现双链表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;// 定义双链表节点结构typedef struct Node &#123; int data; struct Node* prev; struct Node* next;&#125; Node;// 创建一个新节点Node* createNode(int data) &#123; Node* newNode = (Node*)malloc(sizeof(Node)); if (newNode == NULL) &#123; printf(&quot;内存分配失败&quot;); exit(1); &#125; newNode-&gt;data = data; newNode-&gt;prev = NULL; newNode-&gt;next = NULL; return newNode;&#125;// 在双链表前插入节点void insertFront(Node** head, int data) &#123; Node* newNode = createNode(data); newNode-&gt;next = *head; if (*head != NULL) &#123; (*head)-&gt;prev = newNode; &#125; *head = newNode;&#125;// 在双链表后插入节点void insertRear(Node** head, int data) &#123; Node* newNode = createNode(data); if (*head == NULL) &#123; *head = newNode; return; &#125; Node* last = *head; while (last-&gt;next != NULL) &#123; last = last-&gt;next; &#125; last-&gt;next = newNode; newNode-&gt;prev = last;&#125;// 删除双链表前的节点void deleteFront(Node** head) &#123; if (*head == NULL) &#123; printf(&quot;链表为空，无法删除&quot;); return; &#125; Node* temp = *head; *head = (*head)-&gt;next; if (*head != NULL) &#123; (*head)-&gt;prev = NULL; &#125; free(temp);&#125;// 删除双链表后的节点void deleteRear(Node** head) &#123; if (*head == NULL) &#123; printf(&quot;链表为空，无法删除&quot;); return; &#125; Node* secondLast = *head; while (secondLast-&gt;next-&gt;next != NULL) &#123; secondLast = secondLast-&gt;next; &#125; Node* temp = secondLast-&gt;next; secondLast-&gt;next = NULL; free(temp);&#125;// 打印双链表void printList(Node* node) &#123; while (node != NULL) &#123; printf(&quot;%d &quot;, node-&gt;data); node = node-&gt;next; &#125; printf(&quot;\\n&quot;);&#125;int main() &#123; Node* head = NULL; insertFront(&amp;head, 10); insertFront(&amp;head, 20); insertRear(&amp;head, 30); insertRear(&amp;head, 40); printList(head); // 输出：20 10 30 40 deleteFront(&amp;head); deleteRear(&amp;head); printList(head); // 输出：10 30 return 0;&#125; 区别： c语言的双链表 我们要清楚 改变了头节点 所以要传入二级指针 才能正确的记录到头指针的变化 而Go语言，因为 Go 中的切片、映射和通道等是引用类型，它们在函数参数传递时本身就是按引用传递的，不需要通过指针的指针（二级指针）来实现修改。这实际上是 Go 语言的一个特性：切片、映射和通道在函数间传递时，共享底层数据结构，因此不需要额外的二级指针。 栈的c语言实现1.数组12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include&lt;stdio.h&gt;#include&lt;stdbool.h&gt;typedef struct Stack &#123; int data[10]; int top;&#125; Stack;void InitStack(Stack* stack) &#123; stack-&gt;top = -1;&#125;bool IsFull(Stack* stack) &#123; return stack-&gt;top == 9;&#125;bool IsEmpty(Stack* stack) &#123; return stack-&gt;top == -1;&#125;bool push(Stack* stack, int data) &#123; if (IsFull(stack)) &#123; printf(&quot;栈已经满了不能执行入栈操作\\n&quot;); return false; &#125; stack-&gt;data[++stack-&gt;top] = data; return true;&#125;int pop(Stack* stack) &#123; if (IsEmpty(stack)) &#123; printf(&quot;栈已经空了不能出栈\\n&quot;); return -1; &#125; return stack-&gt;data[stack-&gt;top--];&#125;void Println(Stack* stack) &#123; printf(&quot;栈中元素：&quot;); for (int i = stack-&gt;top; i &gt;= 0 ; i--) &#123; printf(&quot;%d &quot;, stack-&gt;data[i]); &#125; printf(&quot;\\n&quot;);&#125;int main() &#123; Stack stack; InitStack(&amp;stack); push(&amp;stack, 1); push(&amp;stack, 2); push(&amp;stack, 3); push(&amp;stack, 4); Println(&amp;stack); //pop(&amp;stack); pop(&amp;stack); pop(&amp;stack); // pop(&amp;stack); Println(&amp;stack); return 0;&#125; 2.链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdbool.h&gt;typedef struct stack &#123; int data; struct stack* next;&#125; Stack;void InitStack(Stack** top) &#123; *top = NULL; // 初始化为空链表，头指针为NULL&#125;bool IsEmpty(Stack* top) &#123; return top == NULL;&#125;Stack* CreateNode(int data) &#123; Stack* node = (Stack*)malloc(sizeof(Stack)); if (node == NULL) &#123; printf(&quot;分配空间出现错误&quot;); return NULL; &#125; node-&gt;data = data; node-&gt;next = NULL; return node;&#125;void Push(Stack** top, int data) &#123; Stack* newnode = CreateNode(data); if (newnode == NULL) return; newnode-&gt;next = *top; *top = newnode; // 更新头指针指向新节点&#125;int Pop(Stack** top) &#123; if (IsEmpty(*top)) &#123; printf(&quot;栈已经空了不能出栈\\n&quot;); return -1; &#125; Stack* temp = *top; int data = temp-&gt;data; *top = temp-&gt;next; // 更新头指针指向下一个节点 free(temp); return data;&#125;void Println(Stack* top) &#123; Stack* temp = top; while (temp != NULL) &#123; printf(&quot;%d &quot;, temp-&gt;data); temp = temp-&gt;next; &#125; printf(&quot;\\n&quot;);&#125;int main() &#123; Stack* stack; InitStack(&amp;stack); Push(&amp;stack, 1); Push(&amp;stack, 2); Push(&amp;stack, 3); Push(&amp;stack, 4); Println(stack); printf(&quot;出栈: %d\\n&quot;, Pop(&amp;stack)); printf(&quot;出栈: %d\\n&quot;, Pop(&amp;stack)); Println(stack); return 0;&#125; 队列c语言实现数组实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdbool.h&gt;typedef struct stack &#123; int data; struct stack* next;&#125; Stack;void InitStack(Stack** top) &#123; *top = NULL; // 初始化为空链表，头指针为NULL&#125;bool IsEmpty(Stack* top) &#123; return top == NULL;&#125;Stack* CreateNode(int data) &#123; Stack* node = (Stack*)malloc(sizeof(Stack)); if (node == NULL) &#123; printf(&quot;分配空间出现错误&quot;); return NULL; &#125; node-&gt;data = data; node-&gt;next = NULL; return node;&#125;void Push(Stack** top, int data) &#123; Stack* newnode = CreateNode(data); if (newnode == NULL) return; newnode-&gt;next = *top; *top = newnode; // 更新头指针指向新节点&#125;int Pop(Stack** top) &#123; if (IsEmpty(*top)) &#123; printf(&quot;栈已经空了不能出栈\\n&quot;); return -1; &#125; Stack* temp = *top; int data = temp-&gt;data; *top = temp-&gt;next; // 更新头指针指向下一个节点 free(temp); return data;&#125;void Println(Stack* top) &#123; Stack* temp = top; while (temp != NULL) &#123; printf(&quot;%d &quot;, temp-&gt;data); temp = temp-&gt;next; &#125; printf(&quot;\\n&quot;);&#125;int main() &#123; Stack* stack; InitStack(&amp;stack); Push(&amp;stack, 1); Push(&amp;stack, 2); Push(&amp;stack, 3); Push(&amp;stack, 4); Println(stack); printf(&quot;出栈: %d\\n&quot;, Pop(&amp;stack)); printf(&quot;出栈: %d\\n&quot;, Pop(&amp;stack)); Println(stack); return 0;&#125; 哈希表c简单实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#define NUM 5typedef struct HashList &#123; int num; char data[NUM]; // 修改为字符数组&#125; HashList;HashList* initList() &#123; HashList* list = (HashList*)malloc(sizeof(HashList)); list-&gt;num = 0; for (int i = 0; i &lt; NUM; i++) &#123; list-&gt;data[i] = 0; // 初始化所有元素为0 &#125; return list;&#125;// ASCII码计算自动计算int hash(int data) &#123; return data % NUM;&#125;void put(HashList* list, char data) &#123; int index = hash(data); printf(&quot;index = %d\\n&quot;, index); // 发生冲突 while (list-&gt;data[index] != 0) &#123; // 确保这个位置已经被占用 int count = 1; index = hash(index + 1); // 线性查找 count++; printf(&quot;index = %d\\n&quot;, index); &#125; list-&gt;data[index] = data;&#125;int main() &#123; HashList* list = initList(); put(list, &#x27;A&#x27;); put(list, &#x27;F&#x27;); for (int i = 0; i &lt; NUM; i++) &#123; if (list-&gt;data[i] != 0) &#123; // 只打印已经使用的槽位 printf(&quot;%c\\n&quot;, list-&gt;data[i]); &#125; &#125; return 0;&#125; 借鉴： https://github.com/hunterhug/goa.c/blob/master/algorithm/dict.md go实现可变数组123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package mainimport ( &quot;fmt&quot; &quot;sync&quot;)// Array 可变长数组type Array struct &#123; array []int // 固定大小的数组，用满容量和满大小的切片来代替 len int // 真正长度 cap int // 容量 lock sync.Mutex // 为了并发安全使用的锁&#125;// Make 新建一个可变长数组func Make(len, cap int) *Array &#123; s := new(Array) if len &gt; cap &#123; panic(&quot;len large than cap&quot;) &#125; // 把切片当数组用 array := make([]int, cap, cap) // 元数据 s.array = array s.cap = cap s.len = 0 return s&#125;// Append 增加一个元素func (a *Array) Append(element int) &#123; // 并发锁 a.lock.Lock() defer a.lock.Unlock() // 大小等于容量，表示没多余位置了 if a.len == a.cap &#123; // 没容量，数组要扩容，扩容到两倍 newCap := 2 * a.len // 如果之前的容量为0，那么新容量为1 if a.cap == 0 &#123; newCap = 1 &#125; newArray := make([]int, newCap, newCap) // 把老数组的数据移动到新数组 for k, v := range a.array &#123; newArray[k] = v &#125; // 替换数组 a.array = newArray a.cap = newCap &#125; // 把元素放在数组里 a.array[a.len] = element // 真实长度+1 a.len = a.len + 1&#125;// AppendMany 增加多个元素func (a *Array) AppendMany(element ...int) &#123; for _, v := range element &#123; a.Append(v) &#125;&#125;// Get 获取某个下标的元素func (a *Array) Get(index int) int &#123; // 越界了 if a.len == 0 || index &gt;= a.len &#123; panic(&quot;index over len&quot;) &#125; return a.array[index]&#125;// Len 返回真实长度func (a *Array) Len() int &#123; return a.len&#125;// Cap 返回容量func (a *Array) Cap() int &#123; return a.cap&#125;// Print 辅助打印func Print(array *Array) (result string) &#123; result = &quot;[&quot; for i := 0; i &lt; array.Len(); i++ &#123; // 第一个元素 if i == 0 &#123; result = fmt.Sprintf(&quot;%s%d&quot;, result, array.Get(i)) continue &#125; result = fmt.Sprintf(&quot;%s %d&quot;, result, array.Get(i)) &#125; result = result + &quot;]&quot; return&#125;func main() &#123; // 创建一个容量为3的动态数组 a := Make(0, 3) fmt.Println(&quot;cap&quot;, a.Cap(), &quot;len&quot;, a.Len(), &quot;array:&quot;, Print(a)) // 增加一个元素 a.Append(10) fmt.Println(&quot;cap&quot;, a.Cap(), &quot;len&quot;, a.Len(), &quot;array:&quot;, Print(a)) // 增加一个元素 a.Append(9) fmt.Println(&quot;cap&quot;, a.Cap(), &quot;len&quot;, a.Len(), &quot;array:&quot;, Print(a)) // 增加多个元素 a.AppendMany(8, 7) fmt.Println(&quot;cap&quot;, a.Cap(), &quot;len&quot;, a.Len(), &quot;array:&quot;, Print(a))&#125; 字典123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;unsafe&quot;)// 集合结构体type Set struct &#123; m map[int]struct&#123;&#125; // 用字典来实现，因为字段键不能重复 len int // 集合的大小 sync.RWMutex // 锁，实现并发安全&#125;// 新建一个空集合func NewSet(cap int64) *Set &#123; temp := make(map[int]struct&#123;&#125;, cap) return &amp;Set&#123; m: temp, &#125;&#125;// 增加一个元素func (s *Set) Add(item int) &#123; s.Lock() defer s.Unlock() s.m[item] = struct&#123;&#125;&#123;&#125; // 实际往字典添加这个键 s.len = len(s.m) // 重新计算元素数量&#125;// 移除一个元素func (s *Set) Remove(item int) &#123; s.Lock() defer s.Unlock() // 集合没元素直接返回 if s.len == 0 &#123; return &#125; delete(s.m, item) // 实际从字典删除这个键 s.len = len(s.m) // 重新计算元素数量&#125;// 查看是否存在元素func (s *Set) Has(item int) bool &#123; s.RLock() defer s.RUnlock() _, ok := s.m[item] return ok&#125;// 查看集合大小func (s *Set) Len() int &#123; return s.len&#125;// 清除集合所有元素func (s *Set) Clear() &#123; s.Lock() defer s.Unlock() s.m = map[int]struct&#123;&#125;&#123;&#125; // 字典重新赋值 s.len = 0 // 大小归零&#125;// 集合是够为空func (s *Set) IsEmpty() bool &#123; if s.Len() == 0 &#123; return true &#125; return false&#125;// 将集合转化为列表func (s *Set) List() []int &#123; s.RLock() defer s.RUnlock() list := make([]int, 0, s.len) for item := range s.m &#123; list = append(list, item) &#125; return list&#125;// 为什么使用空结构体func other() &#123; a := struct&#123;&#125;&#123;&#125; b := struct&#123;&#125;&#123;&#125; if a == b &#123; fmt.Printf(&quot;right:%p\\n&quot;, &amp;a) &#125; fmt.Println(unsafe.Sizeof(a))&#125;func main() &#123; //other() // 初始化一个容量为5的不可重复集合 s := NewSet(5) s.Add(1) s.Add(1) s.Add(2) fmt.Println(&quot;list of all items&quot;, s.List()) s.Clear() if s.IsEmpty() &#123; fmt.Println(&quot;empty&quot;) &#125; s.Add(1) s.Add(2) s.Add(3) if s.Has(2) &#123; fmt.Println(&quot;2 does exist&quot;) &#125; s.Remove(2) s.Remove(3) fmt.Println(&quot;list of all items&quot;, s.List())&#125; 加并发锁，实现线程安全，然后往结构体s *Set 里面的内置 map 添加该元素：item，元素作为字典的键，会自动去重。同时，集合大小重新生成。 s.m[item] &#x3D; struct{}{} 这行代码向 m 这个映射中添加一个 item 作为键，并将其值设置为 struct{}{}。由于 m 是 map[int]struct{} 类型的，它的键是 int 类型，而值是空结构体 struct{} 类型，它们不占用任何空间。这一步实际上是往字典添加一个键，而不需要关心值。 最大堆的建立堆排序中的（递归）是制造最大堆的关键 其实也可以不用最大堆 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include&lt;stdio.h&gt;void heapsort(int a[],int length,int i);void buildheap(int a[], int length);void swap(int* a, int* b);void prinarry(int a[], int length);void prinarry(int a[], int length)&#123; for (int i = 0; i &lt; length; i++) &#123; printf(&quot;%d&quot;, a[i]); &#125; printf(&quot;\\n&quot;);&#125;void swap(int* a, int* b)&#123; int temp = 0; temp=*a; * a = *b; * b = temp;&#125;//重点在这里如何交换使得成为最大堆void heapsort(int a[], int length, int i)&#123; int largest = i; int left = 2 * i + 1; int right = 2 * i + 2; if (left&lt;length &amp;&amp; a[left]&gt;a[largest]) &#123; largest = left; &#125; if (right&lt;length &amp;&amp; a[right]&gt;a[largest]) &#123; largest = right; &#125; if (largest != i) &#123; swap(&amp;a[i], &amp;a[largest]);//必须加&amp; heapsort(a, length, largest);//这步递归是关键能确保整体保证是堆的性质 &#125;&#125;void buildheap(int a[], int length)//建立堆&#123; int i = (length - 1) / 2; for(i=(length-1)/2;i&gt;=0;i--) &#123; heapsort(a, length, i); &#125; &#125;int main()&#123; int arry[6] = &#123; 2,4,7,9,5,8&#125;; int length = sizeof(arry) / sizeof(arry[0]); buildheap(arry, length); prinarry(arry, length); return 0;&#125; 好像不对劲 如果你期望的是排序后的数组（比如 120 100 90 50），你的代码缺少以下步骤： 交换堆顶和末尾元素：将最大堆的根节点（最大值）移动到数组末尾。重新堆化剩余部分：对剩余的数组部分（即去掉最后一个元素的堆）重新堆化。重复步骤：直到数组完全排序。 你的代码本身并没有严重的问题，但它仅仅完成了“构建最大堆”的功能，没有实现堆排序，因此输出的数组只是一个堆的结构（满足最大堆性质，但并非有序数组）。如果你预期的结果是排序后的数组，那么确实还需要补充代码来完成堆排序的逻辑。 啊我靠 go实现最大堆123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101// 一个最大堆，一棵完全二叉树// 最大堆要求节点元素都不小于其左右孩子type Heap struct &#123; // 堆的大小 Size int // 使用内部的数组来模拟树 // 一个节点下标为 i，那么父亲节点的下标为 (i-1)/2 // 一个节点下标为 i，那么左儿子的下标为 2i+1，右儿子下标为 2i+2 Array []int&#125;// 初始化一个堆func NewHeap(array []int) *Heap &#123; h := new(Heap) h.Array = array return h&#125;// 最大堆插入元素func (h *Heap) Push(x int) &#123; // 堆没有元素时，使元素成为顶点后退出 if h.Size == 0 &#123; h.Array[0] = x h.Size++ return &#125; // i 是要插入节点的下标 i := h.Size // 如果下标存在 // 将小的值 x 一直上浮 for i &gt; 0 &#123; // parent为该元素父亲节点的下标 parent := (i - 1) / 2 // 如果插入的值小于等于父亲节点，那么可以直接退出循环，因为父亲仍然是最大的 if x &lt;= h.Array[parent] &#123; break &#125; // 否则将父亲节点与该节点互换，然后向上翻转，将最大的元素一直往上推 h.Array[i] = h.Array[parent] i = parent &#125; // 将该值 x 放在不会再翻转的位置 h.Array[i] = x // 堆数量加一 h.Size++&#125;// 最大堆移除根节点元素，也就是最大的元素func (h *Heap) Pop() int &#123; // 没有元素，返回-1 if h.Size == 0 &#123; return -1 &#125; // 取出根节点 ret := h.Array[0] // 因为根节点要被删除了，将最后一个节点放到根节点的位置上 h.Size-- x := h.Array[h.Size] // 将最后一个元素的值先拿出来 h.Array[h.Size] = ret // 将移除的元素放在最后一个元素的位置上 // 对根节点进行向下翻转，小的值 x 一直下沉，维持最大堆的特征 i := 0 for &#123; // a，b为下标 i 左右两个子节点的下标 a := 2*i + 1 b := 2*i + 2 // 左儿子下标超出了，表示没有左子树，那么右子树也没有，直接返回 if a &gt;= h.Size &#123; break &#125; // 有右子树，拿到两个子节点中较大节点的下标 if b &lt; h.Size &amp;&amp; h.Array[b] &gt; h.Array[a] &#123; a = b &#125; // 父亲节点的值都大于或等于两个儿子较大的那个，不需要向下继续翻转了，返回 if x &gt;= h.Array[a] &#123; break &#125; // 将较大的儿子与父亲交换，维持这个最大堆的特征 h.Array[i] = h.Array[a] // 继续往下操作 i = a &#125; // 将最后一个元素的值 x 放在不会再翻转的位置 h.Array[i] = x return ret&#125; 这段代码太帅了 没有使用递归 用循环 构造了最大堆！ 学习思想","categories":[{"name":"计算机系统 只能由一个","slug":"计算机系统-只能由一个","permalink":"https://whuichenggong.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F-%E5%8F%AA%E8%83%BD%E7%94%B1%E4%B8%80%E4%B8%AA/"}],"tags":[]},{"title":"leet-code之旅","slug":"leetcode/leet-code","date":"2024-11-09T10:33:32.483Z","updated":"2025-01-21T07:09:28.833Z","comments":true,"path":"2024/11/09/leetcode/leet-code/","permalink":"https://whuichenggong.github.io/2024/11/09/leetcode/leet-code/","excerpt":"","text":"正式开启刷leet-code第225.用两个队列实现栈问题： 请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通栈的全部四种操作（push、top、pop 和 empty）。 实现 MyStack 类： void push(int x) 将元素 x 压入栈顶。int pop() 移除并返回栈顶元素。int top() 返回栈顶元素。boolean empty() 如果栈是空的，返回 true ；否则，返回 false 。 我的代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849type MyStack struct &#123; list1 := list.New() list2 := list.New()&#125;func Constructor() MyStack &#123; MyStack.Push(x) MyStack.Push(x) MyStack.Push(x) MyStack.Pop() MyStack.Top() MyStack.empty()&#125;func (this *MyStack) Push(x int) &#123; this.list1.PushBack(x) temp := x this.list2.PushFront(temp)&#125;func (this *MyStack) Pop() int &#123; temp = this.list2.Value e = e.Next&#125;func (this *MyStack) Top() int &#123; temp = this.list2.Value return temp&#125;func (this *MyStack) Empty() bool &#123; if this.list2.Value == nil return false&#125;/** * Your MyStack object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Top(); * param_4 := obj.Empty(); */ 虚伪的正确的代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package mainimport (&quot;container/list&quot;)type MyStack struct &#123;list1 *list.Listlist2 *list.List&#125;func Constructor() MyStack &#123;return MyStack &#123;list1: list.New(),list2: list.New(),&#125;&#125;func (this *MyStack) Push(x int) &#123;this.list1.PushBack(x)temp := xthis.list2.PushFront(temp)&#125;func (this *MyStack) Pop() int &#123;if this.list2.Len() == 0 &#123;return -1 // 如果stack为空返回-1或者其他适当的值&#125;temp := this.list2.Front()this.list2.Remove(temp)return temp.Value.(int)&#125;func (this *MyStack) Top() int &#123;if this.list2.Len() == 0 &#123;return -1 // 如果栈为空则返回-1或者其他适当的值&#125;temp := this.list2.Front().Value(int)return temp&#125;func (this *MyStack) Empty() bool &#123;return this.list2.Len() == 0&#125;/*** Your MyStack object will be instantiated and called as such:* obj := Constructor();* obj.Push(x);* param_2 := obj.Pop();* param_3 := obj.Top();* param_4 := obj.Empty(); */ 使用go语言内置的list包 也就是双向链表的操作运用到了go语言的断言 this.list2.Front().Value.(int) 但是 虽然通过了 但是思路应该是错了哈哈哈哈 ！ 这段代码并没有用到队列的性质而是双链表。。。。并没有遵守题目的规则代码问题： 而只是使用了两个链表，其中 list2 实际上扮演了“栈”的角色。这样的话，list2 单独一个链表就能实现后进先出，不需要 list1 的辅助。 真正的正确代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package mainimport &quot;container/list&quot;type MyStack struct &#123; queue1 *list.List queue2 *list.List&#125;func Constructor() MyStack &#123; return MyStack&#123; queue1: list.New(), queue2: list.New(), &#125;&#125;func (this *MyStack) Push(x int) &#123; this.queue1.PushBack(x)&#125;func (this *MyStack) Pop() int &#123; if this.queue1.Len() == 0 &#123; return -1 &#125; for this.queue1.Len() &gt; 1 &#123; front := this.queue1.Front() this.queue1.Remove(front) this.queue2.PushBack(front.Value) &#125; top := this.queue1.Front() this.queue1.Remove(top) this.queue1, this.queue2 = this.queue2, this.queue1 return top.Value.(int)&#125;func (this *MyStack) Top() int &#123; if this.queue1.Len() == 0 &#123; return -1 &#125; for this.queue1.Len() &gt; 1 &#123; front := this.queue1.Front() this.queue1.Remove(front) this.queue2.PushBack(front.Value) &#125; top := this.queue1.Front() this.queue2.PushBack(top.Value) this.queue1, this.queue2 = this.queue2, this.queue1 return top.Value.(int)&#125;func (this *MyStack) Empty() bool &#123; return this.queue1.Len() == 0&#125; 第20题有效括号问题： 给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串 s ，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。左括号必须以正确的顺序闭合。每个右括号都有一个对应的相同类型的左括号。 解答过程123456789101112131415161718192021222324252627282930func isValid(s string) bool &#123; // 创建一个栈来存储左括号 stack := make([]rune, 0) // 括号的对应关系 pairs := map[rune]rune&#123; &#x27;)&#x27;: &#x27;(&#x27;, &#x27;&#125;&#x27;: &#x27;&#123;&#x27;, &#x27;]&#x27;: &#x27;[&#x27;, &#125; // 遍历字符串s for _, char := range s &#123; // 如果是右括号 if _, exists := pairs[char]; exists &#123; // 取出栈顶元素，如果栈为空或者不匹配则返回false if len(stack) == 0 || stack[len(stack)-1] != pairs[char] &#123; return false &#125; // 否则弹出栈顶元素 stack = stack[:len(stack)-1] &#125; else &#123; // 如果是左括号，压入栈中 stack = append(stack, char) &#125; &#125; // 如果栈为空，则所有括号正确匹配 return len(stack) == 0&#125; 栈的问题 字节刷题（队列）相关：问题： 小R的随机播放顺序问题描述小有一个特殊的随机播放规则。他首先播放歌单中的第一首歌，播放后将其从歌单中移除。如果歌单中还有歌曲，则会将当前第一首歌移到最后一首。这个过程会一直重复，直到歌单中没有任何歌曲。例如，给定歌单[5,3,2,1,4]，真实的播放顺序是[5,2,4,1,3]。保证歌曲中的id两两不同。测试样例样例1：输入：n&#x3D;5,a&#x3D;[5,3,2,1,4]输出：[5,2,4,1,3]样2：输入：n&#x3D;4,a&#x3D;[4,1,3,2]输出：[4,3,1,2]样3：输入：n&#x3D;6,a&#x3D;[1,2,3,4,5,6]输出：[1,3,5,2,6,4] 看完题之后的思路 ： 就是队列问题 如何操作栈 在文中也就是实现： 先出栈-》再执行出栈入栈-》再出栈 这是目前简单的思路然后搜索Go语言队列的相关操作 用slice实现队列：或者 list实现队列 题解：12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;func solution(n int, a []int) []int &#123; result := []int&#123;&#125; // 用于存储播放顺序 for len(a) &gt; 0 &#123; // 播放第一首歌并加入到结果中 result = append(result, a[0]) // 移除播放的歌曲 a = a[1:] // 如果歌单还有剩余，将当前第一首歌移到最后 if len(a) &gt; 0 &#123; a = append(a[1:], a[0]) &#125; &#125; return result&#125;func main() &#123; fmt.Println(fmt.Sprintf(&quot;%v&quot;, solution(5, []int&#123;5, 3, 2, 1, 4&#125;)) == fmt.Sprintf(&quot;%v&quot;, []int&#123;5, 2, 4, 1, 3&#125;)) fmt.Println(fmt.Sprintf(&quot;%v&quot;, solution(4, []int&#123;4, 1, 3, 2&#125;)) == fmt.Sprintf(&quot;%v&quot;, []int&#123;4, 3, 1, 2&#125;)) fmt.Println(fmt.Sprintf(&quot;%v&quot;, solution(6, []int&#123;1, 2, 3, 4, 5, 6&#125;)) == fmt.Sprintf(&quot;%v&quot;, []int&#123;1, 3, 5, 2, 6, 4&#125;))&#125; 看到题解我蒙了：我在思考的时候确实想如何实现这个队列并且如何实现添加元素并且删除元素 但是 在这道题中，Go 切片的特性其实已经很好地帮你实现了这些操作。切片的 append 和切片操作符 a[1:] 直接完成了队列的“入队”和“出队”需求。只是在简化的问题上，利用 Go 自带的切片操作让解决方案更简洁、易懂。 12.2 日重刷两数之和我的代码1234567891011func twoSum(nums []int, target int) []int &#123; k := make(map[int]int) for i, v := range nums &#123; other := target - v if _ , ok := map[other]; ok &#123; return &#123;i, map[nums[i]]&#125; &#125; m[nums[i]] = i &#125; return nil&#125; 更正后：1234567891011func twoSum(nums []int, target int) []int &#123; k := make(map[int]int) for i, v := range nums &#123; other := target - v if idx , ok := k[other]; ok &#123; return []int&#123;i, idx&#125; &#125; k[v] = i &#125; return nil&#125; 删除有序数组中的重复项错误的代码1234567891011121314151617func removeDuplicates(nums []int) int &#123; k := make([]int,10) for i:=0;i&lt;len(nums);i++ &#123; for j:=i; j&lt;len(nums); j++&#123; if nums[i] == nums[j] &#123; nums[i] = nums[j] continue &#125; k[i] = nums[i] break &#125; &#125; return len(k)&#125; 题目要求：题目需要在原地删除重复项，使用 O(1) 额外空间，返回去重后数组的长度。去重后的元素必须保留在数组的前部，后续位置可以随意。代码中存在的问题： 额外空间不符合要求：你使用了 k 数组存储去重后的结果，违背了 O(1) 额外空间的限制。逻辑问题：双重循环实际上是在尝试复制和比较元素，但逻辑上没有保证正确的去重。continue 和 break 的混乱：循环控制没有明确目的，导致部分逻辑跳过了关键步骤。返回值错误：你返回的是辅助数组 k 的长度，而不是修改后数组 nums 的有效长度。 正确解法：123456789101112131415func removeDuplicates(nums []int) int &#123; if len(nums) == 0&#123; return 0 &#125; var k = 0 for i :=1; i&lt;len(nums); i++ &#123; if nums[k] != nums [i] &#123; k++ nums[k] = nums[i] &#125; &#125; return k+1 &#125; 27 移除元素错误代码12345678910111213func removeElement(nums []int, val int) int &#123; var length = 0 for i := length; i&lt;len(nums); i++ &#123; if val == nums[length] &#123; var k = 0 k = nums[length] length ++ &#125; &#125; return length&#125; 不出意外又是错误的代码k 被赋值：k &#x3D; nums[length]然而，k 在后续的代码中并没有被用于任何地方，它没有被打印、返回、存储或进一步处理。只是简单地在 if 语句内被赋值。 k 的作用无效： k 是在 if 语句中声明并赋值的，但它没有发挥任何作用。Go 编译器会在编译时检查到这一点，并给出警告，因为声明了一个变量却没有用到。 正确代码：123456789101112func removeElement(nums []int, val int) int &#123; var length = 0 for i := 0; i &lt; len(nums); i++ &#123; if nums[i] != val &#123; nums[length] = nums[i] length++ &#125; &#125; return length&#125; 思路是 把不相等的元素按照顺序放到开头 而我是想覆盖相同的元素 处理不了这个撮箕 28 找出字符串中的第一个匹配项下标 题目： 输入：haystack &#x3D; “sadbutsad”, needle &#x3D; “sad”输出：0解释：”sad” 在下标 0 和 6 处匹配。第一个匹配项的下标是 0 ，所以返回 0 。示例 2： 输入：haystack &#x3D; “leetcode”, needle &#x3D; “leeto”输出：-1解释：”leeto” 没有在 “leetcode” 中出现，所以返回 -1 。 12345678910111213141516 var num intfunc strStr(haystack string, needle string) int &#123; for i:=0; i&lt;len(haystack); i++ &#123; for j := 0; j&lt;len(needle); j++ &#123; if needle[j] == haystack[i]&#123; num++ i++ if num == len(needle)&#123; return i-len(needle) &#125; &#125; &#125; &#125; return -1 &#125; 只通过了一个用例， 你要反思了 只通过一个用例，说明了你的想法是错的 暴力解法： 123456789101112131415func strStr(haystack string, needle string) int &#123; if len(needle) == 0 &#123; // 空字符串直接返回 0 return 0 &#125; for i := 0; i &lt;= len(haystack)-len(needle); i++ &#123; j := 0 for j &lt; len(needle) &amp;&amp; haystack[i+j] == needle[j] &#123; j++ &#125; if j == len(needle) &#123; return i // 完全匹配，返回起始索引 &#125; &#125; return -1 // 未找到匹配&#125; 多多练习， haystack[i+j] &#x3D;&#x3D; needle[j] 这里是很巧妙的地方，同时比对了两个字符串， i的位置就是起始位置， 如果整个字符串都在内部匹配完成了，说明i就是起始位置记录需要对比的字符串长度 58题： 最后一个单词的长度示例 1： 输入：s &#x3D; “Hello World”输出：5解释：最后一个单词是“World”，长度为 5。示例 2： 输入：s &#x3D; “ fly me to the moon “输出：4解释：最后一个单词是“moon”，长度为 4。示例 3： 输入：s &#x3D; “luffy is still joyboy”输出：6解释：最后一个单词是长度为 6 的“joyboy”。 我的代码： 12345678910111213var length intfunc lengthOfLastWord(s string) int &#123; for i := len(s)-1; i&gt;0; i-- &#123; if s[i] != &#x27; &#x27; &#123; for s[i] != &#x27; &#x27;&#123; length++ i-- &#125; return length &#125;&#125;return 0&#125; 还是错了 但是错的不太离谱，简单的呗GPT加了一点就过了 12345678910111213func lengthOfLastWord(s string) int &#123; length := 0 for i := len(s) - 1; i &gt;= 0; i-- &#123; // 修正条件为 i &gt;= 0 if s[i] != &#x27; &#x27; &#123; for i &gt;= 0 &amp;&amp; s[i] != &#x27; &#x27; &#123; // 避免索引越界 length++ i-- &#125; return length &#125; &#125; return 0 // 如果没有找到任何单词，返回 0&#125; 但是在其中话是有一个有意思的事情 1234567891011121314func lengthOfLastWord(s string) int &#123; length := 0 for i := len(s)-1; i&gt;=0; i-- &#123; if s[i] != &#x27; &#x27; &#123; for s[i] != &#x27; &#x27; &amp;&amp; i &gt;= 0&#123; length++ i-- &#125; return length &#125;&#125;return 0&#125; 代码我是这么写的 跟上面的没什么区别，但是没有通过 我又询问到底是为什么 关键在于顺序 以防止越界 for s[i] !&#x3D; ‘ ‘ &amp;&amp; i &gt;&#x3D; 0 内层循环条件： for s[i] !&#x3D; ‘ ‘ &amp;&amp; i &gt;&#x3D; 0 {当 i 等于 0 时，s[i] 可能会访问索引 0 的内容，然后才进行 i &gt;&#x3D; 0 的检查。由于条件的顺序，s[i] 的访问可能在 i &lt; 0 时执行，导致索引越界。也就是说： 问题在于： 在执行 s[i] !&#x3D; ‘ ‘ 这个条件时，i 可能会变成负数（比如 i &#x3D;&#x3D; 0 时，接下来你做 i–，i 会变成 -1）。但是，i &gt;&#x3D; 0 的条件是后面的检查，也就是说，在 i– 之后，s[i] !&#x3D; ‘ ‘ 已经执行了，导致 i &#x3D;&#x3D; -1 时，程序尝试访问 s[-1]，而 Go 语言数组下标不能为负数，这样会导致 索引越界 错误。 21 合并两个有序链表：l1 &#x3D; [1,2,4], l2 &#x3D; [1,3,4]输出：[1,1,2,3,4,4]示例 2： 输入：l1 &#x3D; [], l2 &#x3D; []输出：[]示例 3： 输入：l1 &#x3D; [], l2 &#x3D; [0]输出：[0] 我写的又臭又长的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode &#123; list3 := &amp;ListNode&#123; Val: 0, Next: nil,&#125; if list1 == nil &#123; return list2 &#125; if list2 == nil &#123; return list1 &#125; for list1.Val &lt;= list2.Val &#123; if list1.Next == nil &#123; for list2.Next != nil&#123; list3.Val = list2.Val list2 = list2.Next &#125; &#125;else &#123; list3.Val = list1.Val list3 = list3.Next list1 = list1.Next &#125; if list1.Next == nil &#123; for list1.Next != nil &#123; list3.Val = list1.Val list1 = list1.Next &#125; &#125;else &#123; list3.Val = list2.Val list3 = list3.Next list2 = list2.Next &#125; &#125; for list1.Val &gt;= list2.Val &#123; &#125;return list3&#125; 疑惑： 你说得对，list3 :&#x3D; &amp;ListNode{} 确实只初始化了一个节点，但这个节点的作用是 哨兵节点 (dummy node)，用来简化链表操作和边界条件处理。 哨兵节点的主要特点是： 它本身并不存储有效数据（值通常是默认值，比如 0）。它的作用是作为链表的起点，使链表构造和返回操作更加简单和一致。以下是对你的疑问的详细解释： 为什么哨兵节点只初始化一个节点却能构造完整链表？哨兵节点的作用只是提供链表的起点，后续节点是通过动态创建并连接到它的 Next 指针上构造的。例如： list3 :&#x3D; &amp;ListNode{} &#x2F;&#x2F; 初始化哨兵节点current :&#x3D; list3 &#x2F;&#x2F; current 指向哨兵节点 current.Next &#x3D; &amp;ListNode{Val: 1} &#x2F;&#x2F; 创建第一个有效节点current &#x3D; current.Next &#x2F;&#x2F; 移动指针到新节点 current.Next &#x3D; &amp;ListNode{Val: 2} &#x2F;&#x2F; 创建第二个有效节点current &#x3D; current.Next &#x2F;&#x2F; 移动指针到新节点这段代码最终形成的链表结构是： scss复制代码哨兵节点 (值: 0) -&gt; 节点1 (值: 1) -&gt; 节点2 (值: 2)返回值时，通过 list3.Next 跳过哨兵节点，直接指向第一个有效节点。 正确思维： 期望行为：应该创建一个新节点并将其连接到 current.Next。 我没有理解怎么初始化一个链表，并为后续创建新的结点添加值 emm 正解 正确代码：123456789101112131415161718192021func mergeTwoLists(list1, list2 *ListNode) *ListNode &#123; dummy := ListNode&#123;&#125; // 用哨兵节点简化代码逻辑 cur := &amp;dummy // cur 指向新链表的末尾 for list1 != nil &amp;&amp; list2 != nil &#123; if list1.Val &lt; list2.Val &#123; cur.Next = list1 // 把 list1 加到新链表中 list1 = list1.Next &#125; else &#123; // 注：相等的情况加哪个节点都是可以的 cur.Next = list2 // 把 list2 加到新链表中 list2 = list2.Next &#125; cur = cur.Next &#125; // 拼接剩余链表 if list1 != nil &#123; cur.Next = list1 &#125; else &#123; cur.Next = list2 &#125; return dummy.Next&#125; 这段代码中直接使用 list1 或 list2 而不是 list1.Val 是因为它要把整个节点连接到新链表中，而不仅仅是节点的值。 区别list1.Val 仅获取当前节点的值。 如果只使用 Val，你只能获得一个值，无法直接将这个值插入链表中，还需要手动创建一个新节点。list1 是指针，代表当前节点。 直接使用 list1 表示把当前节点（包括其 Val 和 Next 指针）插入到新链表中，效率更高且代码更简单。 今天又重新做了一下20题 有效括号 刚开始我在想，电脑应该怎么区分左括号和右括号这两个是怎么合并的？ 绞尽脑汁。 最终思想就是遍历字符串， 将左括号放入栈中 将栈顶元素和当前元素作比较 如果相同弹出括号，成功的标志是栈中元素为空 232 用两个栈实现队列 [“MyQueue”, “push”, “push”, “peek”, “pop”, “empty”][[], [1], [2], [], [], []]输出：[null, null, null, 1, 1, false] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647type MyQueue struct &#123; Rear *MyQueue Head *MyQueue size int&#125;func Constructor() MyQueue &#123; Stack1 := []int Stack2 := []int &#125;func (this *MyQueue) Push(x int) &#123; Stack1 := []int Stack2 := []int Stack1 = append(Stack1,x) legth := len(Stack1) v := Stack1[l-1]&#125;func (this *MyQueue) Pop() int &#123; Stack1 = Stack1(:len(Stack1)-1) Stack2 = append(Stack2,)&#125;func (this *MyQueue) Peek() int &#123; &#125;func (this *MyQueue) Empty() bool &#123; &#125;/** * Your MyQueue object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Peek(); * param_4 := obj.Empty(); */ 看到代码有点不知所措了，在每个地方应该放入什么 两个栈实现队列：思路我是有的 把数字放入其中一个栈中，然后在弹出来，放入第二个栈中，然后在第二个栈中弹出来就是队列 思路是对的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576type MyQueue struct &#123; Stack1 []int Stack2 []int&#125;func Constructor() MyQueue &#123; return MyQueue&#123;&#125;&#125;func (this *MyQueue) Push(x int) &#123; this.Stack1 = append (this.Stack1,x)&#125;func (this *MyQueue) Pop() int &#123; if len(this.Stack2) == 0 &amp;&amp; len(this.Stack1) == 0 &#123; return -1 &#125; if len(this.Stack1) != 0 &#123; for len(this.Stack1) &gt; 0 &#123; length1 := len(this.Stack1)-1 val := this.Stack1[length1] this.Stack1 = this.Stack1[:length1] this.Stack2 = append(this.Stack2,val) &#125; &#125; length2 := len(this.Stack2)-1 result := this.Stack2[length2] this.Stack2 = this.Stack2[:length2] return result&#125;func (this *MyQueue) Peek() int &#123; if len(this.Stack1) == 0 &amp;&amp; len(this.Stack2) == 0 &#123; return -1 &#125; if len(this.Stack1) != 0 &#123; for len(this.Stack1) &gt;0 &#123; length1 := len(this.Stack1)-1 val := this.Stack1[length1] this.Stack1 = this.Stack1[:length1] this.Stack2 = append(this.Stack2,val) &#125; &#125; length2 := len(this.Stack2) -1 return this.Stack2[length2]&#125;func (this *MyQueue) Empty() bool &#123; return len(this.Stack1) == 0 &amp;&amp; len(this.Stack2) == 0&#125;/** * Your MyQueue object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Peek(); * param_4 := obj.Empty(); */ 重新写了一遍 用例没有完全通过 [null,null,null,null,null,1,null,5,2,3,4] 预期结果[null,null,null,null,null,1,null,2,3,4,5] 有两个地方出错导致没有通过 if len(this.Stack1) !&#x3D; 0 条件判断句 改成 &#x3D;&#x3D;0 就通过了 思考为什么 383.赎金信参考两数之和的哈希表用法 我写出了以下代码 12345678910111213141516171819func canConstruct(ransomNote string, magazine string) bool &#123; m := make(map[byte]int) for i:=1 ; i&lt;len(ransomNote); i++ &#123; if _,ok := m[ransomNote[i]]; ok&#123; continue &#125; m[ransomNote[i]] = i &#125; for k:=1; k&lt;len(magazine); k++ &#123; if _, ok := m[magazine[k]]; ok &#123; continue &#125; if k == len(magazine) &#123; return true &#125; &#125; return false&#125; 但是没有通过，应该是情况考虑错了 123456789101112131415161718func canConstruct(ransomNote string, magazine string) bool &#123; m := make(map[byte]int) for i:=0; i&lt;len(magazine); i++ &#123; if _,ok := m[magazine[i]]; ok&#123; continue &#125; m[magazine[i]] = i &#125; for k:=0; k&lt;len(ransomNote); k++ &#123; if _, ok := m[ransomNote[k]]; ok &#123; continue &#125; else &#123; return false &#125; &#125; return true&#125; 最终修改成这样 题目中话有一个条件 字母无法重复使用！！！这点给忘记给忘记了问了这一点！ 关键就是对于字符的统计！ 正确代码： 12345678910111213141516171819func canConstruct(ransomNote string, magazine string) bool &#123; // 用一个 map 记录 magazine 中每个字符出现的次数 m := make(map[byte]int) for i := 0; i &lt; len(magazine); i++ &#123; m[magazine[i]]++ &#125; // 检查 ransomNote 中的每个字符是否在 magazine 中有足够的次数 for i := 0; i &lt; len(ransomNote); i++ &#123; if m[ransomNote[i]] &gt; 0 &#123; m[ransomNote[i]]-- // 使用一个字符 &#125; else &#123; return false // 如果次数不足，无法构造 &#125; &#125; return true // 所有字符都能满足&#125; 我的疑惑：我理解前两个a会增到2 但是第三个字符是b的时候为什么会从0开始计算起而不是2 这是因为在 Go 的 map 中，每个键（key）是独立的，互相之间没有关联。 在你的例子中，当处理第三个字符 b 时： 之前已经对 a 进行了计数，所以 m[‘a’] &#x3D; 2。但是 b 是一个新的键，之前并没有在 map 中出现过。当访问 m[‘b’] 时，由于 map 默认返回未初始化键的值为类型的 零值（对于 int 类型来说，零值是 0），所以 m[‘b’] &#x3D; 0。然后执行 m[‘b’]++，将其从 0 增加到 1。 141.环形链表 123456789101112131415161718192021/** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func hasCycle(head *ListNode) bool &#123; if head == nil &#123; return false &#125; m := make(map[*ListNode]int) for head != nil &#123; m[head]++ if _,ok := m[head]; ok &#123; return true &#125; head = head.Next &#125; return false&#125; 又没有一次性通过 条件感太差了！ 啊居然自己改对了！！！ 调整了一下顺序， 12345678910111213141516171819202122/** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */func hasCycle(head *ListNode) bool &#123; if head == nil &#123; return false &#125; m := make(map[*ListNode]int) for head != nil &#123; m[head]++ head = head.Next if _,ok := m[head]; ok &#123; return true &#125; &#125; return false&#125; 在其中出现的错误： map中的地址应该是结构体指针 而不是 *int 如何在go中使用中序遍历 94题： 12345678910111213141516171819func inorderTraversal(root *TreeNode) []int &#123; result := []int&#123;&#125; // 用于存储中序遍历的结果 // 定义递归函数 var inorder func(node *TreeNode) inorder = func(node *TreeNode) &#123; if node == nil &#123; // 递归终止条件：当前节点为空 return &#125; inorder(node.Left) // 遍历左子树 result = append(result, node.Val) // 访问当前节点 inorder(node.Right) // 遍历右子树 &#125; inorder(root) // 从根节点开始中序遍历 return result // 返回结果&#125; inorder &#x3D; func(node *TreeNode) {if node &#x3D;&#x3D; nil { &#x2F;&#x2F; 递归终止条件：当前节点为空return} 这块使用我不太清楚 我还以为是对原函数递归 933.最近的请求次数 写一个 RecentCounter 类来计算特定时间范围内最近的请求。 请你实现 RecentCounter 类： RecentCounter() 初始化计数器，请求数为 0 。int ping(int t) 在时间 t 添加一个新请求，其中 t 表示以毫秒为单位的某个时间，并返回过去 3000 毫秒内发生的所有请求数（包括新请求）。确切地说，返回在 [t-3000, t] 内发生的请求数。保证 每次对 ping 的调用都使用比之前更大的 t 值。 输入：[“RecentCounter”, “ping”, “ping”, “ping”, “ping”][[], [1], [100], [3001], [3002]]输出：[null, 1, 2, 3, 3] 解释：RecentCounter recentCounter &#x3D; new RecentCounter();recentCounter.ping(1); &#x2F;&#x2F; requests &#x3D; [1]，范围是 [-2999,1]，返回 1recentCounter.ping(100); &#x2F;&#x2F; requests &#x3D; [1, 100]，范围是 [-2900,100]，返回 2recentCounter.ping(3001); &#x2F;&#x2F; requests &#x3D; [1, 100, 3001]，范围是 [1,3001]，返回 3recentCounter.ping(3002); &#x2F;&#x2F; requests &#x3D; [1, 100, 3001, 3002]，范围是 [2,3002]，返回 3 读题读了一会才读懂，最后反应过来应该就是返回 在范围内的ping次数 需要用一个切片（其实应该是队列思想 入队 出队不符合条件的 返回符合条件的数量）（这在go语言中就可以用切片来简化操作 返回 符合条件的ping次数 也就是 队列中剩下的长度 len（）） 正确解答 1234567891011121314151617181920212223242526272829type RecentCounter struct &#123; count []int&#125;func Constructor() RecentCounter &#123; return RecentCounter &#123; count: []int&#123;&#125;, &#125;&#125;func (this *RecentCounter) Ping(t int) int &#123; this.count = append(this.count,t) //重点怎么移除不符合条件的 一个个对比 for len(this.count)&gt;0 &amp;&amp; this.count[0]&lt;t-3000 &#123; this.count = this.count[1:] &#125; return len(this.count)&#125;/** * Your RecentCounter object will be instantiated and called as such: * obj := Constructor(); * param_1 := obj.Ping(t); */ 1.学会初始化结构体2.学会使用切片思想实现 队列 栈等 加强对切片的操作 12.17日 开始执行树和递归 104 二叉树的最大深度110 平衡二叉树 104代码 123456789101112func maxDepth(root *TreeNode) int &#123; if root == nil &#123; return 0 &#125; var l, r = maxDepth(root.Left), maxDepth(root.Right) if l &gt; r &#123; return l + 1 &#125; else &#123; return r + 1 &#125;&#125; 这段代码我是抄的 我对递归的思想还是不太理解 递归的 隐式深度记录 是通过调用栈实现的： 每次递归调用时，程序会进入一个新的函数调用，并等待其返回值。当递归调用到底（即遇到叶子节点或 nil 节点）时，递归开始返回。每一层递归通过返回值，将子树的深度信息逐层传递回上一层。可以理解为： 每个函数调用相当于“记住”当前节点的状态，等待左右子树的深度计算完成后，才计算当前节点的深度并返回。 递归的返回值 自然累加 深度的方式，不需要额外的变量来显式记录深度。","categories":[{"name":"算法","slug":"算法","permalink":"https://whuichenggong.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"字节关于框架学习","slug":"go/Dance_Frame","date":"2024-11-08T12:34:23.890Z","updated":"2025-05-11T07:20:03.565Z","comments":true,"path":"2024/11/08/go/Dance_Frame/","permalink":"https://whuichenggong.github.io/2024/11/08/go/Dance_Frame/","excerpt":"","text":"字节内部课程学习一.走进RPC框架1.基本概念本地函数调用 压栈弹出 RPC调用 网上购物 {（付款操作） 远程调用 中间隔着网路 不能用函数指针了 是两个进程 机器id找到函数运行 解决问题 1. 函数映射 数据转换成字节流 （客户端转换成字节流 传送给 服务端） 网络传输（高效稳定传输数据） } 过程：User本地调用 打包参数 -》 RPC -》 对端-》解压-》调用真正业务逻辑 然后在返回 整个流程 IDL文件（接口描述文件） Caller（调用段）和 生成代码 -》 encoder编码 -》字节流 -》打包传送给对端 好处 2.编解码层： 编解码层： 二进制编码 左侧是IDL中写的统一的 -》字节流 有额外的内存开销 多路复用：同一个链接内 可以有多个请求流通过 协议解析： 4.网络通信层： SCOEKT API （ip+端口） 一端关闭套接字 如果另一端如果尝试去读 可能就会返回（End Of File）也就是 EOF 在项目中我好像遇到过这个问题 用postman测试的时候返回了EOF错误和nil 网络库 二.RPC关键指标分析与企业实践稳定性 易用性 扩展性 观测性 高性能 稳定性： 过程：a调用b b调用c c如果响应慢 b就会一直等待 a也就超时了 a就会频繁调用b b堆积大量请求就会宕机 熔断起保护作用 稳定性：请求成功了率 1.均匀调用服务的每个节点 重试几次 备份请求： 左侧正常 1失败 2是重试请求 总时间 t1＋t2 ​ 右侧 t3 tct99（这个值 在这个时间内应该可以返回值）如果在时间内没返回 就发送2请求 总时间就是 t4 1.注册中间件 2.易用性： 自动生成代码工具 ： 减少重复性工作 3.扩展性 用户请求 经过中间件处理-》和远端交互 -》 也通过中间件处理-》服务器 4.观测性： 日志观察 监控面板qbs 链路跟踪（服务通过请求为什么超时了 耗费的时间是多少） linux的top工具类似原理 5.高性能： 高吞吐：在单位时间内尽可能多的处理更多请求 低延迟： 一次请求发出去延迟尽可能地低（重要） ​ 6. 本章总结： 字节实践： 组件 结构 远端交互层 网络库 代码生成工具 （最左侧） 为什么自研网络库？ gonet Netpoll 交互方式pingpang（一发一回） 编解码 应用层协议 优化： 你应该想这些是怎么实现的？ 三.走进HTTP协议1.再谈http协议HTTP 超文本传输协议 http协议将人话以计算机语言传输过去 123456789请求行：分隔 原数据包的字节数大空行我们想说的话下面是回复 上述功能代码： 处理流程: H1的不足 H2也没完全解决 UDP解决对头阻塞 四.HTTP框架实现1.分层设计的好处 高内聚 低耦合 易复用 高扩展性 应用层 中间件层 预处理 路由层 协议层 中间件设计： 洋葱模型 路由设计： map[string]handlers 静态路由有效 动态不太行 前缀匹配树构建路由： 啊啊啊啊：前两天刚看 7_days_golang 构建动态路由的方法 这里就讲解了 啊啊啊 参数路由： 协议层设计 网络层设计 性能修炼之道针对网络库的优化 netpoll （中大包性能高 时延低） go net（流式友好，小包性能高） 存下全部Header 拷贝身体 针对协议的优化 Headers 解析 找到Header Line边界 &#x2F;r&#x2F;n SIMD Sonic 五.微服务架构：单体架构 -》 垂直应用架构 -》 分布式架构 -》 SOA架构 -》 微服务架构 单体架构： 优势： 性能最高 冗余小 劣势： 1.debug困难 2.模块相互影响 3.模块 垂直应用架构： 优点： 业务独立开发维护 缺点 ： 存在冗余 分布式架构： SOA架构： 服务注册中心： 服务注册 劣势： 整个系统设计是中心化的 ​ 需要从上至下设计 ​ 重构困难 微服务架构： 开发效率高 但是运维难度大 安全性 服务： 相同逻辑 的 运行实体 实例 ： 每一个运行实体为一个实例 逻辑划分称一个（集群） 集群包含实例 有状态 无状态服务： 是否存储了可持续化数据 服务间通信： HTTP RPC 目标服务地址： hardcode 服务A调用服务B（指定一个目标服务地址会有什么问题？） ip地址不会固定 只有一个实例可以接受请求 别的接收不到 ip也是会变化的 如果用DNS域名来访问 DNS缓存机制： 导致延时 负载均衡问题：无法指定请求某个ip回应 不支持探活检查 域名无法配置端口 负载均衡算法 若要 下线某个实例： 流量会不会走到第三个实例上面 服务1 和 服务2 压力变大 可以在开启一个实例 统一网关入口 四层负载均衡租用了一台公网ip 现状 找一个物理机 ifconfig将网卡配上这个ip 起server监听即可 应用多 起多个server监听不同的端口 基于ip＋端口 基于某种算法 将报文转发给后端服务器 常见调度算法RR轮询： 加权RR轮询： 最小连接 五元组hash 一致性hash FULLNAT 纯用户态协议栈 无缓存 零拷贝 大页内存 （减少 cache miss） 7层负载均衡 NGINX： 最灵活的高性能Web 7层反向代理 网络接入实践与课程总结 ： 七层负载均衡 配置https访问","categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"}],"tags":[]},{"title":"发布博客出现的问题","slug":"github/github_actions","date":"2024-11-06T01:37:07.076Z","updated":"2025-05-11T07:11:39.544Z","comments":true,"path":"2024/11/06/github/github_actions/","permalink":"https://whuichenggong.github.io/2024/11/06/github/github_actions/","excerpt":"","text":"每一次用push推送到githubpage都会出现构建部署错误 我问了一下ai原因 这才有点明白到底是为什么 原因为什么会有这种差异？GitHub Pages 和 本地环境的差异： 在本地执行 hexo d 时，你的本地环境会根据 package.json 中的依赖来安装所有的主题和插件，确保所有必要的资源都存在。但是 GitHub Pages 仅仅依赖仓库中已经推送的文件（通常是 public&#x2F; 文件夹和 ._config.yml），它不会自动运行 npm、yarn 或 pnpm 来安装依赖。换句话说，GitHub Pages 并不会在部署过程中安装缺少的主题或插件。依赖没有正确推送： 你在本地运行 hexo d 时，可能已经正确地安装了 butterfly 主题，并且该主题存在于本地的 _config.yml 中和 node_modules 文件夹中。然而，在推送到 GitHub 上时，你没有将 node_modules 中的 butterfly 主题或相关配置文件推送到 GitHub 仓库。GitHub Pages 需要能够访问这些主题文件，而它不会在部署过程中下载和安装这些依赖。GitHub Pages 配置问题： 如果你直接使用 GitHub Pages 作为部署平台，GitHub 并不会自动安装你的 Hexo 依赖，因此它不能像本地环境一样找到 butterfly 主题。GitHub Pages 需要使用一个可以通过静态文件夹来部署的版本，而 Hexo 本地运行时通常会将主题内容放在 node_modules 中，这些内容并不会自动推送到 GitHub，除非你特别将它们包含在仓库中。 解决方法使用github-actions并且在google查找到的方法添加 .nojekyll文件 让github站点不适用jekyll 1234567891011121314151617181920212223242526272829name: Hexo Deployon: push: branches: - main # 监听主分支的推送jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Setup Node.js uses: actions/setup-node@v2 with: node-version: &#x27;16&#x27; - name: Install dependencies run: | npm install - name: Generate and Deploy run: | hexo generate hexo deploy env: HEXO_DEPLOY_PATH: $&#123;&#123; secrets.HEXO_DEPLOY_PATH &#125;&#125; # 设置部署路径 多看源码 基础真的很重要 多看官方文档能解决很多问题","categories":[{"name":"github","slug":"github","permalink":"https://whuichenggong.github.io/categories/github/"}],"tags":[]},{"title":"github参与开源应该做什么","slug":"github/github","date":"2024-11-05T12:34:20.687Z","updated":"2025-05-11T07:11:39.546Z","comments":true,"path":"2024/11/05/github/github/","permalink":"https://whuichenggong.github.io/2024/11/05/github/github/","excerpt":"","text":"第一次参与开源项目应该做些什么借鉴Moment老哥文档 https://juejin.cn/post/7354233858063925267 第一步forkfork到自己的仓库下 且选择fork所有分支 这样就可以有修改项目的权限通过Pull Request方式 commits合到上游项目 第二步克隆项目git clone … 第三步更新本地分支代码1234git remote add upstream &lt;原始仓库的URL&gt;git fetch upstreamgit checkout maingit rebase upstream/main 等等指令在此省略 详细的等到具体运用中再做增加 创建新的分支并在新的分支上作出修改 回到fork的仓库中找到pullRequestNewRequest并把自己更改的分支上传到作者的仓库也就完成了一次Request 写入你想更改的地方提交你的更改 开一个PR在完成 push 操作后，我们打开 GitHub，可以看到一个黄色的提示框，告诉我们可以开一个 Pull Request 了 参考： https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fxun082%2Fcreate-neat%2Fpull%2F83一定要参与一次实践，才懂得如何去做。只有错过了，才能保证下一次的完美运行。 最后希望自己早入加入开源大家庭中，加油！ 2024 11.5日","categories":[{"name":"github","slug":"github","permalink":"https://whuichenggong.github.io/categories/github/"}],"tags":[]},{"title":"北京之旅","slug":"生活/hello-world","date":"2024-11-04T08:44:58.056Z","updated":"2025-05-11T07:14:53.977Z","comments":true,"path":"2024/11/04/生活/hello-world/","permalink":"https://whuichenggong.github.io/2024/11/04/%E7%94%9F%E6%B4%BB/hello-world/","excerpt":"","text":"开源社在偶然一次发现中 开源社举办了第九届中国开源年会，我很是激动，心中迅速萌发了去北京参加的冲动并和小伙伴赵冰决定这周五来一次说走就走的旅行~~~ 到达北京在周六的早上到达会场 扫了入场的码 领到了活动给的一些礼品 7点多我俩就到达了会场，刚开始觉得平平无奇，后来直到大会开始，陆陆续续的大家都来到了会场，开源社的老哥，老姐们开始了自己的演讲，我发现这真的不是一个普通大会，很多人报着开源的理念 一直维持着开源社，让开源社越来越大虽然是第一次参加，但是我对于这种氛围是非常的喜欢，各位有着自己想法的人都在开源社散发光辉，有为抗癌人士专门发布app的小胰宝等其他的产品，这令我深受触动，把科技真真正正的融合到了生活当中，使人们都能享受科技带来的便捷！大会中的每一个人的演讲都令我感到激动！但是对我印象的最深刻的就是yihong0618这个id，伊洪老师的演讲令我眼前一亮心里一跳哈哈哈哈简直太爽啦！！！ yihong0618请大家自己去看伊洪老师的github，你真的能从中学到很多，在火车上我一直再看伊洪老师的github每一件事是写的那么的真诚，有很多我也感同身受，生活的迷茫原来真的不是自己才有，面临各种压力，各种抉择！做好自己。老师的仓库里也有非常多的实用的产品大家可以自己去看！！ [github] https://github.com/yihong0618 在伊洪老师的演讲中，令我觉得钦佩的是，每一天的记录自己，我太喜欢这种感觉了，发布到github上，我也便想向这么做在4日赶回来我便从网上学习搭建博客，坚持记录每一天 结语这次旅程，说走就走，哈哈哈，这才是大学生嘛，遇见了开源社的大家，我希望从今的每一天，慢慢的融入到开源社这个大家庭 -感谢冰哥陪我这次旅行 2024年11.4日","categories":[{"name":"生活","slug":"生活","permalink":"https://whuichenggong.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[]}],"categories":[{"name":"go","slug":"go","permalink":"https://whuichenggong.github.io/categories/go/"},{"name":"生活","slug":"生活","permalink":"https://whuichenggong.github.io/categories/%E7%94%9F%E6%B4%BB/"},{"name":"文章分享","slug":"文章分享","permalink":"https://whuichenggong.github.io/categories/%E6%96%87%E7%AB%A0%E5%88%86%E4%BA%AB/"},{"name":"书后心得","slug":"书后心得","permalink":"https://whuichenggong.github.io/categories/%E4%B9%A6%E5%90%8E%E5%BF%83%E5%BE%97/"},{"name":"计算机系统","slug":"计算机系统","permalink":"https://whuichenggong.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"},{"name":"技术分享","slug":"技术分享","permalink":"https://whuichenggong.github.io/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"},{"name":"backend","slug":"backend","permalink":"https://whuichenggong.github.io/categories/backend/"},{"name":"困惑","slug":"困惑","permalink":"https://whuichenggong.github.io/categories/%E5%9B%B0%E6%83%91/"},{"name":"项目","slug":"项目","permalink":"https://whuichenggong.github.io/categories/%E9%A1%B9%E7%9B%AE/"},{"name":"计算机系统 只能由一个","slug":"计算机系统-只能由一个","permalink":"https://whuichenggong.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F-%E5%8F%AA%E8%83%BD%E7%94%B1%E4%B8%80%E4%B8%AA/"},{"name":"算法","slug":"算法","permalink":"https://whuichenggong.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"github","slug":"github","permalink":"https://whuichenggong.github.io/categories/github/"}],"tags":[{"name":"Go语法","slug":"Go语法","permalink":"https://whuichenggong.github.io/tags/Go%E8%AF%AD%E6%B3%95/"},{"name":"计算机系统","slug":"计算机系统","permalink":"https://whuichenggong.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"}]}